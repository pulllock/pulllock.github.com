<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Dubbo启动以及服务调用的过程总结]]></title>
      <url>%2F2020%2F03%2F20%2FDubbo%E5%90%AF%E5%8A%A8%E4%BB%A5%E5%8F%8A%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8%E7%9A%84%E8%BF%87%E7%A8%8B%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[服务暴露过程、服务引用过程、服务调用过程、消费者调用底层通信过程、提供者接受请求底层通信过程简单总结。 服务暴露过程服务暴露、服务提供者初始化 服务转化成Invoker -&gt; Invoker转化成Exporter -&gt; Transporter使用具体的Server启动服务监听端口 -&gt; 使用具体的Registry将服务注册到注册中心。 开始暴露服务，调用ServiceConfig的export方法导出服务，ServiceConfig使用ProxyFactory将我们要暴露的服务转化成一个Invoker。服务转化成Invoker后，需要通过具体的协议（比如Dubbo）将Invoker转化成Exporter（比如DubboExporter）。Exporter中使用Transporter来初始化一个具体的Server（比如Netty），并绑定服务端口，此时服务就被暴露出去了。服务暴露之后会调用具体的Registry（比如Zookeeper）将服务注册到注册中心去。 引用服务过程引用服务、消费者初始化、消费者订阅服务 服务订阅 -&gt; 服务转化成Invoker -&gt; Transporter使用具体的Client启动服务准备连接 -&gt; 使用Cluster并继续初始化Invoker -&gt; 封装成一个代理返回。 开始引用服务，调用ReferenceConfig的get方法引用服务，ReferenceConfig调用RegistryProtocol并使用具体的Registry（比如Zookeeper）来订阅服务，Registry会通知Directory开始引用服务（异步），也就是将要引用的服务转化成一个Invoker。Directory会使用具体的Protocol（如Dubbo）将引用的服务转化成一个Invoker。Invoker中使用Transporter来初始化一个具体的Client（比如Netty）用来准备和服务端提供者进行通信。RegistryProtocol调用Cluster的合并方法来初始化Invoker，然后ReferenceConfig在Invoker生成之后返回一个服务的代理。 服务调用过程服务调用过程分为两部分：服务消费者调用服务和服务提供者接受服务请求。 服务消费者调用服务获取到代理 -&gt; 调用Invoker -&gt; Exchange调用远程服务 服务开始调用，首先获取到在服务引用过程中生成的代理，获取到代理后先执行一些过滤器链，比如：缓存、mock等等。接下来会根据Cluster来选择一个具体的Invoker，比如：failover、failsave、failfast、failback、forking、broadcast等，同时使用Directory从Registry中获取所有的invokers，然后使用LoadBalance（random、roundRobin、leastActive、consistentHash）选中具体调用的服务。选中服务之后会先执行过滤器链，再使用具体的Protocol（比如DubboProtocol）调用Transporter并使用具体的Client（比如Netty）来进行服务的调用。发送的请求会进行Codec编码和Serialzation序列化。 服务提供者接受服务请求服务提供者接收到请求后，会进行反序列化和Decodec解码，然后从线程池中获取一个线程交给具体的Server（比如Netty)进行处理，然后会交给具体的Protocol（比如Dubbo）来根据参数获取具体的Exporter，继续执行一系列的过滤器链，然后使用ProxyFactory来获取具体的Invoker（比如Dubbo），Invoker就会调用真正的服务实现类，然后将结果返回。 底层通信过程服务消费者发送请求底层通信过程和服务提供者接受服务请求底层通信过程 稍后添加]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo架构简单理解]]></title>
      <url>%2F2020%2F03%2F19%2FDubbo%E6%9E%B6%E6%9E%84%E7%AE%80%E5%8D%95%E7%90%86%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[分析总结一下Dubbo的架构，通过对Dubbo、RocketMQ、Tair等架构的类比，从整体上来理解一般分布式框架、应用的组成。 Dubbo架构Dubbo在日常开发中我们应该是接触的最多的一个框架，它的组成我们最熟悉的应该就是三部分：Provider、Consumer、Registry。以下是官方的架构图： 使用的时候，第一步我们要启动注册中心。注册中心用来注册服务、发现服务，充当着整个系统的中心点，提供指挥或者导航的作用。 第二步，启动服务提供者，服务提供者启动后会把自己注册到注册中心，告诉注册中心我可以使用了。这里服务提供者是把自己告诉给注册中心，而不是服务使用者，服务提供者不知道服务使用者是谁，也不知道服务使用者在哪里，也不知道有多少服务使用者，但是我就把自己告诉注册中心，剩下的你们自己决定怎么使用。 试想一下如果服务提供者要把自己亲自告诉服务使用者，那会是怎样的场景。 第三步，启动服务消费者，服务消费者启动后会向注册中心订阅服务，也就是向注册中心要自己需要的服务，找到需要的服务后，就可以调用服务了。 这根我们现实生活中的很多场景都类似，我们需要一个中心点，比如交通指挥中心、电力指挥中心，甚至于社区中心都可以类比。这种中心实际上还是以前的中心化管理方式，只不过我们可以让中心复制出来几个，让一个或者几个中心对外服务，其他的作为备份，用来做高可用方案，保证任一时刻中心都能对外服务。 Tair架构我们再看下Tair的架构，最重要的也是三个：ConfigServer、DataServer、Client。下面是架构图： 其中ConfigServer就是类似传统应用系统的中心节点，DataServer会保持和ConfigServer的心跳，ConfigServer知道DataServer的信息。Client会到ConfigServer中获取DataServer信息，然后才能知道要去哪里找数据。 同样ConfigServer也是采用主备方案来保证高可用，如果从宏观上看其实它还是一个中心节点，没有变。 RocketMQ架构接下来看看RocketMQ的架构设计，它由四部分组成：NameServer、Broker、Producer、Consumer，以下是架构图： 这里NameServer用来管理Broker，Producer和Consumer从NameServer中获取Broker的信息，整体的逻辑和上面Dubbo以及Tair类似。NameServer这次不是采用主备这种带有等级意义的关系，而是采用平等关系，Broker向所有的NameServer注册，而Producer和Consumer则选择其中一台NameServer进行通信，因为NameServer上存储的信息都一样。 这样宏观看下来其实NameServer还是中心，只不过它也是通过同时部署多台服务器来保证高可用。 Zookeeper另外像zookeeper我们也可以理解成类似的，只不过zookeeper的中心可认为是动态中心，它的Leader角色可以进行选举更换。 小结这样总结一下，我们使用的其实还是以前的中心化管理方式，并没有变化，变化的是我们让中心保持高可用，不再是传统意义上的单点中心。更一般的场景：中心、用户、服务商。成千上万的服务商不可能直接和上亿的用户直接打交道，否则一团乱麻，但是中间可以通过一个中心来打交道，这样就会更加有秩序了。 以上仅仅是个人的理解和观点，不对或者不恰当的地方还请指出。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring中扩展点汇总]]></title>
      <url>%2F2020%2F03%2F19%2FSpring%E4%B8%AD%E6%89%A9%E5%B1%95%E7%82%B9%E6%B1%87%E6%80%BB%2F</url>
      <content type="text"><![CDATA[通过阅读Spring的源码，按照自己的理解，汇总了一下Spring中常用的扩展点，可能还有遗漏或者理解不对的地方。直接使用processon画了一张图，按照容器的初始化以及bean的实例化和初始化等过程来描述。 这里是源文件SpringExtension.pos，可以导入processon修改。 下面是导出的图片：]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo中SPI源码解析]]></title>
      <url>%2F2019%2F02%2F20%2FDubbo%E4%B8%ADSPI%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[从两个示例代码，介绍dubbo的SPI的使用以及相关源码分析，分析了获取扩展实现和获取自适应扩展点实现的源码，最后简单说了下ExtensionFactory的流程，看完就可以理解为什么dubbo是自包含的了。从上往下看，再回头看，应该能看明白，文章比较长，希望能耐心读下去。如果有错误的地方希望能指出来，我也理解不是太完整或者表述不是太明白。 ExtensionLoader使用以及简单流程分析假设有这样一段示例代码： 123456public static void main(String[] args) &#123; ExtensionLoader&lt;Protocol&gt; extensionLoader = ExtensionLoader.getExtensionLoader(Protocol.class); Protocol dubboProtocol = extensionLoader.getExtension("dubbo"); System.out.println(dubboProtocol.getDefaultPort()); &#125; 我们先通过ExtensionLoader.getExtensionLoader(Protocol.class)获取ExtensionLoader实例，然后通过getExtension(&quot;dubbo&quot;)获取到具体的Protocol实现DubboProtocol。 首先看下获取ExtensionLoader实例的过程： 各种校验。 从缓存中获取指定类型的ExtensionLoader实例。 如果缓存中不存在的话，就新建一个ExtensionLoader实例，并放入缓存。 返回ExtensionLoader实例。 这部分源码如下： 1234567891011121314151617181920212223242526public static &lt;T&gt; ExtensionLoader&lt;T&gt; getExtensionLoader(Class&lt;T&gt; type) &#123; // 扩展点类型不能为空 if (type == null) throw new IllegalArgumentException("Extension type == null"); // 扩展点类型只能是接口类型的 if(!type.isInterface()) &#123; throw new IllegalArgumentException("Extension type(" + type + ") is not interface!"); &#125; // 没有添加@SPI注解 if(!withExtensionAnnotation(type)) &#123; throw new IllegalArgumentException("Extension type(" + type + ") is not extension, because WITHOUT @" + SPI.class.getSimpleName() + " Annotation!"); &#125; // 先从缓存中获取指定类型的ExtensionLoader ExtensionLoader&lt;T&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); // 缓存中不存在 if (loader == null) &#123; /** * 创建一个新的ExtensionLoader实例，放到缓存中去 * 对于每一个扩展，dubbo中只有个对应的ExtensionLoader实例 */ EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader&lt;T&gt;(type)); loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); &#125; return loader;&#125; ExtensionLoader缓存前面的校验可以参考注释，这里先说下缓存EXTENSION_LOADERS： 1private static final ConcurrentMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt; EXTENSION_LOADERS = new ConcurrentHashMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt;(); 可以看到每个SPI扩展的ExtensionLoader的实例只有一个，缓存的key就是具体SPI接口类型，比如com.alibaba.dubbo.rpc.Protocol作为key。 ExtensionLoader实例化new ExtensionLoader&lt;T&gt;(type)这里做了什么？ 12345678private ExtensionLoader(Class&lt;?&gt; type) &#123; this.type = type; objectFactory = ( type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension() );&#125; 上面示例代码执行后，第一次到这里，type是com.alibaba.dubbo.rpc.Protocol，所以这里会先执行ExtensionLoader.getExtensionLoader(ExtensionFactory.class)，然后执行getAdaptiveExtension()。 也就是说如果是第一次执行获取Protocol类型的ExtensionLoader的实例的话，会先获取ExtensionFactory类型的ExtensionLoader实例。为什么要先获取ExtensionFactory类型的ExtensionLoader的实例呢？因为ExtensionFactory是用来生成扩展点具体实现的工厂，这里暂时先到这里，后面会再说ExtensionFactory相关的东西。 获取完了ExtensionFactory类型的ExtensionLoader后，紧接着调用getAdaptiveExtension()方法来获取一个自适应的ExtensionFactory实例，获取自适应AdaptiveExtensionFactory实例的原因是ExtensionFactory会有多个实现，这样可以在运行时来决定调用哪个具体实现，而不是直接写死使用哪个具体实现。 ExtensionFactory的具体实现有三个： AdaptiveExtensionFactory SpiExtensionFactory SpringExtensionFactory 其中AdaptiveExtensionFactory注解了@Adaptive注解，是ExtensionFactory这个SPI接口的自适应实现，如果在运行时需要获取一个ExtensionFactory的实现时，会调用AdaptiveExtensionFactory来进行动态获取。 说明一下，一个扩展点最多只能有一个自适应实现，也就是一个扩展点的具体实现类最多只能有一个可以在类级别上注解@Adaptive。如果一个扩展点没有任何一个实现在类级别上注解@Adaptive，那么dubbo会在运行时动态生成一个自适应实现类，比如Protocol的具体实现类就没有任何一个有在类级别上注解了@Adaptive，dubbo会自动生成一个名字是Protocol$Adpative的自适应实现类。 使用ExtensionLoader获取扩展点实现上面的步骤完成了获取Protocol类型的ExtensionLoader的实例，同时也完成了ExtensionFactory类型的ExtensionLoader实例的加载，同时也生成了ExtensionFactory的自适应实现，接下来继续往下走： 1Protocol dubboProtocol = extensionLoader.getExtension("dubbo"); 获取了Protocol类型的ExtensionLoader实例后，就可以根据名字来加载具体的实现类了，Protocol的具体实现类有： DubboProtocol HessianProtocol HttpProtocol ThriftProtocol InjvmProtocol RmiProtocol WebServiceProtocol RegistryProtocol RedisProtocol MemcachedProtocol 一些Wrapper类 可以看到Protocol有很多具体的实现，根据使用协议的不同，可以动态选择具体使用哪一个Protocol实现。 继续看getExtension()方法： 123456789101112131415161718192021222324252627public T getExtension(String name) &#123; if (name == null || name.length() == 0) throw new IllegalArgumentException("Extension name == null"); // 获取默认实现 if ("true".equals(name)) &#123; return getDefaultExtension(); &#125; // 从缓存获取 Holder&lt;Object&gt; holder = cachedInstances.get(name); if (holder == null) &#123; cachedInstances.putIfAbsent(name, new Holder&lt;Object&gt;()); holder = cachedInstances.get(name); &#125; Object instance = holder.get(); if (instance == null) &#123; synchronized (holder) &#123; instance = holder.get(); if (instance == null) &#123; // 缓存不存在，创建实例 instance = createExtension(name); // 加入缓存 holder.set(instance); &#125; &#125; &#125; return (T) instance;&#125; 该方法是根据指定的名字来获取具体的扩展点的实现的实例，比如我们这里传的name是dubbo，就会获取DubboProtocol的实例，具体步骤如下： 校验 如果name是true，就获取默认扩展点的实现实例 从缓存中获取扩展点实现实例 如果缓存中不存在，就根据name创建具体的扩展点实现实例 返回name对应的具体扩展点实现的实例 扩展点实现的实例缓存获取默认扩展点实现实例暂时不说，先看下cachedInstances缓存： 1private final ConcurrentMap&lt;String, Holder&lt;Object&gt;&gt; cachedInstances = new ConcurrentHashMap&lt;String, Holder&lt;Object&gt;&gt;(); 这里缓存了扩展点具体实现的实例，key是扩展点的名字，比如DubboProtocol的实例，key就是dubbo，value是DubboProtocol的实例，Holder中持有DubboProtocol的实例。 创建扩展点实现实例接下来看根据name创建具体扩展点实现实例的方法createExtension(name)方法，该方法的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647private T createExtension(String name) &#123; /** * getExtensionClasses加载当前扩展点的所有实现 * 比如： * 我们在使用ExtensionLoader.getExtensionLoader(Protocol.class) * 获取Protocol的ExtensionLoader的时候，就已经设置了当前ExtensionLoader * 的类型是Protocol的，所以这里获取的时候就是Protocol的所有实现。 * * 获取到所有的实现之后，getExtensionClasses()返回的是Map&lt;String, Class&lt;?&gt;&gt; */ Class&lt;?&gt; clazz = getExtensionClasses().get(name); if (clazz == null) &#123; throw findException(name); &#125; try &#123; /** * 从缓存中获取已经创建的扩展点的实现的实例 * 如果还没有，就根据Class通过反射来创建具体的实例， * 并放到缓存中去 */ T instance = (T) EXTENSION_INSTANCES.get(clazz); if (instance == null) &#123; EXTENSION_INSTANCES.putIfAbsent(clazz, (T) clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); &#125; /** * 向实例中注入依赖的扩展 * 如果一个扩展点A依赖了其他的扩展点B，并且有setter方法 * 就会执行将扩展点B注入扩展点A的操作 */ injectExtension(instance); /** * 如果扩展点有包装类，将扩展点进行包装 * 包装后如果也依赖了其他扩展点，也需要注入其他扩展点 */ Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; if (wrapperClasses != null &amp;&amp; wrapperClasses.size() &gt; 0) &#123; for (Class&lt;?&gt; wrapperClass : wrapperClasses) &#123; instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); &#125; &#125; return instance; &#125; catch (Throwable t) &#123; throw new IllegalStateException(&quot;Extension instance(name: &quot; + name + &quot;, class: &quot; + type + &quot;) could not be instantiated: &quot; + t.getMessage(), t); &#125;&#125; 该方法根据扩展点的名字来创建具体扩展点实现的实例，具体步骤如下： 通过getExtensionClasses()方法将当前扩展点的所有的实现类进行加载，如果是@Adaptive注解的自适应实现类，则放到cachedAdaptiveClass缓存中；如果是包装类，则放到cachedWrapperCalsses缓存中。经过这一步，扩展点的所有实现都已经解析加载。 根据名字获取到具体的某一个扩展点实现类，并去EXTENSION_INSTANCES缓存中查询是不是有实例，如果没有的话，就使用反射创建一个实例。 如果该实例中依赖了其他的扩展点（需要有setter方法），需要将依赖的扩展点进行注入。 如果扩展点有包装类，则将扩展点进行包装，如果包装后，也依赖了其他的扩展点（需要有setter方法），需要将依赖的扩展点进行注入。 返回注入和包装后的扩展点实现的实例，在我们的这个例子中返回的不是DubboProtocol实例了，而是经过了ProtocolFilterWrapper和ProtocolListenerWrapper包装后的实例。 总体的流程就算说完了，已经获取到了名字为dubbo的Protocol的实现的实例，接下来的执行最后一行代码，得到结果： 1System.out.println(dubboProtocol.getDefaultPort()); 加载扩展点实现类的Class接下来我们看看getExtensionClasses()方法具体做了什么，该方法是用来加载当前扩展点的所有实现的class的，具体代码如下： 123456789101112131415161718192021222324private Map&lt;String, Class&lt;?&gt;&gt; getExtensionClasses() &#123; /** * 先从缓存中获取，不存在的话就调用loadExtensionClasses进行加载 * cachedClasses缓存中存储了当前扩展点所有的实现类 */ Map&lt;String, Class&lt;?&gt;&gt; classes = cachedClasses.get(); if (classes == null) &#123; synchronized (cachedClasses) &#123; classes = cachedClasses.get(); if (classes == null) &#123; /** * 如果没有加载Extension的实现，进行扫描加载，完成后缓存起来 * 每个扩展点，其实现的加载只会执行一次 * 例如，如果Protocol的某个具体实现加载出错了，没有放到缓存中去 * 后面再使用，也不会再进行加载了。 */ classes = loadExtensionClasses(); // 缓存起来 cachedClasses.set(classes); &#125; &#125; &#125; return classes;&#125; 这里也只是尝试从缓存中获取，如果缓存中不存在的话，就进行具体的加载逻辑。但是这里有个点要注意，一个扩展点的的实现类加载只会执行一次。 继续往下走就是真正的加载扩展点的实现逻辑了，代码如下： 12345678910111213141516171819202122232425private Map&lt;String, Class&lt;?&gt;&gt; loadExtensionClasses() &#123; final SPI defaultAnnotation = type.getAnnotation(SPI.class); if(defaultAnnotation != null) &#123; // 当前扩展点的默认实现名字，如果有的话进行缓存 String value = defaultAnnotation.value(); if(value != null &amp;&amp; (value = value.trim()).length() &gt; 0) &#123; String[] names = NAME_SEPARATOR.split(value); if(names.length &gt; 1) &#123; throw new IllegalStateException("more than 1 default extension name on extension " + type.getName() + ": " + Arrays.toString(names)); &#125; if(names.length == 1) cachedDefaultName = names[0]; &#125; &#125; // 从配置文件中加载扩展实现类 Map&lt;String, Class&lt;?&gt;&gt; extensionClasses = new HashMap&lt;String, Class&lt;?&gt;&gt;(); // 从META-INF/dubbo/internal目录下加载 loadFile(extensionClasses, DUBBO_INTERNAL_DIRECTORY); // 从META-INF/dubbo/目录下加载 loadFile(extensionClasses, DUBBO_DIRECTORY); // 从META-INF/services/下加载 loadFile(extensionClasses, SERVICES_DIRECTORY); return extensionClasses;&#125; 这里面逻辑也挺简单的，先获取扩展点的默认名字，如果有的话进行缓存；然后就从配置文件中加载具体的实现类了，加载的位置有三个，请参照代码里的注释。 具体的从配置文件中加载的代码，就不在贴出来了，太长了。说下大概的逻辑： 组装配置文件名字，加载配置文件，遍历文件中每一行进行处理。 加载配置文件中配置的实现类。 如果是注解了@Adaptive注解的实现类，加入到cachedAdaptiveClass缓存中。 如果是包装类型的实现类，加入到cachedWrapperClasses缓存中。 如果是除了上面两种的类，放到extensionClasses这个map中，用于在上层返回。 扩展点依赖注入我们在返回上面，还又一点没说，就是依赖注入的功能injectExtension的代码： 12345678910111213141516171819202122232425262728293031323334353637private T injectExtension(T instance) &#123; try &#123; // 在获取第一个扩展点的ExtensionLoader的实例的时候，objectFactory就被实例化了，是AdaptiveExtensionFactory if (objectFactory != null) &#123; // 遍历要注入的实例的方法 for (Method method : instance.getClass().getMethods()) &#123; // 只处理set方法，比如setA，就是要把A注入到instance中 if (method.getName().startsWith("set") &amp;&amp; method.getParameterTypes().length == 1 &amp;&amp; Modifier.isPublic(method.getModifiers())) &#123; // set方法参数类型 Class&lt;?&gt; pt = method.getParameterTypes()[0]; try &#123; // setter方法对应的属性名，也就是扩展点接口名称 String property = method.getName().length() &gt; 3 ? method.getName().substring(3, 4).toLowerCase() + method.getName().substring(4) : ""; /** * objectFactory是AdaptiveExtensionFactory实例 * 比如这里的pt是com.alibaba.dubbo.rpc.Protocol，property是protocol * objectFactory就会根据这两个参数去获取Protocol对应的扩展实现的实例 */ Object object = objectFactory.getExtension(pt, property); // 获取到了setter方法的参数的实现，可以进行注入 if (object != null) &#123; method.invoke(instance, object); &#125; &#125; catch (Exception e) &#123; logger.error("fail to inject via method " + method.getName() + " of interface " + type.getName() + ": " + e.getMessage(), e); &#125; &#125; &#125; &#125; &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; return instance;&#125; 依赖注入的代码也很简单，就是实例化要注入的类，然后反射调用set方法注入实例中去。 自适应扩展点使用到这里，使用指定名称加载扩展点实现的流程就分析完了，但是这种直接指定扩展点名字的方式却不是我们主要使用的方式。可以想象一下，dubbo是可以配置多协议的，也就是可以同时配置比如dubbo、rmi等协议。如果我们使用了多协议的话，那dubbo是怎么做的呢？我们可以想到最简单的方法就是有一个转发器，用来根据实际请求中配置的协议来使用不同的实现来处理，下面可以写个伪代码： 12345678910public class ProtocolDispatcher implements Protocol &#123; public void refer(String name) &#123; if (name.equals("dubbo")) &#123; Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getExtension("dubbo"); &#125; else if(name.equals("rmi")) &#123; Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getExtension("rmi"); &#125; &#125;&#125; 实际上dubbo中没有这样的代码，但实际上也差不多类似这样的方式来处理的，我们看下实际在dubbo中的使用方式： 1private static final Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); 可以看到第一步还是先获取Protocol类型的ExtensionLoader的实例，这个过程跟最上面的获取ExtensionLoader实例的过程是一样的，接下来这一步getAdaptiveExtension()就跟我们之前的示例不一样了，这是获取自适应扩展的方法。 自适应扩展是不是很熟悉，上面我们也说过自适应，可以回头先去看下大概情况。首先说下获取自适应扩展是干嘛的？其实就是做到上面那个伪代码的转发器功能。 自适应扩展点动态生成的代码当调用了上面getAdaptiveExtension()方法后，dubbo会动态生成如下代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.alibaba.dubbo.rpc;import com.alibaba.dubbo.common.extension.ExtensionLoader;public class Protocol$Adpative implements com.alibaba.dubbo.rpc.Protocol &#123; public void destroy() &#123; throw new UnsupportedOperationException( "method public abstract void com.alibaba.dubbo.rpc.Protocol.destroy() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!" ); &#125; public int getDefaultPort() &#123; throw new UnsupportedOperationException( "method public abstract int com.alibaba.dubbo.rpc.Protocol.getDefaultPort() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!" ); &#125; public com.alibaba.dubbo.rpc.Exporter export(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker &#123; if (arg0 == null) throw new IllegalArgumentException("com.alibaba.dubbo.rpc.Invoker argument == null"); if (arg0.getUrl() == null) throw new IllegalArgumentException("com.alibaba.dubbo.rpc.Invoker argument getUrl() == null"); com.alibaba.dubbo.common.URL url = arg0.getUrl(); String extName = (url.getProtocol() == null ? "dubbo" : url.getProtocol()); if (extName == null) throw new IllegalStateException( "Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(" + url.toString() + ") use keys([protocol])" ); com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol) ExtensionLoader .getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class) .getExtension(extName); return extension.export(arg0); &#125; public com.alibaba.dubbo.rpc.Invoker refer(java.lang.Class arg0, com.alibaba.dubbo.common.URL arg1) throws java.lang.Class &#123; if (arg1 == null) throw new IllegalArgumentException("url == null"); com.alibaba.dubbo.common.URL url = arg1; String extName = (url.getProtocol() == null ? "dubbo" : url.getProtocol()); if (extName == null) throw new IllegalStateException( "Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(" + url.toString() + ") use keys([protocol])" ); com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol) ExtensionLoader .getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class) .getExtension(extName); return extension.refer(arg0, arg1); &#125;&#125; 当我们调用protocol.xxxx()方法的时候，其实就是调用动态生成的Protocol$Adaptive这个类的方法，这里面的逻辑其还是就跟我们的伪代码差不多了，根据url中传入的Protocol名字，通过getExtension(extName)方法获取实际的扩展点实现实例。 自适应扩展点的获取接下来就看下获取自适应扩展的源码： 1234567891011121314151617181920212223242526272829public T getAdaptiveExtension() &#123; // 先从自适应实例缓存中查找实例对象 Object instance = cachedAdaptiveInstance.get(); // 缓存中不存在 if (instance == null) &#123; if(createAdaptiveInstanceError == null) &#123; synchronized (cachedAdaptiveInstance) &#123; // 获取锁之后再检查一次缓存中是不是已经存在 instance = cachedAdaptiveInstance.get(); if (instance == null) &#123; try &#123; // 缓存中没有，就创建新的AdaptiveExtension实例 instance = createAdaptiveExtension(); // 新实例加入缓存 cachedAdaptiveInstance.set(instance); &#125; catch (Throwable t) &#123; createAdaptiveInstanceError = t; throw new IllegalStateException("fail to create adaptive instance: " + t.toString(), t); &#125; &#125; &#125; &#125; else &#123; throw new IllegalStateException("fail to create adaptive instance: " + createAdaptiveInstanceError.toString(), createAdaptiveInstanceError); &#125; &#125; return (T) instance;&#125; 这边还是老套路，先从缓存中获取，如果缓存中不存在，就创建自适应扩展实例，继续看createAdaptiveExtension()方法： 123456789101112private T createAdaptiveExtension() &#123; try &#123; /** * 先通过getAdaptiveExtensionClass获取自适应扩展类的Class * 然后通过反射获取实例 * 最后如果自适应扩展依赖了其他的扩展点，就进行扩展点注入 */ return injectExtension((T) getAdaptiveExtensionClass().newInstance()); &#125; catch (Exception e) &#123; throw new IllegalStateException("Can not create adaptive extenstion " + type + ", cause: " + e.getMessage(), e); &#125;&#125; 这里的逻辑跟createExtension()差不多，大概步骤： 先通过getAdaptiveExtensionClass()方法获取自适应扩展类的Class 然后通过反射获取实例 最后如果自适应扩展类实例依赖了其他的扩展点，就进行扩展点的注入 获取自适应扩展点类的Class首先看下获取自适应扩展类的Class方法： 12345678910111213141516171819202122232425262728293031323334private Class&lt;?&gt; getAdaptiveExtensionClass() &#123; /** * getExtensionClasses加载当前扩展点的所有实现 * 比如： * 我们在使用ExtensionLoader.getExtensionLoader(Protocol.class) * 获取Protocol的ExtensionLoader的时候，就已经设置了当前ExtensionLoader * 的类型是Protocol的，所以这里获取的时候就是Protocol的所有实现。 * * 获取到所有的实现之后，getExtensionClasses()返回的是Map&lt;String, Class&lt;?&gt;&gt; * * 另外需要说的是，如果扩展点的实现注解了类级别的@Adaptive注解， * 这些实现的Class加载完后会赋值给cachedAdaptiveClass缓存。如果扩展点的实现 * 是包装类，这些实现的Class加载完后会放到cachedWrapperClasses缓存中。 * 其他的正常的扩展点的实现都会放到Map&lt;String, Class&lt;?&gt;&gt;中返回。 * * 目前只有AdaptiveExtensionFactory和AdaptiveCompiler两个实现类是被注解了@Adaptive * 也就是说这两个就是自适应扩展，如果要加载ExtensionFactory和Compiler的自适应扩展 * 不需要使用自动生成代码，而是直接使用两个实现类就可以了。 * 其他的扩展点如果想要获取自适应扩展实现，就需要继续往下走，使用生成的Xxx$Adaptive代码。 * * 一个扩展点有且只有一个自适应扩展点，要么是内置的两个AdaptiveExtensionFactory和AdaptiveCompiler， * 要么是生成的Xxx$Adaptive */ getExtensionClasses(); /** * 自适应扩展实现，在上面一步加载的时候，就会被加载缓存起来 * 只会执行一次，后面再获取的时候，就是获取缓存起来的这个。 */ if (cachedAdaptiveClass != null) &#123; return cachedAdaptiveClass; &#125; // 没有缓存自适应扩展实现，就动态创建一个 return cachedAdaptiveClass = createAdaptiveExtensionClass();&#125; 获取自适应扩展类的过程参考上面代码的注释即可，继续往下说创建自适应扩展类的方法createAdaptiveExtensionClass()： 12345678910111213private Class&lt;?&gt; createAdaptiveExtensionClass() &#123; /** * 根据具体的接口来生成自适应扩展类的代码 * 比如Protocol就会生成Protocol$Adaptive为名字的类的代码 */ String code = createAdaptiveExtensionClassCode(); // 获取类加载器 ClassLoader classLoader = findClassLoader(); // 获取Compiler的自适应扩展，获取到的是AdaptiveCompiler实例 com.alibaba.dubbo.common.compiler.Compiler compiler = ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.common.compiler.Compiler.class).getAdaptiveExtension(); // 如果我们没有指定名字，默认使用javassist return compiler.compile(code, classLoader);&#125; 这里大概的步骤是： 生成自适应扩展类的代码。 获取类加载器。 获取自适应的Compiler的扩展实现，获取到的AdaptiveCompiler实例，这个在上面已经说过了。 最后使用具体的Compiler进行生成代码的编译。 这里只看第一步，生成自适应扩展类的代码这步，这里代码有点长，不在此贴出来了，参考我的github上ExtensionLoader的源码注释ExtensionLoader.java。 @Adaptive注解这里说下@Adaptive注解，有两种地方使用这个注解： 使用在实现类上 使用在接口的方法上 这两种不能重复使用。如果用在实现类上，一个扩展点的实现类有且只能有一个类使用此注解，比如ExtensionFactory的实现类AdaptiveExtensionFactory使用了此注解，这个类本身就是一个自适应扩展类了；如果用在接口的方法上，表示dubbo框架会在生成该接口的自适应扩展类的时候，生成该方法的代码，如果方法没有添加此注解，则生成抛出不支持异常的代码。 ExtensionFactory到这里获取扩展和获取自适应扩展就已经说完了，接下来可以把最上面留下的ExtensionFactory相关的加载流程说下了，每个ExtensionLoader实例中都会有一个objectFactory实例，而objectFactory实例的赋值都是在ExtensionLoader的构造方法中： 123456789101112131415private ExtensionLoader(Class&lt;?&gt; type) &#123; this.type = type; /** * 对于扩展类型是ExtensionFactory的，设置为null * getAdaptiveExtension方法获取一个运行时自适应的扩展类型 * 每个Extension只能有一个@Adaptive类型的实现，如果么有，dubbo会自动生成一个类 * objectFactory是一个ExtensionFactory类型的属性，主要用于加载扩展的实现 */ objectFactory = ( type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension() );&#125; 可以看到ExtensionFactory的实例获取也是通过扩展点自适应来获取到的，获取到的实例是AdaptiveExtensionFactory。而在AdaptiveExtensionFactory实例化的时候，会通过SPI机制加载所有的ExtensionFactory的实现： 123456789public AdaptiveExtensionFactory() &#123; ExtensionLoader&lt;ExtensionFactory&gt; loader = ExtensionLoader.getExtensionLoader(ExtensionFactory.class); List&lt;ExtensionFactory&gt; list = new ArrayList&lt;ExtensionFactory&gt;(); for (String name : loader.getSupportedExtensions()) &#123; // 保存所有ExtensionFactor y的实现 list.add(loader.getExtension(name)); &#125; factories = Collections.unmodifiableList(list);&#125; 使用objectFactory获取扩展的时候，是调用AdaptiveExtensionFactory的getExtension方法，该方法会遍历所有的ExtensionFactory的实现的getExtension方法： 1234567891011public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) &#123; // 依次遍历各个ExtensionFactory实现的getExtension方法 // 找到Extension后立即返回，没找到返回null for (ExtensionFactory factory : factories) &#123; T extension = factory.getExtension(type, name); if (extension != null) &#123; return extension; &#125; &#125; return null;&#125; 共两种实现SpiExtensionFactory和SpringExtensionFactory，如果在任何一个实现中找到了扩展点实现，就返回结束了。 dubbo是自包含的，这个概念通过上面的解析也应该不难理解了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ArrayList的初始容量现在为0，不再是10了]]></title>
      <url>%2F2018%2F10%2F19%2FArrayList%E7%9A%84%E5%88%9D%E5%A7%8B%E5%AE%B9%E9%87%8F%E7%8E%B0%E5%9C%A8%E4%B8%BA0%EF%BC%8C%E4%B8%8D%E5%86%8D%E6%98%AF10%E4%BA%86%2F</url>
      <content type="text"><![CDATA[前言一直记得ArrayList的初始容量大小是10，今天再次看ArrayList的源码（版本：Jdk 7u80）时发现在构造函数的注释上写着初始化容量是10，但是构造函数中却没有指定初始容量，仅仅初始化了一个空的数组。应该是不知道在哪个版本中已经修改了，我却还记着之前从别人口里得来的一句话：初始容量是10。实际上初始容量已经是0了，写出来分享下，有错的地方烦请指出来，说的不一定对。 测试写了下代码来测试下，ArrayList中没有直接获取capacity的方法，只能通过反射获取elementData数组的size来间接获取到capacity。代码如下： 123456789101112131415161718192021222324public class ArrayListCapacityTest &#123; public static void main(String[] args) &#123; ArrayList arrayList = new ArrayList(); System.out.println("capacity: " + getCapacity(arrayList) + " size: " + arrayList.size()); arrayList.add("test"); System.out.println("capacity: " + getCapacity(arrayList) + " size: " + arrayList.size()); arrayList = new ArrayList(11); System.out.println("capacity: " + getCapacity(arrayList) + " size: " + arrayList.size()); &#125; public static int getCapacity(ArrayList arrayList) &#123; try &#123; Field elementDataField = ArrayList.class.getDeclaredField("elementData"); elementDataField.setAccessible(true); return ((Object[]) elementDataField.get(arrayList)).length; &#125; catch (NoSuchFieldException | IllegalAccessException e) &#123; e.printStackTrace(); return -1; &#125; &#125;&#125; 结果如下： 123capacity: 0 size: 0capacity: 10 size: 1capacity: 11 size: 0 分析上面结果也可以看出来，确实是初始容量为0了。接着看下ArrayList的源码（下面所有源码版本为Jdk 7u80）： 1234567 /** * Constructs an empty list with an initial capacity of ten. */public ArrayList() &#123; super(); this.elementData = EMPTY_ELEMENTDATA;&#125; 源码中这注释确实很误导人，构造函数中没有初始化大小。但是现在这样有个问题，数组大小为0， 我怎么添加元素进去？应该就是在add的时候初始化，继续跟进add方法的源码： 123456public boolean add(E e) &#123; // 如果刚初始化ArrayList，size肯定是0 ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125; add方法中第一步先确保容量够用，这里面有可能就是初始化容量的方法，继续跟进ensureCapacityInternal的源码： 123456789private void ensureCapacityInternal(int minCapacity) &#123; // 由上一步知道minCapacity为1 // 这里if的条件也一定为true if (elementData == EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; // 经过上一步之后，minCapacity就等于DEFAULT_CAPACITY，即10。 ensureExplicitCapacity(minCapacity);&#125; 继续跟进ensureExplicitCapacity源码： 12345678private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code // minCapacity此时为10，if条件成立 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125; 继续跟进grow源码： 123456789101112131415private void grow(int minCapacity) &#123; // overflow-conscious code // oldCapacity = 0 int oldCapacity = elementData.length; // newCapacity = 0 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) // newCapacity由上层传来为10 newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: // 这里就是数组初始化为10的地方了 elementData = Arrays.copyOf(elementData, newCapacity);&#125; 源码跟到这里就算完了，确实是在add的时候初始化容量为10。 结论ArrayList的初始化容量已经变了，不再是以前的10了，而是初始化为0，等到第一次add的时候再初始化为10。 做这样的改动，就是延迟初始化ArrayList的实际容量，应该是考虑到空间的问题，如果一开始就初始化为10，这个大小为10的数组中就全部是存的null，如果数量多了，这个也是很大的空间。应该是这样的原因吧。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[上传Zip文件不解压读取文件内容时ZipEntry的size为-1的问题]]></title>
      <url>%2F2018%2F03%2F03%2F%E4%B8%8A%E4%BC%A0Zip%E6%96%87%E4%BB%B6%E4%B8%8D%E8%A7%A3%E5%8E%8B%E8%AF%BB%E5%8F%96%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9%E6%97%B6ZipEntry%E7%9A%84size%E4%B8%BA-1%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
      <content type="text"><![CDATA[简介这几天在做通过流下载zip文件以及上传zip文件不解压读取zip文件内容的功能，在读取zip文件内容的时候遇到了size为-1的情况，在此记录下遇到的情况、解决办法、以及未解决的问题。 示例将上传和下载zip文件的功能做成了一个示例，放到了github上，链接：export-import-zip-use-stream，可以尝试运行下。 遇到的问题通过流下载zip文件之后，再次导入该zip文件，不解压读取zip文件内容，发现ZipEntry的size()返回-1，如下图所示： 但是尝试使用系统自带的压缩软件压缩了一个zip文件，并上传读取，发现一切正常，size不为-1。使用zipinfo命令查看两个文件作为对比，如下： 可以看到上面文件是通过导出功能生成的，红框里缺少size。而下面的是系统压缩软件压缩的zip文件，红框里面带有size大小。故猜测可能是由于代码里生成ZipEntry的时候没有设置size，compressize，crc32等属性的原因。 读取zip文件时ZipEntry的size为-1解决办法直接读取当前ZipEntry的流，直到为-1为止，代码如下： 123456789101112131415161718192021222324252627282930313233343536@PostMapping("import")@ResponseBodypublic void importZip(@RequestParam("file")MultipartFile file) throws IOException &#123; ZipInputStream zipInputStream = new ZipInputStream(file.getInputStream()); ZipEntry zipEntry; while ((zipEntry = zipInputStream.getNextEntry()) != null) &#123; if (zipEntry.isDirectory()) &#123; // do nothing &#125;else &#123; String name = zipEntry.getName(); long size = zipEntry.getSize(); // unknown size // ZipEntry的size可能为-1，表示未知 // 通过上面的几种方式下载，就会产生这种情况 if (size == -1) &#123; ByteArrayOutputStream baos = new ByteArrayOutputStream(); while (true) &#123; int bytes = zipInputStream.read(); if (bytes == -1) break; baos.write(bytes); &#125; baos.close(); System.out.println(String.format("Name:%s,Content:%s",name,new String(baos.toByteArray()))); &#125; else &#123; // ZipEntry的size正常 byte[] bytes = new byte[(int) zipEntry.getSize()]; zipInputStream.read(bytes, 0, (int) zipEntry.getSize()); System.out.println(String.format("Name:%s,Content:%s",name,new String(bytes))); &#125; &#125; &#125; zipInputStream.closeEntry(); zipInputStream.close();&#125; 此时可以正确读取文件内容。 下载文件时设置size的解决办法需要设置ZipEntry的size，compresSize以及crc32等属性。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[最近没更新博客，但是我还在]]></title>
      <url>%2F2017%2F06%2F08%2F%E6%9C%80%E8%BF%91%E6%B2%A1%E6%9B%B4%E6%96%B0%E5%8D%9A%E5%AE%A2%EF%BC%8C%E4%BD%86%E6%98%AF%E6%88%91%E8%BF%98%E5%9C%A8%2F</url>
      <content type="text"><![CDATA[最近一直没更新博客，不是懒惰了，这段时间一直在看Spring源码，从1.x到5.x，接下来还要准备看下Spring Boot的相关实现和Spring Cloud。另外最重要的是怕写出来的东西误人子弟，不敢乱写了～回头看看自己写的太肤浅了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[tomcat7中Digester的使用以及对server.xml的解析过程分析]]></title>
      <url>%2F2017%2F05%2F17%2Ftomcat7%E4%B8%ADDigester%E7%9A%84%E4%BD%BF%E7%94%A8%E4%BB%A5%E5%8F%8A%E5%AF%B9server.xml%E7%9A%84%E8%A7%A3%E6%9E%90%E8%BF%87%E7%A8%8B%E5%88%86%E6%9E%90%2F</url>
      <content type="text"><![CDATA[tomcat在启动的时候，会调用Catalina的load的方法启动一个新的Server实例，在这里会有关于Digester的使用，以及对server.xml的解析过程。load方法的代码如下： 1234567891011121314151617public void load() &#123; ... // Create and execute our Digester Digester digester = createStartDigester(); ... try &#123; inputSource.setByteStream(inputStream); digester.push(this); digester.parse(inputSource); &#125; ...&#125; 代码做了精简，只保留了Digester的最重要部分。首先是创建并配置要用来启动的Digester实例，然后获取到server.xml文件的输入流之后，使用digester进行解析。 Digester介绍在进行具体步骤的解析之前，首先看一下Digester的简单介绍，Digester用来处理xml，是对SAX的包装，所以也是基于文件流来解析xml的。Digester使用的步骤也很简单： 创建一个Digester实例 设置相关属性 设置具体的规则 调用parse方法进行解析 createStartDigester此方法用来创建和配置Digester，对应着上面的前三个步骤，具体代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576protected Digester createStartDigester() &#123; long t1=System.currentTimeMillis(); //创建一个digester实例 Digester digester = new Digester(); //是否需要验证xml文档的合法性，false表示不需要进行DTD规则校验 digester.setValidating(false); //是否需要进行节点设置规则校验 digester.setRulesValidation(true); //将xml节点中的className作为假属性，不用调用默认的setter方法 //在解析时，调用相应对象的setter方法来设置属性值，setter的参数就是节点属性， //而有className的话，则直接使用className来直接实例化对象 HashMap&lt;Class&lt;?&gt;, List&lt;String&gt;&gt; fakeAttributes = new HashMap&lt;Class&lt;?&gt;, List&lt;String&gt;&gt;(); ArrayList&lt;String&gt; attrs = new ArrayList&lt;String&gt;(); attrs.add(&quot;className&quot;); fakeAttributes.put(Object.class, attrs); digester.setFakeAttributes(fakeAttributes); digester.setUseContextClassLoader(true); //下面添加各种规则 //遇到xml中Server节点，就创建一个StandardServer对象 digester.addObjectCreate(&quot;Server&quot;, &quot;org.apache.catalina.core.StandardServer&quot;, &quot;className&quot;); //根据Server节点中的属性信息，调用属性的setter方法，比如说server节点中会有port=“8080”属性，则会调用setPort方法 digester.addSetProperties(&quot;Server&quot;); //在上面的load方法中有个digester.push(this)，this对象就是栈顶了 //这里将Server节点对应的对象作为参数，调用this对象，也就是Catalina对象的setServer方法 digester.addSetNext(&quot;Server&quot;, &quot;setServer&quot;, &quot;org.apache.catalina.Server&quot;); //Server节点下的GlobalNamingResources节点，创建一个NamingResource对象 digester.addObjectCreate(&quot;Server/GlobalNamingResources&quot;, &quot;org.apache.catalina.deploy.NamingResources&quot;); digester.addSetProperties(&quot;Server/GlobalNamingResources&quot;); digester.addSetNext(&quot;Server/GlobalNamingResources&quot;, &quot;setGlobalNamingResources&quot;, &quot;org.apache.catalina.deploy.NamingResources&quot;); //Server下的Listener节点 digester.addObjectCreate(&quot;Server/Listener&quot;, null, // MUST be specified in the element &quot;className&quot;); digester.addSetProperties(&quot;Server/Listener&quot;); digester.addSetNext(&quot;Server/Listener&quot;, &quot;addLifecycleListener&quot;, &quot;org.apache.catalina.LifecycleListener&quot;); //Server下的Service节点 digester.addObjectCreate(&quot;Server/Service&quot;, &quot;org.apache.catalina.core.StandardService&quot;, &quot;className&quot;); digester.addSetProperties(&quot;Server/Service&quot;); digester.addSetNext(&quot;Server/Service&quot;, &quot;addService&quot;, &quot;org.apache.catalina.Service&quot;); //Service节点下的Listener节点 digester.addObjectCreate(&quot;Server/Service/Listener&quot;, null, &quot;className&quot;); digester.addSetProperties(&quot;Server/Service/Listener&quot;); digester.addSetNext(&quot;Server/Service/Listener&quot;, &quot;addLifecycleListener&quot;, &quot;org.apache.catalina.LifecycleListener&quot;); //Executor节点 digester.addObjectCreate(&quot;Server/Service/Executor&quot;, &quot;org.apache.catalina.core.StandardThreadExecutor&quot;, &quot;className&quot;); digester.addSetProperties(&quot;Server/Service/Executor&quot;); digester.addSetNext(&quot;Server/Service/Executor&quot;, &quot;addExecutor&quot;, &quot;org.apache.catalina.Executor&quot;); //给Connector添加规则，就是当遇到Connector的时候，会调用ConnectorCreateRule里面定义的规则 //跟上面的作用是一样的，只不过该节点的规则比较多，就创建一个规则类 digester.addRule(&quot;Server/Service/Connector&quot;, new ConnectorCreateRule()); digester.addRule(&quot;Server/Service/Connector&quot;, new SetAllPropertiesRule(new String[]&#123;&quot;executor&quot;&#125;)); digester.addSetNext(&quot;Server/Service/Connector&quot;, &quot;addConnector&quot;, &quot;org.apache.catalina.connector.Connector&quot;); digester.addObjectCreate(&quot;Server/Service/Connector/Listener&quot;, null, &quot;className&quot;); digester.addSetProperties(&quot;Server/Service/Connector/Listener&quot;); digester.addSetNext(&quot;Server/Service/Connector/Listener&quot;, &quot;addLifecycleListener&quot;, &quot;org.apache.catalina.LifecycleListener&quot;); //给嵌入元素添加RuleSet自定义规则 //每个rule规则，都会有tomcat对自身业务逻辑的判断和处理 digester.addRuleSet(new NamingRuleSet(&quot;Server/GlobalNamingResources/&quot;)); digester.addRuleSet(new EngineRuleSet(&quot;Server/Service/&quot;)); digester.addRuleSet(new HostRuleSet(&quot;Server/Service/Engine/&quot;)); digester.addRuleSet(new ContextRuleSet(&quot;Server/Service/Engine/Host/&quot;)); addClusterRuleSet(digester, &quot;Server/Service/Engine/Host/Cluster/&quot;); digester.addRuleSet(new NamingRuleSet(&quot;Server/Service/Engine/Host/Context/&quot;)); // When the &apos;engine&apos; is found, set the parentClassLoader. digester.addRule(&quot;Server/Service/Engine&quot;, new SetParentClassLoaderRule(parentClassLoader)); addClusterRuleSet(digester, &quot;Server/Service/Engine/Cluster/&quot;); return (digester);&#125; 上面创建完Digester对象，并设置了属性和各种规则之后，接下来主要的就是解析工作。 parse解析parse方法代码如下： 12345678public Object parse(InputSource input) throws IOException, SAXException &#123; //解析前的配置，默认什么也没做，需要子类去实现 configure(); //获取解析器去解析 getXMLReader().parse(input); return (root);&#125; 解析完成之后，Server,Service等等在server.xml中存在的节点，就会有对应的对象存在，后续就可以使用这些对象进行初始化和启动了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[tomcat7的server.xml解析]]></title>
      <url>%2F2017%2F05%2F16%2Ftomcat7%E7%9A%84server.xml%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[这里对tomcat7的server.xml文件进行解释一下，方便在分析启动源码的时候理解Digester做的事情。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;?xml version=&apos;1.0&apos; encoding=&apos;utf-8&apos;?&gt;&lt;Server port=&quot;8005&quot; shutdown=&quot;SHUTDOWN&quot;&gt; &lt;Listener className=&quot;org.apache.catalina.startup.VersionLoggerListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.security.SecurityListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.AprLifecycleListener&quot; SSLEngine=&quot;on&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.JasperListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.JreMemoryLeakPreventionListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.ThreadLocalLeakPreventionListener&quot; /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name=&quot;UserDatabase&quot; auth=&quot;Container&quot; type=&quot;org.apache.catalina.UserDatabase&quot; description=&quot;User database that can be updated and saved&quot; factory=&quot;org.apache.catalina.users.MemoryUserDatabaseFactory&quot; pathname=&quot;conf/tomcat-users.xml&quot; /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name=&quot;Catalina&quot;&gt; &lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot; maxThreads=&quot;150&quot; minSpareThreads=&quot;4&quot;/&gt; &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Connector port=&quot;8443&quot; protocol=&quot;org.apache.coyote.http11.Http11Protocol&quot; maxThreads=&quot;150&quot; SSLEnabled=&quot;true&quot; scheme=&quot;https&quot; secure=&quot;true&quot; clientAuth=&quot;false&quot; sslProtocol=&quot;TLS&quot; /&gt; &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt; &lt;Cluster className=&quot;org.apache.catalina.ha.tcp.SimpleTcpCluster&quot;/&gt; &lt;Realm className=&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.UserDatabaseRealm&quot; resourceName=&quot;UserDatabase&quot;/&gt; &lt;/Realm&gt; &lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Valve className=&quot;org.apache.catalina.authenticator.SingleSignOn&quot; /&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log.&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; Servertomcat中Server代表一个tomcat实例，所以只会存在一个Server，而在配置文件中也是作为顶级元素出现，代码如下： 123&lt;Server port=&quot;8005&quot; shutdown=&quot;SHUTDOWN&quot;&gt;。。。&lt;/Server&gt; port，监听shutdown命令的端口，-1表示禁用shutdown命令。 shutdown，关闭tomcat的指令。 Listener监听器，用来监听某些事件的发生。 &lt;Listener className=&quot;org.apache.catalina.startup.VersionLoggerListener&quot; /&gt; VersionLoggerListener，启动时对tomcat，java，操作系统信息打印日志。 &lt;Listener className=&quot;org.apache.catalina.security.SecurityListener&quot; /&gt; SecurityListener，启动tomcat时，做一些安全检查。 &lt;Listener className=&quot;org.apache.catalina.core.AprLifecycleListener&quot; SSLEngine=&quot;on&quot; /&gt; AprLifecycleListener，用来监听Apache服务器相关的。 &lt;Listener className=&quot;org.apache.catalina.core.JasperListener&quot; /&gt; JasperListener，Jasper 2 JSP 引擎，主要负责对更新之后的jsp进行重新编译。 &lt;Listener className=&quot;org.apache.catalina.core.JreMemoryLeakPreventionListener&quot; /&gt; JreMemoryLeakPreventionListener，防止内存溢出的监听器。 &lt;Listener className=&quot;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener&quot; /&gt; GlobalResourcesLifecycleListener，初始化定义在元素GlobalNamingResources下的全局JNDI资源 &lt;Listener className=&quot;org.apache.catalina.core.ThreadLocalLeakPreventionListener&quot; /&gt; ThreadLocalLeakPreventionListener，防止ThreadLocal溢出监听器。 GlobalNamingResourcesGlobalNamingResources定义Server的全局JNDI资源。可以为所有的引擎应用程序引用。 1234567&lt;GlobalNamingResources&gt; &lt;Resource name=&quot;UserDatabase&quot; auth=&quot;Container&quot; type=&quot;org.apache.catalina.UserDatabase&quot; description=&quot;User database that can be updated and saved&quot; factory=&quot;org.apache.catalina.users.MemoryUserDatabaseFactory&quot; pathname=&quot;conf/tomcat-users.xml&quot; /&gt;&lt;/GlobalNamingResources&gt; 配置文件中定义了一个JNDI，名为UserDatabase，通过conf/tomcat-users.xml的内容，来得到一个用于授权用户的数据库，是一个内存数据库。 Service123&lt;Service name=&quot;Catalina&quot;&gt;。。。&lt;/Service&gt; Server下面可以有多个Service，Service下面有多个Connector和一个Engine。这里默认的Service名字为Catalina，下面有两个Connector：Http和AJP。 name，Service显示的名称，名字必须唯一。 Connector123&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; 上面是用来处理http请求的Connector。 port，端口号8080。 protocol，协议，http协议 connectionTimeout，响应的最大等待时间，20秒 redirectPort，ssl请求会重定向到8443端口 1234&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; 上面是使用线程池，处理http请求。 123&lt;Connector port=&quot;8443&quot; protocol=&quot;org.apache.coyote.http11.Http11Protocol&quot; maxThreads=&quot;150&quot; SSLEnabled=&quot;true&quot; scheme=&quot;https&quot; secure=&quot;true&quot; clientAuth=&quot;false&quot; sslProtocol=&quot;TLS&quot; /&gt; 上面处理ssl请求，端口是8443。 1&lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; 上面处理AJP请求，可以将tomcat和apache的http服务器一起运行。 EngineEngine是容器，一个Service中只包含一个Engine： 123&lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt;...&lt;/Engine&gt; Engine下面可以包含一个多或者多个Host。Engine从http请求的头信息中的主机名或者ip映射到真确的主机上。 name，Engine的名字，需要唯一。 defaultHost，默认主机名 Cluster集群相关的配置。tomcat支持服务器集群，可以复制整个集群的回话和上下文属性，也可以部署一个war包到所有的集群上。 1&lt;Cluster className=&quot;org.apache.catalina.ha.tcp.SimpleTcpCluster&quot;/&gt; Realm1234&lt;Realm className=&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.UserDatabaseRealm&quot; resourceName=&quot;UserDatabase&quot;/&gt;&lt;/Realm&gt; Realm是一个包含user、password、role的数据库，Realm可以定义在任何容器中。这里通过外部资源UserDatabase进行认证。 Host123456789&lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Valve className=&quot;org.apache.catalina.authenticator.SingleSignOn&quot; /&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log.&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt;&lt;/Host&gt; Host虚拟主机，定义在Engine下面，一个Engine下面可以有多个Host，在一个Host下面可以有多个Context。 name，虚拟主机的网络名称，必须有一个host的名字和Engine的defaulHost一样。 appBase，虚拟主机应用的根目录，默认是webapps。 unpackWARs，在webapps目录下的war文件是否应该解压。 autoDeploy，值为true时，tomcat会定时检查appBase等目录，对新的web应用和Context描述文件进行部署。 Value12345&lt;Valve className=&quot;org.apache.catalina.authenticator.SingleSignOn&quot; /&gt;&lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log.&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; Value在这里是阀门的意思，可以拦截http请求，可以定义在任何容器中。 SingleSignOn 是单点登录，AccessLogValve是访问日志的记录。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[tomcat7启动流程源码分析]]></title>
      <url>%2F2017%2F05%2F10%2Ftomcat7%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
      <content type="text"><![CDATA[主要介绍下tomcat7的启动流程，以及相关源码的分析。这里从我们常用的tomcat7的启动脚本为分析入口，然后进入到tomcat7相关源码中去。使用到的tomcat的版本为tomcat 7.0.77。在正式进入源码分析之前，首先需要了解下tomcat的类加载器的东西。请参考tomcat7类加载器解析 启动脚本startup.sh平时启动tomcat都是从这里开始，先看下这里都做了什么，下面是startup.sh源码： 12345678# CATALINA服务启动脚本。。。# 执行的脚本是catalina.shEXECUTABLE=catalina.sh。。。# 执行catalina.sh脚本，参数是startexec &quot;$PRGDIR&quot;/&quot;$EXECUTABLE&quot; start &quot;$@&quot; catalina.sh这里脚本有点长，我们只看有关start的部分，其他的都暂先省略掉。 12算了，这里不装逼了，脚本基本上内容都不太了解。不解析了，直接看最主要的一句org.apache.catalina.startup.Bootstrap &quot;$@&quot; start \ 上面这句就是要调用org.apache.catalina.startup.Bootstrap的main方法，参数是start，这里就进入了我们的源码。 Bootstrap类org.apache.catalina.startup.BootStrap，BootStrap类中的main方法是我们要分析的入口，是通过脚本启动tomcat的主方法和入口。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public static void main(String args[]) &#123; if (daemon == null) &#123; // Don&apos;t set daemon until init() has completed Bootstrap bootstrap = new Bootstrap(); try &#123; //初始化 bootstrap.init(); &#125; catch (Throwable t) &#123;。。。&#125; daemon = bootstrap; &#125; else &#123; Thread.currentThread().setContextClassLoader(daemon.catalinaLoader); &#125; try &#123; String command = &quot;start&quot;; if (args.length &gt; 0) &#123; command = args[args.length - 1]; &#125; //暂不知是啥意思 if (command.equals(&quot;startd&quot;)) &#123; args[args.length - 1] = &quot;start&quot;; daemon.load(args); daemon.start(); &#125; else if (command.equals(&quot;stopd&quot;)) &#123; args[args.length - 1] = &quot;stop&quot;; daemon.stop(); &#125; else if (command.equals(&quot;start&quot;)) &#123; //start命令 daemon.setAwait(true); daemon.load(args); daemon.start(); &#125; else if (command.equals(&quot;stop&quot;)) &#123; //stop命令 daemon.stopServer(args); &#125; else if (command.equals(&quot;configtest&quot;)) &#123; daemon.load(args); if (null==daemon.getServer()) &#123; System.exit(1); &#125; System.exit(0); &#125; else &#123;。。。&#125; &#125; catch (Throwable t) &#123; 。。。 System.exit(1); &#125;&#125; main方法做的事情也不复杂，当我们第一次启动的时候，首先初始化，然后调用start方法。 初始化初始化的时候做的工作也不复杂，大概如下： 首先设置catalina home和catalina base目录。 初始化类加载器，这是很重要的步骤 设置上下文类加载器和安全相关类加载器 加载启动类，创建启动类的实例 设置启动类实例的parentClassLoader为sharedLoader 初始化BootStrap方法代码如下： 12345678910111213141516171819202122232425262728293031public void init() throws Exception &#123; //设置catalina.home属性，如果不存在就使用当前工作目录 setCatalinaHome(); // 设置catalina.base属性，如果不存在就使用当前工作目录 setCatalinaBase(); //初始化类加载器 initClassLoaders(); //设置当前线程的类加载器 Thread.currentThread().setContextClassLoader(catalinaLoader); SecurityClassLoad.securityClassLoad(catalinaLoader); // 使用catalinaLoader类加载器加载Catalina类 Class&lt;?&gt; startupClass = catalinaLoader.loadClass(&quot;org.apache.catalina.startup.Catalina&quot;); //创建启动类的实例 Object startupInstance = startupClass.newInstance(); //以下设置启动类实例的parentClassLoader为sharedLoader String methodName = &quot;setParentClassLoader&quot;; Class&lt;?&gt; paramTypes[] = new Class[1]; paramTypes[0] = Class.forName(&quot;java.lang.ClassLoader&quot;); Object paramValues[] = new Object[1]; paramValues[0] = sharedLoader; Method method = startupInstance.getClass().getMethod(methodName, paramTypes); method.invoke(startupInstance, paramValues); //启动实例 catalinaDaemon = startupInstance;&#125; 初始化类加载器重点看下有关类加载器的初始化，代码如下： 123456789101112131415private void initClassLoaders() &#123; try &#123; //创建CommonClassLoader，common对应的是配置文件中的common.loader //这里和下面的配置文件指的是conf/catalina.properties文件 commonLoader = createClassLoader(&quot;common&quot;, null); if( commonLoader == null ) &#123; //配置文件中没有配置common，就使用当前类的ClassLoader commonLoader=this.getClass().getClassLoader(); &#125; //创建ServerClassLoader，对应配置文件中的server.loader catalinaLoader = createClassLoader(&quot;server&quot;, commonLoader); //创建SharedClassLoader，对应配置文件中的shared.loader sharedLoader = createClassLoader(&quot;shared&quot;, commonLoader); &#125; catch (Throwable t) &#123;。。。&#125;&#125; 这里会创建三个ClassLoader，commonLoader，catalinaLoader，sharedLoader，配置文件conf/catalina.properties中server.loader和shared.loader是空的，所以在运行时这两个Loader和commonLoader是一样的，这一点可以在下面的源码中看到。目前只有commonLoader具备实际的意义。 看下createClassLoader方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152private ClassLoader createClassLoader(String name, ClassLoader parent) throws Exception &#123; //CatalinaProperties对应着conf/catalina.properties文件 //配置文件中配置：common.loader=$&#123;catalina.base&#125;/lib,$&#123;catalina.base&#125;/lib/*.jar,$&#123;catalina.home&#125;/lib,$&#123;catalina.home&#125;/lib/*.jar //先从配置文件中获取name对应的name.loader //分别是common.loader、server.loader、shared.loader String value = CatalinaProperties.getProperty(name + &quot;.loader&quot;); //如果value为空，就直接返回parent //这里也验证了上面说到的，运行时由于server.loader、shared.loader是空的，所以之前说的三个Loader其实是同一个CommonLoader if ((value == null) || (value.equals(&quot;&quot;))) return parent; //将value中$&#123;catalina.base&#125;和$&#123;catalina.home&#125;替换成实际的目录 value = replace(value); //仓库列表，仓库指的是指定的目录，比如lib；或者是*.jar等 List&lt;Repository&gt; repositories = new ArrayList&lt;Repository&gt;(); //逗号分割 StringTokenizer tokenizer = new StringTokenizer(value, &quot;,&quot;); while (tokenizer.hasMoreElements()) &#123; String repository = tokenizer.nextToken().trim(); if (repository.length() == 0) &#123; continue; &#125; //仓库封装着对应的位置和类型，添加进list中保存 //这里是URL类型的 try &#123; URL url = new URL(repository); repositories.add( new Repository(repository, RepositoryType.URL)); continue; &#125; catch (MalformedURLException e) &#123; // Ignore &#125; //本地仓库 if (repository.endsWith(&quot;*.jar&quot;)) &#123;//多个jar repository = repository.substring (0, repository.length() - &quot;*.jar&quot;.length()); repositories.add( new Repository(repository, RepositoryType.GLOB)); &#125; else if (repository.endsWith(&quot;.jar&quot;)) &#123;//单个jar repositories.add( new Repository(repository, RepositoryType.JAR)); &#125; else &#123;//目录类型的 repositories.add( new Repository(repository, RepositoryType.DIR)); &#125; &#125; //使用ClassLoaderFactory的createClassLoader方法来创建ClassLoader //仓库是上面解析过的仓库 return ClassLoaderFactory.createClassLoader(repositories, parent);&#125; 继续往下看createClassLoader方法，创建新的类加载器： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public static ClassLoader createClassLoader(List&lt;Repository&gt; repositories, final ClassLoader parent) throws Exception &#123; Set&lt;URL&gt; set = new LinkedHashSet&lt;URL&gt;(); //将各种类型的repository解析成url，保存进set中 if (repositories != null) &#123; for (Repository repository : repositories) &#123; if (repository.getType() == RepositoryType.URL) &#123; URL url = buildClassLoaderUrl(repository.getLocation()); set.add(url); &#125; else if (repository.getType() == RepositoryType.DIR) &#123; File directory = new File(repository.getLocation()); directory = directory.getCanonicalFile(); if (!validateFile(directory, RepositoryType.DIR)) &#123; continue; &#125; URL url = buildClassLoaderUrl(directory); set.add(url); &#125; else if (repository.getType() == RepositoryType.JAR) &#123; File file=new File(repository.getLocation()); file = file.getCanonicalFile(); if (!validateFile(file, RepositoryType.JAR)) &#123; continue; &#125; URL url = buildClassLoaderUrl(file); set.add(url); &#125; else if (repository.getType() == RepositoryType.GLOB) &#123; File directory=new File(repository.getLocation()); directory = directory.getCanonicalFile(); if (!validateFile(directory, RepositoryType.GLOB)) &#123; continue; &#125; String filenames[] = directory.list(); if (filenames == null) &#123; continue; &#125; for (int j = 0; j &lt; filenames.length; j++) &#123; String filename = filenames[j].toLowerCase(Locale.ENGLISH); if (!filename.endsWith(&quot;.jar&quot;)) continue; File file = new File(directory, filenames[j]); file = file.getCanonicalFile(); if (!validateFile(file, RepositoryType.JAR)) &#123; continue; &#125;; URL url = buildClassLoaderUrl(file); set.add(url); &#125; &#125; &#125; &#125; // Construct the class loader itself final URL[] array = set.toArray(new URL[set.size()]); //使用上面解析到的url来新建URLClassLoader实例 return AccessController.doPrivileged( new PrivilegedAction&lt;URLClassLoader&gt;() &#123; @Override public URLClassLoader run() &#123; if (parent == null) return new URLClassLoader(array); else return new URLClassLoader(array, parent); &#125; &#125;);&#125; 这里进行新的类加载器创建，过程并不复杂，首先根据不同类型解析仓库，然后根据解析到的url新建URLClassLoader的实例。URLClassLoader是ClassLoader的子类，用于从目录的url或者jar文件来加载类和资源。 创建启动类并创建新实例上面创建完成三个ClassLoader之后，然后设置当前上下文的ClassLoader和安全ClassLoader为catalinaLoader，接下来一步就是使用catalinaLoader加载org.apache.catalina.startup.Catalina启动类。 1234Class&lt;?&gt; startupClass = catalinaLoader.loadClass (&quot;org.apache.catalina.startup.Catalina&quot;);Object startupInstance = startupClass.newInstance(); 调用start方法启动Catalina上面init方法完成之后，ClassLoader已经被创建，catalinaDaemon为启动的新实例。然后就该调用start方法了，调用的位置如下： 123456789else if (command.equals(&quot;start&quot;)) &#123; //这个是让服务器启动之后，保持运行状态，监听后面发来的命令。 daemon.setAwait(true); //对tomcat的相关的配置文件进行加载解析 //对tomcat各个组件进行初始化配置操作 daemon.load(args); //启动Catalina daemon.start();&#125; 启动前的三个步骤如下： 设置await状态，让服务器启动之后，保持运行状态，监听后面发来的命令。 load方法，对tomcat的相关的配置文件进行加载解析，并对各个组件进行初始化配置操作。 start方法，真正启动Catalina load方法加载和初始化load方法主要对tomcat的相关配置文件进行加载解析，对各个组件进行初始化配置操作，代码如下： 1234567891011121314151617181920212223private void load(String[] arguments) throws Exception &#123; //要调用的load()方法 String methodName = &quot;load&quot;; //启动时候参数的处理 Object param[]; Class&lt;?&gt; paramTypes[]; if (arguments==null || arguments.length==0) &#123; paramTypes = null; param = null; &#125; else &#123; paramTypes = new Class[1]; paramTypes[0] = arguments.getClass(); param = new Object[1]; param[0] = arguments; &#125; //下面调用Catalina的load方法 Method method = catalinaDaemon.getClass().getMethod(methodName, paramTypes); method.invoke(catalinaDaemon, param);&#125; 这里没有做详细处理，只是使用反射调用Catalina实例的load方法，Catalina实例是我们上面使用反射新建的实例。接续往下看Catalina的load方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public void load() &#123; //记录初始化开始的时间 long t1 = System.nanoTime(); //初始化目录，还有embedded的目录处理 initDirs(); //初始化命名空间？这里不太理解还，应该是跟JNDI有关系 initNaming(); //创建并配置一个Digester实例，并设置相关规则属性，Digester用来解析xml，采用的是SAX方式。 Digester digester = createStartDigester(); InputSource inputSource = null; InputStream inputStream = null; File file = null; try &#123; try &#123; //配置文件，默认是conf/server.xml file = configFile(); inputStream = new FileInputStream(file); inputSource = new InputSource(file.toURI().toURL().toString()); &#125; catch (Exception e) &#123;。。。&#125; if (inputStream == null) &#123; try &#123; inputStream = getClass().getClassLoader() .getResourceAsStream(getConfigFile()); inputSource = new InputSource (getClass().getClassLoader() .getResource(getConfigFile()).toString()); &#125; catch (Exception e) &#123;。。。&#125; &#125; //上面没有找到配置文件，就找server-embed.xml if( inputStream==null ) &#123; try &#123; inputStream = getClass().getClassLoader() .getResourceAsStream(&quot;server-embed.xml&quot;); inputSource = new InputSource (getClass().getClassLoader() .getResource(&quot;server-embed.xml&quot;).toString()); &#125; catch (Exception e) &#123;。。。&#125; &#125; if (inputStream == null || inputSource == null) &#123; 。。。 return; &#125; //解析配置文件 try &#123; inputSource.setByteStream(inputStream); digester.push(this); digester.parse(inputSource); &#125; catch (SAXParseException spe) &#123;。。。&#125; &#125; finally &#123; if (inputStream != null) &#123; try &#123; inputStream.close(); &#125; catch (IOException e) &#123;。。。&#125; &#125; &#125; //解析配置文件中会实例化server，是一个StandardServer //设置server的catalina getServer().setCatalina(this); //重定向流 //使用自定义的PrintStream代替System.out和System.err initStreams(); //初始化新的server try &#123; //对Server进行初始化 getServer().init(); &#125; catch (LifecycleException e) &#123;。。。&#125; //启动结束时间 long t2 = System.nanoTime();&#125; load方法做的事情如下： 初始化目录，还有embedded的目录处理。 初始化命名空间。 创建并配置一个Digester实例，并设置相关规则属性，Digester用来解析xml，采用的是SAX方式。 读取解析配置文件。 调用解析配置文件时候已经初始化过的StandardServer的init方法，对Server进行初始化。 前面的步骤先不解析，直接看Server的init方法，刚方法实现在LifecycleBase类中。 初始化ServerLifecycleBase中的init方法如下： 123456789101112131415public final synchronized void init() throws LifecycleException &#123; //状态不为new，抛异常 if (!state.equals(LifecycleState.NEW)) &#123; invalidTransition(Lifecycle.BEFORE_INIT_EVENT); &#125; try &#123; //设置状态为INITIALIZING setStateInternal(LifecycleState.INITIALIZING, null, false); //初始化 initInternal(); //设置状态为INITIALIZED setStateInternal(LifecycleState.INITIALIZED, null, false); &#125; catch (Throwable t) &#123;。。。&#125;&#125; 继续往下看initInternal方法，在子类中实现，这里是在StandardServer中，对于下面的Engine，Host，Context的初始化也是这种步骤： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849protected void initInternal() throws LifecycleException &#123; //调用父类方法，设置oname super.initInternal(); //？？？ onameStringCache = register(new StringCache(), &quot;type=StringCache&quot;); // 注册MBeanFactory MBeanFactory factory = new MBeanFactory(); factory.setContainer(this); onameMBeanFactory = register(factory, &quot;type=MBeanFactory&quot;); //注册naming资源 globalNamingResources.init(); // Populate the extension validator with JARs from common and shared // class loaders //使用从common和shared类加载器加载的类来填充扩展验证器 if (getCatalina() != null) &#123; ClassLoader cl = getCatalina().getParentClassLoader(); //遍历类加载器，对于SystemClassLoader不处理 while (cl != null &amp;&amp; cl != ClassLoader.getSystemClassLoader()) &#123; //URLClassLoader if (cl instanceof URLClassLoader) &#123; URL[] urls = ((URLClassLoader) cl).getURLs(); for (URL url : urls) &#123; if (url.getProtocol().equals(&quot;file&quot;)) &#123; try &#123; File f = new File (url.toURI()); if (f.isFile() &amp;&amp; f.getName().endsWith(&quot;.jar&quot;)) &#123; ExtensionValidator.addSystemResource(f); &#125; &#125; catch (URISyntaxException e) &#123; // Ignore &#125; catch (IOException e) &#123; // Ignore &#125; &#125; &#125; &#125; cl = cl.getParent(); &#125; &#125; //调用各个service的init方法，一个Server下面可能有多个Service for (int i = 0; i &lt; services.length; i++) &#123; services[i].init(); &#125;&#125; 初始化Service也是先调用LifecycleBase中的init方法，然后initInternal方法由子类实现，这里是StandardService： 1234567891011121314151617181920212223242526protected void initInternal() throws LifecycleException &#123; super.initInternal(); //调用Container的init方法，这里是StandardEngine if (container != null) &#123; container.init(); &#125; //实例化线程池 for (Executor executor : findExecutors()) &#123; if (executor instanceof LifecycleMBeanBase) &#123; ((LifecycleMBeanBase) executor).setDomain(getDomain()); &#125; executor.init(); &#125; //实例化Connector，可能有多个Connector synchronized (connectorsLock) &#123; for (Connector connector : connectors) &#123; try &#123; //调用Connector的init方法 connector.init(); &#125; catch (Exception e) &#123;...&#125; &#125; &#125;&#125; 首先实例化Container，然后实例化Connector。 初始化Container这里的Container是StandardEngine，看下init方法： 12345protected void initInternal() throws LifecycleException &#123; //启动之前确保Realm存在 getRealm(); super.initInternal();&#125; 初始化ConnectorConnector用来处理和客户端的通信相关内容。 Connector初始化，也是调用Connector的initInternal方法： 1234567891011121314151617181920212223protected void initInternal() throws LifecycleException &#123; super.initInternal(); // CoyoteAdapter，用来处理请求 adapter = new CoyoteAdapter(this); //protocolHandler对于不同请求会有不同的Handler //我们这里重点看http请求的处理，即是Http11Protocol protocolHandler.setAdapter(adapter); // Make sure parseBodyMethodsSet has a default if( null == parseBodyMethodsSet ) &#123; setParseBodyMethods(getParseBodyMethods()); &#125; try &#123; //处理器初始化 protocolHandler.init(); &#125; catch (Exception e) &#123;。。。&#125; // 初始化 mapper listener mapperListener.init();&#125; 初始化的时候先初始化Service，然后是Container，然后是Connector。往下还有对protocolHandler的初始化和mapperListener的初始化。 初始化protocolHandler这里主要看下对于http请求的处理，对应的Handler为Http11Protocol。初始化方法为init，实现在Http11Protocol的父类AbstractHttp11JsseProtocol中： 123456public void init() throws Exception &#123; // SSL implementation needs to be in place before end point is // initialized sslImplementation = SSLImplementation.getInstance(sslImplementationName); super.init();&#125; 调用父类的init方法： 12345678910111213141516171819202122232425262728293031public void init() throws Exception &#123; if (oname == null) &#123; // Component not pre-registered so register it oname = createObjectName(); if (oname != null) &#123; Registry.getRegistry(null, null).registerComponent(this, oname, null); &#125; &#125; if (this.domain != null) &#123; try &#123; tpOname = new ObjectName(domain + &quot;:&quot; + &quot;type=ThreadPool,name=&quot; + getName()); Registry.getRegistry(null, null).registerComponent(endpoint, tpOname, null); &#125; catch (Exception e) &#123;。。。&#125; rgOname=new ObjectName(domain + &quot;:type=GlobalRequestProcessor,name=&quot; + getName()); Registry.getRegistry(null, null).registerComponent( getHandler().getGlobal(), rgOname, null ); &#125; String endpointName = getName(); endpoint.setName(endpointName.substring(1, endpointName.length()-1)); try &#123; //endpoint的初始化 endpoint.init(); &#125; catch (Exception ex) &#123;。。。&#125;&#125; 关于oname和domain先不讲解，主要看初始化endpoint。 初始化endpointendpoint提供底层的网络io实现。init方法实现在AbstractEndpoint中： 12345678public final void init() throws Exception &#123; testServerCipherSuitesOrderSupport(); if (bindOnInit) &#123; //绑定方法，该对底层的Socket之类的进行处理了。 bind(); bindState = BindState.BOUND_ON_INIT; &#125;&#125; bind方法的实现在子类中，这里使用的是JioEndpoint： 123456789101112131415161718192021222324252627282930313233343536public void bind() throws Exception &#123; //初始化acceptor的默认线程总数 if (acceptorThreadCount == 0) &#123; acceptorThreadCount = 1; &#125; //初始化最大连接数 if (getMaxConnections() == 0) &#123; setMaxConnections(getMaxThreadsInternal()); &#125; if (serverSocketFactory == null) &#123; //https的处理 if (isSSLEnabled()) &#123; serverSocketFactory = handler.getSslImplementation().getServerSocketFactory(this); &#125; else &#123; //处理http请求的serversocket工厂 serverSocketFactory = new DefaultServerSocketFactory(this); &#125; &#125; if (serverSocket == null) &#123; //创建serverSocket try &#123; if (getAddress() == null) &#123; serverSocket = serverSocketFactory.createSocket(getPort(), getBacklog()); &#125; else &#123; serverSocket = serverSocketFactory.createSocket(getPort(), getBacklog(), getAddress()); &#125; &#125; catch (BindException orig) &#123;。。。&#125; &#125;&#125; 创建ServerSocket代码如下： 1234public ServerSocket createSocket (int port, int backlog, InetAddress ifAddress) throws IOException &#123; return new ServerSocket (port, backlog, ifAddress);&#125; 创建ServerSocket，根据端口号和地址直接返回一个ServerSocket实例。到这里对于Handler的处理已经完成。接下来初始化mapperListener。 初始化mapperListenerMapperListener用来建立配置的URL映射的管理，即Host，Context，Wrapper（Servlet）和URL的映射关系。 init方法在LifecycleMBeanBase的initInternal方法中实现，没有做啥事。 初始化完成之后，就开始调用Catalina的start方法进行启动了。 初始化过程总结整个初始化过程层次还是很清晰的： 首先初始化Server 然后初始化Service 接着初始化Container，Executor，Connector 初始化Connector的时候，需要初始化protocolHandler和mapperListener 初始化protocolHandler，这里需要初始化endpoint，初始化endpoint就是返回一个ServerSocket实例 start方法启动CatalinaCatalina的start方法代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public void start() &#123; //没有Server实例，就走一遍load if (getServer() == null) &#123; load(); &#125; //还是没有Server实例，有错误！ if (getServer() == null) &#123; log.fatal(&quot;Cannot start server. Server instance is not configured.&quot;); return; &#125; long t1 = System.nanoTime(); //启动新的Server try &#123; //这里Server是StandardServer getServer().start(); &#125; catch (LifecycleException e) &#123; try &#123; //异常，需要销毁 getServer().destroy(); &#125; catch (LifecycleException e1) &#123;。。。&#125; return; &#125; long t2 = System.nanoTime(); // 注册关闭钩子 if (useShutdownHook) &#123; if (shutdownHook == null) &#123; shutdownHook = new CatalinaShutdownHook(); &#125; Runtime.getRuntime().addShutdownHook(shutdownHook); LogManager logManager = LogManager.getLogManager(); if (logManager instanceof ClassLoaderLogManager) &#123; ((ClassLoaderLogManager) logManager).setUseShutdownHook( false); &#125; &#125; //如果是await状态 if (await) &#123; await(); stop(); &#125;&#125; 这里主要的步骤是调用Server的start方法，启动服务。这里Server是StandardServer。 启动ServerStandardServer的start方法，start方法在LifecycleBase中： 1234567891011121314151617181920212223242526272829public final synchronized void start() throws LifecycleException &#123; if (LifecycleState.STARTING_PREP.equals(state) || LifecycleState.STARTING.equals(state) || LifecycleState.STARTED.equals(state)) &#123; return; &#125; //init if (state.equals(LifecycleState.NEW)) &#123; init(); &#125; else if (state.equals(LifecycleState.FAILED)) &#123; //stop stop(); &#125; else if (!state.equals(LifecycleState.INITIALIZED) &amp;&amp; !state.equals(LifecycleState.STOPPED)) &#123; invalidTransition(Lifecycle.BEFORE_START_EVENT); &#125; try &#123; setStateInternal(LifecycleState.STARTING_PREP, null, false); startInternal(); if (state.equals(LifecycleState.FAILED)) &#123; stop(); &#125; else if (!state.equals(LifecycleState.STARTING)) &#123; invalidTransition(Lifecycle.AFTER_START_EVENT); &#125; else &#123; setStateInternal(LifecycleState.STARTED, null, false); &#125; &#125; catch (Throwable t) &#123;。。。&#125;&#125; 上面也是调用startInternal()方法进行启动，在子类中实现，这里是在StandardServer中： 1234567891011121314protected void startInternal() throws LifecycleException &#123; //暂先不解释 fireLifecycleEvent(CONFIGURE_START_EVENT, null); setState(LifecycleState.STARTING); //暂先不解释 globalNamingResources.start(); //启动Service synchronized (servicesLock) &#123; for (int i = 0; i &lt; services.length; i++) &#123; services[i].start(); &#125; &#125;&#125; 这里调用Service方法的start启动Service。 启动ServiceStandardService的start方法，具体的实现是在StandardService的startInternal方法中： 12345678910111213141516171819202122232425262728protected void startInternal() throws LifecycleException &#123; setState(LifecycleState.STARTING); //启动Container if (container != null) &#123; synchronized (container) &#123; container.start(); &#125; &#125; //启动线程池 synchronized (executors) &#123; for (Executor executor: executors) &#123; executor.start(); &#125; &#125; //启动Connector synchronized (connectorsLock) &#123; for (Connector connector: connectors) &#123; try &#123; if (connector.getState() != LifecycleState.FAILED) &#123; connector.start(); &#125; &#125; catch (Exception e) &#123;。。。&#125; &#125; &#125;&#125; 启动ContainerStandardEngine的start方法，也是调用startInternal方法，实现在StandardEngine中： 1234protected synchronized void startInternal() throws LifecycleException &#123; //标准容器启动，在父类中实现 super.startInternal();&#125; 继续看ContainerBase的startInternal方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//暂未解析protected synchronized void startInternal() throws LifecycleException &#123; // Start our subordinate components, if any if ((loader != null) &amp;&amp; (loader instanceof Lifecycle)) ((Lifecycle) loader).start(); logger = null; getLogger(); if ((manager != null) &amp;&amp; (manager instanceof Lifecycle)) ((Lifecycle) manager).start(); if ((cluster != null) &amp;&amp; (cluster instanceof Lifecycle)) ((Lifecycle) cluster).start(); Realm realm = getRealmInternal(); if ((realm != null) &amp;&amp; (realm instanceof Lifecycle)) ((Lifecycle) realm).start(); if ((resources != null) &amp;&amp; (resources instanceof Lifecycle)) ((Lifecycle) resources).start(); //启动子容器 Container children[] = findChildren(); List&lt;Future&lt;Void&gt;&gt; results = new ArrayList&lt;Future&lt;Void&gt;&gt;(); for (int i = 0; i &lt; children.length; i++) &#123; results.add(startStopExecutor.submit(new StartChild(children[i]))); &#125; boolean fail = false; for (Future&lt;Void&gt; result : results) &#123; try &#123; result.get(); &#125; catch (Exception e) &#123; log.error(sm.getString(&quot;containerBase.threadedStartFailed&quot;), e); fail = true; &#125; &#125; if (fail) &#123; throw new LifecycleException( sm.getString(&quot;containerBase.threadedStartFailed&quot;)); &#125; // Start the Valves in our pipeline (including the basic), if any if (pipeline instanceof Lifecycle) ((Lifecycle) pipeline).start(); setState(LifecycleState.STARTING); // Start our thread threadStart();&#125; 启动ConnectorConnector的start方法，Connector的startInternal方法： 123456789protected void startInternal() throws LifecycleException &#123; setState(LifecycleState.STARTING); try &#123; protocolHandler.start(); &#125; catch (Exception e) &#123;。。。&#125; mapperListener.start();&#125; Connector的启动跟初始化差不多，也是先启动protocolHandler，然后启动mapperListener。 启动protocolHandler代码实现在AbstractProtocol中： 12345public void start() throws Exception &#123; try &#123; endpoint.start(); &#125; catch (Exception ex) &#123;。。。&#125;&#125; 这里启动endpoint，代码实现在AbstractEndpoint中： 123456789public final void start() throws Exception &#123; //没有绑定，先绑定 if (bindState == BindState.UNBOUND) &#123; bind(); bindState = BindState.BOUND_ON_START; &#125; //启动 startInternal();&#125; startInternal方法用来启动endpoint，我们这里还是以JIoEndpoint来分析，代码如下： 1234567891011121314151617181920212223public void startInternal() throws Exception &#123; if (!running) &#123; running = true; paused = false; //创建工作者线程 if (getExecutor() == null) &#123; createExecutor(); &#125; //实例化连接数栅栏 initializeConnectionLatch(); //启动Acceptor线程 startAcceptorThreads(); //启动异步超时线程 Thread timeoutThread = new Thread(new AsyncTimeout(), getName() + &quot;-AsyncTimeout&quot;); timeoutThread.setPriority(threadPriority); timeoutThread.setDaemon(true); timeoutThread.start(); &#125;&#125; 启动mapperListenerMapperListener的startInternal方法： 123456789101112131415161718public void startInternal() throws LifecycleException &#123; setState(LifecycleState.STARTING); findDefaultHost(); Engine engine = (Engine) connector.getService().getContainer(); addListeners(engine); Container[] conHosts = engine.findChildren(); for (Container conHost : conHosts) &#123; Host host = (Host) conHost; if (!LifecycleState.NEW.equals(host.getState())) &#123; // Registering the host will register the context and wrappers registerHost(host); &#125; &#125;&#125; 到这里就启动完成，tomcat启动完毕，有关启动的还没有详细解释，待续～～～]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[tomcat7类加载器解析]]></title>
      <url>%2F2017%2F05%2F10%2Ftomcat7%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[tomcat中也有很多的自定义的类加载器，保证容器的不同部分，以及运行在容器中的web应用可以访问不同的保存着类和资源的仓库。tomcat的类加载器机制跟jdk的类加载器机制基本类似，但是web应用类加载器处理请求的时候会稍微有些不同，jdk的类加载机制不再重复。 tomcat类加载器结构tomcat的类加载器的结构大概如下： 1234567 Bootstrap | System | Common / \Webapp1 Webapp2 ... Bootstrap，包含JVM的基本运行时类，以及系统扩展目录（$JAVA_HOME/jre/lib/ext）下的jar包。 System，通常是根据CLASSPATH环境变量内容进行初始化的。这些类对tomcat内部类以及web应用都是可见的。tomcat启动脚本$CATALINA_HOME/bin/catalina.sh忽略了CLASSPATH的内容，会从以下位置中构建类加载器： $CATALINA_HOME/bin/bootstrap.jar包含用来初始化tomcat服务器的main方法，以及它依赖的类加载器实现类。 $CATALINA_BASE/bin/tomcat-juli.jar或者$CATALINA_HOME/bin/tomcat-juli.jar是日志实现类，优先使用CATALINA_BASE下的tomcat-juli.jar。 $CATALINA_HOME/bin/commons-daemon.jar引用自bootstrap.jar的清单文件中。 Common，这种类加载器包含额外的类，对于tomcat内部以及所有web应用都是可见的。一般情况，应用类不会放在这里，Common类加载器会加载${catalina.base}/lib,${catalina.base}/lib/*.jar,${catalina.home}/lib,${catalina.home}/lib/*.jar这些目录下的资源或者jar包，该配置在$CATALINA_BASE/conf/catalina.properties的common.loader属性中。 Webapp1，Webapp2等，为每个部署在tomcat中的web应用创建的类加载器，每个web应用只能看到自己的/WEB-INF/classes和/WEB-INF/lib目录，其他应用则不可见。 web应用加载类顺序tomcat启动之后，在web应用类加载器处理请求的时候，Web应用类加载器和JVM的类加载器不太一样，不是双亲委派模型。当请求从Web应用的类加载器加载类时，首先查看自己的仓库，而不是委托给父类加载。类加载器会显式的忽略所有包含Servlert API类的Jar文件。tomcat其他的类加载器则使用双亲委派模型。 Web应用类加载器加载顺序为： JVM的BootStrap类 WEB应用的/WEB-INF/classes下的类 WEB应用的/WEB-INF/lib/*.jar下的jar System类加载器的类 Common类加载器的类 但是如果web应用类加载器有配置了&lt;Loader delegate=&quot;true&quot;/&gt;，这时候就会按照双亲委派模型，顺序变为： JVM的BootStrap类 System类加载器的类 Common类加载器的类 WEB应用的/WEB-INF/classes下的类 WEB应用的/WEB-INF/lib/*.jar下的jar tomcat启动时类加载器的创建顺序tomcat启动的时候，会创建如下的类加载器： Bootstrap类加载器，用来加载JVM启动所需要的类，也会加载JVM的标准扩展类 System类加载器，加载tomcat启动类，比如bootstrap.ja和tomcat-juli.jar。 Common类加载器，是tomcat的类加载器，加载tomcat自身使用的类，也加载web应用通用的类。 WebappClassLoader，web应用类加载器，每个应用都会有一个类加载器，会加载自己的/WEB-INF/classes和/WEB-INF/lib/*.jar下的class和jar文件。 其他的类加载器除了上面说的Common和Webapp类加载器之外，tomcat中还有Server类加载器和Shared类加载器。 Server类加载器负责加载位于$CATALINE_HOME/server目录下的tomcat的核心类，在启动时创建，其父类加载器是Common类加载器。 Shared类加载器负责加载webapp公用的类，其父类加载器是Common类加载器，也是在tomcat启动时创建。 有关更多的内容会在源码分析里面继续解析，这里解析的并不详细，最重要的是还不太熟悉和了解。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于UTF-8的BOM标识以及非法字符65279错误的一些记录]]></title>
      <url>%2F2017%2F05%2F09%2F%E5%85%B3%E4%BA%8EUTF-8%E7%9A%84BOM%E6%A0%87%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%9D%9E%E6%B3%95%E5%AD%97%E7%AC%A665279%E9%94%99%E8%AF%AF%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%B0%E5%BD%95%2F</url>
      <content type="text"><![CDATA[关于UTF-8的BOM标识和非法字符\65279的错误，已经遇到过好几次了，在这里记录一下。关于UTF-8带BOM和UTF-8不带BOM的区别，网上有很多解释。我遇到的最多的就是文件在Windows上被别人修改后，在我的电脑上会出错（我一直使用linux和macos），一般都是导入项目的时候，进行编译就会有问题。 IDEA导入项目出现\65279非法字符这个问题也是由于带BOM的UTF-8格式引起的，至少我遇到都是这样，一般在linux上和macos上导入项目会发生，可能是由于在windows上用一些软件编辑过文件导致的。解决办法也很简单，下面就说一下解决办法。 比如说我将一个项目导入到idea发现报错了，可以使用命令行，首先进入src目录的同级目录： 输入：vi 输入：:args ./src/** 这里的**表示循环src下的所有文件夹 输入：:ar 这一步可选，目的是查看当前添加了哪些目标文件 输入：:argdo set nobomb | update! 这句意思是对args列表中的文件分别执行 set nobomb 然后强制保存 以上就是步骤，这样就可以了。 UTF-8中BOM标志导致项目读取配置文件为空最近公司部署项目到刀片服务器上时候，发现项目可以正常运行，读取配置文件也可以在指定位置找到配置文件，但是就是读取配置文件内容的时候，一直是null。若干人各种调试无果。我想应该是配置文件被人在windows上编辑过或者windows上新建的文本文件，然后放进服务器上的。于是就将服务器配置文件拿下来和我本地的文件对比下，果然是由于UTF-8带有BOM的原因。 重新在服务器上新建配置文件，把内容重新复制进去，完成！ 一般properties和xml文件可能会遇到这个问题。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM运行时数据区域介绍]]></title>
      <url>%2F2017%2F05%2F06%2FJVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%9F%9F%E4%BB%8B%E7%BB%8D%2F</url>
      <content type="text"><![CDATA[此处的内容是根据Java虚拟机规范（Java SE 7）相关内容以及深入理解Java虚拟机等做的总结。可能有不对的地方。了解这些区域，可以从总体上看下虚拟机内部是怎么构造的，网上也有相关的图片介绍，可以适当的记下图片内容，这样可以有一个立体的感受，更容易记忆。Java虚拟机定义了程序运行期间使用到的运行时数据区域，其中一些与虚拟机生命周期相同，另外一些与线程的生命周期相同。JVM运行时数据区域分为： 程序计数器（Program Counter） Java虚拟机栈（Java Virtual Machine Stack） 堆（Heap） 方法区（Method Area） 本地方法栈（Native Method Stack） 程序计数器（Program Counter）程序计数器是线程私有的，每条线程都有自己的程序计数器。 Java虚拟机是支持多线程的，多线程是通过线程的轮流切换来实现的，也就是说每次切换都需要在上次停顿的地方重新开始运行，这时候就需要程序计数器来保存当前线程正在执行的字节码指令的地址，切换到该线程的时候，就能知道该执行哪一个字节码指令了。 如果一个线程正在执行的方法是Java方法，程序计数器保存的是Java虚拟机正在执行的字节码指令的地址；如果正在执行的方法是native的，程序计数器的值为undefined。 Java虚拟机栈（Java Virtual Machine Stack）Java虚拟机栈也是线程私有的，与线程同时创建，用于存储栈帧（Fremas），栈帧用来存储局部变量，操作数栈、指向当前方法所属类的运行时常量池、处理动态链接、方法返回值和异常分派。方法从调用到执行完成的过程就对应着一个栈帧从入栈到出栈的过程。 Java虚拟机栈可以被实现为固定大小的，此时每一条线程的Java虚拟机栈在线程创建的时候容量就已经确定；还可以被实现为根据计算动态扩展和收缩的。 Java虚拟机栈可能会发生异常： 如果线程请求的栈容量超过Java虚拟机栈允许的最大容量，会抛出StackOverflowError异常。 如果虚拟机栈可动态扩展，申请不到足够的内存去完成扩展，或者建立新线程时没有足够的内存去创建虚拟机栈，会抛出OutOfMemoryError异常。 栈帧栈帧随着方法的调用而创建，随着方法的结束（正常或者异常结束）而销毁，是用来存储数据和部分过程结果的数据结构，同时也被用来处理动态链接（Dynamic Linking）、方法返回值和异常分派（Dispatch Exception）。 栈帧存在于Java虚拟机栈中，栈帧中包含局部变量表、操作数栈和指向当前方法所属类的运行时常量池的引用。 局部变量表和操作数栈的容量在编译期确定，通过方法的Code属性保存并提供给栈帧使用。栈帧的容量大小仅仅取决于Java虚拟机的实现和方法调用时可分配的内存。 局部变量表局部变量表存在于栈帧中，长度在编译期决定，存储在类和接口的二进制表示中，也就是存储在方法的Code属性中并提供给栈帧使用。 局部变量表可以保存类型为boolean、byte、char、short、int、float、reference、returnAddress，而long和double类型需要两个局部变量表来存储。 局部变量表还用来完成方法调用时参数的传递，一个方法被调用，它的参数会传递至0开始的连续局部变量表位置上。对于实例方法来说，局部变量表第0个位置是用来存储实例方法所在对象的引用，也就是我们通常说的this。 操作数栈操作数栈存在于栈帧中，是一个LIFO的栈，长度由编译期确定，也是存储在方法的Code属性中提供给栈帧使用。 操作数栈会有一个确定的栈深度，一个long或者double类型的数据会占用两个单位的栈深度，其他数据类型则会占用一个单位深度。 动态链接栈帧内部包含一个指向运行时常量池的引用（运行时常量池的解释在下面，可以先看一下运行时常量池），这个引用用来支持当前方法的代码实现动态链接。 Class文件中，一个方法调用其他方法或者访问其成员变量是通过符号引用来表示的，动态链接作用就是将符号引用转换为实际的直接引用。 堆（Heap）堆是各个线程共享的运行时内存区域，也是所有的类实例和数组对象分配内存的区域。堆在虚拟机启动的时候被创建，存储了被垃圾收集器所管理的各种对象。 堆的容量可以是固定大小的，也可以是动态扩展和自动收缩的。Java堆的内存不需要保证是连续的。 Java堆可能发生异常情况： 实际所需的堆超过了最大容量，抛出OutOfMemoryError异常。 方法区（Method Area）方法区也是被各个线程所共享的运行时内存区域。用于存储类的结构信息，例如运行时常量池、字段、方法数据、构造函数、普通方法的字节码内容、还包括一些在类、实例、接口初始化时用到的特殊方法。 方法区在虚拟机启动的时候被创建，是堆的逻辑组成部分。方法区的容量可以是固定大小的，也可以是动态扩展和自动收缩的。内存空间不需要保证是连续的。 方法区可能发生异常的情况： 方法区的内存不能满足内存分配时，会抛出OutOfMemoryError异常。 运行时常量池运行时常量池分配在方法区中，类和接口被加载到虚拟机之后，运行时常量池就被创建了。 运行时常量池是类或接口的常量池的运行时表示形式，包括从编译期可知的数值字面量和运行期解析后才能获得的方法或字段引用。 可能会发生异常的情况： 构造运行时常量池所需的内存空间超过了方法区能提供的最大值，会抛出OutOfMemoryError异常。 本地方法栈（Native Method Stack）用来支持native方法。跟虚拟机栈功能类似。本地方法栈被实现成固定大小或者是动态扩展和收缩的。 可能会发生的异常情况： 如果线程请求的栈容量超过本地方法栈允许的最大容量，会抛出StackOverflowError异常。 如果本地方法栈可动态扩展，申请不到足够的内存去完成扩展，或者建立新线程时没有足够的内存去创建对应的本地方法栈，会抛出OutOfMemoryError异常。 简要总结程序计数器为线程私有，用来指示程序运行时的位置。 Java虚拟机栈是线程私有的，用来存储局部变量表等，出栈入栈对应着方法的结束开始。 堆是线程共享的区域，虚拟机启动时创建，创建的实例对象和数组都分配在堆上。 方法区是线程共享的区域，虚拟机启动时创建，用来存储类的信息，常量字段等等。 本地方法栈用来执行本地方法的。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[tomcat7中对http请求的处理过程]]></title>
      <url>%2F2017%2F05%2F05%2Ftomcat7%E4%B8%AD%E5%AF%B9http%E8%AF%B7%E6%B1%82%E7%9A%84%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[每个Server可以代表Tomcat，每个Server下面有多个Service，每个Service中包含多个Connector和一个Container，Connector用来处理和客户端的通信，然后把请求交给Container进行处理。这里就简单看下处理http请求的流程。Tomcat启动初始化之后，会有一个线程一直在等待连接的到来，接收到新的连接之后，把请求交给相关处理器进行处理，这里等待连接到来的那个角色是一个Acceptor，是JIoEndpoint的内部类，处理连接的角色是SocketProcessor，也是JIoEndpoint的内部类。 Acceptor初始化的过程这里不做说明，直接开始看Acceptor，这个内部类的注释如下：一个一直监听进来的TCP/IP连接的后台线程，并交给适当的processor去处理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263//AbstractEndpoint.Acceptor实现了Runnable接口protected class Acceptor extends AbstractEndpoint.Acceptor &#123; @Override public void run() &#123; int errorDelay = 0; // 一直循环，直到接到shutdown命令 while (running) &#123; // Loop if endpoint is paused while (paused &amp;&amp; running) &#123; state = AcceptorState.PAUSED; try &#123; Thread.sleep(50); &#125; catch (InterruptedException e) &#123; // Ignore &#125; &#125; if (!running) &#123; break; &#125; state = AcceptorState.RUNNING; try &#123; //达到了最大连接数，等待 countUpOrAwaitConnection(); Socket socket = null; try &#123; //接受下一个进来的连接 socket = serverSocketFactory.acceptSocket(serverSocket); &#125; catch (IOException ioe) &#123; //异常，连接数减一个 countDownConnection(); // Introduce delay if necessary errorDelay = handleExceptionWithDelay(errorDelay); throw ioe; &#125; // Successful accept, reset the error delay errorDelay = 0; // 配置socket if (running &amp;&amp; !paused &amp;&amp; setSocketOptions(socket)) &#123; //交给合适的处理器处理Socket if (!processSocket(socket)) &#123; //处理完之后，连接数减少 countDownConnection(); //处理完之后，关闭Socket closeSocket(socket); &#125; &#125; else &#123; countDownConnection(); // Close socket right away closeSocket(socket); &#125; &#125; catch (IOException x) &#123;。。。&#125; &#125; state = AcceptorState.ENDED; &#125;&#125; processSocket可以看到，Acceptor中就是一直循环等待连接到来，连接到来之后，获取到Socket并交给处理器去处理，下面看看processSocket的处理过程。 123456789101112131415161718protected boolean processSocket(Socket socket) &#123; //处理当前Socket中的request try &#123; //将Socket封装成SocketWrapper SocketWrapper&lt;Socket&gt; wrapper = new SocketWrapper&lt;Socket&gt;(socket); //设置连接保持时间 wrapper.setKeepAliveLeft(getMaxKeepAliveRequests()); //设置是否ssl可用 wrapper.setSecure(isSSLEnabled()); // During shutdown, executor may be null - avoid NPE if (!running) &#123; return false; &#125; //创建一个SocketProcessor实例，并提交到线程池执行 getExecutor().execute(new SocketProcessor(wrapper)); &#125; catch (RejectedExecutionException x) &#123;。。。 &#125; return true;&#125; processSocket是将Socket封装成一个SocketWrapper，然后设置其他属性，以wrapper新建一个SocketProcessor实例执行。 SocketProcessorSocketProcessor处理器进行处理包装后的Socket，SocketProcessor也是JIoEndpoint的内部类，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384//实现了Runnable接口protected class SocketProcessor implements Runnable &#123; protected SocketWrapper&lt;Socket&gt; socket = null; protected SocketStatus status = null; public SocketProcessor(SocketWrapper&lt;Socket&gt; socket) &#123; if (socket==null) throw new NullPointerException(); this.socket = socket; &#125; public SocketProcessor(SocketWrapper&lt;Socket&gt; socket, SocketStatus status) &#123; this(socket); this.status = status; &#125; @Override public void run() &#123; boolean launch = false; synchronized (socket) &#123; try &#123; SocketState state = SocketState.OPEN; try &#123; // SSL 握手 serverSocketFactory.handshake(socket.getSocket()); &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); state = SocketState.CLOSED; &#125; if ((state != SocketState.CLOSED)) &#123; if (status == null) &#123; //调用handler的process进行处理，实现是在AbstractProtocol中 state = handler.process(socket, SocketStatus.OPEN_READ); &#125; else &#123; state = handler.process(socket,status); &#125; &#125; if (state == SocketState.CLOSED) &#123; //关闭 countDownConnection(); try &#123; socket.getSocket().close(); &#125; catch (IOException e) &#123; // Ignore &#125; &#125; else if (state == SocketState.OPEN || state == SocketState.UPGRADING || state == SocketState.UPGRADING_TOMCAT || state == SocketState.UPGRADED)&#123; //保持连接设置为true socket.setKeptAlive(true); socket.access(); launch = true; &#125; else if (state == SocketState.LONG) &#123; //作为长连接 socket.access(); waitingRequests.add(socket); &#125; &#125; finally &#123; //launch为true表示上面状态为SocketState.OPEN //保持连接，继续提交到线程池执行 if (launch) &#123; try &#123; getExecutor().execute(new SocketProcessor(socket, SocketStatus.OPEN_READ)); &#125; catch (RejectedExecutionException x) &#123; try &#123; //unable to handle connection at this time handler.process(socket, SocketStatus.DISCONNECT); &#125; finally &#123; countDownConnection(); &#125; &#125; catch (NullPointerException npe) &#123;。。。&#125; &#125; &#125; &#125; socket = null; // Finish up this request &#125;&#125; process方法这里主要的是调用handler的process方法处理请求，实现是在AbstractProtocol的内部抽象类AbstractConnectionHandler中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114public SocketState process(SocketWrapper&lt;S&gt; wrapper, SocketStatus status) &#123; //Socket已经被关闭 if (wrapper == null) &#123; return SocketState.CLOSED; &#125; //取得要处理的Socket S socket = wrapper.getSocket(); if (socket == null) &#123; return SocketState.CLOSED; &#125; //从缓存中获取Socket对应的处理器 Processor&lt;S&gt; processor = connections.get(socket); if (status == SocketStatus.DISCONNECT &amp;&amp; processor == null) &#123; return SocketState.CLOSED; &#125; wrapper.setAsync(false); ContainerThreadMarker.markAsContainerThread(); try &#123; if (processor == null) &#123; //从可循环使用的处理器中查找 processor = recycledProcessors.poll(); &#125; if (processor == null) &#123; //创建处理器 //该方法在子类中实现 //我们这里是http请求，默认是在Http11Protocol的Http11ConnectionHandler中实现的 processor = createProcessor(); &#125; //初始化ssl的信息 //也是在子类中实现的 //默认是在Http11Protocol的Http11ConnectionHandler中实现的 initSsl(wrapper, processor); SocketState state = SocketState.CLOSED; do &#123; if (status == SocketStatus.DISCONNECT &amp;&amp;!processor.isComet()) &#123; &#125; else if (processor.isAsync() || state == SocketState.ASYNC_END) &#123; //异步 state = processor.asyncDispatch(status); if (state == SocketState.OPEN) &#123; getProtocol().endpoint.removeWaitingRequest(wrapper); state = processor.process(wrapper); &#125; &#125; else if (processor.isComet()) &#123;//往下是同步 state = processor.event(status); &#125; else if (processor.getUpgradeInbound() != null) &#123; state = processor.upgradeDispatch(); &#125; else if (processor.isUpgrade()) &#123; state = processor.upgradeDispatch(status); &#125; else &#123; state = processor.process(wrapper); &#125; if (state != SocketState.CLOSED &amp;&amp; processor.isAsync()) &#123; state = processor.asyncPostProcess(); &#125; if (state == SocketState.UPGRADING) &#123; HttpUpgradeHandler httpUpgradeHandler = processor.getHttpUpgradeHandler(); release(wrapper, processor, false, false); processor = createUpgradeProcessor( wrapper, httpUpgradeHandler); wrapper.setUpgraded(true); connections.put(socket, processor); httpUpgradeHandler.init((WebConnection) processor); &#125; else if (state == SocketState.UPGRADING_TOMCAT) &#123; org.apache.coyote.http11.upgrade.UpgradeInbound inbound = processor.getUpgradeInbound(); release(wrapper, processor, false, false); processor = createUpgradeProcessor(wrapper, inbound); inbound.onUpgradeComplete(); &#125; &#125; while (state == SocketState.ASYNC_END || state == SocketState.UPGRADING || state == SocketState.UPGRADING_TOMCAT); //长连接 if (state == SocketState.LONG) &#123; //长连接放入connections中缓存 connections.put(socket, processor); longPoll(wrapper, processor); &#125; else if (state == SocketState.OPEN) &#123; connections.remove(socket); release(wrapper, processor, false, true); &#125; else if (state == SocketState.SENDFILE) &#123; connections.put(socket, processor); &#125; else if (state == SocketState.UPGRADED) &#123; connections.put(socket, processor); if (status != SocketStatus.OPEN_WRITE) &#123; longPoll(wrapper, processor); &#125; &#125; else &#123; connections.remove(socket); if (processor.isUpgrade()) &#123; processor.getHttpUpgradeHandler().destroy(); &#125; else if (processor instanceof org.apache.coyote.http11.upgrade.UpgradeProcessor) &#123; // NO-OP &#125; else &#123; release(wrapper, processor, true, false); &#125; &#125; return state; &#125; catch(java.net.SocketException e) &#123;。。。&#125; connections.remove(socket); if (!(processor instanceof org.apache.coyote.http11.upgrade.UpgradeProcessor) &amp;&amp; !processor.isUpgrade()) &#123; release(wrapper, processor, true, false); &#125; return SocketState.CLOSED;&#125; 同步的process方法createProcessor方法不列出，就是新建一个Http11Processor实例，设置属性。上面process进行处理分为异步和同步，这里我们没有配置，默认使用同步进行处理，process实现在AbstractHttp11Processor中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108public SocketState process(SocketWrapper&lt;S&gt; socketWrapper) throws IOException &#123; //得到请求的信息 RequestInfo rp = request.getRequestProcessor(); rp.setStage(org.apache.coyote.Constants.STAGE_PARSE); setSocketWrapper(socketWrapper); //输入流 getInputBuffer().init(socketWrapper, endpoint); //输出流 getOutputBuffer().init(socketWrapper, endpoint); keepAlive = true; comet = false; openSocket = false; sendfileInProgress = false; readComplete = true; if (endpoint.getUsePolling()) &#123; keptAlive = false; &#125; else &#123; keptAlive = socketWrapper.isKeptAlive(); &#125; if (disableKeepAlive()) &#123; socketWrapper.setKeepAliveLeft(0); &#125; while (!getErrorState().isError() &amp;&amp; keepAlive &amp;&amp; !comet &amp;&amp; !isAsync() &amp;&amp; upgradeInbound == null &amp;&amp; httpUpgradeHandler == null &amp;&amp; !endpoint.isPaused()) &#123; // Parsing the request header try &#123; setRequestLineReadTimeout(); //解析请求行 if (!getInputBuffer().parseRequestLine(keptAlive)) &#123; if (handleIncompleteRequestLineRead()) &#123; break; &#125; &#125; if (endpoint.isPaused()) &#123; // 503 - Service unavailable response.setStatus(503); setErrorState(ErrorState.CLOSE_CLEAN, null); &#125; else &#123; keptAlive = true; request.getMimeHeaders().setLimit(endpoint.getMaxHeaderCount()); request.getCookies().setLimit(getMaxCookieCount()); // 解析请求头 if (!getInputBuffer().parseHeaders()) &#123; openSocket = true; readComplete = false; break; &#125; if (!disableUploadTimeout) &#123; setSocketTimeout(connectionUploadTimeout); &#125; &#125; &#125; catch (IOException e) &#123; 。。。 // 400 - Bad Request response.setStatus(400); setErrorState(ErrorState.CLOSE_CLEAN, t); getAdapter().log(request, response, 0); &#125; if (!getErrorState().isError()) &#123; rp.setStage(org.apache.coyote.Constants.STAGE_PREPARE); try &#123; //读取完请求头之后，需要设置请求的过滤器 prepareRequest(); &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); // 500 - Internal Server Error response.setStatus(500); setErrorState(ErrorState.CLOSE_CLEAN, t); getAdapter().log(request, response, 0); &#125; &#125; if (maxKeepAliveRequests == 1) &#123; keepAlive = false; &#125; else if (maxKeepAliveRequests &gt; 0 &amp;&amp; socketWrapper.decrementKeepAlive() &lt;= 0) &#123; keepAlive = false; &#125; //在Adapter中处理请求 if (!getErrorState().isError()) &#123; try &#123; rp.setStage(org.apache.coyote.Constants.STAGE_SERVICE); //CoyoteAdapter处理 adapter.service(request, response); setCometTimeouts(socketWrapper); &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); // 500 - Internal Server Error response.setStatus(500); setErrorState(ErrorState.CLOSE_CLEAN, t); getAdapter().log(request, response, 0); &#125; &#125; &#125;&#125; 代码比较长，主要的步骤是： parseRequestLine解析请求行。 parseHeaders解析请求头。 prepareReques读取完请求头之后设置过滤器。 adapter.service交给Adapter进行真正的处理。 解析请求行parseRequestLine方法是用来解析请求行的方法，在InternalInputBuffer中，具体代码不做解析。 解析请求头parseHeaders方法是用来解析请求头的方法，在InternalInputBuffer中，具体代码不做解析。 设置过滤器也暂先不做解析。 Adapter真正的进行处理请求真正处理请求的地方在CoyoteAdapter的service方法中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public void service(org.apache.coyote.Request req, org.apache.coyote.Response res) throws Exception &#123; //创建Request和Response对象，将requ和res转换 Request request = (Request) req.getNote(ADAPTER_NOTES); Response response = (Response) res.getNote(ADAPTER_NOTES); if (request == null) &#123; // Create objects request = connector.createRequest(); request.setCoyoteRequest(req); response = connector.createResponse(); response.setCoyoteResponse(res); // Link objects request.setResponse(response); response.setRequest(request); // Set as notes req.setNote(ADAPTER_NOTES, request); res.setNote(ADAPTER_NOTES, response); // Set query string encoding req.getParameters().setQueryStringEncoding (connector.getURIEncoding()); &#125; if (connector.getXpoweredBy()) &#123; response.addHeader(&quot;X-Powered-By&quot;, POWERED_BY); &#125; boolean comet = false; boolean async = false; boolean postParseSuccess = false; try &#123; req.getRequestProcessor().setWorkerThreadName(Thread.currentThread().getName()); //解析请求，根据Request对象找到对应的Host，Context，Wrapper对象 postParseSuccess = postParseRequest(req, request, res, response); if (postParseSuccess) &#123; request.setAsyncSupported(connector.getService().getContainer().getPipeline().isAsyncSupported()); // 调用Container进行处理 //这就交给了Engine去处理了 //通过Pipeline链传递给最终的Servlet去处理 connector.getService().getContainer().getPipeline().getFirst().invoke(request, response); if (request.isComet()) &#123; if (!response.isClosed() &amp;&amp; !response.isError()) &#123; if (request.getAvailable() || (request.getContentLength() &gt; 0 &amp;&amp; (!request.isParametersParsed()))) &#123; // Invoke a read event right away if there are available bytes if (event(req, res, SocketStatus.OPEN_READ)) &#123; comet = true; res.action(ActionCode.COMET_BEGIN, null); &#125; else &#123; return; &#125; &#125; else &#123; comet = true; res.action(ActionCode.COMET_BEGIN, null); &#125; &#125; else &#123; request.setFilterChain(null); &#125; &#125; &#125; //异步 if (request.isAsync()) &#123; 。。。 &#125; else if (!comet) &#123; 。。。 &#125; &#125; catch (IOException e) &#123;。。。&#125; finally &#123;。。。 &#125;&#125; 这里主要做的事情是调用postParseRquest方法对请求进行处理，然后交给Engine去真正处理请求。 postParseRquest123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199protected boolean postParseRequest(org.apache.coyote.Request req, Request request, org.apache.coyote.Response res, Response response) throws Exception &#123; if (! req.scheme().isNull()) &#123; request.setSecure(req.scheme().equals(&quot;https&quot;)); &#125; else &#123; req.scheme().setString(connector.getScheme()); request.setSecure(connector.getSecure()); &#125; String proxyName = connector.getProxyName(); int proxyPort = connector.getProxyPort(); if (proxyPort != 0) &#123; req.setServerPort(proxyPort); &#125; if (proxyName != null) &#123; req.serverName().setString(proxyName); &#125; // Copy the raw URI to the decodedURI MessageBytes decodedURI = req.decodedURI(); decodedURI.duplicate(req.requestURI()); // 解析url的参数 parsePathParameters(req, request); // URI解码 try &#123; req.getURLDecoder().convert(decodedURI, false); &#125; catch (IOException ioe) &#123;。。。&#125; //调用normalize方法判断请求路径是否正确 if (!normalize(req.decodedURI())) &#123; res.setStatus(400); res.setMessage(&quot;Invalid URI&quot;); connector.getService().getContainer().logAccess( request, response, 0, true); return false; &#125; //字符解码 convertURI(decodedURI, request); // 查看解码之后是否正常 if (!checkNormalize(req.decodedURI())) &#123; res.setStatus(400); res.setMessage(&quot;Invalid URI character encoding&quot;); connector.getService().getContainer().logAccess( request, response, 0, true); return false; &#125; //请求映射 MessageBytes serverName; if (connector.getUseIPVHosts()) &#123; serverName = req.localName(); if (serverName.isNull()) &#123; res.action(ActionCode.REQ_LOCAL_NAME_ATTRIBUTE, null); &#125; &#125; else &#123; serverName = req.serverName(); &#125; if (request.isAsyncStarted()) &#123; //TODO SERVLET3 - async //reset mapping data, should prolly be done elsewhere request.getMappingData().recycle(); &#125; String version = null; Context versionContext = null; boolean mapRequired = true; while (mapRequired) &#123; connector.getMapper().map(serverName, decodedURI, version, request.getMappingData()); request.setContext((Context) request.getMappingData().context); request.setWrapper((Wrapper) request.getMappingData().wrapper); if (request.getContext() == null) &#123; res.setStatus(404); res.setMessage(&quot;Not found&quot;); // No context, so use host Host host = request.getHost(); // Make sure there is a host (might not be during shutdown) if (host != null) &#123; host.logAccess(request, response, 0, true); &#125; return false; &#125; //处理sessionId String sessionID; if (request.getServletContext().getEffectiveSessionTrackingModes() .contains(SessionTrackingMode.URL)) &#123; // Get the session ID if there was one sessionID = request.getPathParameter( SessionConfig.getSessionUriParamName( request.getContext())); if (sessionID != null) &#123; request.setRequestedSessionId(sessionID); request.setRequestedSessionURL(true); &#125; &#125; // Look for session ID in cookies and SSL session parseSessionCookiesId(req, request); parseSessionSslId(request); sessionID = request.getRequestedSessionId(); mapRequired = false; if (version != null &amp;&amp; request.getContext() == versionContext) &#123; // We got the version that we asked for. That is it. &#125; else &#123; version = null; versionContext = null; Object[] contexts = request.getMappingData().contexts; if (contexts != null &amp;&amp; sessionID != null) &#123; for (int i = (contexts.length); i &gt; 0; i--) &#123; Context ctxt = (Context) contexts[i - 1]; if (ctxt.getManager().findSession(sessionID) != null) &#123; if (!ctxt.equals(request.getMappingData().context)) &#123; version = ctxt.getWebappVersion(); versionContext = ctxt; request.getMappingData().recycle(); mapRequired = true; request.recycleSessionInfo(); &#125; break; &#125; &#125; &#125; &#125; if (!mapRequired &amp;&amp; request.getContext().getPaused()) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; // Should never happen &#125; // Reset mapping request.getMappingData().recycle(); mapRequired = true; &#125; &#125; //重定向 MessageBytes redirectPathMB = request.getMappingData().redirectPath; if (!redirectPathMB.isNull()) &#123; String redirectPath = urlEncoder.encode(redirectPathMB.toString(), &quot;UTF-8&quot;); String query = request.getQueryString(); if (request.isRequestedSessionIdFromURL()) &#123; redirectPath = redirectPath + &quot;;&quot; + SessionConfig.getSessionUriParamName( request.getContext()) + &quot;=&quot; + request.getRequestedSessionId(); &#125; if (query != null) &#123; redirectPath = redirectPath + &quot;?&quot; + query; &#125; response.sendRedirect(redirectPath); request.getContext().logAccess(request, response, 0, true); return false; &#125; //过滤trace方法 if (!connector.getAllowTrace() &amp;&amp; req.method().equalsIgnoreCase(&quot;TRACE&quot;)) &#123; Wrapper wrapper = request.getWrapper(); String header = null; if (wrapper != null) &#123; String[] methods = wrapper.getServletMethods(); if (methods != null) &#123; for (int i=0; i&lt;methods.length; i++) &#123; if (&quot;TRACE&quot;.equals(methods[i])) &#123; continue; &#125; if (header == null) &#123; header = methods[i]; &#125; else &#123; header += &quot;, &quot; + methods[i]; &#125; &#125; &#125; &#125; res.setStatus(405); res.addHeader(&quot;Allow&quot;, header); res.setMessage(&quot;TRACE method is not allowed&quot;); request.getContext().logAccess(request, response, 0, true); return false; &#125; doConnectorAuthenticationAuthorization(req, request); return true;&#125; Engine去真正处理请求connector.getService().getContainer().getPipeline().getFirst().invoke(request, response);这句代码是Engine处理请求的地方。这里面还有复杂的过程，最后会调用Servlet去处理。这里是责任链模式的使用。 在看一下处理过程之前，先看下这里使用的责任链模式，会更容易理解。 Container中责任链模式的使用在责任链模式中有两个角色：抽象处理者Handler和具体的处理者ConcreteHandler。在抽象处理者中一般会定义一个处理请求的接口，另外还会包含调用下一个或者上一个处理者的方法。 在tomcat中Container就是责任链模式中的抽象处理者，StandardEngine，StandardHost，StandardContext等等是具体的处理者。 请求过来时候，Engine首先接受请求，然后传递给Host容器，接着传递给Context容器，再传递给Wrapper容器，最后给Servlet处理。 而两个容器之间进行请求传递的时候涉及到另外两个概念：Pipeline和Value。Pipeline作为请求传递的管道，这个管道连接两个处理者，Value是管道上对请求加工的组件，就相当于管道上的一个口子，通过这个口子我们可以做一些其他事情。 容器间处理请求connector.getService().getContainer().getPipeline().getFirst().invoke(request, response);看这行代码，首先connector.getService().getContainer()获取到的是一个StandardEngine，然后调用getPipeline()，得到的是一个StandardPipeline标准的管道，接着调用getFirst()方法获取Value，这里没有设置first所以返回的是一个basic，类型是StandardEngineValve，然后调用的是StandardEngineValve的invoke方法，执行处理请求，看下StandardEngineValue的处理方法： 1234567891011121314151617181920public final void invoke(Request request, Response response) throws IOException, ServletException &#123; //从request中获取Host Host host = request.getHost(); if (host == null) &#123; response.sendError (HttpServletResponse.SC_BAD_REQUEST, sm.getString(&quot;standardEngine.noHost&quot;, request.getServerName())); return; &#125; if (request.isAsyncSupported()) &#123; request.setAsyncSupported(host.getPipeline().isAsyncSupported()); &#125; //获取到Host之后，交给Host进行处理，Host就是下一个处理者 host.getPipeline().getFirst().invoke(request, response);&#125; 得到Host之后，Engine就处理完了，该Host进行处理了，也是先获得Pipeline，得到的是StandardPipeline，然后调用getFirst获取到的是StandardHostValue，调用invoke方法： 12345678910public final void invoke(Request request, Response response) throws IOException, ServletException &#123; //获取Context Context context = request.getContext(); 。。。 context.getPipeline().getFirst().invoke(request, response); 。。。 可以看到在Host中处理也是如此，接着是调用Context进行请求处理，到了StandardContextValue的invoke方法进行处理，接着是Wrapper进行处理，调用StandardWrapperValve的invoke方法进行处理。 在StandardWrapperValue中还有构建Filter链的过程，对于Filter的处理也是责任链模式的应用，暂先不做解析。 在Filter链的最后，执行Servlet的service方法，往下就该是Servlet的执行了，有关Servlet的执行流程不再解析。到这里大概的流程就完成了，中间很多细节没有说明，等看完整个源码之后，再做详细说明。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[tomcat7架构简介]]></title>
      <url>%2F2017%2F05%2F05%2Ftomcat7%E6%9E%B6%E6%9E%84%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[这里仅仅是对Tomcat7中主要组件进行简单说明，详细的可以查看下tomcat的相关文档。首先看下网上找来的一张架构图，还有其他的类似的图，可以自行谷歌一下。看图片也大概能了解tomcat整体的组成。 ServerServer表示整个容器，Tomcat提供了一个默认的Server接口的实现，用户几乎很少自己实现Server接口。 ServiceService是一个中间组件，存活于Server中，绑定一个或者多个Connector到一个Engine上。用户很少自己实现Service接口，默认实现已经足够用。 Engine表示一个特定Service的请求处理流程。一个Service可能有多个Connector，Engine接受并处理这些来自Connector的所有请求，将响应传回给适当的Connector以传输到客户端。Engine也很少由用户自定义实现。 HostHost是一个网络名称同Tomcat服务器的关联。Engine可能存在多个Host。 ConnectorConnector处理和客户端的通信。Tomcat中有很多可用的Connector。 ContextContext表示一个web应用，一个Host可能包含多个Context，每个Context都有一个唯一的path。 总的架构Server可以表示是Tomcat，一个Tomcat中只有一个Server，一个Server下面可以有多个Service，每一个Service中包含多个Connector和一个Engine，每个Engine包含多个Host，每个Host包含多个Context。 Engine其实是一个Container，Container是Engine，Host，Context的父接口，这里把Engine称为Container，所以此时可以有如下表示：一个Server下面有多个Service，每个Service包含多个Connector和一个Container。 多个Connector和一个Container组成一个Service，这个Service就可以向外提供服务了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式中的责任链模式解析]]></title>
      <url>%2F2017%2F05%2F05%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B8%AD%E7%9A%84%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[这篇主要是在看Tomcat源码的时候，遇到了责任链模式相关的东西，做一下简单记录，可以和Tomcat源码中责任链的应用对比学习下，会更有效果。 责任链模式的定义 责任链模式（Chain of Responsibility）是一种对象的行为模式。在责任链模式里，很多对象由每一个对象对其下家的引用而连接起来形成一条链。请求在这个链上传递，直到链上的某一个对象决定处理此请求。发出这个请求的客户端并不知道链上的哪一个对象最终处理这个请求，这使得系统可以在不影响客户端的情况下动态地重新组织和分配责任。《JAVA与模式》-阎宏 责任链模式的结构责任链模式总共存在两个角色，抽象处理者（Handler）和具体处理者（ConcreteHandler）。 抽象处理者，定义处理请求的接口，通常也会有包含下一个和上一个处理者的方法，抽象处理者一般是一个接口或者抽象类。 具体处理者，是对抽象处理者的实现，不同的实现。当前如果能处理请求，就处理，如果不能处理请求就交给下家处理。 责任链模式的举例Handler： 123456789101112131415161718package me.cxis.test.gof.chainofresponsibility;/** * Created by cheng.xi on 2017-05-05 17:46. */public abstract class Handler &#123; protected Handler successor; public abstract void handleRequest(String condition); public Handler getSuccessor() &#123; return successor; &#125; public void setSuccessor(Handler successor) &#123; this.successor = successor; &#125;&#125; ConcreteHandler1： 1234567891011121314151617package me.cxis.test.gof.chainofresponsibility;/** * Created by cheng.xi on 2017-05-05 17:49. */public class ConcreteHandler1 extends Handler &#123; @Override public void handleRequest(String condition) &#123; if(condition.equals(&quot;1&quot;))&#123; System.out.println(&quot;ConcreteHandler1处理&quot;); return; &#125;else &#123; System.out.println(&quot;ConcreteHandler1不处理，由其他的Handler处理&quot;); getSuccessor().handleRequest(condition); &#125; &#125;&#125; ConcreteHandler2： 1234567891011121314151617package me.cxis.test.gof.chainofresponsibility;/** * Created by cheng.xi on 2017-05-05 17:49. */public class ConcreteHandler2 extends Handler &#123; @Override public void handleRequest(String condition) &#123; if(condition.equals(&quot;2&quot;))&#123; System.out.println(&quot;ConcreteHandler2处理&quot;); return; &#125;else &#123; System.out.println(&quot;ConcreteHandler2不处理，由其他的Handler处理&quot;); getSuccessor().handleRequest(condition); &#125; &#125;&#125; ConcreteHandlerX： 123456789101112package me.cxis.test.gof.chainofresponsibility;/** * Created by cheng.xi on 2017-05-05 17:49. */public class ConcreteHandlerX extends Handler &#123; @Override public void handleRequest(String condition) &#123; //一般是最后一个处理者 System.out.println(&quot;ConcreteHandlerX处理&quot;); &#125;&#125; Client： 1234567891011121314151617package me.cxis.test.gof.chainofresponsibility;/** * Created by cheng.xi on 2017-05-05 17:53. */public class Client &#123; public static void main(String[] args) &#123; Handler handler1 = new ConcreteHandler1(); Handler handler2 = new ConcreteHandler2(); Handler handlerX = new ConcreteHandlerX(); handler1.setSuccessor(handler2); handler2.setSuccessor(handlerX); handler1.handleRequest(&quot;2&quot;); &#125;&#125; 责任链模式的优点当然上面的例子我们可以直接在Client中写if-else，不过这样耦合度就太高了，而且如果顺序发生变化会很难弄，而责任链模式可以解耦，将发送者和接受者分开。 责任链模式的缺点责任链可能很长，即便某一个点不处理请求，也需要经过这个点，这样会有性能问题。 责任链模式的应用场景 Servlet中的过滤器 Tomcat中的Filter Tomcat中容器的设置]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[http协议简单解析]]></title>
      <url>%2F2017%2F05%2F04%2Fhttp%E5%8D%8F%E8%AE%AE%E7%AE%80%E5%8D%95%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[主要记录一下http协议的一些简单的知识，主要包括请求消息，响应消息的组成，以及get和post的‘对比’，对于更详细的信息可以看下http RFC。https也没有做说明。http基于请求响应模式，无状态，应用层的协议，特点如下： 支持C/S模式。 无连接，每次连接只处理一个请求，服务器处理完请求，并返回给客户端之后，就会断开连接。 无状态，指的是协议对于事务处理没有记忆能力，如果需要前面的信息，需要重传。 http请求消息（Request）http请求由三部分组成：请求行，请求头，请求体。比如下面的例子： 12345678910GET / HTTP/1.1Host: cxis.meConnection: keep-alivePragma: no-cacheCache-Control: no-cacheUpgrade-Insecure-Requests: 1User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.81 Safari/537.36Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8Accept-Encoding: gzip, deflate, sdchAccept-Language: zh-CN,zh;q=0.8,en-US;q=0.6,en;q=0.4,zh-TW;q=0.2,nb;q=0.2,da;q=0.2 GET / HTTP/1.1是请求行，GET是请求方法，/是请求资源在服务器上的路径，HTTP/1.1是http协议版本号。 剩下的是请求头，格式为xxxx: value。 这里是get方法，所有没有请求体，请求体是向服务器提交的数据，在请求头和请求体中间会有一行空行。 http响应消息（Response）响应消息包括：响应行，响应头，响应体。一个响应消息如下： 123456789101112131415161718192021HTTP/1.1 200 OKServer: GitHub.comContent-Type: text/html; charset=utf-8Last-Modified: Wed, 03 May 2017 08:32:57 GMTAccess-Control-Allow-Origin: *Expires: Wed, 03 May 2017 13:51:42 GMTCache-Control: max-age=600Content-Encoding: gzipX-GitHub-Request-Id: AACA:40A3:65A338:8EB391:5909DE15Content-Length: 9905Accept-Ranges: bytesDate: Wed, 03 May 2017 14:41:45 GMTVia: 1.1 varnishAge: 0Connection: keep-aliveX-Served-By: cache-nrt6130-NRTX-Cache: HITX-Cache-Hits: 1X-Timer: S1493822505.031176,VS0,VE181Vary: Accept-EncodingX-Fastly-Request-ID: bc385cef3dbff07f200175fa461c920cb6ca4b3f HTTP/1.1 200 OK是响应行，HTTP/1.1是http协议版本号，200是状态码，OK是状态消息，和响应码对应。 剩下的是响应头，这里没有响应体。GET方法的响应体为空。 请求方法 GET，获取被Request-URI指定的信息。 POST，向服务器提交数据。 HEAD，获取响应消息报头。 PUT，请求服务器保存一个资源。 DELETE，请求服务器删除资源。 TRACE，请求服务器回应收到的请求消息。 OPTIONS，查询相关的资源和选项。 CONNECT，预留关键字，现在没有用。 GET和POST对比GET和POST我觉得不应该硬拿来对比，他们是http规范定义的两种不同的方法，各有各的用处，为什么要对比呢？ 关于定义GET是获取资源，是幂等的；POST是提交资源，是非幂等的。它们是http协议里面定义的两个不同的方法。 关于缓存GET请求的响应是可缓存的，但是需要响应满足HTTP缓存的要求。POST响应是不可缓存的，除非响应里面有Cache-Control或者Expires属性。 关于请求数据GET方法会把请求的数据附加到URL之后，也就是放到请求行中；POST则是把提交的数据放到请求体中。因此在地址栏可以直接看到GET请求提交的参数，而看不到POST请求的参数。 关于安全通常我们说的有关安全，只是相对的安全，比如说GET方法能直接在地址栏看到参数，而POST不能。这通常让人认为是安全和不安全的区别，其实如果抓包或者其他手段一样可以看到GET和POST提交的数据，两者并没有什么安全可言。 关于数据长度http协议并没有对传输的数据大小做限制，也没有对URL长度做限制，所以从http协议本身来说并没有长度的限制。而我们通常说的URL或者数据的长度限制其实是浏览器或者服务器的限制。 对于GET请求来说，提交的数据都会在URL中，各浏览器对URL的限制不太一样，所以没有什么标准可言；对于POST请求来说，数据存放在请求体中，并没有长度限制，但是服务器通常会有对POST提交数据的大小限制，因此也没有标准可言。 关于POST两次请求对于GET请求，浏览器会把请求头和请求体一起发送；而对于POST请求，浏览器会先发送请求头，服务器响应100 continue之后，浏览器再发送请求体。 状态码在响应消息的状态行中有一个状态码和状态消息，两者是对应的，状态码总共有五大类： 1xx，做指示信息，表示请求被接收到，继续处理。 2xx，成功，表示被成功接收，理解，接受。 3xx，重定向，为了完成请求必须采取进一步的动作。 4xx，客户端错误，请求有语法错误或者请求无法实现。 5xx，服务端错误，服务器未能实现请求。 而具体的状态码有很多，不在这里一一列举，下面是一些常用到的： 200 OK，表示请求成功 400 Bad Request 客户端错误，有语法错误 401 Unauthorized，请求未授权 403 Forbidden，服务器拒绝服务 404 Not Found，资源不存在 405 Method Not Allowed，方法不被允许 500 Internal Server Error，服务器内部错误 502 Bad Gateway，网关错误 503 Service Unavailable，服务不可用 消息报头在请求消息的第二部分是请求头，在响应消息的第二部分是响应头，请求头和响应头又叫做消息报头，这是可选的。其实消息报头不只是包括请求头和响应头，一个消息报头包括：普通报头、请求报头、响应报头、实体报头。 下面列出了各种报头，含义没有一一列出，如有需要可以查看http RFC 普通报头普通报头既适用于请求消息也适用于响应消息，这些头域不适用于实体传输，只适用于传输消息。 Cache-Control 控制缓存指令，缓存指令是单向，独立的。 Connection 允许发送指定连接的选项 Date 消息产生的日期和时间 Pragma Trailer Transfer-Encoding Upgrade Via Waring 请求报头 Accept 指定客户端接受哪些类型的信息 Accept-Charset 指定客户端接受的字符集 Accept-Encoding 指定客户端可接受的内容编码 Accept-Language 指定客户端可接受的语言 Authorization 客户端有权限查看某个资源 Expect From Host 指定被请求资源的主机和端口号 If-Match If-Modified-Since If-None-Match If-Range If-Unmodified-Since Max-Forwards Proxy-Authorization Range Referer TE User-Agent 响应报头 Accept-Ranges Age ETag Location Proxy-Authenticate Retry-After Server Vary WWW-Authenticate 实体报头 Allow Content-Encoding Content-Language Content-Length 指明实体正文的长度，以字节方式存储的十进制数字来表示 Content-Location Content-MD5 Content-Range Content-Type 指明发送给接收者的实体正文的媒体类型 Expires 响应过期的日期和时间 Last-Modified 用于指示资源的最后修改日期和时间 extension-header]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[跨域以及CORS相关知识简介]]></title>
      <url>%2F2017%2F05%2F03%2F%E8%B7%A8%E5%9F%9F%E4%BB%A5%E5%8F%8ACORS%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[html同源策略是不允许JavaScript的跨域请求的，而使用CORS（Cross-origin resource sharing）可以实现跨域请求，当然也有其他的办法，常用的有JSONP方式来实现跨域，这里就简单的列举一下实现跨域的几种办法，对于CROS和JSONP详细的了解一下。 CROSCROS可以实现跨域，是HTML5的标准，需要浏览器的支持，同时也需要服务器端的支持。使用CROS实现跨域，主要的工作是在后端实现，需要在服务器端做设置，一般都是设置http头中的Access-Control-Allow-Origin属性，用来指定哪些站点可以访问。 CROS常用属性 Access-Control-Allow-Origin，允许哪些站点访问。 Access-Control-Max-Age，表示多久之内不需要在发送预检请求，有关预检请求下面说明。 Access-Control-Allow-Methods，表示允许的请求方法，比如get、post、delete等。 Access-Control-Allow-Headers，表示允许的content-type。 Access-Control-Allow-Credentials，表示允许请求发送Cookie。 Access-Control-Expose-Headers，表示允许的Header。 CROS中简单请求和非简单请求CROS中简单请求规则： 请求方法是HEAD，GET或者POST。 HTTP头中只能包括以下几种：Accept，Content-Type，Content-Language，Accept-Language，Last-Event-ID 比如有一个get方法，请求头中包括的信息为以上列举的，当浏览器发送请求时发现这是一个简单请求，就会在发送的请求头中自动添加一个Origin表示请求发送的源地址。请求头如下： 123456GET /test HTTP/1.1Accept-Language: en-USConnection: keep-aliveUser-Agent: Mozilla/5.0Host: www.aaa.comOrigin: http://www.bbb.com 服务端接受到请求之后，根据Origin字段判断是否允许该请求，如果服务端允许，则在Http的头信息中添加Access-Control-Allow-Origin以及服务端配置的其他属性，然后返回正确的结果；如果服务端不允许该请求，不会在头信息中添加Access-Control-Allow-Origin属性。 服务端返回结果后，浏览器接收到请求，根据Access-Control-Allow-Origin来决定是否拦截该请求。如果没有这个属性，就会出错，有这个属性就可以正常处理。 非简单请求就是除了上面的简单请求之外的，都是非简单请求。非简单请求的跨域操作，其实会有两次请求到服务端，一次是预检请求（Prelight request），另外一次才是真正的请求。 比如当发送一个DELETE请求时，浏览器会发现这是一个非简单请求，就会先发送一个预检请求，请求如下： 1234567OPTIONS /test HTTP/1.1Accept-Language: en-USConnection: keep-aliveUser-Agent: Mozilla/5.0Host: www.aaa.comOrigin: http://www.bbb.comAccess-Control-Request-Method: DELETE 请注意预检请求使用的是OPTIONS，预检请求会询问服务器是否允许Origin的DELETE方法，允许的话就可以回应了。 浏览器接收到预检请求的回应之后，会根据返回的头信息判断，不允许的话就报错，允许的话就可以发送正常请求了，正在的CORS请求和简单请求一样。 过滤器的形式使用CROS通常可以使用过滤器的形式来实现CROS，只需要实现Filter接口，然后把自定义的过滤器配置到web.xml中即可。 1234567891011121314151617181920212223public class CorsFilter implements Filter &#123; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; &#125; @Override public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) res; response.setHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;); response.setHeader(&quot;Access-Control-Allow-Methods&quot;, &quot;GET,POST,DELETE,PUT,OPTIONS&quot;); response.setHeader(&quot;Access-Control-Allow-Credentials&quot;, true); response.setHeader(&quot;Access-Control-Allow-Headers&quot;,&quot; Content-Type,X-Token&quot;); response.setHeader(&quot;Access-Control-Max-Age&quot;, &quot;3600&quot;); response.setHeader(&quot;Access-Control-Expose-Headers&quot;, &quot;X-My-Header&quot;); chain.doFilter(req, res); &#125; @Override public void destroy() &#123; &#125;&#125; 需要在web.xml中配置过滤器： 123456789&lt;!--支持跨域访问--&gt;&lt;filter&gt;&lt;filter-name&gt;corsFilter&lt;/filter-name&gt;&lt;filter-class&gt;tb.admin.api.cors.CorsFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;corsFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 服务器端设置好了CROS相关配置后，其他前端就可以跨域访问了。 SpringMVC中使用CROSSpringMVC中使用CROS需要到4.2版本之后，并且使用很方便，如果版本对应的话，可以优先考虑使用Spring的CORS配置。 使用@CrossOrigin注解Spring4.2中提供了@CrossOrigin注解，用来实现CROS，@CrossOrigin(origins = &quot;http://localhost:9000&quot;)直接用在Controller中的方法上，也可以用在类级别上。该注解默认允许所有的origins，所有的headers，所有在@RequestMapping中指定的方法，maxAge默认为30分钟。（具体的可以看下Spring相关源码。） 使用全局CORS配置还可以使用全局的CORS配置，继承WebMvcCOnfigurerAdapter来实现： 123456public class CorsConfigurerAdapter extends WebMvcConfigurerAdapter&#123; @Override public void addCorsMappings(CorsRegistry registry) &#123; registry.addMapping(&quot;/*&quot;).allowedOrigins(&quot;http://localhost:9000&quot;); &#125;&#125; 其他的配置也可以依次添加，然后将该类注入到容器中即可。 nginx中配置CORS如果使用了nginx的话，也可以在nginx中配置CORS来实现跨域请求，在nginx.conf里找到server项,并添加如下配置： 1234567location / &#123; add_header &apos;Access-Control-Allow-Origin&apos; &apos;*&apos;; add_header &apos;Access-Control-Allow-Credentials&apos; &apos;true&apos;; add_header &apos;Access-Control-Allow-Headers&apos; &apos;Authorization,Content-Type&apos;; add_header &apos;Access-Control-Allow-Methods&apos; &apos;GET,POST,PUT,DELETE,OPTIONS&apos;;...&#125; nginx具体的测试没有做，猜测原理应该跟上面类似，暂先不做过多解释。 JSONP方式实现跨域在CROS没有出现之前，JSONP方式实现跨域请求十分常见。JSONP原理实际上是对script标签的利用。需要服务端和前端都做处理，现在感觉耦合性有点大了，尤其是跟上面的CORS对比起来。 JSONP只支持get请求，但是它能够支持老的浏览器。 其他方法其他方法还有使用document.domain，src标签，navigation对象，以及html5中的window.postMessage，这里都不做讲解，条件允许，尽量使用新的CORS来解决跨域问题。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring定时器的配置从1.0到5.0的演进]]></title>
      <url>%2F2017%2F04%2F19%2FSpring%E5%AE%9A%E6%97%B6%E5%99%A8%E7%9A%84%E9%85%8D%E7%BD%AE%E4%BB%8E1.0%E5%88%B05.0%E7%9A%84%E6%BC%94%E8%BF%9B%2F</url>
      <content type="text"><![CDATA[这里主要是记录下从Spring1.0到现在的5.0中定时器的配置方式，关于源码，暂先不解释。主要用作自己记录用，如果有错误的还请指出一起改正学习，免得误导别人，谢谢。 Spring1中定时器的配置直接看Spring1.1.1的文档，里面都已经给出来了各种配置方式，更高版本的也都包含了这些，但是觉得看1.1.1的更纯粹一些。 Spring1中对定时器的支持有两种方式： jdk的Timer Quartz Scheduler Quartz SchedulerQuartz Scheduler使用Triggers，Jobs，JobDetail来实现定时器功能。Spring提供了对Quartz的支持。 使用的大概步骤是： 定义JobDetail，也就是定义具体的任务。 定义trigger，就是定义触发器，指定什么任务，在什么时间执行或者隔多久执行。 定义SchedulerFactoryBean，来执行任务。 下面我们以一个例子来说明，是一个定时的去获取信息和定时统计信息的示例。 定义JobDetail定义JobDetail有两种方式，一种是使用JobDetailBean，一种是使用MethodInvokingJobDetailFactoryBean，后者可以指定要执行的具体方法。 使用JobDetailBeanCountUserJob： 1234567891011121314151617181920212223242526package me.cxis.spring.scheduling.quartz;import org.quartz.JobExecutionContext;import org.quartz.JobExecutionException;import org.springframework.scheduling.quartz.QuartzJobBean;/** * Created by cheng.xi on 2017-04-19 11:00. * 定时的统计信息的JOb * 比如这里是定时的统计系统中总的用户数，总的用户数是我查询到的数和我在xml指定的数的总和 */public class CountUserJob extends QuartzJobBean&#123; private int adminUser; public void setAdminUser(int adminUser) &#123; this.adminUser = adminUser; &#125; protected void executeInternal(JobExecutionContext context) throws JobExecutionException &#123; //执行真正的统计任务 System.out.println(&quot;开始统计系统中人数&quot;); System.out.println(&quot;统计完成，共有101人&quot;); System.out.println(&quot;加上系统管理员之后共有&quot; + (adminUser + 101) + &quot;人&quot;); &#125;&#125; xml中声明一个job： 12345678910111213&lt;!--定义一个JobDetailBean类型的Job，用来统计系统中总的人数，adminUser指的是系统中预先留的管理员数目--&gt;&lt;bean name=&quot;countUserJob&quot; class=&quot;org.springframework.scheduling.quartz.JobDetailBean&quot;&gt; &lt;property name=&quot;jobClass&quot;&gt; &lt;value&gt;me.cxis.spring.scheduling.quartz.CountUserJob&lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;jobDataAsMap&quot;&gt; &lt;map&gt; &lt;entry key=&quot;adminUser&quot;&gt; &lt;value&gt;10&lt;/value&gt; &lt;/entry&gt; &lt;/map&gt; &lt;/property&gt;&lt;/bean&gt; 使用MethodInvokingJobDetailFactoryBeanMethodInvokingJobDetailFactoryBean可以指定方法。直接看例子。 GetJob： 1234567891011package me.cxis.spring.scheduling.quartz;/** * Created by cheng.xi on 2017-04-19 11:01. * 定时的获取信息的Job，定时从文件中获取数据 */public class GetJob &#123; public void getSomethingFromFile()&#123; System.out.println(&quot;从文件中获取数据。。。。&quot;); &#125;&#125; xml中配置： 12345678&lt;!--从文件中获取信息的bean--&gt;&lt;bean id=&quot;getJob&quot; class=&quot;me.cxis.spring.scheduling.quartz.GetJob&quot;/&gt;&lt;!--定义一个MethodInvokingJobDetailFactoryBean，从文件中获取数据的Job--&gt;&lt;bean id=&quot;getJobDetail&quot; class=&quot;org.springframework.scheduling.quartz.MethodInvokingJobDetailFactoryBean&quot;&gt; &lt;property name=&quot;targetObject&quot;&gt;&lt;ref bean=&quot;getJob&quot;/&gt;&lt;/property&gt; &lt;property name=&quot;targetMethod&quot;&gt;&lt;value&gt;getSomethingFromFile&lt;/value&gt;&lt;/property&gt;&lt;/bean&gt; 定义Triggers上面我们把JobDetail都定义好了，也都配置好了，但是怎么去执行，多长时间执行一次都没有说明，这时候需要定义Triggers来描述任务什么时候执行等。只需要在xml中配置就可以了。 Triggers也有两种方式，一种是SimpleTriggerBean，一种是CronTriggerBean。我们的例子中，统计用户数使用SimpleTriggerBean，从文件中获取信息使用CronTriggerBean。 1234567891011121314151617181920212223242526&lt;!--定义Triggers，统计用户数--&gt;&lt;bean id=&quot;countUserTrigger&quot; class=&quot;org.springframework.scheduling.quartz.SimpleTriggerBean&quot;&gt; &lt;property name=&quot;jobDetail&quot;&gt; &lt;ref bean=&quot;countUserJob&quot;/&gt; &lt;/property&gt; &lt;!--第一次执行之前需要等待的时间--&gt; &lt;property name=&quot;startDelay&quot;&gt; &lt;!--10秒--&gt; &lt;value&gt;10000&lt;/value&gt; &lt;/property&gt; &lt;!--任务重复时间，每隔多少时间执行一次--&gt; &lt;property name=&quot;repeatInterval&quot;&gt; &lt;value&gt;20000&lt;/value&gt; &lt;/property&gt;&lt;/bean&gt;&lt;!--定义Triggers，定时从文件中获取数据--&gt;&lt;bean id=&quot;getJobTrigger&quot; class=&quot;org.springframework.scheduling.quartz.CronTriggerBean&quot;&gt; &lt;property name=&quot;jobDetail&quot;&gt; &lt;ref bean=&quot;getJobDetail&quot;/&gt; &lt;/property&gt; &lt;property name=&quot;cronExpression&quot;&gt; &lt;!--cron表达式，这里是每隔两分钟执行一次--&gt; &lt;value&gt;0 0/2 * * * ?&lt;/value&gt; &lt;/property&gt;&lt;/bean&gt; 定义SchedulerFactoryBean123456789&lt;!--定义SchedulerFactoryBean--&gt;&lt;bean class=&quot;org.springframework.scheduling.quartz.SchedulerFactoryBean&quot;&gt; &lt;property name=&quot;triggers&quot;&gt; &lt;list&gt; &lt;ref local=&quot;countUserTrigger&quot;/&gt; &lt;ref local=&quot;getJobTrigger&quot;/&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; 测试Main： 12345678910111213package me.cxis.spring.scheduling.quartz;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;/** * Created by cheng.xi on 2017-04-19 11:34. */public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;classpath:scheduling-quartz.xml&quot;); &#125;&#125; JDK Timer使用JDK Timer，也跟上面类似，大概的步骤是： 创建一个TimerTask，里面是执行任务的逻辑。 创建ScheduledTimerTask，就是什么时候或者隔多久执行任务。 创建TimerFactoryBean，来执行任务。 创建TimerTask同样，创建一个Task也有两种方式，一种是继承TimerTask，另外一种是使用MethodInvokingTimerTaskFactoryBean，后者可以指定具体方法。 继承TimerTaskCountUserTask： 123456789101112131415161718192021222324package me.cxis.spring.scheduling.timer;import java.util.TimerTask;/** * Created by cheng.xi on 2017-04-19 11:00. * 定时的统计信息的 task * 比如这里是定时的统计系统中总的用户数，总的用户数是我查询到的数和我在xml指定的数的总和 */public class CountUserTask extends TimerTask&#123; private int adminUser; public void setAdminUser(int adminUser) &#123; this.adminUser = adminUser; &#125; public void run() &#123; //执行真正的统计任务 System.out.println(&quot;开始统计系统中人数&quot;); System.out.println(&quot;统计完成，共有101人&quot;); System.out.println(&quot;加上系统管理员之后共有&quot; + (adminUser + 101) + &quot;人&quot;); &#125;&#125; 在xml中配置bean： 123456&lt;!--统计用户数的bean--&gt;&lt;bean id=&quot;countUserTask&quot; class=&quot;me.cxis.spring.scheduling.timer.CountUserTask&quot;&gt; &lt;property name=&quot;adminUser&quot;&gt; &lt;value&gt;10&lt;/value&gt; &lt;/property&gt;&lt;/bean&gt; 使用MethodInvokingTimerTaskFactoryBeanGetTask: 1234567891011package me.cxis.spring.scheduling.timer;/** * Created by cheng.xi on 2017-04-19 11:01. * 定时的获取信息的task，定时从文件中获取数据 */public class GetTask &#123; public void getSomethingFromFile()&#123; System.out.println(&quot;从文件中获取数据。。。。&quot;); &#125;&#125; xml中配置： 12345678&lt;!--从文件中获取信息的bean--&gt;&lt;bean id=&quot;getTaskBean&quot; class=&quot;me.cxis.spring.scheduling.timer.GetTask&quot;&gt;&lt;/bean&gt;&lt;!--使用MethodInvokingTimerTaskFactoryBean--&gt;&lt;bean id=&quot;getTask&quot; class=&quot;org.springframework.scheduling.timer.MethodInvokingTimerTaskFactoryBean&quot;&gt; &lt;property name=&quot;targetObject&quot;&gt;&lt;ref bean=&quot;getTaskBean&quot;/&gt; &lt;/property&gt; &lt;property name=&quot;targetMethod&quot;&gt;&lt;value&gt;getSomethingFromFile&lt;/value&gt;&lt;/property&gt;&lt;/bean&gt; 创建ScheduledTimerTask定义ScheduledTimerTask来描述任务什么时候执行等。只需要在xml中配置就可以了。 使用Timer的方式，就这么一种配置，没法使用cron的方式。 12345678910111213141516171819202122&lt;!--创建统计用户的ScheduledTimerTask，描述任务怎么运行--&gt;&lt;bean id=&quot;countUserScheduledTimerTask&quot; class=&quot;org.springframework.scheduling.timer.ScheduledTimerTask&quot;&gt; &lt;property name=&quot;delay&quot;&gt; &lt;value&gt;10000&lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;period&quot;&gt; &lt;value&gt;20000&lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;timerTask&quot;&gt; &lt;ref local=&quot;countUserTask&quot;/&gt; &lt;/property&gt;&lt;/bean&gt;&lt;!--创建从文件获取信息的ScheduledTimerTask，描述任务怎么运行--&gt;&lt;bean id=&quot;getScheduledTimerTask&quot; class=&quot;org.springframework.scheduling.timer.ScheduledTimerTask&quot;&gt; &lt;property name=&quot;period&quot;&gt; &lt;value&gt;60000&lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;timerTask&quot;&gt; &lt;ref local=&quot;getTask&quot;/&gt; &lt;/property&gt;&lt;/bean&gt; 创建TimerFactoryBean任务执行的配置： 123456789&lt;!--创建TimerFactoryBean，执行任务--&gt;&lt;bean id=&quot;timerFactory&quot; class=&quot;org.springframework.scheduling.timer.TimerFactoryBean&quot;&gt; &lt;property name=&quot;scheduledTimerTasks&quot;&gt; &lt;list&gt; &lt;ref local=&quot;countUserScheduledTimerTask&quot;/&gt; &lt;ref local=&quot;getScheduledTimerTask&quot;/&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; 测试123456789101112131415161718192021package me.cxis.spring.scheduling.timer;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import java.io.IOException;import java.io.InputStream;/** * Created by cheng.xi on 2017-04-19 11:34. */public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;classpath:scheduling-timer.xml&quot;); try &#123; System.in.read(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 上面就是Spring1.x中关于定时器的配置方式，配置清晰，易懂，但是任务多了之后，就会发现配置文件会迅速变得臃肿。 Spring2中定时器的配置What’s new in Spring 2.0? 增加对Executors的支持 上面就是AOP在2.0版本新增的特性，1.0的所有AOP配置方式在2.0中都支持，下面主要看看2.0中新增的一些方法。 Spring2.0中新定义了一个TaskExecutor接口，增加了对线程池的支持，这个接口的功能跟JDK1.5中的Executor接口一样。那么2.0中线程池的增加，对定时器有什么影响呢？其实就是可以在定时任务执行的时候，使用线程池来执行任务，我们不用关心其他的实现。 Spring2中配置示例直接看示例，我们定时，每隔5分钟，每次都从20个文件中同时获取数据。 首先写实际执行业务的类， 12345678910111213141516171819package me.cxis.spring.scheduling.executor;/** * Created by cheng.xi on 2017-04-19 14:51. * 从文件中获取数据的Task */public class GetDataFromFileTask implements Runnable &#123; private int fileId; public GetDataFromFileTask(int fileId)&#123; this.fileId = fileId; &#125; public void run() &#123; //真正执行从文件中获取数据的逻辑 System.out.println(&quot;从文件&quot; + fileId + &quot;中获取数据&quot;); &#125;&#125; 然后是执行任务的定时器： 1234567891011121314151617181920212223242526package me.cxis.spring.scheduling.executor;import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;import java.util.TimerTask;/** * Created by cheng.xi on 2017-04-19 14:54. * 批量从文件中获取数据的定时器 */public class GetDataFromFileScheduler extends TimerTask &#123; private ThreadPoolTaskExecutor executor; public void setExecutor(ThreadPoolTaskExecutor executor) &#123; this.executor = executor; &#125; public void run() &#123; System.out.println(&quot;CorePoolSize:&quot; + taskExecutor.getCorePoolSize() + &quot;;MaxPoolSize:&quot; + taskExecutor.getMaxPoolSize()); //每次都会同时执行从20个文件中获取数据 for(int i = 0; i &lt; 20;i++)&#123; executor.execute(new GetDataFromFileTask(i)); &#125; &#125;&#125; 接着是xml的配置： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE beans PUBLIC &quot;-//SPRING//DTD BEAN//EN&quot; &quot;http://www.springframework.org/dtd/spring-beans.dtd&quot;&gt;&lt;beans&gt; &lt;!--线程池taskExecutor--&gt; &lt;bean id=&quot;taskExecutor&quot; class=&quot;org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor&quot;&gt; &lt;!--核心线程数--&gt; &lt;property name=&quot;corePoolSize&quot;&gt; &lt;value&gt;5&lt;/value&gt; &lt;/property&gt; &lt;!--最大线程数--&gt; &lt;property name=&quot;maxPoolSize&quot;&gt; &lt;value&gt;10&lt;/value&gt; &lt;/property&gt; &lt;!--队列最大长度--&gt; &lt;property name=&quot;queueCapacity&quot;&gt; &lt;value&gt;40&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!--GetDataFromFileScheduler，获取数据的定时器--&gt; &lt;bean id=&quot;getDataFromFileScheduler&quot; class=&quot;me.cxis.spring.scheduling.executor.GetDataFromFileScheduler&quot;&gt; &lt;property name=&quot;taskExecutor&quot;&gt; &lt;ref local=&quot;taskExecutor&quot;/&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!--创建统计用户的ScheduledTimerTask，描述任务怎么运行--&gt; &lt;bean id=&quot;getDataFromFileTimerTask&quot; class=&quot;org.springframework.scheduling.timer.ScheduledTimerTask&quot;&gt; &lt;property name=&quot;delay&quot;&gt; &lt;value&gt;10000&lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;period&quot;&gt; &lt;value&gt;20000&lt;/value&gt; &lt;/property&gt; &lt;property name=&quot;timerTask&quot;&gt; &lt;ref local=&quot;getDataFromFileScheduler&quot;/&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!--创建TimerFactoryBean，执行任务--&gt; &lt;bean id=&quot;timerFactory&quot; class=&quot;org.springframework.scheduling.timer.TimerFactoryBean&quot;&gt; &lt;property name=&quot;scheduledTimerTasks&quot;&gt; &lt;list&gt; &lt;ref local=&quot;getDataFromFileTimerTask&quot;/&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 测试类： 12345678910111213package me.cxis.spring.scheduling.executor;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;/** * Created by cheng.xi on 2017-04-19 15:11. */public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;classpath:scheduling-executor.xml&quot;); &#125;&#125; 上面就是结合线程池的示例。也就是在执行任务的时候多了线程池，基本的配置方式使用方法基本没变。 Spring3中定时器的配置 Spring3中TaskExecutor继承了JDK的Executor。使用方面还是跟原来2.0一样。 Spring3中还引入了新的接口TaskScheduler，Trigger，TriggerContext等。 Spring3中还引入了task的命名空间&lt;task:scheduler/&gt;，&lt;task:executor/&gt;，&lt;task:scheduled-tasks/&gt;等。 Spring3中还支持注解的方式@Scheduled，@Async，使配置更加简化。使用注解的方式，需要在配置文件中先开启注解支持&lt;task:annotation-driven/&gt; 注解方式的示例如下。 CountUserTask： 123456789101112131415161718192021package me.cxis.spring.scheduling.annotation;import org.springframework.scheduling.annotation.Scheduled;/** * Created by cheng.xi on 2017-04-19 11:00. * 定时的统计信息的Task * */public class CountUserTask&#123; //@Scheduled(cron=&quot;*/5 * * * * MON-FRI&quot;) cron的方式 //下面是固定时间，每隔5秒执行一次 @Scheduled(fixedRate = 5000) public void countUser()&#123; //执行真正的统计任务 System.out.println(&quot;开始统计系统中人数&quot;); System.out.println(&quot;统计完成，共有101人&quot;); &#125;&#125; 配置文件： 1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:task=&quot;http://www.springframework.org/schema/task&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task.xsd&quot;&gt; &lt;!--开启task的注解支持--&gt; &lt;task:annotation-driven /&gt; &lt;!--执行任务的bean--&gt; &lt;bean id=&quot;countUserTask&quot; class=&quot;me.cxis.spring.scheduling.annotation.CountUserTask&quot;/&gt;&lt;/beans&gt; 测试： 1234567891011121314151617181920package me.cxis.spring.scheduling.annotation;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import java.io.IOException;/** * Created by cheng.xi on 2017-04-19 16:08. */public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;classpath:scheduling-annotation.xml&quot;); try &#123; System.in.read(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 可以看到，使用注解的方式简化了很多很多。 Spring4和Spring5中定时器的配置Spring4中增加了@EnableScheduling注解来启用对@Scheduled注解的支持。其他的基本没有什么变化，使用方式还是跟以前一样，现在使用注解更多。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java中SPI机制深入及源码解析]]></title>
      <url>%2F2017%2F04%2F17%2FJava%E4%B8%ADSPI%E6%9C%BA%E5%88%B6%E6%B7%B1%E5%85%A5%E5%8F%8A%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[SPI，Service Provider Interface，主要是被框架的开发人员使用，比如java.sql.Driver接口，其他不同厂商可以针对同一接口做出不同的实现，mysql和postgresql都有不同的实现提供给用户，而Java的SPI机制可以为某个接口寻找服务实现。当服务的提供者提供了一种接口的实现之后，需要在classpath下的META-INF/services/目录里创建一个以服务接口命名的文件，这个文件里的内容就是这个接口的具体的实现类。当其他的程序需要这个服务的时候，就可以通过查找这个jar包（一般都是以jar包做依赖）的META-INF/services/中的配置文件，配置文件中有接口的具体实现类名，可以根据这个类名进行加载实例化，就可以使用该服务了。JDK中查找服务的实现的工具类是：java.util.ServiceLoader。 SPI实例有很多的SPI扩展机制应用的实例，比如common-logging，JDBC等等，我们这里以JDBC为例。 JDBC在JDBC4.0之前，我们开发有连接数据库的时候，通常会用Class.forName(&quot;com.mysql.jdbc.Driver&quot;)这句先加载数据库相关的驱动，然后再进行获取连接等的操作。而JDBC4.0之后不需要用Class.forName(&quot;com.mysql.jdbc.Driver&quot;)来加载驱动，直接获取连接就可以了，现在这种方式就是使用了Java的SPI扩展机制来实现。 JDBC接口定义首先在java中定义了接口java.sql.Driver，并没有具体的实现，具体的实现都是由不同厂商来提供的。 mysql实现在mysql的jar包mysql-connector-java-6.0.6.jar中，可以找到META-INF/services目录，该目录下会有一个名字为java.sql.Driver的文件，文件内容是com.mysql.cj.jdbc.Driver，这里面的内容就是针对Java中定义的接口的实现。 postgresql实现同样在postgresql的jar包postgresql-42.0.0.jar中，也可以找到同样的配置文件，文件内容是org.postgresql.Driver，这是postgresql对Java的java.sql.Driver的实现。 使用方法上面说了，现在使用SPI扩展来加载具体的驱动，我们在Java中写连接数据库的代码的时候，不需要再使用Class.forName(&quot;com.mysql.jdbc.Driver&quot;)来加载驱动了，而是直接使用如下代码： 123String url = &quot;jdbc:xxxx://xxxx:xxxx/xxxx&quot;;Connection conn = DriverManager.getConnection(url,username,password);..... 这里并没有涉及到spi的使用，接着看下面的解析。 源码实现上面的使用方法，就是我们普通的连接数据库的代码，并没有涉及到SPI的东西，但是有一点我们可以确定的是，我们没有写有关具体驱动的硬编码Class.forName(&quot;com.mysql.jdbc.Driver&quot;)！ 上面的代码可以直接获取数据库连接进行操作，但是跟SPI有啥关系呢？上面代码没有了加载驱动的代码，我们怎么去确定使用哪个数据库连接的驱动呢？这里就涉及到使用Java的SPI扩展机制来查找相关驱动的东西了，关于驱动的查找其实都在DriverManager中，DriverManager是Java中的实现，用来获取数据库连接，在DriverManager中有一个静态代码块如下： 1234static &#123; loadInitialDrivers(); println(&quot;JDBC DriverManager initialized&quot;);&#125; 可以看到是加载实例化驱动的，接着看loadInitialDrivers方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445private static void loadInitialDrivers() &#123; String drivers; try &#123; drivers = AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() &#123; public String run() &#123; return System.getProperty(&quot;jdbc.drivers&quot;); &#125; &#125;); &#125; catch (Exception ex) &#123; drivers = null; &#125; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; //使用SPI的ServiceLoader来加载接口的实现 ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator(); try&#123; while(driversIterator.hasNext()) &#123; driversIterator.next(); &#125; &#125; catch(Throwable t) &#123; // Do nothing &#125; return null; &#125; &#125;); println(&quot;DriverManager.initialize: jdbc.drivers = &quot; + drivers); if (drivers == null || drivers.equals(&quot;&quot;)) &#123; return; &#125; String[] driversList = drivers.split(&quot;:&quot;); println(&quot;number of Drivers:&quot; + driversList.length); for (String aDriver : driversList) &#123; try &#123; println(&quot;DriverManager.Initialize: loading &quot; + aDriver); Class.forName(aDriver, true, ClassLoader.getSystemClassLoader()); &#125; catch (Exception ex) &#123; println(&quot;DriverManager.Initialize: load failed: &quot; + ex); &#125; &#125;&#125; 上面的代码主要步骤是： 从系统变量中获取有关驱动的定义。 使用SPI来获取驱动的实现。 遍历使用SPI获取到的具体实现，实例化各个实现类。 根据第一步获取到的驱动列表来实例化具体实现类。 我们主要关注2,3步，这两步是SPI的用法，首先看第二步，使用SPI来获取驱动的实现，对应的代码是： 1ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); 这里没有去META-INF/services目录下查找配置文件，也没有加载具体实现类，做的事情就是封装了我们的接口类型和类加载器，并初始化了一个迭代器。 接着看第三步，遍历使用SPI获取到的具体实现，实例化各个实现类，对应的代码如下： 123456//获取迭代器Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator();//遍历所有的驱动实现while(driversIterator.hasNext()) &#123; driversIterator.next();&#125; 在遍历的时候，首先调用driversIterator.hasNext()方法，这里会搜索classpath下以及jar包中所有的META-INF/services目录下的java.sql.Driver文件，并找到文件中的实现类的名字，此时并没有实例化具体的实现类（ServiceLoader具体的源码实现在下面）。 然后是调用driversIterator.next();方法，此时就会根据驱动名字具体实例化各个实现类了。现在驱动就被找到并实例化了。 可以看下截图，我在测试项目中添加了两个jar包，mysql-connector-java-6.0.6.jar和postgresql-42.0.0.0.jar，跟踪到DriverManager中之后： 可以看到此时迭代器中有两个驱动，mysql和postgresql的都被加载了。有关两个驱动都加载了，具体使用哪个驱动，请自行深入jdbc的源码。这里不做过多解析。 SPI的使用步骤总结看完上面的数据库驱动的解析，应该都能知道大概的流程了： 有关组织或者公司定义标准。 具体厂商或者框架开发者实现。 程序猿使用。 定义标准定义标准，就是定义接口。比如接口java.sql.Driver 具体厂商或者框架开发者实现。厂商或者框架开发者开发具体的实现： 在META-INF/services目录下定义一个名字为接口全限定名的文件，比如java.sql.Driver文件，文件内容是具体的实现名字，比如me.cxis.sql.MyDriver。 写具体的实现me.cxis.sql.MyDriver，都是对接口Driver的实现。 程序猿使用我们会引用具体厂商的jar包来实现我们的功能： 12345678ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class);//获取迭代器Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator();//遍历while(driversIterator.hasNext()) &#123; driversIterator.next(); //可以做具体的业务逻辑&#125; SPI相关的源码解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259//ServiceLoader实现了Iterable接口，可以遍历所有的服务实现者public final class ServiceLoader&lt;S&gt; implements Iterable&lt;S&gt;&#123; //查找配置文件的目录 private static final String PREFIX = &quot;META-INF/services/&quot;; //表示要被加载的服务的类或接口 private final Class&lt;S&gt; service; //这个ClassLoader用来定位，加载，实例化服务提供者 private final ClassLoader loader; // 访问控制上下文 private final AccessControlContext acc; // 缓存已经被实例化的服务提供者，按照实例化的顺序存储 private LinkedHashMap&lt;String,S&gt; providers = new LinkedHashMap&lt;&gt;(); // 迭代器 private LazyIterator lookupIterator; //重新加载，就相当于重新创建ServiceLoader了，用于新的服务提供者安装到正在运行的Java虚拟机中的情况。 public void reload() &#123; //清空缓存中所有已实例化的服务提供者 providers.clear(); //新建一个迭代器，该迭代器会从头查找和实例化服务提供者 lookupIterator = new LazyIterator(service, loader); &#125; //私有构造器 //使用指定的类加载器和服务创建服务加载器 //如果没有指定类加载器，使用系统类加载器，就是应用类加载器。 private ServiceLoader(Class&lt;S&gt; svc, ClassLoader cl) &#123; service = Objects.requireNonNull(svc, &quot;Service interface cannot be null&quot;); loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl; acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null; reload(); &#125; //解析失败处理的方法 private static void fail(Class&lt;?&gt; service, String msg, Throwable cause) throws ServiceConfigurationError &#123; throw new ServiceConfigurationError(service.getName() + &quot;: &quot; + msg, cause); &#125; private static void fail(Class&lt;?&gt; service, String msg) throws ServiceConfigurationError &#123; throw new ServiceConfigurationError(service.getName() + &quot;: &quot; + msg); &#125; private static void fail(Class&lt;?&gt; service, URL u, int line, String msg) throws ServiceConfigurationError &#123; fail(service, u + &quot;:&quot; + line + &quot;: &quot; + msg); &#125; //解析服务提供者配置文件中的一行 //首先去掉注释校验，然后保存 //返回下一行行号 //重复的配置项和已经被实例化的配置项不会被保存 private int parseLine(Class&lt;?&gt; service, URL u, BufferedReader r, int lc, List&lt;String&gt; names) throws IOException, ServiceConfigurationError &#123; //读取一行 String ln = r.readLine(); if (ln == null) &#123; return -1; &#125; //#号代表注释行 int ci = ln.indexOf(&apos;#&apos;); if (ci &gt;= 0) ln = ln.substring(0, ci); ln = ln.trim(); int n = ln.length(); if (n != 0) &#123; if ((ln.indexOf(&apos; &apos;) &gt;= 0) || (ln.indexOf(&apos;\t&apos;) &gt;= 0)) fail(service, u, lc, &quot;Illegal configuration-file syntax&quot;); int cp = ln.codePointAt(0); if (!Character.isJavaIdentifierStart(cp)) fail(service, u, lc, &quot;Illegal provider-class name: &quot; + ln); for (int i = Character.charCount(cp); i &lt; n; i += Character.charCount(cp)) &#123; cp = ln.codePointAt(i); if (!Character.isJavaIdentifierPart(cp) &amp;&amp; (cp != &apos;.&apos;)) fail(service, u, lc, &quot;Illegal provider-class name: &quot; + ln); &#125; if (!providers.containsKey(ln) &amp;&amp; !names.contains(ln)) names.add(ln); &#125; return lc + 1; &#125; //解析配置文件，解析指定的url配置文件 //使用parseLine方法进行解析，未被实例化的服务提供者会被保存到缓存中去 private Iterator&lt;String&gt; parse(Class&lt;?&gt; service, URL u) throws ServiceConfigurationError &#123; InputStream in = null; BufferedReader r = null; ArrayList&lt;String&gt; names = new ArrayList&lt;&gt;(); try &#123; in = u.openStream(); r = new BufferedReader(new InputStreamReader(in, &quot;utf-8&quot;)); int lc = 1; while ((lc = parseLine(service, u, r, lc, names)) &gt;= 0); &#125; return names.iterator(); &#125; //服务提供者查找的迭代器 private class LazyIterator implements Iterator&lt;S&gt; &#123; Class&lt;S&gt; service;//服务提供者接口 ClassLoader loader;//类加载器 Enumeration&lt;URL&gt; configs = null;//保存实现类的url Iterator&lt;String&gt; pending = null;//保存实现类的全名 String nextName = null;//迭代器中下一个实现类的全名 private LazyIterator(Class&lt;S&gt; service, ClassLoader loader) &#123; this.service = service; this.loader = loader; &#125; private boolean hasNextService() &#123; if (nextName != null) &#123; return true; &#125; if (configs == null) &#123; try &#123; String fullName = PREFIX + service.getName(); if (loader == null) configs = ClassLoader.getSystemResources(fullName); else configs = loader.getResources(fullName); &#125; &#125; while ((pending == null) || !pending.hasNext()) &#123; if (!configs.hasMoreElements()) &#123; return false; &#125; pending = parse(service, configs.nextElement()); &#125; nextName = pending.next(); return true; &#125; private S nextService() &#123; if (!hasNextService()) throw new NoSuchElementException(); String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try &#123; c = Class.forName(cn, false, loader); &#125; if (!service.isAssignableFrom(c)) &#123; fail(service, &quot;Provider &quot; + cn + &quot; not a subtype&quot;); &#125; try &#123; S p = service.cast(c.newInstance()); providers.put(cn, p); return p; &#125; &#125; public boolean hasNext() &#123; if (acc == null) &#123; return hasNextService(); &#125; else &#123; PrivilegedAction&lt;Boolean&gt; action = new PrivilegedAction&lt;Boolean&gt;() &#123; public Boolean run() &#123; return hasNextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125; &#125; public S next() &#123; if (acc == null) &#123; return nextService(); &#125; else &#123; PrivilegedAction&lt;S&gt; action = new PrivilegedAction&lt;S&gt;() &#123; public S run() &#123; return nextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125; &#125; public void remove() &#123; throw new UnsupportedOperationException(); &#125; &#125; //获取迭代器 //返回遍历服务提供者的迭代器 //以懒加载的方式加载可用的服务提供者 //懒加载的实现是：解析配置文件和实例化服务提供者的工作由迭代器本身完成 public Iterator&lt;S&gt; iterator() &#123; return new Iterator&lt;S&gt;() &#123; //按照实例化顺序返回已经缓存的服务提供者实例 Iterator&lt;Map.Entry&lt;String,S&gt;&gt; knownProviders = providers.entrySet().iterator(); public boolean hasNext() &#123; if (knownProviders.hasNext()) return true; return lookupIterator.hasNext(); &#125; public S next() &#123; if (knownProviders.hasNext()) return knownProviders.next().getValue(); return lookupIterator.next(); &#125; public void remove() &#123; throw new UnsupportedOperationException(); &#125; &#125;; &#125; //为指定的服务使用指定的类加载器来创建一个ServiceLoader public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service, ClassLoader loader) &#123; return new ServiceLoader&lt;&gt;(service, loader); &#125; //使用线程上下文的类加载器来创建ServiceLoader public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) &#123; ClassLoader cl = Thread.currentThread().getContextClassLoader(); return ServiceLoader.load(service, cl); &#125; //使用扩展类加载器为指定的服务创建ServiceLoader //只能找到并加载已经安装到当前Java虚拟机中的服务提供者，应用程序类路径中的服务提供者将被忽略 public static &lt;S&gt; ServiceLoader&lt;S&gt; loadInstalled(Class&lt;S&gt; service) &#123; ClassLoader cl = ClassLoader.getSystemClassLoader(); ClassLoader prev = null; while (cl != null) &#123; prev = cl; cl = cl.getParent(); &#125; return ServiceLoader.load(service, prev); &#125; public String toString() &#123; return &quot;java.util.ServiceLoader[&quot; + service.getName() + &quot;]&quot;; &#125;&#125; ServiceLoader不是实例化以后，就去读取配置文件中的具体实现，并进行实例化。而是等到使用迭代器去遍历的时候，才会加载对应的配置文件去解析，调用hasNext方法的时候会去加载配置文件进行解析，调用next方法的时候进行实例化并缓存。 所有的配置文件只会加载一次，服务提供者也只会被实例化一次，重新加载配置文件可使用reload方法。 SPI缺点通过上面的解析，可以发现，我们使用SPI查找具体的实现的时候，需要遍历所有的实现，并实例化，然后我们在循环中才能找到我们需要实现。这应该也是最大的缺点，需要把所有的实现都实例化了，即便我们不需要，也都给实例化了。 有关SPI的东西暂先了解到这里，有深入的以后再添加。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[从头开始写一个迷你dubbo]]></title>
      <url>%2F2017%2F04%2F14%2F%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E4%B8%80%E4%B8%AA%E8%BF%B7%E4%BD%A0dubbo%2F</url>
      <content type="text"><![CDATA[从头开始写一个迷你的dubbo，仅用作学习用，学习的过程中更深入的了解下dubbo，同时也补充下其他的知识。 工程说明mini-dubbo-provider服务提供者端，主要是暴露服务，处理消费者端请求等 mini-dubbo-consumer服务消费者端，主要作用是引用服务 mini-dubbo-common一些公用类 mini-dubbo-sample-*sample是示例项目 目标 可以使用API和Spring两种方式启动 提供完整暴露服务和服务引用功能 提供多协议支持 实现注册中心支持 提供自定义编解码 使用Netty和Mina 提供对多种序列化的支持 已有实现 可以使用API启动 简单的暴露和服务引用 现使用TCP协议 使用Netty 使用Netty的编解码 使用Java序列化方式 源码地址https://github.com/dachengxi/mini-dubbo 过程现在的版本就是一个简单的RPC调用功能。下面是大概的过程： 服务提供者端DubboProvider，这是API，用来启动服务暴露的功能，会调用Netty实现的服务端暴露服务，并监听处理。 编写Netty服务和Handler。 实现请求和相应分别对应的两个bean：Request和Response。 服务消费者端DubboConsumer，这是API，用来初始化消费者，和调用服务提供者。实际应该是先获取代理，在真正使用的时候采取调用服务提供者端，现在都在一步中完成了。 编写获取代理类DubboConsumerProxy。 编写Netty客户端和Handler。 测试都在sample的模块下。 还有很多要做的～加油！！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于Servlet线程安全性和DispatcherServlet的线程安全性的解析]]></title>
      <url>%2F2017%2F04%2F13%2F%E5%85%B3%E4%BA%8EServlet%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E6%80%A7%E5%92%8CDispatcherServlet%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E6%80%A7%E7%9A%84%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[我们知道在Servlet第一次被调用的时候，Servlet容器会根据web.xml中配置的信息去实例化Servlet，而且这个Servlet只会被实例化一次。当多个请求同时到来时，可能会使用同一个Servlet进行处理，这时候就会涉及到线程安全的问题。纠结！！！ Servlet的线程安全性？不确定Servlet是单实例多线程的方式来处理请求，这应该就是造成线程安全的主要原因了。我们知道Servlet本身是无状态的，也就是说Servlet本身是线程安全的，但是为什么网上都说Servlet是线程不安全的呢？可能就是根据一句多个线程会同时访问一个Servlet实例来判断的把。 而Servlet是不是线程安全的，主要是由实现来决定的，如果一个Servlet实现有实例变量，并且会被多线程更改，这时候就不是线程安全的；而如果有实例变量，但是变量又是只读的，这时候不涉及变量的更改，就是线程安全的；而如果一个Servlet实现没有实例变量，都是局部变量，这时候也是线程安全的。 HttpServletHttpServlet是Servlet的一个实现，继承自GenericServlet，并且也是我们自定义Servlet所要继承的一个类，HttpServlet是不是线程安全的，也不好说，也得根据在使用过程中不同情况来确定。另外对于Servlet中的属性的使用也会对线程安全产生影响，见下面。 自定义的Servlet通常我们开发自己的Servlet都是继承HttpServlet，然后重写相关方法，这时候线程安全和不安全都是靠我们自己来决定了，没有实例变量的时候，就是线程安全的；而有实例变量的时候，并且会被改变，这时候就不是线程安全的了，需要使用其他手段保证线程安全。另外对于Servlet中的属性的使用也会对线程安全产生影响，见下面。 如何控制Servlet的线程安全性变量的线程安全我们知道当没有实例变量的时候，就基本不存在线程不安全的问题了，所以不使用实例变量是一种方法。 属性的线程安全 ServletContext，不是线程安全的，多线程可以同时读写。使用时要注意。 HttpSession，不是线程安全的，比如用户打开多个浏览器窗口时候就会产生多个请求针对同一个session的操作。使用时要注意。 ServletRequest，线程安全的，它对应着一个request请求，所以说是线程安全的。 SingleThreadModel我们还可以使用这个接口来创建自己的实现，可以保证线程安全，同一时刻只有一个线程可以执行Servlet实例的service方法，这就成了单线程了，该方式已经被废弃。 常用框架的线程安全性SpringMVC，我们知道Spring的IOC容器默认管理的bean是单实例的，对于SpringMVC的Controller来说也是单实例的，所以开发的时候需要保证线程安全。 Struts1中的action也是单实例的，使用的时候会有线程安全问题。 Struts2中Action会为每一个请求产生一个实例，所以不存在线程安全问题。 注意：当使用Spring管理Struts2的Action时，需要将Action的scope设置为prototype，因为Spring IOC容器中bean默认是单例的。 DispatcherServlet的线程安全性在应用启动的时候，就会根据web.xml中配置的有关Spring和SpringMVC的配置启动初始化，对于SpringMVC初始化的是DispatcherServlet，对于Servlet初始化只会进行一次，并且只有一个实例，所以DispatcherServlet只会存在一个。 但是当多线程同时访问DispatcherServlet的时候是线程安全的，因为DispatcherServlet中的内部属性都不会影响线程安全，所以DispatcherServlet可以忽略线程安全的问题。 虽然DispatcherServlet可以认为是线程安全的，但是SpringMVC中的Controller不是。Controller也是单例的，每个请求对应一个Controller中的方法，方法如果没有使用实例变量，可以认为是线程安全的，但是如果有实例变量就要考虑线程安全的问题了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java Servlet工作流程以及源码解析]]></title>
      <url>%2F2017%2F04%2F13%2FJava%20Servlet%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E4%BB%A5%E5%8F%8A%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[关于Servlet的学习还是在上学的时候，自学Java，也就是只是了解了Servlet是什么以及怎么使用，现在慢慢的明白很多很多的框架等等都是在Servlet上做的扩展，也开始明白自己的基础不好。现在回头来学习一下Servlet的相关知识。 Servlet的使用对于Servlet怎么写，以及在Servlet容器（这里特指Tomcat）中怎么配置几乎都忘记了，先回头了下一个最简单的Servlet的开发。 这里以一个最简单的自定义Servlet显示一个页面来作为例子。 首先写一个TestServlet，继承HttpServlet： 123456789101112131415161718192021222324252627282930313233343536373839package me.cxis.servlet;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.io.PrintWriter;/** * Created by cheng.xi on 2017-04-12 23:42. */public class TestServlet extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; System.out.println(&quot;doGet...&quot;); resp.setContentType( &quot;text/html;charset=UTF-8&quot; ); PrintWriter out = resp.getWriter(); try &#123; out.println( &quot;&lt;html&gt;&quot; ); out.println( &quot;&lt;head&gt;&quot; ); out.println( &quot;&lt;title&gt;TestServlet&lt;/title&gt;&quot; ); out.println( &quot;&lt;/head&gt;&quot; ); out.println( &quot;&lt;body&gt;&quot; ); out.println( &quot;&lt;h2&gt;testServlet&lt;/h2&gt;&quot; ); out.println( &quot;&lt;/body&gt;&quot; ); out.println( &quot;&lt;/html&gt;&quot; ); &#125; finally &#123; out.close(); &#125; &#125; @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; System.out.println(&quot;doPost...&quot;); this.doGet(req,resp); &#125;&#125; 然后在web.xml中配置刚才写的servlet： 1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot; version=&quot;3.1&quot;&gt; &lt;servlet&gt; &lt;servlet-name&gt;testServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;me.cxis.servlet.TestServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;testServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/testServlet&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 这就可以了，启动Servlet容器，这里是tomcat，然后访问http://localhost:8080/testServlet就可以看到结果了。 写到这里感觉大学时光又回来了，那时候做项目的时候，可没少写了servlet，老师，学长，实验室，三年，几个人每天就写代码，太单纯！ Servlet的工作流程这里只看下一个请求到来时候Servlet是怎么处理的流程，不涉及容器的启动初始化之类的。 大概流程 客户端发起一个http请求，比如get类型。 Servlet容器接收到请求，根据请求信息调用相应的Servlet。 Servlet来处理具体的业务逻辑，也就是我们写的Servlet中的代码。 Servlet处理完成之后，返回给Servlet容器。 Servlet容器将最后结果返回给客户端。 具体流程 客户端发起一个http请求，比如get类型。 Servlet容器接收到请求，根据请求信息，封装成HttpServletRequest和HttpServletResponse对象。 Servlet容器调用HttpServlet的init()方法，init方法只在第一次请求的时候被调用。 Servlet容器调用service()方法。 service()方法根据请求类型，这里是get类型，分别调用doGet或者doPost方法，这里调用doGet方法。 doXXX方法中是我们自己写的业务逻辑。 业务逻辑处理完成之后，返回给Servlet容器，然后容器将结果返回给客户端。 容器关闭时候，会调用destory方法 这其中的2,3,4,5,6使我们要关注的，其他的步骤是容器实现的，先不了解具体信息。 注意： 同一个Servlet只会被初始化一次，也就是init方法只会被调用一次。 同一个Servlet只存在一个实例，而可能会有多个请求同时请求一个Servlet，所以存在线程安全问题。 Servlet生命周期Servlet生命周期由容器来管理，大致包含了四个阶段： 加载和实例化，由容器负责加载和实例化Servlet。 初始化，容器会调用init方法初始化Servlet对象，init方法只会被调用一次。 处理请求，容器会调用service方法进行请求的处理，service会调用相应的doXxx方法来处理。 服务销毁，即一个Servlet实例从服务中被移除的时候，会调用destory方法，这个方法也只会被执行一次。 下面我们解析的是从初始化开始，对于加载和实例化不做说明。 Servlet流程的源码分析初始化，init请求到来时候，会由容器先处理，然后调用Servlet的init方法进行初始化，init方法在GenericServlet中： 12345678@Overridepublic void init(ServletConfig config) throws ServletException &#123; //config是由容器处理的，里面包含了请求和Servlet的相关配置信息 this.config = config; //由子类进行实现的init方法 //我们可以重写init方法，进行一些资源的初始化等的操作 this.init();&#125; 有关init方法只会执行一次的问题，这里并没有体现到，这是具体的实现，而有关判断是在容器的StandardWrapper类中，会判断是否已经实例化，没有实例化就调用实例化方法实例Servlet，这就会调用init方法。 处理请求service当初始化完成之后，容器会进行处理，然后容器再去调用Servlet的service方法去进行请求的处理，首先进入HttpServlet的service方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; //请求类型方法 String method = req.getMethod(); //对每种类型分别进行处理 if (method.equals(METHOD_GET)) &#123;//get方法 //get方法涉及到缓存的问题，会对最后修改时间进行判断 long lastModified = getLastModified(req); //不支持lastModified，直接调用doGet方法进行处理 if (lastModified == -1) &#123; // servlet doesn&apos;t support if-modified-since, no reason // to go through further expensive logic doGet(req, resp); &#125; else &#123; //支持lastModified long ifModifiedSince; try &#123; //从请求头中获取If-Modified-Since属性的值 ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE); &#125; catch (IllegalArgumentException iae) &#123; // Invalid date header - proceed as if none was set ifModifiedSince = -1; &#125; //比较时间 if (ifModifiedSince &lt; (lastModified / 1000 * 1000)) &#123; //Servlet的修改时间晚，表示数据比客户端新 //需要修改时间，并调用get方法处理 maybeSetLastModified(resp, lastModified); doGet(req, resp); &#125; else &#123; //没有修改 直接返回状态给客户端 resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); &#125; &#125; &#125; else if (method.equals(METHOD_HEAD)) &#123;//Head方法 long lastModified = getLastModified(req); maybeSetLastModified(resp, lastModified); doHead(req, resp); &#125; else if (method.equals(METHOD_POST)) &#123;//post方法 doPost(req, resp); &#125; else if (method.equals(METHOD_PUT)) &#123;//put方法 doPut(req, resp); &#125; else if (method.equals(METHOD_DELETE)) &#123;//delete方法 doDelete(req, resp); &#125; else if (method.equals(METHOD_OPTIONS)) &#123;//options方法 doOptions(req,resp); &#125; else if (method.equals(METHOD_TRACE)) &#123;//trace方法 doTrace(req,resp); &#125; else &#123; //servlet不支持其他类型方法 String errMsg = lStrings.getString(&quot;http.method_not_implemented&quot;); Object[] errArgs = new Object[1]; errArgs[0] = method; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg); &#125; &#125; 可以看到，service方法处理请求，会根据请求的类型分别进行处理，get会涉及到最后修改时间问题。这些doXxx方法都会有默认的实现，如果子类不做重写就会执行默认方法。 请求处理完成之后会回到容器中由容器进行其他的处理。 销毁方法destory如果我们重写了destory方法，在容器关闭或者Servlet实例移除的时候，会回调我们的destory方法，一般用来释放资源，这个方法也只会被调用一次。 上面只是最简单的一个Servlet流程，没有涉及到更多的内容，比如上下文，比如session，filter等等，还有一个就是线程安全问题，这个问题会在下面文章继续说明，流程的解析就到这里。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring中AOP源码深入解析]]></title>
      <url>%2F2017%2F04%2F12%2FSpring%E4%B8%ADAOP%E6%BA%90%E7%A0%81%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[有关AOP相关概念以及Spring AOP相关概念和Spring AOP的使用不再重复。关于AOP在Spring中的地位，不用说相信我们都知道，也都会用，但是对于更深入的东西，还未接触过，这里就对Spring AOP的相关源码进行说明一下，看看到底Spring中AOP是怎么实现的。有关AOP的概念和Spring AOP相关配置，请参考其他两篇文章：AOP概念，原理，应用介绍 和 Spring中AOP的配置从1.0到5.0的演进 另外，本文使用的源码是Spring1.1.1版本的，之所以使用这么老的版本，是觉得相对来说简单一些，并且无关的东西更少，这样更容易去理解。对于后续版本新增功能可以在此基础上进行对比，理解的效果会更好。 示例程序首先我们还是先使用一个实例来看一下怎么使用，再从实例中一步一步跟进到源码中。 先定义业务接口和实现： LoginService： 12345678package me.cxis.spring.aop;/** * Created by cheng.xi on 2017-03-29 12:02. */public interface LoginService &#123; String login(String userName);&#125; LoginServiceImpl： 123456789101112package me.cxis.spring.aop;/** * Created by cheng.xi on 2017-03-29 10:36. */public class LoginServiceImpl implements LoginService &#123; public String login(String userName)&#123; System.out.println(&quot;正在登录&quot;); return &quot;success&quot;; &#125;&#125; 接着是三个通知类： 12345678910111213141516171819202122232425262728293031323334353637383940//这里只是在登录方法调用之前打印一句话public class LogBeforeLogin implements MethodBeforeAdvice &#123; public void before(Method method, Object[] objects, Object o) throws Throwable &#123; System.out.println(&quot;有人要登录了。。。&quot;); &#125;&#125;package me.cxis.spring.aop.proxyfactory;import org.springframework.aop.AfterReturningAdvice;import org.springframework.aop.MethodBeforeAdvice;import java.lang.reflect.Method;/** * Created by cheng.xi on 2017-03-29 10:56. */public class LogAfterLogin implements AfterReturningAdvice &#123; public void afterReturning(Object o, Method method, Object[] objects, Object o1) throws Throwable &#123; System.out.println(&quot;有人已经登录了。。。&quot;); &#125;&#125;package me.cxis.spring.aop.proxyfactory;import org.aopalliance.intercept.MethodInterceptor;import org.aopalliance.intercept.MethodInvocation;/** * Created by cheng.xi on 2017-03-30 23:36. */public class LogAroundLogin implements MethodInterceptor &#123; public Object invoke(MethodInvocation invocation) throws Throwable &#123; System.out.println(&quot;有人要登录。。。&quot;); Object result = invocation.proceed(); System.out.println(&quot;登录完了&quot;); return result; &#125;&#125; 测试方法： 1234567891011121314151617181920212223package me.cxis.spring.aop.proxyfactory;import org.springframework.aop.framework.ProxyFactory;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;/** * Created by cheng.xi on 2017-03-29 10:34. */public class Main &#123; public static void main(String[] args) &#123; ProxyFactory proxyFactory = new ProxyFactory();//创建代理工厂 proxyFactory.setTarget(new LoginServiceImpl());//设置目标对象 proxyFactory.addAdvice(new LogBeforeLogin());//前置增强 proxyFactory.addAdvice(new LogAfterLogin());//后置增强 //proxyFactory.addAdvice(new LogAroundLogin());//环绕增强 LoginService loginService = (LoginService) proxyFactory.getProxy();//从代理工厂中获取代理 loginService.login(&quot;x&quot;); &#125;&#125; 关于实例中要说明的：我们看到在使用的时候，直接获取的是一个代理，不是要使用的实现类，这也很好懂，之前文章都说过AOP其实就是代理模式，在编译期或者运行期，给我们原来的代码增加一些功能，变成一个代理。当我们调用的时候，实际就是调用的代理类。 源码解析对于源码的解析，我们这里使用的是代码的方式，没有选择xml配置文件的方式。关于xml配置的方式，后面再讲解。 创建AOP代理首先我们要明白，Spring中实现AOP，就是生成一个代理，然后在使用的时候调用代理。 创建代理工厂代码中首先创建一个代理工厂实例ProxyFactory proxyFactory = new ProxyFactory();代理工厂的作用就是使用编程的方式创建AOP代理。ProxyFactory继承自AdvisedSupport，AdvicedSupport是AOP代理的配置管理器。 设置目标对象然后是设置要代理的目标对象proxyFactory.setTarget(new LoginServiceImpl());，看下setTarget方法： 12345public void setTarget(Object target) &#123; //先根据给定的目标实现类，创建一个单例的TargetSource //然后设置TargetSource setTargetSource(new SingletonTargetSource(target));&#125; TargetSourceTargetSource用来获取当前的Target，也就是TargetSource中会保存着我们的的实现类。 12345678910111213141516public interface TargetSource &#123; //返回目标类的类型 Class getTargetClass(); //查看TargetSource是否是static的 //静态的TargetSource每次都返回同一个Target boolean isStatic(); //获取目标类的实例 Object getTarget() throws Exception; //释放目标类 void releaseTarget(Object target) throws Exception;&#125; SingletonTargetSourceTargetSource的默认实现，是一个单例的TargetSource，isStatic方法直接返回true。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public final class SingletonTargetSource implements TargetSource, Serializable &#123; //用来保存目标类 private final Object target; //构造方法 public SingletonTargetSource(Object target) &#123; this.target = target; &#125; //直接返回目标类的类型 public Class getTargetClass() &#123; return target.getClass(); &#125; //返回目标类 public Object getTarget() &#123; return this.target; &#125; //释放目标类，这里啥也没做 public void releaseTarget(Object o) &#123; // Nothing to do &#125; //直接返回true public boolean isStatic() &#123; return true; &#125; //equals方法 public boolean equals(Object other) &#123; //相等，返回true if (this == other) &#123; return true; &#125; //不是SingletonTargetSource类型的返回false if (!(other instanceof SingletonTargetSource)) &#123; return false; &#125; SingletonTargetSource otherTargetSource = (SingletonTargetSource) other; //判断目标类是否相等 return ObjectUtils.nullSafeEquals(this.target, otherTargetSource.target); &#125; //toString方法 public String toString() &#123; return &quot;SingletonTargetSource: target=(&quot; + target + &quot;)&quot;; &#125;&#125; 上面是有关TargetSource和SingletonTargetSource的说明，接着往下一步就是设置目标类setTargetSource方法，在AdvisedSupport类中： 1234567public void setTargetSource(TargetSource targetSource) &#123; if (isActive() &amp;&amp; getOptimize()) &#123; throw new AopConfigException(&quot;Can&apos;t change target with an optimized CGLIB proxy: it has its own target&quot;); &#125; //么有做什么处理，只是将我们构建的TargetSource缓存起来 this.targetSource = targetSource;&#125; 添加通知上面设置了要代理的目标类之后，接着是添加通知，也就是添加增强类，proxyFactory.addAdvice()方法是添加增强类的方法。我们在例子中是这么使用的： 123proxyFactory.addAdvice(new LogBeforeLogin());//前置增强proxyFactory.addAdvice(new LogAfterLogin());//后置增强//proxyFactory.addAdvice(new LogAroundLogin());//环绕增强 addAdvice方法的参数是一个Advice类型的类，也就是通知或者叫增强，可以去我们的增强类中查看，我们都继承了各种Advice，比如MethodBeforeAdvice，AfterReturningAdvice，MethodInterceptor，这里先讲一下有关通知Advice的代码，然后再继续说明addAdvice方法。 Advice接口Advice不属于Spring，是AOP联盟定义的接口。Advice接口并没有定义任何方法，是一个空的接口，用来做标记，实现了此接口的的类是一个通知类。Advice有几个子接口： BeforeAdvice，前置增强，意思是在我们的目标类之前调用的增强。这个接口也没有定义任何方法。 AfterReturningAdvice，方法正常返回前的增强，该增强可以看到方法的返回值，但是不能更改返回值，该接口有一个方法afterReturning ThrowsAdvice，抛出异常时候的增强，也是一个标志接口，没有定义任何方法。 Interceptor，拦截器，也没有定义任何方法，表示一个通用的拦截器。不属于Spring，是AOP联盟定义的接口 DynamicIntroductionAdvice，动态引介增强，有一个方法implementsInterface。 MethodBeforeAdviceMethodBeforeAdvice接口，是BeforeAdvice的子接口，表示在方法前调用的增强，方法前置增强不能阻止方法的调用，但是能抛异常来使目标方法不继续执行。 12345678public interface MethodBeforeAdvice extends BeforeAdvice &#123; //在给定的方法调用前，调用该方法 //参数method是被代理的方法 //参数args是被代理方法的参数 //参数target是方法调用的目标，可能为null void before(Method m, Object[] args, Object target) throws Throwable;&#125; MethodInterceptorMethodInterceptor不属于Spring，是AOP联盟定义的接口，是Interceptor的子接口，我们通常叫做环绕增强。 123456public interface MethodInterceptor extends Interceptor &#123; //在目标方法调用前后做一些事情 //返回的是invocation.proceed()方法的返回值 Object invoke(MethodInvocation invocation) throws Throwable;&#125; 参数MethodInvocation是一个方法调用的连接点，接下来先看看MethodInvocation相关的代码。 Joinpoint连接点JointPoint接口，是一个通用的运行时连接点，运行时连接点是在一个静态连接点发生的事件。 123456789101112public interface Joinpoint &#123; //开始调用拦截器链中的下一个拦截器 Object proceed() throws Throwable; // Object getThis(); // AccessibleObject getStaticPart(); &#125; Invocation接口Invocation接口是Joinpoint的子接口，表示程序的调用，一个Invocation就是一个连接点，可以被拦截器拦截。 123456public interface Invocation extends Joinpoint &#123; //获取参数 Object[] getArguments();&#125; MethodInvocation接口MethodInvocation接口是Invocation的子接口，用来描述一个方法的调用。 1234567public interface MethodInvocation extends Invocation&#123; //获取被调用的方法 Method getMethod();&#125; 另外还有一个ConstructorInvocation接口，也是Invocation的子接口，描述的是构造器的调用。 上面介绍完了Advice的相关定义，接着看往代理工厂中添加增强的addAdvice方法，addAdvice方法在AdvisedSupport类中： 12345678public void addAdvice(Advice advice) throws AopConfigException &#123; //advisors是Advice列表，是一个LinkedList //如果被添加进来的是一个Interceptor，会先被包装成一个Advice //添加之前现获取advisor的大小，当做添加的Advice的位置 int pos = (this.advisors != null) ? this.advisors.size() : 0; //添加Advice addAdvice(pos, advice);&#125; 接着看addAdvice(pos, advice)方法： 1234567891011121314151617181920public void addAdvice(int pos, Advice advice) throws AopConfigException &#123; //只能处理实现了AOP联盟的接口的拦截器 if (advice instanceof Interceptor &amp;&amp; !(advice instanceof MethodInterceptor)) &#123; throw new AopConfigException(getClass().getName() + &quot; only handles AOP Alliance MethodInterceptors&quot;); &#125; //IntroductionInfo接口类型，表示引介信息 if (advice instanceof IntroductionInfo) &#123; //不需要IntroductionAdvisor addAdvisor(pos, new DefaultIntroductionAdvisor(advice, (IntroductionInfo) advice)); &#125; //动态引介增强的处理 else if (advice instanceof DynamicIntroductionAdvice) &#123; //需要IntroductionAdvisor throw new AopConfigException(&quot;DynamicIntroductionAdvice may only be added as part of IntroductionAdvisor&quot;); &#125; else &#123; //添加增强器，需要先把我们的增强包装成增强器，然后添加 addAdvisor(pos, new DefaultPointcutAdvisor(advice)); &#125;&#125; 我们看到添加增强的时候，实际调用添加增强器这个方法，首先需要把我们的Advice包装成一个PointCutAdvisor，然后在添加增强器。这里先了解一下有关PointCutAdvisor的相关信息。 Advisor接口Advisor，增强器，它持有一个增强Advice，还持有一个过滤器，来决定Advice可以用在哪里。 123456789public interface Advisor &#123; //判断Advice是不是每个实例中都有 boolean isPerInstance(); //返回持有的Advice Advice getAdvice();&#125; PointcutAdvisor是一个持有Pointcut切点的增强器，PointcutAdvisor现在就会持有一个Advice和一个Pointcut。 123456public interface PointcutAdvisor extends Advisor &#123; //获取Pointcut Pointcut getPointcut();&#125; Pointcut接口切入点，定义了哪些连接点需要被织入横切逻辑。可以 12345678910public interface Pointcut &#123; //类过滤器，可以知道哪些类需要拦截 ClassFilter getClassFilter(); //方法匹配器，可以知道哪些方法需要拦截 MethodMatcher getMethodMatcher(); // could add getFieldMatcher() without breaking most existing code Pointcut TRUE = TruePointcut.INSTANCE; &#125; ClassFilter接口12345678public interface ClassFilter &#123; //判断给定的类是不是要拦截 boolean matches(Class clazz); ClassFilter TRUE = TrueClassFilter.INSTANCE;&#125; MethodMatcher接口1234567891011121314public interface MethodMatcher &#123; / 静态方法匹配 boolean matches(Method m, Class targetClass); //是否是运行时动态匹配 boolean isRuntime(); //运行是动态匹配 boolean matches(Method m, Class targetClass, Object[] args); MethodMatcher TRUE = TrueMethodMatcher.INSTANCE;&#125; 看完相关的定义之后，接着看方法new DefaultPointcutAdvisor(advice)，将Advice包装成一个DefaultPointcutAdvisor。其实就是将advice和默认的Pointcut包装进DefaultPointcutAdvisor。 DefaultPointcutAdvisor是Advisor的最常用的一个实现，可以使用任意类型的Pointcut和Advice，但是不能使用Introduction。 构造完成了DefaultPointcutAdvisor只有，接着就是添加增强器方法addAdvisor： 12345678910public void addAdvisor(int pos, Advisor advisor) throws AopConfigException &#123; //引介增强器处理 if (advisor instanceof IntroductionAdvisor) &#123; addAdvisor(pos, (IntroductionAdvisor) advisor); &#125; else &#123; //其他的增强器处理 addAdvisorInternal(pos, advisor); &#125;&#125; 首先看下非引介增强器的添加方法addAdvisorInternal： 1234567891011private void addAdvisorInternal(int pos, Advisor advice) throws AopConfigException &#123; if (isFrozen()) &#123; throw new AopConfigException(&quot;Cannot add advisor: config is frozen&quot;); &#125; //把Advice添加到LinkedList中指定位置 this.advisors.add(pos, advice); //同时更新一下Advisors数组 updateAdvisorArray(); //通知监听器 adviceChanged();&#125; 然后看下关于引介增强器的添加addAdvisor，我们知道引介就是对目标类增加新的接口，所以引介增强，也就是对接口的处理： 123456789101112public void addAdvisor(int pos, IntroductionAdvisor advisor) throws AopConfigException &#123; //对接口进行校验 advisor.validateInterfaces(); // 遍历要添加的接口，添加 for (int i = 0; i &lt; advisor.getInterfaces().length; i++) &#123; //就是添加到interfaces集合中，interfaces是一个HashSet addInterface(advisor.getInterfaces()[i]); &#125; //然后添加到advisors中 addAdvisorInternal(pos, advisor);&#125; 对于添加增强的步骤，就是把我们的增强器添加进代理工厂中，保存在一个LinkedList中，顺序是添加进来的顺序。 获取代理到目前为止，我们看到的都还是在组装代理工厂，并没有看到代理的生成，接下来proxyFactory.getProxy()这一步就是获取代理的过程，我们继续看ProxyFactory的getProxy方法： 123456public Object getProxy() &#123; //创建一个AOP代理 AopProxy proxy = createAopProxy(); //返回代理 return proxy.getProxy();&#125; 我们知道一般创建代理会有两种方式，一种是JDK动态代理，另外一种是CGLIB动态代理，而这里的创建AOP代理就是生成这两种代理中的一种。先看createAopProxy()方法，在AdvisedSupport类中： 1234567protected synchronized AopProxy createAopProxy() &#123; if (!this.isActive) &#123; activate(); &#125; //获取AOP代理工厂，然后创建代理 return getAopProxyFactory().createAopProxy(this);&#125; 获取代理工厂这一步，这里就是默认获取一个DefaultAopProxyFactory实例，然后调用createAopProxy创建AOP代理： 1234567891011public AopProxy createAopProxy(AdvisedSupport advisedSupport) throws AopConfigException &#123; //对于指定了使用CGLIB方式，或者代理的是类，或者代理的不是接口，就使用CGLIB的方式来创建代理 boolean useCglib = advisedSupport.getOptimize() || advisedSupport.getProxyTargetClass() || advisedSupport.getProxiedInterfaces().length == 0; if (useCglib) &#123; return CglibProxyFactory.createCglibProxy(advisedSupport); &#125; else &#123; //使用JDK动态代理来创建代理 return new JdkDynamicAopProxy(advisedSupport); &#125;&#125; 获取完AOP代理之后返回，然后就是调用getProxy方法获取代理，这里分为CGLIB的获取方式和JDK动态代理的获取方式两种。 JDK动态代理方式获取代理JDK动态代理方式获取代理，实现在JdkDynamicAopProxy中： 123public Object getProxy() &#123; return getProxy(Thread.currentThread().getContextClassLoader());&#125; 1234567public Object getProxy(ClassLoader cl) &#123; //JDK动态代理只能代理接口类型，先获取接口 //就是从AdvisedSupport中获取保存在interfaces中的接口 Class[] proxiedInterfaces = AopProxyUtils.completeProxiedInterfaces(this.advisedSupport); //使用Java的反射机制创建一个代理实例 return Proxy.newProxyInstance(cl, proxiedInterfaces, this);&#125; 关于JDK反射创建代理之类的，这里不做解析。 CGLIB方式获取代理CGLIB获取方式，实现在Cglib2AopProxy中： 1234public Object getProxy() &#123; //使用CGLIB的方式来获取，CGLIB这里不做解析 return getProxy(Thread.currentThread().getContextClassLoader());&#125; 使用代理上面获取代理之后，就剩最后一步，使用，当我们调用业务方法的时候，实际上是调用代理中的方法，对于CGLIB生成的代理，调用的是DynamicAdvisedInterceptor的intercept方法；JDK动态代理生成的代理是调用invoke方法。 JDK动态代理看下JDK动态代理的方式，对于方法的调用，实际上调用的是代理类的invoke方法，在JdkDynamicAopProxy中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; MethodInvocation invocation = null; Object oldProxy = null; boolean setProxyContext = false; //代理的目标对象 TargetSource targetSource = advisedSupport.targetSource; Class targetClass = null; Object target = null; try &#123; //equals方法 if (method.getDeclaringClass() == Object.class &amp;&amp; &quot;equals&quot;.equals(method.getName())) &#123; return equals(args[0]) ? Boolean.TRUE : Boolean.FALSE; &#125; else if (Advised.class == method.getDeclaringClass()) &#123; //？？？ return AopProxyUtils.invokeJoinpointUsingReflection(this.advisedSupport, method, args); &#125; Object retVal = null; //代理目标对象 target = targetSource.getTarget(); if (target != null) &#123; targetClass = target.getClass(); &#125; //？？？ if (this.advisedSupport.exposeProxy) &#123; // Make invocation available if necessary oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; //获取配置的通知Advicelian List chain = this.advisedSupport.advisorChainFactory.getInterceptorsAndDynamicInterceptionAdvice( this.advisedSupport, proxy, method, targetClass); //没有配置通知 if (chain.isEmpty()) &#123; //直接调用目标对象的方法 retVal = AopProxyUtils.invokeJoinpointUsingReflection(target, method, args); &#125; else &#123; //配置了通知，创建一个MethodInvocation invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); //执行通知链，沿着通知器链调用所有的通知 retVal = invocation.proceed(); &#125; //返回值 if (retVal != null &amp;&amp; retVal == target) &#123; //返回值为自己 retVal = proxy; &#125; //返回 return retVal; &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; AopContext.setCurrentProxy(oldProxy); &#125; &#125;&#125; CGLIB动态代理CGLIB的是调用DynamicAdvisedInterceptor的intercept方法对目标对象进行处理，具体暂先不解析。 使用ProxyFactoryBean创建AOP代理ProxyFactoryBean对Pointcut和Advice提供了完全的控制，还包括应用的顺序。ProxyFactoryBean的getObject方法会返回一个AOP代理，包装了目标对象。 Spring在初始化的过程中，createBean的时候，如果是FactoryBean的话，会调用((BeanFactoryAware)bean).setBeanFactory(this);： 12345678910111213public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; this.beanFactory = beanFactory; //创建通知器链 this.createAdvisorChain(); if(this.singleton) &#123; //刷新目标对象 this.targetSource = this.freshTargetSource(); //获取单例实例 this.getSingletonInstance(); this.addListener(this); &#125;&#125; 看下获取单例实例的方法： 1234567private Object getSingletonInstance() &#123; if(this.singletonInstance == null) &#123; this.singletonInstance = this.createAopProxy().getProxy(); &#125; return this.singletonInstance;&#125; createAopProxy方法在AdvisedSupport类中，下面创建的流程跟上面解析的都一样了。 到这里AOP的一个流程的源码算是走完了，这只是其中一小部分，还有很多的没有涉及到，包括AOP标签的解析，CGLIB生成代理以及调用代理等等。其中有些还没明白的已经画上了问号，慢慢的在研究下。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java动态代理机制解析]]></title>
      <url>%2F2017%2F04%2F12%2FJava%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E6%9C%BA%E5%88%B6%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[动态代理是指在运行时动态生成代理类。不需要我们像静态代理那个去手动写一个个的代理类。生成动态代理类有很多方式：Java动态代理，CGLIB，Javassist，ASM库等。这里主要说一下Java动态代理的实现。 Java动态代理InvocationHandler接口Java动态代理中，每一个动态代理类都必须要实现InvocationHandler接口，当我们通过代理对象调用一个方法的时候，这个方法就会被转发给代理类的invoke方法来调用，InvocationHandler接口只有一个方法： 1public Object invoke(Object proxy, Method method, Object[] args) throws Throwable; proxy，真实对象。method，我们调用的真实对象的方法。args，要调用真实对象的方法时接受的参数。 Proxy类实现了InvocationHandler的类是动态代理类，而Proxy就是用来动态创建代理类对象的工具，通常情况下我们只使用newProxyInstance这个方法，newProxyInstance定义： 1public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123;&#125; loader，对生成的代理类对象进行加载的ClassLoader。interfaces，代理对象会实现这些接口。h，动态代理对象调用方法的时候，要发送到哪个InvocationHandler上。 例子我们知道，在之前的静态代理中，每个代理类都实现了特定接口，针对每一个事情都需要去定义一个代理类，会迅速的使类变多，重复也会多。而使用动态代理可以避免这一点，还是使用之前的找人还钱的例子。 Subject： 1234567891011121314package me.cxis.test.gof.proxy.dynamicproxy;/** * Created by cheng.xi on 2017-04-12 19:58. * 代理模式的主题类，这里代表的是欠钱的人 */public interface Subject &#123; /** * 还给我的钱 * @param moneyCount 欠钱数 * @return 还给我的钱数 */ int giveMeMyMoney(int moneyCount);&#125; RealSubject： 123456789101112package me.cxis.test.gof.proxy.dynamicproxy;/** * Created by cheng.xi on 2017-04-12 19:58. * 真实主题，这里代表的是欠我钱的人 */public class RealSubject implements Subject &#123; @Override public int giveMeMyMoney(int moneyCount) &#123; return moneyCount; &#125;&#125; DynamicProxy： 1234567891011121314151617181920212223242526272829303132333435package me.cxis.test.gof.proxy.dynamicproxy;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;/** * Created by cheng.xi on 2017-04-12 19:59. * 代理 */public class DynamicProxy implements InvocationHandler&#123; private Object target; public DynamicProxy(Object target)&#123; this.target = target; &#125; public &lt;T&gt; T getProxy()&#123; return (T) Proxy.newProxyInstance( target.getClass().getClassLoader(), target.getClass().getInterfaces(), this); &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(&quot;办事之前先收取点费用&quot;); System.out.println(&quot;开始办事&quot;); Object result = method.invoke(target,args); System.out.println(&quot;办完了&quot;); return result; &#125;&#125; 测试方法： 1234567891011121314package me.cxis.test.gof.proxy.dynamicproxy;/** * Created by cheng.xi on 2017-04-12 20:06. */public class Main &#123; public static void main(String[] args) &#123; Subject zhangsan = new RealSubject(); Subject proxy = new DynamicProxy(zhangsan).getProxy(); int money = proxy.giveMeMyMoney(1000); System.out.println(money); &#125;&#125; 可以看到我们把之前的代理类，换成了现在的动态代理类，调用方法也有所改变，看起来没什么大的区别，但是当我们在需要一个类似的业务的时候，就有差别了，我们无需在定义第二个动态代理类，只需要有新的Subject1接口和RealSubject1实现即可，在我们测试方法中直接调用就可以了，动态代理类完全不需要改变。 Java动态代理的优缺点优点：Java动态代理可以避免静态代理带来的代码冗余的问题。 缺点：Java动态代理只能针对接口创建代理，不能针对类创建代理。 Java动态代理到底做了什么？其实动态代理是在运行时候为我们生成了一个代理类，大概如下： 12345678910111213public final class $Proxy1 extends Proxy implements Subject&#123; private InvocationHandler h; private $Proxy1()&#123;&#125; public $Proxy1(InvocationHandler h)&#123; this.h = h; &#125; public int giveMeMyMoney(int i)&#123; ////创建method对象 Method method = Subject.class.getMethod(&quot;giveMeMyMoney&quot;, new Class[]&#123;int.class&#125;); //调用了invoke方法 return (Integer)h.invoke(this, method, new Object[]&#123;new Integer(i)&#125;); &#125;&#125; 从中可以看到，InvocationHandler是我们实现的那个类，我们实现了invoke方法，这里就是调用了invoke方法。 同时我们看到这个类实际上实现了我们的主题类Subject，看着和静态代理差不多了把。另外着重看下这个类继承了Proxy类，看到这里，对于JDK动态代理为什么不能代理类只能代理接口，就明了了，因为他已经继承了Proxy类。 动态代理的用处 Spring AOP就是使用的动态代理方式。 dubbo消费者初始化的时候生成代理，也是使用的动态代理。 hibernate的懒加载。 其他例子延迟加载代理举例： 接口类： 123public interface ILoadFile&#123; String load();&#125; 真实实现类： 12345678910111213141516171819public class LoadFile implements ILoadFile&#123; String fileContent = &quot;&quot;; public LoadFile()&#123; try&#123; //这里模拟加载一个大文件，需要时间很长 Thread.sleep(10000); //加载完之后 fileContent = &quot;file contents...&quot;; &#125;catch(Exception e)&#123; &#125; &#125; public String load()&#123; return fileContent; &#125; &#125; 代理类： 1234567891011public LoadFileHandler implements InvocationHandler&#123; ILoadFile loadFile = null; public Object invoke(Object proxy,Method method,Object[] args) throws Throwable&#123; if( loadFile == null)&#123; loadFile = new LoadFile(); &#125; return loadFile.load(); &#125;&#125; 生成动态代理对象并使用： 1234public static void main(String[] args)&#123; ILoadFile loadFile = (ILoadFile)Proxy.newProxyInstance(ClassLoader.getSystemClassLoader(),new Class[]&#123;ILoadFile.class&#125;,new LoadFileHandler()); loadFile.load();&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式中的代理模式解析]]></title>
      <url>%2F2017%2F04%2F12%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B8%AD%E7%9A%84%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[很多地方都用到了代理模式，比如AOP就是代理模式的一种应用，还有dubbo中消费者在初始化的时候，并没有真正的去调用服务提供者执行真正业务逻辑，而是返回一个代理，等到使用的时候，再去调用调用实际业务逻辑。代理模式还有很多其他的应用，比如资源懒加载等。 代理模式定义代理模式：为其他对象提供一种代理，用以控制对这个对象的访问。从字面意义来理解，代理，就是代替别人做事。比如我们需要找别人要账，要不回来，怎么办？找代理（专门要账的）去做这件事，不管他们是怎么样去要，最终会把要来的钱给我。 代理模式的结构通常代理模式包含三个角色： Subject，抽象的主题角色 RealSubject，真实的主题角色 Proxy，代理主题角色 Subject一般是一个接口，需要被真实主题和代理主题实现。 代理模式举例比如，张三欠我钱，张三不给我，我就找代理去帮我要，当我去找代理帮我的时候，这时候其实张三已经不是欠我钱了，而是代理欠我钱，张三欠的是代理的钱。所以当我找代理的时候，代理和张三都应该被标记成是欠钱的人。 所以此时： Subject，这里就是表示欠钱的人，欠钱的人应该要做的就是还钱。 RealSubject，这里就是张三 Proxy，这里就是代理 Subject： 1234567891011121314package me.cxis.test.gof.proxy;/** * Created by cheng.xi on 2017-04-12 15:36. * 代理模式的主题类，这里代表的是欠钱的人 */public interface Subject &#123; /** * 还给我的钱 * @param moneyCount 欠钱数 * @return 还给我的钱数 */ int giveMeMyMoney(int moneyCount);&#125; RealSubject： 123456789101112package me.cxis.test.gof.proxy;/** * Created by cheng.xi on 2017-04-12 15:38. * 真实主题，这里代表的是欠我钱的人 */public class RealSubject implements Subject &#123; @Override public int giveMeMyMoney(int moneyCount) &#123; return moneyCount; &#125;&#125; Proxy： 123456789101112131415161718192021222324252627282930package me.cxis.test.gof.proxy;/** * Created by cheng.xi on 2017-04-12 15:40. * 代理，这里是专门要钱的机构 * 为什么他要实现Subject？我现在找代理帮我要钱，张三已经不欠我了， * 张三欠的是代理的，代理现在是欠我钱的人了 */public class Proxy implements Subject&#123; /** * 欠钱的人，代理会接受消息，都是关于欠钱人的信息 */ private Subject subject; public Proxy(Subject subject)&#123; this.subject = subject; &#125; @Override public int giveMeMyMoney(int moneyCount) &#123; System.out.println(&quot;代理：放心，我们去找他要钱&quot;); //要钱之前先跟张三做了一下交流，不知道他们做了什么 System.out.println(&quot;代理：张三，你欠钱不还，我们是xxx代理公司的。。。&quot;); //代理找张三要钱 int money = this.subject.giveMeMyMoney(moneyCount); System.out.println(&quot;代理：要到了，总共是：&quot; + money); return money; &#125;&#125; 测试方法： 12345678910111213141516171819package me.cxis.test.gof.proxy;/** * Created by cheng.xi on 2017-04-12 15:47. * 这里是我，我去找代理要钱，代理帮我找张三要钱 */public class Main &#123; public static void main(String[] args) &#123; //欠钱的人，张三 Subject zhangsan = new RealSubject(); //代理，招代理的时候，需要提供张三的信息 Proxy proxy = new Proxy(zhangsan); //代理去要钱，然后给我 int money = proxy.giveMeMyMoney(1000); System.out.println(&quot;我：我的钱要回来了：&quot; + money); &#125;&#125; 上面的代码只是举一个例子，当然上面并没有体现出来代理模式的好处，而只是做了一个代理模式的定义的解析。下面稍微聊一下关于代理模式的好处。 代理模式的优点其实了解代理模式的优点也不难，需要通过对比，我们还是以上面的例子来说吧，比如我们去找张三要钱，他不给，怎么办？有人说可以揍一顿，这优点不好，都是朋友，万一揍出来毛病咋整，不还得赖我吗？其实这里可以对比一下，直接修改代码，这里揍他就是把原来要钱的逻辑给修改了，要钱的时候先揍一顿，明显不好，不可取。 第二种办法是继承，这个没办法类比上面的例子了，总不能继承张三去！在一些场景也可以使用继承，但是也不太好。 第三种办法就是我们现在这种代理模式，，也是使用面向对象设计原则中合成/聚合复用原则的体现。 代理模式可以对外部提供一个统一的接口方法，代理类是真正操作真实类的地方，我不管代理怎么做的，我要的就是结果，代理再自己调用各种底层的组件去找结果。 代理模式的缺点代理有可能会很复杂，因为他要做的事情非常多；也有可能会有请求的延迟，毕竟中间我加了一层代理；还有可能会有很多很多的代理类需要写。 代理模式的应用场景 AOP是一个代理模式的应用，aop可以帮我们把需要额外的代码切入到现在有的代码中去，然后生成一个代理类，我们调用的时候，实际上调用的是代理类，代理类中就有了我们需要的额外的功能。 dubbo中消费者初始化的时候，初始化bean的时候，并不会去调用远程的服务提供者的实际业务逻辑，而是会在初始化阶段生成一个代理，代理中包含了远程调用的所有东西，只有在使用的时候才回去使用代理中的方法去调用。 远程调用，其实上面dubbo就是远程调用。 另外上面我们介绍的代理模式，是静态代理模式，就是我们需要代理的时候，需要自己写一个代理类，还有另外一一种方式，叫做动态代理，Spring AOP就是使用的动态代理机制。再另外的文章中会再介绍。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[AOP概念，原理，应用介绍]]></title>
      <url>%2F2017%2F04%2F12%2FAOP%E6%A6%82%E5%BF%B5%EF%BC%8C%E5%8E%9F%E7%90%86%EF%BC%8C%E5%BA%94%E7%94%A8%E4%BB%8B%E7%BB%8D%2F</url>
      <content type="text"><![CDATA[心情没法不沉重，被问到AOP是什么？AOP原理是什么？我竟然张大了嘴巴，说不出来！对于一个程序员的打击，还能有比这更大的吗？我没脸说我是个写代码的，我也没脸说我是程序员。 AOP是什么？定义AOP，面向切面编程，是对OOP的补充。从网上看到的一句话：这种在运行时，动态的将代码切入到类的指定方法或者指定位置上的编程思想，就是面向切面的编程。这是其中的一种方式，在运行时动态添加。还有另外一种是在编译代码的时候，将代码切入到指定的方法或者位置上去，这是静态添加的方式。 使用我们在实际的业务中都会有一些公共逻辑，比如日志的记录，事务的管理等等，而如果每次都把日志和事务的代码手动写到业务逻辑前后，重复代码就相当可怕，而如果这些额外代码有修改，必须要每个都修改，这是相当不明智的。AOP可以帮我们解决这些问题。 实现其实AOP本身并不能帮我们解决那些问题，AOP就是一种思想，而帮我们解决的是具体的AOP的实现，比如aspectj，jboss AOP，以及我们最熟悉的Spring AOP，Spring AOP在Spring1.0的时候是自己实现的AOP框架，在2.0之后就开始集成了aspectj。现在我们所说的Spring AOP就是Spring加Aspectj这种方式。 AOP的相关概念对于AOP中相关的概念，我们接触更多的还是Spring AOP，这里主要是以Spring AOP的概念来说明： Aspect，切面，一个关注点的模块化，这个关注点可能会横切多个对象。 JoinPoint，连接点，在程序执行过程中某个特定的点，比如某方法调用的时候或者处理异常的时候。在Spring AOP中，一个连接点总是表示一个方法的执行。 Advice，通知，在切面的某个特定的连接点上执行的动作。 Pointcut，切点，匹配连接点的断言。通知和一个切入点表达式关联，并在满足这个切入点的连接点上运行（例如，当执行某个特定名称的方法时）。切入点表达式如何和连接点匹配是AOP的核心：Spring缺省使用AspectJ切入点语法。 上面是关于AOP中几个基本概念的定义，下面看下有关我们使用时的一些概念： Target Object，目标对象，被一个或者多个切面所通知的对象。也就是我们业务中实际要进行增强的业务对象。 AOP Proxy，AOP代理，AOP框架创建的对象。也就是被增强之后的对象。 Weaving，织入，把切面连接到其它的应用程序类型或者对象上，并创建一个被通知的对象。就是把切面作用到目标对象，然后产生一个代理对象的过程。 还有另外一个概念，是给类声明额外方法的概念： Introduction，引介，用来给一个类型声明额外的方法或属性。就是我可以不用实现另外一个接口，就能使用那个接口的方法。 通知类型Advice是通知，也就是在切面的某个连接点上要执行的动作，也就是我们要编写的增强功能的代码。通知也分为好几种类型，分别有不同作用： 前置通知（Before advice）：在某连接点之前执行的通知，但这个通知不能阻止连接点之前的执行流程（除非它抛出一个异常）。 后置通知（After returning advice）：在某连接点正常完成后执行的通知：例如，一个方法没有抛出任何异常，正常返回。 异常通知（After throwing advice）：在方法抛出异常退出时执行的通知。 最终通知（After (finally) advice）：当某连接点退出的时候执行的通知（不论是正常返回还是异常退出）。 环绕通知（Around Advice）：包围一个连接点的通知，如方法调用。这是最强大的一种通知类型。环绕通知可以在方法调用前后完成自定义的行为。它也会选择是否继续执行连接点或直接返回它自己的返回值或抛出异常来结束执行。 AOP原理上面说到了AOP可以在编译时候将代码织入到指定的方法或者属性上，或者在运行的时候动态的将代码切入到指定的方法或者属性中，这描述了AOP应该要做的事情，其实也基本算是它的原理了，AOP实现的关键就是创建AOP代理，代理有静态代理和动态代理之分，其中aspectj为静态代理，Spring AOP是动态代理，这里把静态和运行时动态的分开说。 AspectJ编译时增强aspectj编译时增强，既是静态代理增强，也就是会在编译阶段生成代理，将代码织入到Java的字节码中去。 Spring AOP的运行时增强Spring AOP是基于代理机制的，并且Spring AOP使用的是动态代理增强，动态代理不会改变类的字节码，而是动态的生成代理对象。Spring AOP的动态代理机制有两种方式：JDK动态代理和CGLIB动态代理。 JDK动态代理JDK动态代理需要被代理的类必须实现一个接口，通过使用反射来接受被代理的类。 CGLIB动态代理CGLIB动态代理可以不用需要被代理类必须实现接口，被代理类可以是一个类。 Spring AOP上面说到了Spring AOP中使用的是动态代理机制，同时也分为两种代理机制：JDK动态代理和CGLIB动态代理，这可以在源码中看到，在DefaultAopProxyFactory的createAopProxy中可看到： 1234567891011public AopProxy createAopProxy(AdvisedSupport advisedSupport) throws AopConfigException &#123; //可以看到这里有条件是没有实现接口 boolean useCglib = advisedSupport.getOptimize() || advisedSupport.getProxyTargetClass() || advisedSupport.getProxiedInterfaces().length == 0; if (useCglib) &#123; return CglibProxyFactory.createCglibProxy(advisedSupport); &#125; else &#123; // Depends on whether we have expose proxy or frozen or static ts return new JdkDynamicAopProxy(advisedSupport); &#125;&#125; 对于接口的代理使用的JDK动态代理，而对于类的代理使用的是CGLIB动态代理。 AOP的使用场景AOP适用于具有横切逻辑的应用，比如性能监控，日志记录，缓存，事务管理，访问控制等。 有关Spring AOP的例子可以参考Spring中AOP的配置从1.0到5.0的演进，这里有具体的配置。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[自己写的，自己说不出来？]]></title>
      <url>%2F2017%2F04%2F11%2F%E8%87%AA%E5%B7%B1%E5%86%99%E7%9A%84%EF%BC%8C%E8%87%AA%E5%B7%B1%E8%AF%B4%E4%B8%8D%E5%87%BA%E6%9D%A5%EF%BC%9F%2F</url>
      <content type="text"><![CDATA[自己写的文章，被问到，自己却说不出来！一塌糊涂！真想抽大嘴巴子抽到不能停～开始怀疑，我是不是不适合做技术？经历一塌糊涂，技术一塌糊涂。还能做啥？ 不敢说我是做技术，做开发，做Java的了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring中AOP的配置从1.0到5.0的演进]]></title>
      <url>%2F2017%2F04%2F10%2FSpring%E4%B8%ADAOP%E7%9A%84%E9%85%8D%E7%BD%AE%E4%BB%8E1.0%E5%88%B05.0%E7%9A%84%E6%BC%94%E8%BF%9B%2F</url>
      <content type="text"><![CDATA[最近在学习Spring稍微深入一点的东西，在这过程中发现虽然有很多关于各种AOP，IOC原理配置等的文章，但是都只是针对某一版本或者压根儿就没有标明版本的解析配置等。或许是我理解力不够，为了方便自己以后快速找到这些东西去看，还是自己记录下。 这里主要是记录下从Spring1.0到现在的5.0中AOP的配置方式，关于AOP原理和源码，暂先不解释。主要用作自己记录用，如果有错误的还请指出一起改正学习，免得误导别人，谢谢。 Spring1中AOP的配置直接看Spring1.1.1的文档，里面都已经给出来了各种配置方式，更高版本的也都包含了这些，但是觉得看1.1.1的更纯粹一些。 使用ProxyFactoryBean创建AOP代理使用ProxyFactoryBean的方式来配置AOP，是最基础的方法。这里我们用的是代理接口的方式，步骤大概是： 定义我们的业务接口和业务实现类。 定义通知类，就是我们要对目标对象进行增强的类。 定义ProxyFactoryBean，这里封装了AOP的功能。 这就是Spring中AOP的配置，这种方式简单明了，往下接着看示例代码。 我们的业务接口，LoginService： 12345678package me.cxis.spring.aop;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125; 业务接口的实现类，LoginServiceImpl： 123456789101112package me.cxis.spring.aop;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; public String login(String userName)&#123; System.out.println(&quot;正在登录&quot;); return &quot;success&quot;; &#125;&#125; 在登录前做一些操作的通知类，LogBeforeLogin： 123456&#x2F;&#x2F;这里只是在登录方法调用之前打印一句话public class LogBeforeLogin implements MethodBeforeAdvice &#123; public void before(Method method, Object[] objects, Object o) throws Throwable &#123; System.out.println(&quot;有人要登录了。。。&quot;); &#125;&#125; 配置文件，在Spring1.x中主要还是用xml的方式来配置： 123456789101112131415161718192021222324252627&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE beans PUBLIC &quot;-&#x2F;&#x2F;SPRING&#x2F;&#x2F;DTD BEAN&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;dtd&#x2F;spring-beans.dtd&quot;&gt;&lt;beans&gt; &lt;!--业务处理类，也就是被代理的类--&gt; &lt;bean id&#x3D;&quot;loginServiceImpl&quot; class&#x3D;&quot;me.cxis.spring.aop.LoginServiceImpl&quot;&#x2F;&gt; &lt;!--通知类--&gt; &lt;bean id&#x3D;&quot;logBeforeLogin&quot; class&#x3D;&quot;me.cxis.spring.aop.LogBeforeLogin&quot;&#x2F;&gt; &lt;!--代理类--&gt; &lt;bean id&#x3D;&quot;loginProxy&quot; class&#x3D;&quot;org.springframework.aop.framework.ProxyFactoryBean&quot;&gt; &lt;!--要代理的接口--&gt; &lt;property name&#x3D;&quot;proxyInterfaces&quot;&gt; &lt;value&gt;me.cxis.spring.aop.LoginService&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;!--拦截器名字，也就是我们定义的通知类--&gt; &lt;property name&#x3D;&quot;interceptorNames&quot;&gt; &lt;list&gt; &lt;value&gt;logBeforeLogin&lt;&#x2F;value&gt; &lt;&#x2F;list&gt; &lt;&#x2F;property&gt; &lt;!--目标类，就是我们业务的实现类--&gt; &lt;property name&#x3D;&quot;target&quot;&gt; &lt;ref bean&#x3D;&quot;loginServiceImpl&quot;&#x2F;&gt; &lt;&#x2F;property&gt; &lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; 测试方法，Main： 1234567891011121314151617package me.cxis.spring.aop;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:aop.xml&quot;); LoginService loginService &#x3D; (LoginService) applicationContext.getBean(&quot;loginProxy&quot;); loginService.login(&quot;sdf&quot;); &#125;&#125; 上面的例子是用的是代理接口的方式，关于代理类的方式这里不做介绍，代理类的方式需要依赖CGLIB。从上面的代码可以看到，这种方式使用AOP简单直观，也是我们理解Spring AOP原理的很好的入口，但是在使用的时候，可能会发现业务增多了之后，ProxyFactoryBean的配置也会增多，导致xml迅速变多。 另外这种方式的使用会把LoginService接口中所有的方法都代理了，也就是说每个方法都会被增强，如果不想被增强，还可以使用另外一种方式，配置Advisor。 使用ProxyFactoryBean和Advisor的方式创建AOP代理使用Advisor配合，可以指定要增强的方法，不会把整个类中的所有方法都代理了。 这种方式跟上面的方式相比较，只是xml配置文件发生了变化，其他的代码都没有变，所以这里只列出了xml代码，其他的参照上面的代码。 xml配置： 12345678910111213141516171819202122232425262728293031&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE beans PUBLIC &quot;-&#x2F;&#x2F;SPRING&#x2F;&#x2F;DTD BEAN&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;dtd&#x2F;spring-beans.dtd&quot;&gt;&lt;beans&gt; &lt;!--业务处理类，也就是被代理的类--&gt; &lt;bean id&#x3D;&quot;loginServiceImpl&quot; class&#x3D;&quot;me.cxis.spring.aop.advisor.LoginServiceImpl&quot;&#x2F;&gt; &lt;!--通知类--&gt; &lt;bean id&#x3D;&quot;logBeforeLogin&quot; class&#x3D;&quot;me.cxis.spring.aop.advisor.LogBeforeLogin&quot;&#x2F;&gt; &lt;!--切面--&gt; &lt;bean id&#x3D;&quot;loginAdvisor&quot; class&#x3D;&quot;org.springframework.aop.support.RegexpMethodPointcutAdvisor&quot;&gt; &lt;property name&#x3D;&quot;advice&quot;&gt; &lt;ref bean&#x3D;&quot;logBeforeLogin&quot;&#x2F;&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;pattern&quot;&gt; &lt;value&gt;me.cxis.spring.aop.advisor.LoginServiceImpl.login*&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;&#x2F;bean&gt; &lt;!--代理类--&gt; &lt;bean id&#x3D;&quot;loginProxy&quot; class&#x3D;&quot;org.springframework.aop.framework.ProxyFactoryBean&quot;&gt; &lt;property name&#x3D;&quot;interceptorNames&quot;&gt; &lt;list&gt; &lt;value&gt;loginAdvisor&lt;&#x2F;value&gt; &lt;&#x2F;list&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;target&quot;&gt; &lt;ref bean&#x3D;&quot;loginServiceImpl&quot;&#x2F;&gt; &lt;&#x2F;property&gt; &lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; 可以看到这里我们多了Advisor，Advisor中可以使用正则表达式来匹配要增强的方法。 使用ProxyFactory编程的方式创建AOP代理也可以使用直接代码的方式，不依赖xml文件，来创建AOP代理，直接看示例代码。 业务接口，LoginService： 12345678package me.cxis.spring.aop.proxyfactory;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125; 业务接口实现类，LoginServiceImpl： 123456789101112package me.cxis.spring.aop.proxyfactory;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; public String login(String userName)&#123; System.out.println(&quot;正在登录&quot;); return &quot;success&quot;; &#125;&#125; 通知类，LogBeforeLogin： 1234567891011121314package me.cxis.spring.aop.proxyfactory;import org.springframework.aop.MethodBeforeAdvice;import java.lang.reflect.Method;&#x2F;** * Created by cheng.xi on 2017-03-29 10:56. *&#x2F;public class LogBeforeLogin implements MethodBeforeAdvice &#123; public void before(Method method, Object[] objects, Object o) throws Throwable &#123; System.out.println(&quot;有人要登录了。。。&quot;); &#125;&#125; 测试方法： 123456789101112131415161718192021package me.cxis.spring.aop.proxyfactory;import org.springframework.aop.framework.ProxyFactory;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ProxyFactory proxyFactory &#x3D; new ProxyFactory();&#x2F;&#x2F;创建代理工厂 proxyFactory.setTarget(new LoginServiceImpl());&#x2F;&#x2F;设置目标对象 proxyFactory.addAdvice(new LogBeforeLogin());&#x2F;&#x2F;前置增强 LoginService loginService &#x3D; (LoginService) proxyFactory.getProxy();&#x2F;&#x2F;从代理工厂中获取代理 loginService.login(&quot;x&quot;); &#125;&#125; 这种方式跟上面使用ProxyFactoryBean的方式差不多，步骤也基本相同，不做过多解释。Spring不推荐这种方式。 使用autoproxy方式创建AOP使用这种方式创建AOP代理，最主要的是可以使用一个配置来代理多个业务bean，也就是跟上面使用ProxyFactoryBean不同的地方，ProxyFactoryBean需要配置很多个ProxyFactoryBean配置，而autoproxy相对会很少。 使用autoproxy也有两种方式：BeanNameAutoProxyCreator和DefaultAdvisorAutoProxyCreator。两种方式的差别直接看代码。 BeanNameAutoProxyCreator方式业务接口，LoginService： 12345678package me.cxis.spring.aop.autoproxy;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125; 业务接口实现类，LoginServiceImpl： 123456789101112package me.cxis.spring.aop.autoproxy;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; public String login(String userName)&#123; System.out.println(&quot;autoproxy:正在登录&quot;); return &quot;success&quot;; &#125;&#125; 通知类，LogBeforeLogin： 1234567891011121314package me.cxis.spring.aop.autoproxy;import org.springframework.aop.MethodBeforeAdvice;import java.lang.reflect.Method;&#x2F;** * Created by cheng.xi on 2017-03-29 10:56. *&#x2F;public class LogBeforeLogin implements MethodBeforeAdvice &#123; public void before(Method method, Object[] objects, Object o) throws Throwable &#123; System.out.println(&quot;autoproxy:有人要登录了。。。&quot;); &#125;&#125; xml配置文件： 12345678910111213141516171819202122&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE beans PUBLIC &quot;-&#x2F;&#x2F;SPRING&#x2F;&#x2F;DTD BEAN&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;dtd&#x2F;spring-beans.dtd&quot;&gt;&lt;beans&gt; &lt;!--业务处理类，也就是被代理的类--&gt; &lt;bean id&#x3D;&quot;loginService&quot; class&#x3D;&quot;me.cxis.spring.aop.autoproxy.LoginServiceImpl&quot;&#x2F;&gt; &lt;!--通知类--&gt; &lt;bean id&#x3D;&quot;logBeforeLogin&quot; class&#x3D;&quot;me.cxis.spring.aop.autoproxy.LogBeforeLogin&quot;&#x2F;&gt; &lt;!--代理类--&gt; &lt;bean id&#x3D;&quot;loginServiceProxy&quot; class&#x3D;&quot;org.springframework.aop.framework.autoproxy.BeanNameAutoProxyCreator&quot;&gt; &lt;property name&#x3D;&quot;interceptorNames&quot;&gt; &lt;list&gt; &lt;value&gt;logBeforeLogin&lt;&#x2F;value&gt; &lt;&#x2F;list&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;beanNames&quot;&gt; &lt;value&gt;loginService*&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; 测试方法，Main： 12345678910111213141516package me.cxis.spring.aop.autoproxy;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:aop-auto-proxy.xml&quot;); LoginService loginService &#x3D; (LoginService) applicationContext.getBean(&quot;loginService&quot;); loginService.login(&quot;sdf&quot;); &#125;&#125; 在xml配置中beanNames的值我们使用了通配符，也就是我们可以使用这一个BeanNameAutoProxyCreator来匹配很多个接口，在ProxyFactoryBean的方式中，我们则需要配置很多ProxyFactoryBean的配置。 另外也需要注意下在测试方法中我们对bean的调用方式，之前我们是调用代理类，现在我们直接调用的Bean。这种方式中也还是把业务类中的所有的方法都增强了。 DefaultAdvisorAutoProxyCreator方式业务接口，LoginService： 12345678package me.cxis.spring.aop.advisorautoproxy;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125; 业务接口实现类，LoginServiceImpl： 123456789101112package me.cxis.spring.aop.advisorautoproxy;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; public String login(String userName)&#123; System.out.println(&quot;advisorautoproxy:正在登录&quot;); return &quot;success&quot;; &#125;&#125; 通知类，LogBeforeLogin： 1234567891011121314package me.cxis.spring.aop.advisorautoproxy;import org.springframework.aop.MethodBeforeAdvice;import java.lang.reflect.Method;&#x2F;** * Created by cheng.xi on 2017-03-29 10:56. *&#x2F;public class LogBeforeLogin implements MethodBeforeAdvice &#123; public void before(Method method, Object[] objects, Object o) throws Throwable &#123; System.out.println(&quot;advisorautoproxy:有人要登录了。。。&quot;); &#125;&#125; 配置文件xml： 12345678910111213141516171819202122&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE beans PUBLIC &quot;-&#x2F;&#x2F;SPRING&#x2F;&#x2F;DTD BEAN&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;dtd&#x2F;spring-beans.dtd&quot;&gt;&lt;beans&gt; &lt;!--业务处理类，也就是被代理的类--&gt; &lt;bean id&#x3D;&quot;loginService&quot; class&#x3D;&quot;me.cxis.spring.aop.advisorautoproxy.LoginServiceImpl&quot;&#x2F;&gt; &lt;!--通知类--&gt; &lt;bean id&#x3D;&quot;logBeforeLogin&quot; class&#x3D;&quot;me.cxis.spring.aop.advisorautoproxy.LogBeforeLogin&quot;&#x2F;&gt; &lt;bean id&#x3D;&quot;logBeforeAdvisor&quot; class&#x3D;&quot;org.springframework.aop.support.RegexpMethodPointcutAdvisor&quot;&gt; &lt;property name&#x3D;&quot;advice&quot;&gt; &lt;ref bean&#x3D;&quot;logBeforeLogin&quot;&#x2F;&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;pattern&quot;&gt; &lt;value&gt;me.cxis.spring.aop.advisorautoproxy.*&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;&#x2F;bean&gt; &lt;!--代理类--&gt; &lt;bean id&#x3D;&quot;advisorAutoProxy&quot; class&#x3D;&quot;org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator&quot;&gt; &lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; 测试方法： 1234567891011121314151617package me.cxis.spring.aop.advisorautoproxy;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:aop-advisor-auto-proxy.xml&quot;); LoginService loginService &#x3D; (LoginService) applicationContext.getBean(&quot;loginService&quot;); loginService.login(&quot;sdf&quot;); &#125;&#125; 在这里的配置文件中我们使用了正则的方式来配置Advisor，这种可以匹配指定的方法，不需要把类中的所有的方法都增强了。 引介增强Introduction上面所有AOP的代理都是对方法的增强，而引介增强则是对类的增强，所谓对类的增强就是，我是A类，实现了接口B，但是我没有实现接口C，那么通过引介增强的方式，我没有实现接口C，但是我可以调用C中的方法。 业务接口，LoginService： 12345678package me.cxis.spring.aop.introduction;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125; 业务接口实现类： 123456789101112package me.cxis.spring.aop.introduction;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; public String login(String userName)&#123; System.out.println(&quot;正在登录&quot;); return &quot;success&quot;; &#125;&#125; 另外一个业务接口，SendEmailService： 12345678package me.cxis.spring.aop.introduction;&#x2F;** * Created by cheng.xi on 2017-03-30 23:45. *&#x2F;public interface SendEmailService &#123; void sendEmail();&#125; 增强，LogAndSendEmailBeforeLogin： 123456789101112131415161718192021222324package me.cxis.spring.aop.introduction;import org.aopalliance.intercept.MethodInvocation;import org.springframework.aop.MethodBeforeAdvice;import org.springframework.aop.support.DelegatingIntroductionInterceptor;import java.lang.reflect.Method;&#x2F;** * Created by cheng.xi on 2017-03-29 10:56. *&#x2F;public class LogAndSendEmailBeforeLogin extends DelegatingIntroductionInterceptor implements SendEmailService &#123; @Override public Object invoke(MethodInvocation mi) throws Throwable &#123; System.out.println(&quot;有人要登录了。。。&quot;); return super.invoke(mi); &#125; public void sendEmail() &#123; System.out.println(&quot;发送邮件。。。。&quot;); &#125;&#125; xml配置文件： 123456789101112131415161718192021222324252627&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE beans PUBLIC &quot;-&#x2F;&#x2F;SPRING&#x2F;&#x2F;DTD BEAN&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;dtd&#x2F;spring-beans.dtd&quot;&gt;&lt;beans&gt; &lt;!--业务处理类，也就是被代理的类--&gt; &lt;bean id&#x3D;&quot;loginServiceImpl&quot; class&#x3D;&quot;me.cxis.spring.aop.introduction.LoginServiceImpl&quot;&#x2F;&gt; &lt;!--通知类--&gt; &lt;bean id&#x3D;&quot;logAndSendEmailBeforeLogin&quot; class&#x3D;&quot;me.cxis.spring.aop.introduction.LogAndSendEmailBeforeLogin&quot;&#x2F;&gt; &lt;!--代理类--&gt; &lt;bean id&#x3D;&quot;loginProxy&quot; class&#x3D;&quot;org.springframework.aop.framework.ProxyFactoryBean&quot;&gt; &lt;property name&#x3D;&quot;interfaces&quot;&gt; &lt;value&gt;me.cxis.spring.aop.introduction.SendEmailService&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;interceptorNames&quot;&gt; &lt;list&gt; &lt;value&gt;logAndSendEmailBeforeLogin&lt;&#x2F;value&gt; &lt;&#x2F;list&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;target&quot;&gt; &lt;ref bean&#x3D;&quot;loginServiceImpl&quot;&#x2F;&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;proxyTargetClass&quot;&gt; &lt;value&gt;true&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; 测试方法： 12345678910111213141516171819package me.cxis.spring.aop.introduction;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:aop-introduction.xml&quot;); LoginServiceImpl loginService &#x3D; (LoginServiceImpl) applicationContext.getBean(&quot;loginProxy&quot;); loginService.login(&quot;sdf&quot;); SendEmailService sendEmailService &#x3D; (SendEmailService) loginService; sendEmailService.sendEmail(); &#125;&#125; 这样就可以了～ Spring2中AOP的配置What’s new in Spring 2.0? 添加了基于schema的AOP支持。 加入了AspectJ的支持，添加了@AspectJ注解。 上面就是AOP在2.0版本新增的特性，1.0的所有AOP配置方式在2.0中都支持，下面主要看看2.0中新增的一些方法。 使用@AspectJ的方式配置AOP代理步骤大概如下： 定义我们的业务接口和业务实现类。 定义通知类，就是我们要对目标对象进行增强的类。使用@AspectJ注解。 启用@AspectJ支持。 还是看代码。 业务接口，LoginService： 12345678package me.cxis.spring.aop;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125; 业务接口实现，LoginServiceImpl： 123456789101112package me.cxis.spring.aop;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; public String login(String userName)&#123; System.out.println(&quot;正在登录&quot;); return &quot;success&quot;; &#125;&#125; 增强类，LogBeforeLogin，请注意这里面使用了注解： 1234567891011121314151617181920package me.cxis.spring.aop;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;&#x2F;** * Created by cheng.xi on 2017-03-29 10:56. *&#x2F;@Aspectpublic class LogBeforeLogin &#123; @Pointcut(&quot;execution(* me.cxis.spring.aop.*.login(..))&quot;) public void loginMethod()&#123;&#125; @Before(&quot;loginMethod()&quot;) public void beforeLogin()&#123; System.out.println(&quot;有人要登录了。。。&quot;); &#125;&#125; xml配置文件： 12345678910111213141516&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xmlns:aop&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&#x2F;spring-aop.xsd&quot;&gt; &lt;!--@AspectJ支持--&gt; &lt;aop:aspectj-autoproxy&#x2F;&gt; &lt;!--业务实现--&gt; &lt;bean id&#x3D;&quot;loginService&quot; class&#x3D;&quot;me.cxis.spring.aop.LoginServiceImpl&quot;&#x2F;&gt; &lt;!--Aspect--&gt; &lt;bean id&#x3D;&quot;logBeforeLoginAspect&quot; class&#x3D;&quot;me.cxis.spring.aop.LogBeforeLogin&quot;&gt; &lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; 测试方法： 12345678910111213141516package me.cxis.spring.aop;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:aop.xml&quot;); LoginService loginService &#x3D; (LoginService) applicationContext.getBean(&quot;loginService&quot;); loginService.login(&quot;sdf&quot;); &#125;&#125; 可以看下上面的配置文件，首先开启@AspectJ注解的支持，然后只需要声明一下业务bean和增强bean，其余的都不用做了，是不是比以前方便多了。以前的那些配置，全部都在增强类中用注解处理了。 使用自定义注解作为execution的表达式上面使用普通的execution表达式来声明对那些方法进行增强，也可以使用注解的方式，其实就是把表达式换成了注解，只有添加了注解的方法才能被增强。 先定义一个注解UseAop： 123456789101112131415package me.cxis.spring.aop.customannotation;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;&#x2F;** * Created by cheng.xi on 2017-03-31 11:29. * 标注此注解的方法，需要使用AOP代理 *&#x2F;@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface UseAop &#123;&#125; 业务接口，LoginService： 12345678package me.cxis.spring.aop.customannotation;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125; 业务接口的实现，LoginServiceImpl： 12345678910111213package me.cxis.spring.aop.customannotation;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; @UseAop public String login(String userName)&#123; System.out.println(&quot;正在登录&quot;); return &quot;success&quot;; &#125;&#125; 这里业务实现类的方法使用了注解，表明这个方法需要使用AOP代理。 增强类，LogBeforeLogin： 1234567891011@Aspectpublic class LogBeforeLogin &#123; @Pointcut(&quot;@annotation(me.cxis.spring.aop.customannotation.UseAop)&quot;) public void loginMethod()&#123;&#125; @Before(&quot;loginMethod()&quot;) public void beforeLogin()&#123; System.out.println(&quot;有人要登录了。。。&quot;); &#125;&#125; 这里是把表达式换成了我们定义的注解。 xml配置： 12345678910111213141516&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xmlns:aop&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&#x2F;spring-aop.xsd&quot;&gt; &lt;!--@AspectJ支持--&gt; &lt;aop:aspectj-autoproxy&#x2F;&gt; &lt;!--业务实现--&gt; &lt;bean id&#x3D;&quot;loginService&quot; class&#x3D;&quot;me.cxis.spring.aop.customannotation.LoginServiceImpl&quot;&#x2F;&gt; &lt;!--Aspect--&gt; &lt;bean id&#x3D;&quot;logBeforeLoginAspect&quot; class&#x3D;&quot;me.cxis.spring.aop.customannotation.LogBeforeLogin&quot;&gt; &lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; xml配置文件并没有改变。同样下面的测试方法也没有变。 测试方法： 12345678910111213141516package me.cxis.spring.aop.customannotation;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:aop-annotation.xml&quot;); LoginService loginService &#x3D; (LoginService) applicationContext.getBean(&quot;loginService&quot;); loginService.login(&quot;sdf&quot;); &#125;&#125; 使用基于schema的方式配置AOP代理基于schema的方式配置，可以不使用注解，而是完全基于xml配置。 业务接口，实现类，增强如下： 123456789101112131415161718192021222324252627282930313233package me.cxis.spring.aop.config;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125;package me.cxis.spring.aop.config;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; public String login(String userName)&#123; System.out.println(&quot;正在登录&quot;); return &quot;success&quot;; &#125;&#125;package me.cxis.spring.aop.config;&#x2F;** * Created by cheng.xi on 2017-03-29 10:56. *&#x2F;public class LogBeforeLogin &#123; public void beforeLogin()&#123; System.out.println(&quot;有人要登录了。。。&quot;); &#125;&#125; 可以看到上面三个类中，增强类只是一个普通的bean而已，所有的配置都在xml中。 xml配置： 12345678910111213141516171819&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xmlns:aop&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&#x2F;spring-aop.xsd&quot;&gt; &lt;!--业务实现类--&gt; &lt;bean id&#x3D;&quot;loginService&quot; class&#x3D;&quot;me.cxis.spring.aop.config.LoginServiceImpl&quot;&gt;&lt;&#x2F;bean&gt; &lt;!--增强类--&gt; &lt;bean id&#x3D;&quot;logBeforeLogin&quot; class&#x3D;&quot;me.cxis.spring.aop.config.LogBeforeLogin&quot;&gt;&lt;&#x2F;bean&gt; &lt;aop:config&gt; &lt;aop:aspect id&#x3D;&quot;loginAspect&quot; ref&#x3D;&quot;logBeforeLogin&quot;&gt; &lt;aop:pointcut expression&#x3D;&quot;execution(* me.cxis.spring.aop.config.*.*(..))&quot; id&#x3D;&quot;beforeLoginPointCut&quot;&#x2F;&gt; &lt;aop:before method&#x3D;&quot;beforeLogin&quot; pointcut-ref&#x3D;&quot;beforeLoginPointCut&quot;&#x2F;&gt; &lt;&#x2F;aop:aspect&gt; &lt;&#x2F;aop:config&gt;&lt;&#x2F;beans&gt; 可以类比下上面@AspectJ的方式，其实是一样的，只不过把注解的东西都放到了xml中。 测试方法： 12345678910111213141516package me.cxis.spring.aop.config;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:aop-config.xml&quot;); LoginService loginService &#x3D; (LoginService) applicationContext.getBean(&quot;loginService&quot;); loginService.login(&quot;sdf&quot;); &#125;&#125; 使用dtd方式我们上面看到使用&lt;aop:aspectj-autoproxy/&gt;来启用@AspectJ的支持，这种方式使用的基于schema扩展的，如果想用原来的DTD模式也是可以的，使用AnnotationAwareAspectJAutoProxyCreator即可。 业务接口，业务实现类，增强类的代码都跟使用@AspectJ的方式配置AOP代理这一步的一样，除了xml里面有点不一样，代码如下： 123456789101112131415&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans.xsd &quot;&gt; &lt;bean class&#x3D;&quot;org.springframework.aop.aspectj.annotation.AnnotationAwareAspectJAutoProxyCreator&quot;&#x2F;&gt; &lt;!--业务实现--&gt; &lt;bean id&#x3D;&quot;loginService&quot; class&#x3D;&quot;me.cxis.spring.aop.dtd.LoginServiceImpl&quot;&#x2F;&gt; &lt;!--Aspect--&gt; &lt;bean id&#x3D;&quot;logBeforeLoginAspect&quot; class&#x3D;&quot;me.cxis.spring.aop.dtd.LogBeforeLogin&quot;&gt; &lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; 就是将&lt;aop:aspectj-autoproxy/&gt;替换成&lt;bean class=&quot;org.springframework.aop.aspectj.annotation.AnnotationAwareAspectJAutoProxyCreator&quot;/&gt;，Spring文档上也有说明。 编程的方式使用@AspectJ业务接口LoginService： 12345678package me.cxis.spring.aop.programmatic;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125; 业务实现类： 123456789101112package me.cxis.spring.aop.programmatic;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; public String login(String userName)&#123; System.out.println(&quot;正在登录&quot;); return &quot;success&quot;; &#125;&#125; 增强类： 123456789101112131415161718192021package me.cxis.spring.aop.programmatic;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;&#x2F;** * Created by cheng.xi on 2017-03-29 10:56. *&#x2F;@Aspectpublic class LogBeforeLogin &#123; @Pointcut(&quot;execution(* me.cxis.spring.aop.programmatic.*.login(..))&quot;) public void loginMethod()&#123;&#125; @Before(&quot;loginMethod()&quot;) public void beforeLogin()&#123; System.out.println(&quot;有人要登录了。。。&quot;); &#125;&#125; 测试方法： 12345678910111213141516171819package me.cxis.spring.aop.programmatic;import org.springframework.aop.aspectj.annotation.AspectJProxyFactory;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; AspectJProxyFactory factory &#x3D; new AspectJProxyFactory();&#x2F;&#x2F;创建代理工厂 factory.setTarget(new LoginServiceImpl());&#x2F;&#x2F;设置目标类 factory.addAspect(LogBeforeLogin.class);&#x2F;&#x2F;设置增强 LoginService loginService &#x3D; factory.getProxy();&#x2F;&#x2F;获取代理 loginService.login(&quot;xsd&quot;); &#125;&#125; 基本跟使用xml方式的@Aspect的步骤差不多。 引介增强Introduction感觉引介增强比1.0更强大了点，直接看代码，对比1.0的引介就知道了。 业务接口： 12345678package me.cxis.spring.aop.introduction;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125; 接口实现： 123456789101112package me.cxis.spring.aop.introduction;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; public String login(String userName)&#123; System.out.println(&quot;正在登录&quot;); return &quot;success&quot;; &#125;&#125; 另外一个业务接口： 12345678package me.cxis.spring.aop.introduction;&#x2F;** * Created by cheng.xi on 2017-03-30 23:45. *&#x2F;public interface SendEmailService &#123; void sendEmail();&#125; 接口实现： 12345678910package me.cxis.spring.aop.introduction;&#x2F;** * Created by cheng.xi on 2017-03-31 13:46. *&#x2F;public class SendMailServiceImpl implements SendEmailService &#123; public void sendEmail() &#123; System.out.println(&quot;发送邮件。。。。&quot;); &#125;&#125; 增强，也就是把上面两个接口关联起来的地方： 1234567891011121314package me.cxis.spring.aop.introduction;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.DeclareParents;&#x2F;** * Created by cheng.xi on 2017-03-29 10:56. *&#x2F;@Aspectpublic class LogAndSendEmailBeforeLogin &#123; @DeclareParents(value &#x3D; &quot;me.cxis.spring.aop.introduction.LoginServiceImpl&quot;,defaultImpl &#x3D; SendMailServiceImpl.class) private SendEmailService sendEmailService;&#125; xml配置： 12345678910111213141516&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xmlns:aop&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&#x2F;spring-aop.xsd&quot;&gt; &lt;!--@AspectJ支持--&gt; &lt;aop:aspectj-autoproxy&#x2F;&gt; &lt;!--业务实现--&gt; &lt;bean id&#x3D;&quot;loginService&quot; class&#x3D;&quot;me.cxis.spring.aop.introduction.LoginServiceImpl&quot;&#x2F;&gt; &lt;!--Aspect--&gt; &lt;bean id&#x3D;&quot;logBeforeLoginAspect&quot; class&#x3D;&quot;me.cxis.spring.aop.introduction.LogAndSendEmailBeforeLogin&quot;&gt; &lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; 测试方法： 12345678910111213141516171819package me.cxis.spring.aop.introduction;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:aop-introduction.xml&quot;); LoginService loginService &#x3D; (LoginService) applicationContext.getBean(&quot;loginService&quot;); loginService.login(&quot;sdf&quot;); SendEmailService sendEmailService &#x3D; (SendEmailService) loginService; sendEmailService.sendEmail(); &#125;&#125; 具体的Introduction不做过多解释。另外上面也都是基于接口进行的代理，关于基于类的，这里不做说明。 上面是Spring2.0新增的关于AOP的配置的东西，1.0的方式在2.0中仍然适用。另外在Spring2.5中还增加了AspectJ的load-time织入的支持，也就是在类加载的时候织入。 Spring3,4,5中AOP的配置Spring3,4,5基本就没在增加新的配置方式了，使用的方式基本都还是1.0和2.0中的方式，但是还会有很多的细节以及小特性添加，这里不能过多深入理解。暂先到这里。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JUC中Lock和ReentrantLock介绍及源码解析]]></title>
      <url>%2F2017%2F04%2F08%2FJUC%E4%B8%ADLock%E5%92%8CReentrantLock%E4%BB%8B%E7%BB%8D%E5%8F%8A%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[Lock框架是jdk1.5新增的，作用和synchronized的作用一样，所以学习的时候可以和synchronized做对比。在这里先和synchronized做一下简单对比，然后分析下Lock接口以及ReentrantLock的源码和说明。具体的其他的Lock实现的分析在后面会慢慢介绍。 Lock框架和synchronized有关synchronized的作用和用法不在具体说明，应该都很熟悉了。而Lock有着和synchronized一样的语意，但是比synchronized多了一些功能，单单就从Lock接口定义来看，比synchronized多出来的功能有： 可中断的获取锁，就是获取锁的线程可以响应中断。 可以尝试获取锁，也就是非阻塞获取锁，一个线程可以尝试去获取锁，获取成功就持有锁并返回true，否则返回false。 带超时的尝试获取锁，就是在尝试获取锁的时候，会有超时时间，当到达了指定的时间后，还未获取到锁，就返回false。 除了定义之外，Lock框架还和synchronized有不一样的是： Lock需要显示的加锁和释放锁，而且一定要在finally中去释放锁。而synchronized则不需要我们去关心锁的释放。 锁的公平性，Lock接口并没有定义有关公平性的方法，而是在具体的实现类中使用AQS来实现锁的公平性。 Lock接口源码1234567891011121314151617181920212223242526public interface Lock &#123; //获取锁，获取到锁后返回 //注意一定要记得释放锁 void lock(); //可中断的获取锁 //获取锁的时候，如果线程正在等待获取锁，则该线程能响应中断 void lockInterruptibly() throws InterruptedException; //尝试获取锁，当线程获取锁的时候，获取成功与否都会立即返回 //不会一直等着去获取锁 boolean tryLock(); //带有超时时间的尝试获取锁 //在一定的时间内获取到锁会返回true //在这段时间内被中断了，会返回 //在这段时间内，没有获取到锁，会返回false boolean tryLock(long time, TimeUnit unit) throws InterruptedException; //释放锁 void unlock(); //获取一个Condition对象。 Condition newCondition();&#125; Lock接口的定义并不复杂，获取锁释放锁以及非阻塞式的获取锁等方法的定义。其实想象一下日常使用的时候，也大概是如此，获取锁，释放锁，获取锁的时候没有得到锁，我就转一圈回来再试试，等到一定时间之后，我就不要了，走了。接口的定义没有太多要说的，接下来看Lock接口的实现。 Lock接口的实现Lock接口主要的实现是ReentrantLock重入锁，另外还有ConcurrentHashMap中的Segment继承了ReentrantLock，在ReentrantReadWriteLock中的WriteLock和ReadLock也实现了Lock接口。 ReentrantLockReentrantLock是一个可重入的互斥锁，等同于synchronized，但是比synchronized更强大灵活，减少死锁发生的概率。我们上面说Lock框架提供了公平锁的机制，就是在ReentrantLock中有提供公平锁机制的实现，默认为非公平锁。 在继续看ReentrantLock的各个方法实现之前，首先需要了解下内部是怎么实现公平锁和非公平锁的，其实想一下也简单，比如我就是一可重入锁ReentrantLock，你想从我这获得到公平的还是不公平的，但是不能我说什么就是什么，我这里有一个天平（AQS），这个是大家公认的可以实现公平和不公平的机器，你找我要，我就给天平说一声，他来操作，然后我再把结果给你。（越描述越复杂！）。几乎ReentrantLock中所有的操作都会交给Sync去实现。 有关AQS这里不做介绍，在AQS专门的文章有介绍，请自行查阅把。接下来就看看我拿着的两把锁，公平和不公平。 SyncSync是公平和非公平两种的基类，直接看代码，看不明白的话，可以先看下面公平和非公平的解析，然后再返回来： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677//继承自AQSabstract static class Sync extends AbstractQueuedSynchronizer &#123; //由具体的子类实现，即公平和非公平的有不同实现 abstract void lock(); //非公平的尝试获取 final boolean nonfairTryAcquire(int acquires) &#123; //当前线程 final Thread current = Thread.currentThread(); //当前AQS同步器的状态 int c = getState(); //状态为0，说明没有人获取锁 if (c == 0) &#123; //尝试获取，获取成功设为独占模式 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; //这里解释跟公平的一样，参照下面的 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; //尝试释放 protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125; //是否是独占 protected final boolean isHeldExclusively() &#123; // While we must in general read state before owner, // we don&apos;t need to do so to check if current thread is owner return getExclusiveOwnerThread() == Thread.currentThread(); &#125; final ConditionObject newCondition() &#123; return new ConditionObject(); &#125; // Methods relayed from outer class //获取持有者线程 final Thread getOwner() &#123; return getState() == 0 ? null : getExclusiveOwnerThread(); &#125; //获取重入数 final int getHoldCount() &#123; return isHeldExclusively() ? getState() : 0; &#125; //是否锁了 final boolean isLocked() &#123; return getState() != 0; &#125; // private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; s.defaultReadObject(); setState(0); // reset to unlocked state &#125;&#125; FairSync公平锁的实现，有关公平的实现，是此类进行处理的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//继承自Syncstatic final class FairSync extends Sync &#123; //获取锁 //公平的lock方法交给了AQS的acquire方法去处理 //acquire方法采用独占模式，并且忽略中断 //而AQS获取锁的实现是先使用tryAcquire方法获取，获取不到就加入到队列中，一直尝试获取，直到成功返回， //tryAcquire的实现又是具体的子类实现的，下面的tryAcquire方法就是公平的tryAcquire实现 // final void lock() &#123; //参数1是AQS的同步状态 //首先了解下AQS中同步状态的定义，state //0表示未被获取到锁，1表示已经被获取到锁了，大于1表示重入数 //我们要获取锁，肯定是想要现在的同步状态为0，然后我们把状态变成1，这样锁就是我们的了 acquire(1); &#125; //公平的tryAcquire方法实现 protected final boolean tryAcquire(int acquires) &#123; //当前线程 final Thread current = Thread.currentThread(); //获取AQS的同步状态 int c = getState(); //状态为0的话，说明没有其他人获取到锁 if (c == 0) &#123; //hasQueuedPredecessors查询是否还有其他线程比当前线程等待获取锁的时间更长 //compareAndSetState使用cas来设置状态，预期为0，我们想要设置的值为1 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; //如果我们是等待获取时间最长的（这就是公平，我等的时间长，就该我第一个被服务） //并且cas设置成功了，表示我们获取到锁了 //设置当前线程为独占访问 setExclusiveOwnerThread(current); return true; &#125; &#125; //往下是state不为0的情况，也就是1，或者大于1 //如果当前线程和独占线程是同一个 else if (current == getExclusiveOwnerThread()) &#123; //当前状态加上我们要获取的参数1 //现在表示的是重入数 int nextc = c + acquires; //state是一个32位整型，小于0，表示重入数超过了最大数 if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); //设置当前状态 setState(nextc); return true; &#125; return false; &#125;&#125; 可以看到公平的tryAcquire在获取锁的开始只调用一次，获取到就获取到了，或者已经获取到增加重入数，没有获取到就返回false，如果返回false的话，AQS就会将其加入到队列中一直尝试获取。 NonfairSync123456789101112131415161718//也是继承自Syncstatic final class NonfairSync extends Sync &#123; //非公平的获取锁 final void lock() &#123; //先尝试直接获取锁 //如果能获取到锁，就设置为独占模式 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else //直接获取不到的话，就会跟公平锁一样的流程去获取 //tryAcquire在下面 acquire(1); &#125; //这里是非公平的tryAcquire，直接调用Sync中的nofairTryAcquire方法 protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125; 公平和非公平的区别上面看完了代码，有点模糊，感觉代码都差不多，到底公平和非公平差别在哪里。首先看下公平的锁获取，公平锁获取会直接调用acquire方法，acquire方法并不是直接去获取锁，而是调用公平的tryAcquire方法，公平的tryAcquire方法首先获取到当前同步器状态，如果没有人用同步器，也就是状态为0，会先去判断有没有人比我等的时间更长，有的话我就不能获取锁，而是让别人先去；如果我是等待最长的那个，我就去使用CAS更改状态，获取锁。 而非公平的实现是，我上来就直接使用CAS获取锁，不问别人是不是等着很长时间了，我获取到了就是我的了，我获取不到，再调用acquire方法，然后acquire方法中调用非公平的tryAcquire方法，非公平的tryAcquire方法也是很直接，如果当前锁没有人用，也就是state为0，我不管有没有人比我等的时间长，我就去获取，然后设置独占。 公平锁，获取锁首先去尝试，没有的话就排队，轮到我之后，还要去问一下有没有等的时间更长的。非公平锁则是不排队，直接上，没有获取到，我也尝试获取，尝试获取的时候我还是直接上，不管其他人。 了解完公平和非公平锁，再去看其他方法就没那么难了。 ReentrantLock构造函数1234//可以看到，默认是非公平的public ReentrantLock() &#123; sync = new NonfairSync();&#125; 还可以指定公平性 123public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; lock方法1234//直接调用公平或者非公平的同步器的lock方法public void lock() &#123; sync.lock();&#125; lock方法有三种情况： 如果锁没有被其他线程持有，当前线程立即获得锁并返回，同步器状态设为1。 如果当前线程已经持有锁，则状态加1，并立即返回。 如果锁被其他线程持有，当前线程挂起直到获取到锁，然后返回，同步器设为1。 lockInterruptibly方法12345//可中断的获取锁public void lockInterruptibly() throws InterruptedException &#123; //调用AQS的方法 sync.acquireInterruptibly(1);&#125; 获取锁，可以被Thread.interrupt打断。也有三种情况： 如果锁没有被其他线程持有，当前线程立即获得锁并返回，同步器状态设为1。 如果当前线程已经持有锁，则状态加1，并立即返回。 如果锁被其他线程持有，当前线程会挂起去获取锁，在这个过程会有两种情况： 当前线程获取到了锁，返回，同步器状态设置1。 当前线程被中断了，会抛出InterruptedException异常，并清除中断状态。 tryLock方法12345//尝试获取锁，不会阻塞，成功与否都会直接返回public boolean tryLock() &#123; //使用的是非公平锁的获取 return sync.nonfairTryAcquire(1);&#125; 使用非公平的锁获取，如果使用了公平的，获取的时候还要判断别人是不是了好久，而非公平的nonfairTryAcquire，能获取就直接获取到，获取不到就返回false，比较直接。 如果不想破坏公平性，可以使用带有超时时间的tryLock方法。 带超时的tryLock方法12345//在超时间内，并且没有被打断，锁没有被其他线程持有，就立即获取到锁并返回public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout));&#125; 如果使用的是公平锁，如果有其他等的时间更长的线程，即便现在锁没有人持有，当前线程也不会获取到锁，给等的时间更长的去获取。 unlock方法12345//释放锁//直接调用AQS来释放锁public void unlock() &#123; sync.release(1);&#125; newCondition方法1234//返回一个新的Condition实例public Condition newCondition() &#123; return sync.newCondition();&#125; 返回的Condition实例的方法，其实和Object的wait，notify，notifyAll方法的作用一样。 其他方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071//重入次数 public int getHoldCount() &#123; return sync.getHoldCount();&#125;//锁是否被当前线程持有public boolean isHeldByCurrentThread() &#123; return sync.isHeldExclusively();&#125;//查询锁是否被任何线程持有public boolean isLocked() &#123; return sync.isLocked();&#125;//是否是公平锁public final boolean isFair() &#123; return sync instanceof FairSync;&#125;//返回当前拥有锁的线程protected Thread getOwner() &#123; return sync.getOwner();&#125;//查询是否有线程在排队获取锁public final boolean hasQueuedThreads() &#123; return sync.hasQueuedThreads();&#125;//查询给定的线程是否在等待获取锁public final boolean hasQueuedThread(Thread thread) &#123; return sync.isQueued(thread);&#125;//得到正在等待获取锁的队列的长度public final int getQueueLength() &#123; return sync.getQueueLength();&#125;//获取正在等待获取锁的所有线程protected Collection&lt;Thread&gt; getQueuedThreads() &#123; return sync.getQueuedThreads();&#125;//查询是否有线程正在等待给定的Conditionpublic boolean hasWaiters(Condition condition) &#123; if (condition == null) throw new NullPointerException(); if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject)) throw new IllegalArgumentException(&quot;not owner&quot;); return sync.hasWaiters((AbstractQueuedSynchronizer.ConditionObject)condition);&#125;//得到正在等待一个Condition的队列的长度public int getWaitQueueLength(Condition condition) &#123; if (condition == null) throw new NullPointerException(); if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject)) throw new IllegalArgumentException(&quot;not owner&quot;); return sync.getWaitQueueLength((AbstractQueuedSynchronizer.ConditionObject)condition);&#125;//获取所有的等待某个Condition的线程集合protected Collection&lt;Thread&gt; getWaitingThreads(Condition condition) &#123; if (condition == null) throw new NullPointerException(); if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject)) throw new IllegalArgumentException(&quot;not owner&quot;); return sync.getWaitingThreads((AbstractQueuedSynchronizer.ConditionObject)condition);&#125; ReentrantLock和synchronized的区别ReentrantLock和synchronized很类似，但是比synchronized多了更多功能，比如可中断锁，锁可以带超时时间，可以尝试非阻塞获取锁等。ReentrantLock还提供了条件Condition，跟Object的wait/notify类似，但是在多个条件变量和高度竞争锁的地方，ReentrantLock更加合适。 另外AQS是重点，一定要多学几遍，学会了，才能掌握锁（我还不太明白！）。 有关其他实现，比如ReentrantReadWriteLock的ReadLock和WriteLock以及ConcurrentHashMap中的Segment会另行介绍。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringMVC执行流程及源码解析]]></title>
      <url>%2F2017%2F04%2F06%2FSpringMVC%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E5%8F%8A%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[在SpringMVC中主要是围绕着DispatcherServlet来设计，可以把它当做指挥中心。这里先说明一下SpringMVC文档给出的执行流程，然后是我们稍微具体的执行流程，最后是流程大致的源码跟踪。关于很很很详细的源码解析，这里暂先不做。 官方文档中的流程首先看下SpringMVC文档上给的流程图： 这张图片给了我们大概的执行流程： 用户请求首先发送到前端控制器DispatcherServlet，DispatcherServlet根据请求的信息来决定使用哪个页面控制器Controller（也就是我们通常编写的Controller）来处理该请求。找到控制器之后，DispatcherServlet将请求委托给控制器去处理。 接下来页面控制器开始处理用户请求，页面控制器会根据请求信息进行处理，调用业务层等等，处理完成之后，会把结果封装成一个ModelAndView返回给DispatcherServlet。 前端控制器DispatcherServlet接到页面控制器的返回结果后，根据返回的视图名选择相应的试图模板，并根据返回的数据进行渲染。 最后前端控制器DispatcherServlet将结果返回给用户。 更具体的流程上面只是总体流程，接下来我们稍微深入一点，看下更具体的流程，这里没有图，只有步骤解析： 用户请求发送到前端控制器DispatcherServlet。 前端控制器DispatcherServlet接收到请求后，DispatcherServlet会使用HandlerMapping来处理，HandlerMapping会查找到具体进行处理请求的Handler对象。 HandlerMapping找到对应的Handler之后，并不是返回一个Handler原始对象，而是一个Handler执行链，在这个执行链中包括了拦截器和处理请求的Handler。HandlerMapping返回一个执行链给DispatcherServlet。 DispatcherServlet接收到执行链之后，会调用Handler适配器去执行Handler。 Handler适配器执行完成Handler（也就是我们写的Controller）之后会得到一个ModelAndView，并返回给DispatcherServlet。 DispatcherServlet接收到Handler适配器返回的ModelAndView之后，会根据其中的视图名调用视图解析器。 视图解析器根据逻辑视图名解析成一个真正的View视图，并返回给DispatcherServlet。 DispatcherServlet接收到视图之后，会根据上面的ModelAndView中的model来进行视图中数据的填充，也就是所谓的视图渲染。 渲染完成之后，DispatcherServlet就可以将结果返回给用户了。 源码DispatcherServlet是一个Servlet，我们知道在Servlet在处理一个请求的时候会交给service方法进行处理，这里也不例外，DispatcherServlet继承了FrameworkServlet，首先进入FrameworkServlet的service方法： 123456789101112protected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; //请求方法 String method = request.getMethod(); //PATCH方法单独处理 if (method.equalsIgnoreCase(RequestMethod.PATCH.name())) &#123; processRequest(request, response); &#125; else &#123;//其他的请求类型的方法经由父类，也就是HttpServlet处理 super.service(request, response); &#125;&#125; HttpServlet中会根据请求类型的不同分别调用doGet或者doPost等方法，FrameworkServlet中已经重写了这些方法，在这些方法中会调用processRequest进行处理，在processRequest中会调用doService方法，这个doService方法就是在DispatcherServlet中实现的。下面就看下DispatcherServlet中的doService方法的实现。 请求到达DispatcherServletdoService方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; //给request中的属性做一份快照 Map&lt;String, Object&gt; attributesSnapshot = null; if (WebUtils.isIncludeRequest(request)) &#123; logger.debug(&quot;Taking snapshot of request attributes before include&quot;); attributesSnapshot = new HashMap&lt;String, Object&gt;(); Enumeration&lt;?&gt; attrNames = request.getAttributeNames(); while (attrNames.hasMoreElements()) &#123; String attrName = (String) attrNames.nextElement(); if (this.cleanupAfterInclude || attrName.startsWith(&quot;org.springframework.web.servlet&quot;)) &#123; attributesSnapshot.put(attrName, request.getAttribute(attrName)); &#125; &#125; &#125; //如果我们没有配置类似本地化或者主题的处理器之类的 //SpringMVC会使用默认的值 //默认配置文件是DispatcherServlet.properties request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response); if (inputFlashMap != null) &#123; request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap)); &#125; request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); try &#123; //开始处理 doDispatch(request, response); &#125; finally &#123; if (WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123; return; &#125; // Restore the original attribute snapshot, in case of an include. if (attributesSnapshot != null) &#123; restoreAttributesAfterInclude(request, attributesSnapshot); &#125; &#125;&#125; DispatcherServlet开始真正的处理，doDispatch方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; //SpringMVC中异步请求的相关知识，暂先不解释 WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; //先检查是不是Multipart类型的，比如上传等 //如果是Multipart类型的，则转换为MultipartHttpServletRequest类型 processedRequest = checkMultipart(request); multipartRequestParsed = processedRequest != request; //获取当前请求的Handler mappedHandler = getHandler(processedRequest, false); if (mappedHandler == null || mappedHandler.getHandler() == null) &#123; noHandlerFound(processedRequest, response); return; &#125; //获取当前请求的Handler适配器 HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // 对于header中last-modified的处理 String method = request.getMethod(); boolean isGet = &quot;GET&quot;.equals(method); if (isGet || &quot;HEAD&quot;.equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; //拦截器的preHandle方法进行处理 if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; try &#123; //真正调用Handler的地方 mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; &#125; //处理成默认视图名，就是添加前缀和后缀等 applyDefaultViewName(request, mv); //拦截器postHandle方法进行处理 mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; //处理最后的结果，渲染之类的都在这里 processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Error err) &#123; triggerAfterCompletionWithError(processedRequest, response, mappedHandler, err); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; // Instead of postHandle and afterCompletion mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); return; &#125; // Clean up any resources used by a multipart request. if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); &#125; &#125;&#125; 可以看到大概的步骤还是按照我们上面分析的走的。 查找请求对应的Handler对象对应着这句代码mappedHandler = getHandler(processedRequest, false);，看下具体的getHandler方法： 123protected HandlerExecutionChain getHandler(HttpServletRequest request, boolean cache) throws Exception &#123; return getHandler(request);&#125; 继续往下看getHandler： 1234567891011protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; //遍历所有的handlerMappings进行处理 //handlerMappings是在启动的时候预先注册好的 for (HandlerMapping hm : this.handlerMappings) &#123; HandlerExecutionChain handler = hm.getHandler(request); if (handler != null) &#123; return handler; &#125; &#125; return null;&#125; 继续往下看getHandler，在AbstractHandlerMapping类中： 12345678910111213141516171819public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; //根据request获取handler Object handler = getHandlerInternal(request); if (handler == null) &#123; //如果没有找到就使用默认的handler handler = getDefaultHandler(); &#125; if (handler == null) &#123; return null; &#125; //如果Handler是String，表明是一个bean名称 //需要超照对应bean if (handler instanceof String) &#123; String handlerName = (String) handler; handler = getApplicationContext().getBean(handlerName); &#125; //封装Handler执行链 return getHandlerExecutionChain(handler, request);&#125; 根据requrst获取handler首先看下根据requrst获取handler步骤getHandlerInternal方法，在AbstractHandlerMethodMapping中： 12345678protected HandlerMethod getHandlerInternal(HttpServletRequest request) throws Exception &#123; //获取request中的url，用来匹配handler String lookupPath = getUrlPathHelper().getLookupPathForRequest(request); //根据路径寻找Handler HandlerMethod handlerMethod = lookupHandlerMethod(lookupPath, request); //根据handlerMethod中的bean来实例化Handler并添加进HandlerMethod return (handlerMethod != null) ? handlerMethod.createWithResolvedBean() : null;&#125; 看下根据路径寻找handler的方法lookupHandlerMethod： 123456789101112131415161718192021222324252627282930313233343536373839protected HandlerMethod lookupHandlerMethod(String lookupPath, HttpServletRequest request) throws Exception &#123; List&lt;Match&gt; matches = new ArrayList&lt;Match&gt;(); //直接匹配 List&lt;T&gt; directPathMatches = this.urlMap.get(lookupPath); //如果有匹配的，就添加进匹配列表中 if (directPathMatches != null) &#123; addMatchingMappings(directPathMatches, matches, request); &#125; //还没有匹配的，就遍历所有的处理方法查找 if (matches.isEmpty()) &#123; // No choice but to go through all mappings addMatchingMappings(this.handlerMethods.keySet(), matches, request); &#125; //找到了匹配的 if (!matches.isEmpty()) &#123; Comparator&lt;Match&gt; comparator = new MatchComparator(getMappingComparator(request)); Collections.sort(matches, comparator); //排序之后，获取第一个 Match bestMatch = matches.get(0); //如果有多个匹配的，会找到第二个最合适的进行比较一下 if (matches.size() &gt; 1) &#123; Match secondBestMatch = matches.get(1); if (comparator.compare(bestMatch, secondBestMatch) == 0) &#123; Method m1 = bestMatch.handlerMethod.getMethod(); Method m2 = secondBestMatch.handlerMethod.getMethod(); throw new IllegalStateException( &quot;Ambiguous handler methods mapped for HTTP path &apos;&quot; + request.getRequestURL() + &quot;&apos;: &#123;&quot; + m1 + &quot;, &quot; + m2 + &quot;&#125;&quot;); &#125; &#125; //设置request参数 handleMatch(bestMatch.mapping, lookupPath, request); //返回匹配的url的处理的方法 return bestMatch.handlerMethod; &#125; else &#123;//最后还没有找到，返回null return handleNoMatch(handlerMethods.keySet(), lookupPath, request); &#125;&#125; 获取默认Handler如果上面没有获取到Handler，就会获取默认的Handler。如果还获取不到就返回null。 处理String类型的Handler如果上面处理完的Handler是String类型的，就会根据这个handlerName获取bean。 封装Handler执行链上面获取完Handler，就开始封装执行链了，就是将我们配置的拦截器加入到执行链中去，getHandlerExecutionChain： 123456789101112131415161718protected HandlerExecutionChain getHandlerExecutionChain(Object handler, HttpServletRequest request) &#123; //如果当前Handler不是执行链类型，就使用一个新的执行链实例封装起来 HandlerExecutionChain chain = (handler instanceof HandlerExecutionChain) ? (HandlerExecutionChain) handler : new HandlerExecutionChain(handler); //先获取适配类型的拦截器添加进去拦截器链 chain.addInterceptors(getAdaptedInterceptors()); //当前的url String lookupPath = urlPathHelper.getLookupPathForRequest(request); //遍历拦截器，找到跟当前url对应的，添加进执行链中去 for (MappedInterceptor mappedInterceptor : mappedInterceptors) &#123; if (mappedInterceptor.matches(lookupPath, pathMatcher)) &#123; chain.addInterceptor(mappedInterceptor.getInterceptor()); &#125; &#125; return chain;&#125; 获取对应请求的Handler适配器getHandlerAdapter： 123456789protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException &#123; //遍历所有的HandlerAdapter，找到和当前Handler匹配的就返回 //我们这里会匹配到RequestMappingHandlerAdapter for (HandlerAdapter ha : this.handlerAdapters) &#123; if (ha.supports(handler)) &#123; return ha; &#125; &#125;&#125; 缓存的处理也就是对last-modified的处理 执行拦截器的preHandle方法就是遍历所有的我们定义的interceptor，执行preHandle方法 使用Handler适配器执行当前的Handlerha.handle执行当前Handler，我们这里使用的是RequestMappingHandlerAdapter，首先会进入AbstractHandlerMethodAdapter的handle方法： 1234public final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return handleInternal(request, response, (HandlerMethod) handler);&#125; handleInternal方法，在RequestMappingHandlerAdapter中： 12345678910111213141516171819202122232425protected final ModelAndView handleInternal(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; if (getSessionAttributesHandler(handlerMethod).hasSessionAttributes()) &#123; // Always prevent caching in case of session attribute management. checkAndPrepare(request, response, this.cacheSecondsForSessionAttributeHandlers, true); &#125; else &#123; // Uses configured default cacheSeconds setting. checkAndPrepare(request, response, true); &#125; // Execute invokeHandlerMethod in synchronized block if required. if (this.synchronizeOnSession) &#123; HttpSession session = request.getSession(false); if (session != null) &#123; Object mutex = WebUtils.getSessionMutex(session); synchronized (mutex) &#123; return invokeHandleMethod(request, response, handlerMethod); &#125; &#125; &#125; //执行方法，封装ModelAndView return invokeHandleMethod(request, response, handlerMethod);&#125; 组装默认视图名称前缀和后缀名都加上 执行拦截器的postHandle方法遍历intercepter的postHandle方法。 处理最后的结果，渲染之类的processDispatchResult方法： 123456789101112131415161718192021222324252627282930313233343536private void processDispatchResult(HttpServletRequest request, HttpServletResponse response, HandlerExecutionChain mappedHandler, ModelAndView mv, Exception exception) throws Exception &#123; boolean errorView = false; if (exception != null) &#123; if (exception instanceof ModelAndViewDefiningException) &#123; mv = ((ModelAndViewDefiningException) exception).getModelAndView(); &#125; else &#123; Object handler = (mappedHandler != null ? mappedHandler.getHandler() : null); mv = processHandlerException(request, response, handler, exception); errorView = (mv != null); &#125; &#125; // Did the handler return a view to render? if (mv != null &amp;&amp; !mv.wasCleared()) &#123; //渲染 render(mv, request, response); if (errorView) &#123; WebUtils.clearErrorRequestAttributes(request); &#125; &#125; else &#123; &#125; if (WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123; // Concurrent handling started during a forward return; &#125; if (mappedHandler != null) &#123; mappedHandler.triggerAfterCompletion(request, response, null); &#125;&#125; 重点看下render方法，进行渲染： 12345678910111213141516171819202122protected void render(ModelAndView mv, HttpServletRequest request, HttpServletResponse response) throws Exception &#123; //设置本地化 Locale locale = this.localeResolver.resolveLocale(request); response.setLocale(locale); View view; if (mv.isReference()) &#123; //解析视图名，得到视图 view = resolveViewName(mv.getViewName(), mv.getModelInternal(), locale, request); &#125; else &#123; // No need to lookup: the ModelAndView object contains the actual View object. view = mv.getView(); if (view == null) &#123; throw new ServletException(&quot;ModelAndView [&quot; + mv + &quot;] neither contains a view name nor a &quot; + &quot;View object in servlet with name &apos;&quot; + getServletName() + &quot;&apos;&quot;); &#125; &#125; //委托给视图进行渲染 view.render(mv.getModelInternal(), request, response);&#125; view.render就是进行视图的渲染，然后跳转页面等处理。 到这里大概的流程就走完了。其中涉及到的东西还有很多，暂先不做详细处理。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Ubuntu，请告诉我这不是真的！]]></title>
      <url>%2F2017%2F04%2F06%2FUbuntu%EF%BC%8C%E8%AF%B7%E5%91%8A%E8%AF%89%E6%88%91%E8%BF%99%E4%B8%8D%E6%98%AF%E7%9C%9F%E7%9A%84%EF%BC%81%2F</url>
      <content type="text"><![CDATA[Ubuntu别闹，请告诉我这是愚人节的过期玩笑。 We are wrapping up an excellent quarter and an excellent year for the company, with performance in many teams and products that we can be proud of. As we head into the new fiscal year, it’s appropriate to reassess each of our initiatives. I’m writing to let you know that we will end our investment in Unity8, the phone and convergence shell. We will shift our default Ubuntu desktop back to GNOME for Ubuntu 18.04 LTS. 详情见： https://insights.ubuntu.com/2017/04/05/growing-ubuntu-for-cloud-and-iot-rather-than-phone-and-convergence/ Unity8，Phone放弃，可以原谅，但是Unity也要放弃吗？要用Gnome！！我就当没看到～没看到～我不听～我不听！ 又要换回mac了～]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用gogs搭建git服务器记录]]></title>
      <url>%2F2017%2F04%2F03%2F%E4%BD%BF%E7%94%A8gogs%E6%90%AD%E5%BB%BAgit%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%B0%E5%BD%95%2F</url>
      <content type="text"><![CDATA[昨晚半夜网上一个朋友找到我，说是使用gogs搭建git服务器，使用ssh操作要免密啥啥啥的～也没描述清楚。就是要ssh的方式，提交时候不要账号密码，心想这不就三下的事情吗？结果折腾到晚上一点，没好～敢肯定的是他按照网上的毒教程，被坑了！还是自己本地虚拟机配置一下吧～ 环境说明 本机Ubuntu16.10 virtualbox上运行的是Centos7 虚拟机中mysql已经安装好 虚拟机中firewall已禁用，安装了iptables 虚拟机中已经安装git 步骤 去gogs网站下载，这里下载的是0.10.18版本，文件名是linux_amd64.zip mysql建立gogs数据库 新建用户名字为git的用户（用户目录/home/git） 解压下载的文件，然后运行程序 配置，安装 现在已经可以访问了，也可以使用http方式进行clone和提交了 配置ssh方式 下载gogs去gogs网站下载，https://dl.gogs.io/ ，我下载的是0.10.18，linux 64位版本。 建立gogs数据库在mysql中建立gogs数据库。 新建git用户在虚拟机Centos中新建一个git用户。 创建git组：sudo groupadd git。 创建git用户，分到git组中：sudo useradd -g git git 设置git用户的密码：sudo passwd git 接下来切换到刚才新建的git用户，一定要切换到这个git用户！！！！ 切换用户：su git 解压文件，运行现在已经切换到git这个用户了，切记一定要切换到git这个用户才能执行以下步骤。 首先进入/home/git目录下，将下载的文件解压到/home/git目录下并重新命名，我这里是命名为gogs。然后进入gogs文件夹下，运行./gogs web，应该没啥错。 配置，安装上面运行完成之后，打开浏览器输入：http://localhost:3000/install ，就可以看到安装配置页面了，里面配置根据自己需要配置（请先阅读文档了解清楚了，再自定义配置。）我这里填了mysql的密码，其他基本都是默认值。点击保存，有可能会提示git的path问题，请安装git！ 测试http方式现在已经可以访问了，访问：http://localhost:3000 不出意外，可以看到页面了。接下来需要注册一个用户，然后登录，添加一个仓库，在局域网中使用http的方式clone，我猜应该没啥意外情况。我这里是http://192.168.1.104:3000/dachengxi/gogs-test.git，你的根据情况来。 使用ssh方式首先需要在你的机器上生成ssh公钥：ssh-keygen -t rsa -C &quot;your_email@example.com&quot;，各种回车之后完成，生成的文件在你的用户主目录下的.ssh文件夹下，其中id_rsa.pub文件中的内容是我们需要的。打开此文件，复制所有内容。 然后打开gogs页面，点击右上角头像，找到用户设置，然后选择管理SSH密钥，在这里添加一个密钥，名字随便输，下面内容是你刚才复制的那个id_rsa.pub文件中的内容，添加进去保存，就好了。（其实这一步就是在你git用户主目录下的.ssh文件夹下生成一个叫做authorized_keys的文件，里面内容就是上面你添加的内容）。 测试ssh方式上面的步骤没出啥错，现在已经可以使用，我这里是git@192.168.1.104:dachengxi/gogs-test.git，你的根据自己情况来定。 其他其他各种高级功能不做讨论，请自己找文档找文章找自己！ 请确认虚拟机防火墙开放了3000端口，22端口。 请确认git已经安装。 请确认你运行gogs的时候，是你新建的git用户。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo中Directory解析]]></title>
      <url>%2F2017%2F04%2F02%2FDubbo%E4%B8%ADDirectory%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[Directory代表多个Invoker，可以把它看成List，但与List不同的是，它的值可能是动态变化的，比如注册中心推送变更。Cluster将Directory中的多个Invoker伪装成一个Invoker，对上层透明，伪装过程包含了容错逻辑，调用失败后，重试另一个。上面是文档上对Directory的解释。 Directory接口Directory接口继承了Node接口： 1234567public interface Directory&lt;T&gt; extends Node &#123; //获取服务类型 Class&lt;T&gt; getInterface(); //invoker列表，服务的列表 List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException;&#125; AbstractDirectory默认实现为AbstractDirectory： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public abstract class AbstractDirectory&lt;T&gt; implements Directory&lt;T&gt; &#123; // 日志输出 private static final Logger logger = LoggerFactory.getLogger(AbstractDirectory.class); //服务url private final URL url ; private volatile boolean destroyed = false; //消费者url private volatile URL consumerUrl ; //路由 private volatile List&lt;Router&gt; routers; public AbstractDirectory(URL url) &#123; this(url, null); &#125; public AbstractDirectory(URL url, List&lt;Router&gt; routers) &#123; this(url, url, routers); &#125; public AbstractDirectory(URL url, URL consumerUrl, List&lt;Router&gt; routers) &#123; if (url == null) throw new IllegalArgumentException(&quot;url == null&quot;); this.url = url; this.consumerUrl = consumerUrl; setRouters(routers); &#125; //对list方法的默认实现 public List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException &#123; if (destroyed)&#123; throw new RpcException(&quot;Directory already destroyed .url: &quot;+ getUrl()); &#125; //获取Invoker列表的具体实现由具体子类实现 List&lt;Invoker&lt;T&gt;&gt; invokers = doList(invocation); //路由 List&lt;Router&gt; localRouters = this.routers; // local reference if (localRouters != null &amp;&amp; localRouters.size() &gt; 0) &#123; for (Router router: localRouters)&#123; try &#123; if (router.getUrl() == null || router.getUrl().getParameter(Constants.RUNTIME_KEY, true)) &#123; //路由 invokers = router.route(invokers, getConsumerUrl(), invocation); &#125; &#125; catch (Throwable t) &#123; logger.error(&quot;Failed to execute router: &quot; + getUrl() + &quot;, cause: &quot; + t.getMessage(), t); &#125; &#125; &#125; return invokers; &#125; public URL getUrl() &#123; return url; &#125; public List&lt;Router&gt; getRouters()&#123; return routers; &#125; public URL getConsumerUrl() &#123; return consumerUrl; &#125; public void setConsumerUrl(URL consumerUrl) &#123; this.consumerUrl = consumerUrl; &#125; //构造中调用的设置路由的方法 protected void setRouters(List&lt;Router&gt; routers)&#123; // copy list routers = routers == null ? new ArrayList&lt;Router&gt;() : new ArrayList&lt;Router&gt;(routers); // append url router String routerkey = url.getParameter(Constants.ROUTER_KEY); //指定了router，就使用制定的router来获取扩展实现 if (routerkey != null &amp;&amp; routerkey.length() &gt; 0) &#123; RouterFactory routerFactory = ExtensionLoader.getExtensionLoader(RouterFactory.class).getExtension(routerkey); routers.add(routerFactory.getRouter(url)); &#125; // append mock invoker selector routers.add(new MockInvokersSelector()); Collections.sort(routers); this.routers = routers; &#125; public boolean isDestroyed() &#123; return destroyed; &#125; public void destroy()&#123; destroyed = true; &#125; //子类实现具体的获取invoker列表 protected abstract List&lt;Invoker&lt;T&gt;&gt; doList(Invocation invocation) throws RpcException ;&#125; Directory具体的实现有两个RegistryDirectory注册目录服务和StaticDirectory静态目录服务。 RegistryDirectoryRegistryDirectory实现了NotifyListener接口，因此他本身也是一个监听器，可以在服务变更时接受通知，消费方要调用远程服务，会向注册中心订阅这个服务的所有的服务提供方，订阅的时候会调用notify方法，进行invoker实例的重新生成，也就是服务的重新引用。在服务提供方有变动时，也会调用notify方法，有关notify方法在Dubbo中订阅和通知解析那篇文章中已经解释，不做重复。subscribe方法也不做重复解释。 StaticDirectory静态目录服务。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo中订阅和通知解析]]></title>
      <url>%2F2017%2F04%2F02%2FDubbo%E4%B8%AD%E8%AE%A2%E9%98%85%E5%92%8C%E9%80%9A%E7%9F%A5%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[Dubbo中关于服务的订阅和通知主要发生在服务提供方暴露服务的过程和服务消费方初始化时候引用服务的过程中。 服务引用过程中的订阅和通知在服务消费者初始化的过程中，会有一步是进行服务的引用，具体的代码是在RegistryProtocol的refer方法： 12345678910111213141516171819public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; url = url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY); //在这一步获取注册中心实例的过程中，也会有notify的操作。（这里省略） Registry registry = registryFactory.getRegistry(url); if (RegistryService.class.equals(type)) &#123; return proxyFactory.getInvoker((T) registry, type, url); &#125; // group=&quot;a,b&quot; or group=&quot;*&quot; Map&lt;String, String&gt; qs = StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY)); String group = qs.get(Constants.GROUP_KEY); if (group != null &amp;&amp; group.length() &gt; 0 ) &#123; if ( ( Constants.COMMA_SPLIT_PATTERN.split( group ) ).length &gt; 1 || &quot;*&quot;.equals( group ) ) &#123; return doRefer( getMergeableCluster(), registry, type, url ); &#125; &#125; return doRefer(cluster, registry, type, url);&#125; 在refer方法中有一步是获取注册中心实例，这一步中也会有一个notify操作，先暂时不解释。接着就是doRefer方法： 1234567891011121314151617181920private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) &#123; RegistryDirectory&lt;T&gt; directory = new RegistryDirectory&lt;T&gt;(type, url); directory.setRegistry(registry); directory.setProtocol(protocol); //订阅的url URL subscribeUrl = new URL(Constants.CONSUMER_PROTOCOL, NetUtils.getLocalHost(), 0, type.getName(), directory.getUrl().getParameters()); if (! Constants.ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) &#123; //服务消费方向注册中心注册自己，供其他层使用，比如服务治理 registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY, Constants.CHECK_KEY, String.valueOf(false))); &#125; //订阅服务提供方 //同时订阅了三种类型providers，routers，configurators。 directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, Constants.PROVIDERS_CATEGORY + &quot;,&quot; + Constants.CONFIGURATORS_CATEGORY + &quot;,&quot; + Constants.ROUTERS_CATEGORY)); return cluster.join(directory);&#125; 在doRefer方法中服务消费者会订阅服务，同时订阅了三种类型：providers，routers，configurators。 接续看directory.subscribe订阅方法，这里directory是RegistryDirectory： 12345678public void subscribe(URL url) &#123; //设置消费者url setConsumerUrl(url); //订阅 //url为订阅条件，不能为空 //第二个参数this，是变更事件监听器，不允许为空，RegistryDirectory实现了NotifyListener接口，因此是一个事件监听器 registry.subscribe(url, this);&#125; 这里registry是ZookeeperRegistry，在ZookeeperRegistry调用subscribe处理之前会先经过AbstractRegistry的处理，然后经过FailbackRegistry处理，在FailbackRegistry中会调用ZookeeperRegistry的doSubscribe方法。 首先看下AbstractRegistry中subscribe方法： 12345678910111213141516public void subscribe(URL url, NotifyListener listener) &#123; if (url == null) &#123; throw new IllegalArgumentException(&quot;subscribe url == null&quot;); &#125; if (listener == null) &#123; throw new IllegalArgumentException(&quot;subscribe listener == null&quot;); &#125; //从缓存中获取已经订阅的url的监听器 Set&lt;NotifyListener&gt; listeners = subscribed.get(url); if (listeners == null) &#123; subscribed.putIfAbsent(url, new ConcurrentHashSet&lt;NotifyListener&gt;()); listeners = subscribed.get(url); &#125; //将当前监听器添加到监听器的set中 listeners.add(listener);&#125; 然后是FailbackRegistry的subscribe方法： 123456789101112131415161718192021222324252627282930313233public void subscribe(URL url, NotifyListener listener) &#123; //上面AbstractRegistry的处理 super.subscribe(url, listener); //移除订阅失败的 removeFailedSubscribed(url, listener); try &#123; // 向服务器端发送订阅请求 //子类实现，我们这里使用的是ZookeeperRegistry doSubscribe(url, listener); &#125; catch (Exception e) &#123; Throwable t = e; List&lt;URL&gt; urls = getCacheUrls(url); if (urls != null &amp;&amp; urls.size() &gt; 0) &#123; //订阅失败，进行通知，重试 notify(url, listener, urls); &#125; else &#123; // 如果开启了启动时检测，则直接抛出异常 boolean check = getUrl().getParameter(Constants.CHECK_KEY, true) &amp;&amp; url.getParameter(Constants.CHECK_KEY, true); boolean skipFailback = t instanceof SkipFailbackWrapperException; if (check || skipFailback) &#123; if(skipFailback) &#123; t = t.getCause(); &#125; throw new IllegalStateException(&quot;Failed to subscribe &quot; + url + &quot;, cause: &quot; + t.getMessage(), t); &#125; &#125; // 将失败的订阅请求记录到失败列表，定时重试 addFailedSubscribed(url, listener); &#125;&#125; 这里总共进行了一下几件事情： AbstractRegistry的处理 移除订阅失败的 由具体的子类向服务器端发送订阅请求 如果订阅发生失败了，尝试获取缓存url，然后进行失败通知或者如果开启了启动时检测，则直接抛出异常 将失败的订阅请求记录到失败列表，定时重试 主要看下子类向服务器段发送订阅请求的步骤，在ZookeeperRegistry的doSubscribe方法中： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071protected void doSubscribe(final URL url, final NotifyListener listener) &#123; try &#123; if (Constants.ANY_VALUE.equals(url.getServiceInterface())) &#123;//这里暂时没用到先不解释 String root = toRootPath(); ConcurrentMap&lt;NotifyListener, ChildListener&gt; listeners = zkListeners.get(url); if (listeners == null) &#123; zkListeners.putIfAbsent(url, new ConcurrentHashMap&lt;NotifyListener, ChildListener&gt;()); listeners = zkListeners.get(url); &#125; ChildListener zkListener = listeners.get(listener); if (zkListener == null) &#123; listeners.putIfAbsent(listener, new ChildListener() &#123; public void childChanged(String parentPath, List&lt;String&gt; currentChilds) &#123; for (String child : currentChilds) &#123; child = URL.decode(child); if (! anyServices.contains(child)) &#123; anyServices.add(child); subscribe(url.setPath(child).addParameters(Constants.INTERFACE_KEY, child, Constants.CHECK_KEY, String.valueOf(false)), listener); &#125; &#125; &#125; &#125;); zkListener = listeners.get(listener); &#125; zkClient.create(root, false); List&lt;String&gt; services = zkClient.addChildListener(root, zkListener); if (services != null &amp;&amp; services.size() &gt; 0) &#123; for (String service : services) &#123; service = URL.decode(service); anyServices.add(service); subscribe(url.setPath(service).addParameters(Constants.INTERFACE_KEY, service, Constants.CHECK_KEY, String.valueOf(false)), listener); &#125; &#125; &#125; else &#123; List&lt;URL&gt; urls = new ArrayList&lt;URL&gt;(); //这里的path分别为providers，routers，configurators三种 for (String path : toCategoriesPath(url)) &#123; //根据url获取对应的监听器map ConcurrentMap&lt;NotifyListener, ChildListener&gt; listeners = zkListeners.get(url); if (listeners == null) &#123; zkListeners.putIfAbsent(url, new ConcurrentHashMap&lt;NotifyListener, ChildListener&gt;()); listeners = zkListeners.get(url); &#125; //根据我们的listener获取一个ChildListener实例 ChildListener zkListener = listeners.get(listener); //没有的话就创建一个ChildListener实例。 if (zkListener == null) &#123; listeners.putIfAbsent(listener, new ChildListener() &#123; public void childChanged(String parentPath, List&lt;String&gt; currentChilds) &#123; ZookeeperRegistry.this.notify(url, listener, toUrlsWithEmpty(url, parentPath, currentChilds)); &#125; &#125;); zkListener = listeners.get(listener); &#125; //根据path在Zookeeper中创建节点，这里就是订阅服务 zkClient.create(path, false); //这里zkClient是dubbo的ZookeeperClient，在addChildListener中会转化为ZkClient的Listener List&lt;String&gt; children = zkClient.addChildListener(path, zkListener); if (children != null) &#123; urls.addAll(toUrlsWithEmpty(url, path, children)); &#125; &#125; //订阅完成之后，进行通知 notify(url, listener, urls); &#125; &#125; catch (Throwable e) &#123; throw new RpcException(&quot;Failed to subscribe &quot; + url + &quot; to zookeeper &quot; + getUrl() + &quot;, cause: &quot; + e.getMessage(), e); &#125;&#125; 上面主要是分别对providers，routers，configurators三种不同类型的进行订阅，也就是往zookeeper中注册节点，注册之前先给url添加监听器。最后是订阅完之后进行通知。 notify方法，这里notify方法实现是在ZookeeperRegistry的父类FailbackRegistry中： 1234567891011121314151617181920protected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; if (url == null) &#123; throw new IllegalArgumentException(&quot;notify url == null&quot;); &#125; if (listener == null) &#123; throw new IllegalArgumentException(&quot;notify listener == null&quot;); &#125; try &#123; //doNotify方法中没做处理，直接调用父类的notify方法 doNotify(url, listener, urls); &#125; catch (Exception t) &#123; // 将失败的通知请求记录到失败列表，定时重试 Map&lt;NotifyListener, List&lt;URL&gt;&gt; listeners = failedNotified.get(url); if (listeners == null) &#123; failedNotified.putIfAbsent(url, new ConcurrentHashMap&lt;NotifyListener, List&lt;URL&gt;&gt;()); listeners = failedNotified.get(url); &#125; listeners.put(listener, urls); &#125;&#125; 看下AbstractRegistry的notify方法： 123456789101112131415161718192021222324252627282930313233protected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; Map&lt;String, List&lt;URL&gt;&gt; result = new HashMap&lt;String, List&lt;URL&gt;&gt;(); //获取catagory列表，providers，routers，configurators for (URL u : urls) &#123; if (UrlUtils.isMatch(url, u)) &#123; String category = u.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); List&lt;URL&gt; categoryList = result.get(category); if (categoryList == null) &#123; categoryList = new ArrayList&lt;URL&gt;(); result.put(category, categoryList); &#125; categoryList.add(u); &#125; &#125; if (result.size() == 0) &#123; return; &#125; //已经通知过 Map&lt;String, List&lt;URL&gt;&gt; categoryNotified = notified.get(url); if (categoryNotified == null) &#123; notified.putIfAbsent(url, new ConcurrentHashMap&lt;String, List&lt;URL&gt;&gt;()); categoryNotified = notified.get(url); &#125; for (Map.Entry&lt;String, List&lt;URL&gt;&gt; entry : result.entrySet()) &#123; //providers，routers，configurators中的一个 String category = entry.getKey(); List&lt;URL&gt; categoryList = entry.getValue(); categoryNotified.put(category, categoryList); saveProperties(url); //还记得刚开始的时候，listener参数么，这里listener是RegistryDirectory listener.notify(categoryList); &#125;&#125; 继续看RegistryDirectory的notify方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public synchronized void notify(List&lt;URL&gt; urls) &#123; //三种类型分开 List&lt;URL&gt; invokerUrls = new ArrayList&lt;URL&gt;(); List&lt;URL&gt; routerUrls = new ArrayList&lt;URL&gt;(); List&lt;URL&gt; configuratorUrls = new ArrayList&lt;URL&gt;(); for (URL url : urls) &#123; String protocol = url.getProtocol(); String category = url.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); if (Constants.ROUTERS_CATEGORY.equals(category) || Constants.ROUTE_PROTOCOL.equals(protocol)) &#123; routerUrls.add(url); &#125; else if (Constants.CONFIGURATORS_CATEGORY.equals(category) || Constants.OVERRIDE_PROTOCOL.equals(protocol)) &#123; configuratorUrls.add(url); &#125; else if (Constants.PROVIDERS_CATEGORY.equals(category)) &#123; invokerUrls.add(url); &#125; else &#123; &#125; &#125; // configurators //更新缓存的服务提供方配置规则 if (configuratorUrls != null &amp;&amp; configuratorUrls.size() &gt;0 )&#123; this.configurators = toConfigurators(configuratorUrls); &#125; // routers //更新缓存的路由配置规则 if (routerUrls != null &amp;&amp; routerUrls.size() &gt;0 )&#123; List&lt;Router&gt; routers = toRouters(routerUrls); if(routers != null)&#123; // null - do nothing setRouters(routers); &#125; &#125; List&lt;Configurator&gt; localConfigurators = this.configurators; // local reference // 合并override参数 this.overrideDirectoryUrl = directoryUrl; if (localConfigurators != null &amp;&amp; localConfigurators.size() &gt; 0) &#123; for (Configurator configurator : localConfigurators) &#123; this.overrideDirectoryUrl = configurator.configure(overrideDirectoryUrl); &#125; &#125; // providers //重建invoker实例 refreshInvoker(invokerUrls);&#125; 最重要的重建invoker实例，在服务引用的文章中已经介绍过，不再重复，还有上面说省略的获取注册中心实例的过程中，也会有notify的操作。（这里省略）这里也是进行了invoker实例的重建。 暴露服务过程中的订阅和通知服务暴露过程中的订阅在RegistryProtocol的export方法中： 12345678910111213141516171819202122232425262728293031323334353637383940public &lt;T&gt; Exporter&lt;T&gt; export(final Invoker&lt;T&gt; originInvoker) throws RpcException &#123; //export invoker final ExporterChangeableWrapper&lt;T&gt; exporter = doLocalExport(originInvoker); //registry provider final Registry registry = getRegistry(originInvoker); final URL registedProviderUrl = getRegistedProviderUrl(originInvoker); registry.register(registedProviderUrl); // 订阅override数据 // FIXME 提供者订阅时，会影响同一JVM即暴露服务，又引用同一服务的的场景，因为subscribed以服务名为缓存的key，导致订阅信息覆盖。 final URL overrideSubscribeUrl = getSubscribedOverrideUrl(registedProviderUrl); //OverrideListener是RegistryProtocol的内部类 final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl); overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener); //订阅override数据 registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener); //保证每次export都返回一个新的exporter实例 return new Exporter&lt;T&gt;() &#123; public Invoker&lt;T&gt; getInvoker() &#123; return exporter.getInvoker(); &#125; public void unexport() &#123; try &#123; exporter.unexport(); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; try &#123; registry.unregister(registedProviderUrl); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; try &#123; overrideListeners.remove(overrideSubscribeUrl); registry.unsubscribe(overrideSubscribeUrl, overrideSubscribeListener); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; &#125;;&#125; registry.subscribe订阅override数据，会首先经过AbstractRegistry处理，然后经过FailbackRegistry处理。处理方法在上面消费者发布订阅的讲解中都已经介绍。往下的步骤基本相同，不同之处在于AbstractRegistry的notify方法： 12345678910111213141516171819202122232425262728293031323334protected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; Map&lt;String, List&lt;URL&gt;&gt; result = new HashMap&lt;String, List&lt;URL&gt;&gt;(); //获取catagory列表，providers，routers，configurators for (URL u : urls) &#123; if (UrlUtils.isMatch(url, u)) &#123; String category = u.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); List&lt;URL&gt; categoryList = result.get(category); if (categoryList == null) &#123; categoryList = new ArrayList&lt;URL&gt;(); result.put(category, categoryList); &#125; categoryList.add(u); &#125; &#125; if (result.size() == 0) &#123; return; &#125; //已经通知过 Map&lt;String, List&lt;URL&gt;&gt; categoryNotified = notified.get(url); if (categoryNotified == null) &#123; notified.putIfAbsent(url, new ConcurrentHashMap&lt;String, List&lt;URL&gt;&gt;()); categoryNotified = notified.get(url); &#125; for (Map.Entry&lt;String, List&lt;URL&gt;&gt; entry : result.entrySet()) &#123; //providers，routers，configurators中的一个 String category = entry.getKey(); List&lt;URL&gt; categoryList = entry.getValue(); categoryNotified.put(category, categoryList); saveProperties(url); //对于消费者来说这里listener是RegistryDirectory //而对于服务提供者来说这里是OverrideListener，是RegistryProtocol的内部类 listener.notify(categoryList); &#125;&#125; 接下来看OverrideListener的notify方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445/* * provider 端可识别的override url只有这两种. * override://0.0.0.0/serviceName?timeout=10 * override://0.0.0.0/?timeout=10 */public void notify(List&lt;URL&gt; urls) &#123; List&lt;URL&gt; result = null; for (URL url : urls) &#123; URL overrideUrl = url; if (url.getParameter(Constants.CATEGORY_KEY) == null &amp;&amp; Constants.OVERRIDE_PROTOCOL.equals(url.getProtocol())) &#123; // 兼容旧版本 overrideUrl = url.addParameter(Constants.CATEGORY_KEY, Constants.CONFIGURATORS_CATEGORY); &#125; if (! UrlUtils.isMatch(subscribeUrl, overrideUrl)) &#123; if (result == null) &#123; result = new ArrayList&lt;URL&gt;(urls); &#125; result.remove(url); logger.warn(&quot;Subsribe category=configurator, but notifed non-configurator urls. may be registry bug. unexcepted url: &quot; + url); &#125; &#125; if (result != null) &#123; urls = result; &#125; this.configurators = RegistryDirectory.toConfigurators(urls); List&lt;ExporterChangeableWrapper&lt;?&gt;&gt; exporters = new ArrayList&lt;ExporterChangeableWrapper&lt;?&gt;&gt;(bounds.values()); for (ExporterChangeableWrapper&lt;?&gt; exporter : exporters)&#123; Invoker&lt;?&gt; invoker = exporter.getOriginInvoker(); final Invoker&lt;?&gt; originInvoker ; if (invoker instanceof InvokerDelegete)&#123; originInvoker = ((InvokerDelegete&lt;?&gt;)invoker).getInvoker(); &#125;else &#123; originInvoker = invoker; &#125; URL originUrl = RegistryProtocol.this.getProviderUrl(originInvoker); URL newUrl = getNewInvokerUrl(originUrl, urls); if (! originUrl.equals(newUrl))&#123; //对修改了url的invoker重新export RegistryProtocol.this.doChangeLocalExport(originInvoker, newUrl); &#125; &#125;&#125; 这里也是对Invoker重新进行了引用。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo中集群Cluster，负载均衡，容错，路由解析]]></title>
      <url>%2F2017%2F03%2F26%2FDubbo%E4%B8%AD%E9%9B%86%E7%BE%A4Cluster%EF%BC%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%EF%BC%8C%E5%AE%B9%E9%94%99%EF%BC%8C%E8%B7%AF%E7%94%B1%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[Dubbo中的Cluster可以将多个服务提供方伪装成一个提供方，具体也就是将Directory中的多个Invoker伪装成一个Invoker，在伪装的过程中包含了容错的处理，负载均衡的处理和路由的处理。这篇文章介绍下集群相关的东西，开始先对着文档解释下容错模式，负载均衡，路由等概念，然后解析下源码的处理。（稍微有点乱，心情不太好，不适合分析源码。） 集群的容错模式Failover Cluster这是dubbo中默认的集群容错模式 失败自动切换，当出现失败，重试其它服务器。 通常用于读操作，但重试会带来更长延迟。 可通过retries=”2”来设置重试次数(不含第一次)。 Failfast Cluster 快速失败，只发起一次调用，失败立即报错。 通常用于非幂等性的写操作，比如新增记录。 Failsafe Cluster 失败安全，出现异常时，直接忽略。 通常用于写入审计日志等操作。 Failback Cluster 失败自动恢复，后台记录失败请求，定时重发。 通常用于消息通知操作。 Forking Cluster 并行调用多个服务器，只要一个成功即返回。 通常用于实时性要求较高的读操作，但需要浪费更多服务资源。 可通过forks=”2”来设置最大并行数。 Broadcast Cluster 广播调用所有提供者，逐个调用，任意一台报错则报错。(2.1.0开始支持) 通常用于通知所有提供者更新缓存或日志等本地资源信息。 负载均衡dubbo默认的负载均衡策略是random，随机调用。 Random LoadBalance 随机，按权重设置随机概率。 在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。 RoundRobin LoadBalance 轮循，按公约后的权重设置轮循比率。 存在慢的提供者累积请求问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。 LeastActive LoadBalance 最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。 使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。 ConsistentHash LoadBalance 一致性Hash，相同参数的请求总是发到同一提供者。 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。 缺省只对第一个参数Hash。 缺省用160份虚拟节点。 集群相关源码解析回想一下在服务消费者初始化的过程中，在引用远程服务的那一步，也就是RegistryProtocol的refer方法中，调用了doRefer方法，doRefer方法中第一个参数就是cluster，我们就从这里开始解析。RegistryProtocol的refer方法： 1234567891011121314151617181920212223public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; url = url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY); //根据url获取注册中心实例 //这一步连接注册中心，并把消费者注册到注册中心 Registry registry = registryFactory.getRegistry(url); //对注册中心服务的处理 if (RegistryService.class.equals(type)) &#123; return proxyFactory.getInvoker((T) registry, type, url); &#125; //以下是我们自己定义的业务的服务处理 // group=&quot;a,b&quot; or group=&quot;*&quot; Map&lt;String, String&gt; qs = StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY)); String group = qs.get(Constants.GROUP_KEY); //服务需要合并不同实现 if (group != null &amp;&amp; group.length() &gt; 0 ) &#123; if ( ( Constants.COMMA_SPLIT_PATTERN.split( group ) ).length &gt; 1 || &quot;*&quot;.equals( group ) ) &#123; return doRefer( getMergeableCluster(), registry, type, url ); &#125; &#125; //这里参数cluster是集群的适配类，代码在下面 return doRefer(cluster, registry, type, url);&#125; 接着看doRefer，真正去做服务引用的方法： 12345678910111213141516171819202122232425private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) &#123; //Directory中是Invoker的集合，相当于一个List //也就是说这里面存放了多个Invoker，那么我们该调用哪一个呢？ //该调用哪一个Invoker的工作就是Cluster来处理的 RegistryDirectory&lt;T&gt; directory = new RegistryDirectory&lt;T&gt;(type, url); directory.setRegistry(registry); directory.setProtocol(protocol); URL subscribeUrl = new URL(Constants.CONSUMER_PROTOCOL, NetUtils.getLocalHost(), 0, type.getName(), directory.getUrl().getParameters()); if (! Constants.ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) &#123; //到注册中心注册服务 registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY, Constants.CHECK_KEY, String.valueOf(false))); &#125; //订阅服务，注册中心会推送服务消息给消费者，消费者会再次进行服务的引用。 directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, Constants.PROVIDERS_CATEGORY + &quot;,&quot; + Constants.CONFIGURATORS_CATEGORY + &quot;,&quot; + Constants.ROUTERS_CATEGORY)); //服务的引用和变更全部由Directory异步完成 //Directory中可能存在多个Invoker //而Cluster会把多个Invoker伪装成一个Invoker //这一步就是做这个事情的 return cluster.join(directory);&#125; 集群处理的入口入口就是在doRefer的时候最后一步：cluster.join(directory);。 首先解释下cluster，这个是根据dubbo的扩展机制生成的，在RegistryProtocol中有一个setCluster方法，根据扩展机制可以知道，这是注入Cluster的地方，代码如下： 12345678910111213141516import com.alibaba.dubbo.common.extension.ExtensionLoader;public class Cluster$Adpative implements com.alibaba.dubbo.rpc.cluster.Cluster &#123; public com.alibaba.dubbo.rpc.Invoker join(com.alibaba.dubbo.rpc.cluster.Directory arg0) throws com.alibaba.dubbo.rpc.cluster.Directory &#123; if (arg0 == null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.cluster.Directory argument == null&quot;); if (arg0.getUrl() == null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.cluster.Directory argument getUrl() == null&quot;);com.alibaba.dubbo.common.URL url = arg0.getUrl(); String extName = url.getParameter(&quot;cluster&quot;, &quot;failover&quot;); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.cluster.Cluster) name from url(&quot; + url.toString() + &quot;) use keys([cluster])&quot;); com.alibaba.dubbo.rpc.cluster.Cluster extension = (com.alibaba.dubbo.rpc.cluster.Cluster)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.cluster.Cluster.class).getExtension(extName); return extension.join(arg0); &#125;&#125; 可以看到，如果我们没有配置集群策略的话，默认是用failover模式，在Cluster接口的注解上@SPI(FailoverCluster.NAME)也可以看到默认是failover。 继续执行cluster.join方法，会首先进入MockClusterWrapper的join方法： 123456public &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException &#123; //先执行FailoverCluster的join方法处理 //然后将Directory和返回的Invoker封装成一个MockCluster return new MockClusterInvoker&lt;T&gt;(directory, this.cluster.join(directory));&#125; 看下Failover的join方法： 1234public &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException &#123; //直接返回一个FailoverClusterInvoker的实例 return new FailoverClusterInvoker&lt;T&gt;(directory);&#125; 到这里就算把Invoker都封装好了，返回的Invoker是一个MockClusterInvoker，MockClusterInvoker内部包含一个Directory和一个FailoverClusterInvoker。 Invoker都封装好了之后，就是创建代理，然后使用代理调用我们的要调用的方法。 调用方法时集群的处理在进行具体方法调用的时候，代理中会invoker.invoke()，这里Invoker就是我们上面封装好的MockClusterInvoker，所以首先进入MockClusterInvoker的invoke方法： 1234567891011121314151617181920212223242526272829303132public Result invoke(Invocation invocation) throws RpcException &#123; Result result = null; //我们没配置mock，所以这里为false //Mock通常用于服务降级 String value = directory.getUrl().getMethodParameter(invocation.getMethodName(), Constants.MOCK_KEY, Boolean.FALSE.toString()).trim(); //没有使用mock if (value.length() == 0 || value.equalsIgnoreCase(&quot;false&quot;))&#123; //这里的invoker是FailoverClusterInvoker result = this.invoker.invoke(invocation); &#125; else if (value.startsWith(&quot;force&quot;)) &#123; //mock=force:return+null //表示消费方对方法的调用都直接返回null，不发起远程调用 //可用于屏蔽不重要服务不可用的时候，对调用方的影响 //force:direct mock result = doMockInvoke(invocation, null); &#125; else &#123; //mock=fail:return+null //表示消费方对该服务的方法调用失败后，再返回null，不抛异常 //可用于对不重要服务不稳定的时候，忽略对调用方的影响 //fail-mock try &#123; result = this.invoker.invoke(invocation); &#125;catch (RpcException e) &#123; if (e.isBiz()) &#123; throw e; &#125; else &#123; result = doMockInvoke(invocation, e); &#125; &#125; &#125; return result;&#125; 我们这里么有配置mock属性。首先进入的是AbstractClusterInvoker的incoke方法： 123456789101112131415161718192021public Result invoke(final Invocation invocation) throws RpcException &#123; //检查是否已经被销毁 checkWheatherDestoried(); //可以看到这里该处理负载均衡的问题了 LoadBalance loadbalance; //根据invocation中的信息从Directory中获取Invoker列表 //这一步中会进行路由的处理 List&lt;Invoker&lt;T&gt;&gt; invokers = list(invocation); if (invokers != null &amp;&amp; invokers.size() &gt; 0) &#123; //使用扩展机制，加载LoadBalance的实现类，默认使用的是random //我们这里得到的就是RandomLoadBalance loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(invokers.get(0).getUrl() .getMethodParameter(invocation.getMethodName(),Constants.LOADBALANCE_KEY, Constants.DEFAULT_LOADBALANCE)); &#125; else &#123; loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(Constants.DEFAULT_LOADBALANCE); &#125; //异步操作默认添加invocation id RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation); //调用具体的实现类的doInvoke方法，这里是FailoverClusterInvoker return doInvoke(invocation, invokers, loadbalance);&#125; 看下FailoverClusterInvoker的invoke方法： 12345678910111213141516171819202122232425262728293031323334353637public Result doInvoke(Invocation invocation, final List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; //Invoker列表 List&lt;Invoker&lt;T&gt;&gt; copyinvokers = invokers; //确认下Invoker列表不为空 checkInvokers(copyinvokers, invocation); //重试次数 int len = getUrl().getMethodParameter(invocation.getMethodName(), Constants.RETRIES_KEY, Constants.DEFAULT_RETRIES) + 1; if (len &lt;= 0) &#123; len = 1; &#125; // retry loop. RpcException le = null; // last exception. List&lt;Invoker&lt;T&gt;&gt; invoked = new ArrayList&lt;Invoker&lt;T&gt;&gt;(copyinvokers.size()); // invoked invokers. Set&lt;String&gt; providers = new HashSet&lt;String&gt;(len); for (int i = 0; i &lt; len; i++) &#123; //重试时，进行重新选择，避免重试时invoker列表已发生变化. //注意：如果列表发生了变化，那么invoked判断会失效，因为invoker示例已经改变 if (i &gt; 0) &#123; checkWheatherDestoried(); copyinvokers = list(invocation); //重新检查一下 checkInvokers(copyinvokers, invocation); &#125; //使用loadBalance选择一个Invoker返回 Invoker&lt;T&gt; invoker = select(loadbalance, invocation, copyinvokers, invoked); invoked.add(invoker); RpcContext.getContext().setInvokers((List)invoked); try &#123; //使用选择的结果Invoker进行调用，返回结果 Result result = invoker.invoke(invocation); return result; &#125; catch (RpcException e) &#123;。。。&#125; finally &#123; providers.add(invoker.getUrl().getAddress()); &#125; &#125; throw new RpcException(。。。);&#125; 先看下使用loadbalance选择invoker的select方法： 1234567891011121314151617181920212223242526protected Invoker&lt;T&gt; select(LoadBalance loadbalance, Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, List&lt;Invoker&lt;T&gt;&gt; selected) throws RpcException &#123; if (invokers == null || invokers.size() == 0) return null; String methodName = invocation == null ? &quot;&quot; : invocation.getMethodName(); //sticky，滞连接用于有状态服务，尽可能让客户端总是向同一提供者发起调用，除非该提供者挂了，再连另一台。 boolean sticky = invokers.get(0).getUrl().getMethodParameter(methodName,Constants.CLUSTER_STICKY_KEY, Constants.DEFAULT_CLUSTER_STICKY) ; &#123; //ignore overloaded method if ( stickyInvoker != null &amp;&amp; !invokers.contains(stickyInvoker) )&#123; stickyInvoker = null; &#125; //ignore cucurrent problem if (sticky &amp;&amp; stickyInvoker != null &amp;&amp; (selected == null || !selected.contains(stickyInvoker)))&#123; if (availablecheck &amp;&amp; stickyInvoker.isAvailable())&#123; return stickyInvoker; &#125; &#125; &#125; Invoker&lt;T&gt; invoker = doselect(loadbalance, invocation, invokers, selected); if (sticky)&#123; stickyInvoker = invoker; &#125; return invoker;&#125; doselect方法： 123456789101112131415161718192021222324252627282930313233private Invoker&lt;T&gt; doselect(LoadBalance loadbalance, Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, List&lt;Invoker&lt;T&gt;&gt; selected) throws RpcException &#123; if (invokers == null || invokers.size() == 0) return null; //只有一个invoker，直接返回，不需要处理 if (invokers.size() == 1) return invokers.get(0); // 如果只有两个invoker，退化成轮循 if (invokers.size() == 2 &amp;&amp; selected != null &amp;&amp; selected.size() &gt; 0) &#123; return selected.get(0) == invokers.get(0) ? invokers.get(1) : invokers.get(0); &#125; //使用loadBalance进行选择 Invoker&lt;T&gt; invoker = loadbalance.select(invokers, getUrl(), invocation); //如果 selected中包含（优先判断） 或者 不可用&amp;&amp;availablecheck=true 则重试. if( (selected != null &amp;&amp; selected.contains(invoker)) ||(!invoker.isAvailable() &amp;&amp; getUrl()!=null &amp;&amp; availablecheck))&#123; try&#123; //重新选择 Invoker&lt;T&gt; rinvoker = reselect(loadbalance, invocation, invokers, selected, availablecheck); if(rinvoker != null)&#123; invoker = rinvoker; &#125;else&#123; //看下第一次选的位置，如果不是最后，选+1位置. int index = invokers.indexOf(invoker); try&#123; //最后在避免碰撞 invoker = index &lt;invokers.size()-1?invokers.get(index+1) :invoker; &#125;catch (Exception e) &#123;。。。 &#125; &#125; &#125;catch (Throwable t)&#123;。。。&#125; &#125; return invoker;&#125; 接着看使用loadBalance进行选择，首先进入AbstractLoadBalance的select方法： 12345678 public &lt;T&gt; Invoker&lt;T&gt; select(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123; if (invokers == null || invokers.size() == 0) return null; if (invokers.size() == 1) return invokers.get(0); // 进行选择，具体的子类实现，我们这里是RandomLoadBalance return doSelect(invokers, url, invocation);&#125; 接着去RandomLoadBalance中查看： 1234567891011121314151617181920212223242526protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123; int length = invokers.size(); // 总个数 int totalWeight = 0; // 总权重 boolean sameWeight = true; // 权重是否都一样 for (int i = 0; i &lt; length; i++) &#123; int weight = getWeight(invokers.get(i), invocation); totalWeight += weight; // 累计总权重 if (sameWeight &amp;&amp; i &gt; 0 &amp;&amp; weight != getWeight(invokers.get(i - 1), invocation)) &#123; sameWeight = false; // 计算所有权重是否一样 &#125; &#125; if (totalWeight &gt; 0 &amp;&amp; ! sameWeight) &#123; // 如果权重不相同且权重大于0则按总权重数随机 int offset = random.nextInt(totalWeight); // 并确定随机值落在哪个片断上 for (int i = 0; i &lt; length; i++) &#123; offset -= getWeight(invokers.get(i), invocation); if (offset &lt; 0) &#123; return invokers.get(i); &#125; &#125; &#125; // 如果权重相同或权重为0则均等随机 return invokers.get(random.nextInt(length));&#125; 上面根据权重之类的来进行选择一个Invoker返回。接下来reselect的方法不在说明，是先从非selected的列表中选择，没有在从selected列表中选择。 选择好了Invoker之后，就回去FailoverClusterInvoker的doInvoke方法，接着就是根据选中的Invoker调用invoke方法进行返回结果，接着就是到具体的Invoker进行调用的过程了。这部分的解析在消费者和提供者请求响应过程已经解析过了，不再重复。 路由回到AbstractClusterInvoker的invoke方法中，这里有一步是List&lt;Invoker&lt;T&gt;&gt; invokers = list(invocation);获取Invoker列表，这里同时也进行了路由的操作，看下list方法： 1234protected List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException &#123; List&lt;Invoker&lt;T&gt;&gt; invokers = directory.list(invocation); return invokers;&#125; 接着看AbstractDirectory的list方法： 1234567891011121314151617181920public List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException &#123; if (destroyed)&#123; throw new RpcException(&quot;Directory already destroyed .url: &quot;+ getUrl()); &#125; //RegistryDirectory中的doList实现 List&lt;Invoker&lt;T&gt;&gt; invokers = doList(invocation); List&lt;Router&gt; localRouters = this.routers; // local reference if (localRouters != null &amp;&amp; localRouters.size() &gt; 0) &#123; for (Router router: localRouters)&#123; try &#123; if (router.getUrl() == null || router.getUrl().getParameter(Constants.RUNTIME_KEY, true)) &#123; //路由选择 //MockInvokersSelector中 invokers = router.route(invokers, getConsumerUrl(), invocation); &#125; &#125; catch (Throwable t) &#123;。。。&#125; &#125; &#125; return invokers;&#125; 路由来过滤之后，进行负载均衡的处理。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JUC中AQS简介]]></title>
      <url>%2F2017%2F03%2F23%2FJUC%E4%B8%ADAQS%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[AQS，在java.util.concurrent.locks包中，AbstractQueuedSynchronizer这个类是并发包中的核心，了解其他类之前，需要先弄清楚AQS。在JUC的很多类中都会存在一个内部类Sync，Sync都是继承自AbstractQueuedSynchronizer，相信不用说就能明白AQS有多重要。 AQS原理AQS就是一个同步器，要做的事情就相当于一个锁，所以就会有两个动作：一个是获取，一个是释放。获取释放的时候该有一个东西来记住他是被用还是没被用，这个东西就是一个状态。如果锁被获取了，也就是被用了，还有很多其他的要来获取锁，总不能给全部拒绝了，这时候就需要他们排队，这里就需要一个队列。这大概就清楚了AQS的主要构成了： 获取和释放两个动作 同步状态（原子操作） 阻塞队列 stateAQS用32位整形来表示同步状态。 1private volatile int state; 在互斥锁中表示线程是否已经获取了锁，0未获取，1已经获取，大于1表示重入数。 AQS提供了getState(),setState(),compareAndSetState()来获取和修改state的值，这些操作需要atomic包的支持，采用CAS操作，保证其原子性和可见性。 AQS的CLH锁队列CLH其实就是一个FIFO的队列，只不过稍微做了点改进。AQS中内部使用内部类Node来实现，是一个链表队列，原始CLH使用自旋锁，AQS的CLH则在每个node里使用一个状态字段来控制阻塞，不是自旋。直接看代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** +------+ prev +-----+ +-----+ head | | &lt;---- | | &lt;---- | | tail +------+ +-----+ +-----+/**static final class Node &#123; //作为共享模式 static final Node SHARED = new Node(); //作为独占模式 static final Node EXCLUSIVE = null; //等待状态：表示节点中线程是已被取消的 static final int CANCELLED = 1; //等待状态：表示当前节点的后继节点的线程需要被唤醒 static final int SIGNAL = -1; //等待状态：表示线程正在等待条件 static final int CONDITION = -2; //等待状态：表示下一个共享模式的节点应该无条件的传播下去 static final int PROPAGATE = -3; //等待状态，初始化为0，剩下的状态就是上面列出的 volatile int waitStatus; //当前节点的前驱节点 volatile Node prev; //后继节点 volatile Node next; //当前节点的线程 volatile Thread thread; // Node nextWaiter; //是否是共享节点 final boolean isShared() &#123; return nextWaiter == SHARED; &#125; //当前节点的前驱节点 final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; Node() &#123; // Used to establish initial head or SHARED marker &#125; Node(Thread thread, Node mode) &#123; // Used by addWaiter this.nextWaiter = mode; this.thread = thread; &#125; Node(Thread thread, int waitStatus) &#123; // Used by Condition this.waitStatus = waitStatus; this.thread = thread; &#125;&#125; 共享锁和互斥锁AQS的CLH队列锁中，每个节点代表着一个需要获取锁的线程，该node中有两个常量SHARED共享模式，EXCLUSIVE独占模式。 1234/** Marker to indicate a node is waiting in shared mode */static final Node SHARED = new Node();/** Marker to indicate a node is waiting in exclusive mode */static final Node EXCLUSIVE = null; 共享模式允许多个线程可以获取同一个锁，独占模式则一个锁只能被一个线程持有，其他线程必须要等待。 AQS源码1234567891011121314151617181920//阻塞队列的队列头private transient volatile Node head;//队列尾private transient volatile Node tail;//同步状态，这就是上面提到的需要原子操作的状态private volatile int state;//返回当前同步器的状态protected final int getState() &#123; return state;&#125;//设置同步器的状态protected final void setState(int newState) &#123; state = newState;&#125;//原子的设置当前同步器的状态protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125;//static final long spinForTimeoutThreshold = 1000L; 独占模式的获取acquire，独占，忽略中断12345678910//独占模式的获取方法，会忽略中断//tryAcquire方法会被至少调用一次，由子类实现//如果tryAcquire不能成功，当前线程就会进入队列排队public final void acquire(int arg) &#123; //首先调用tryAcquire尝试获取 //获取不成功，就使用acquireQueued使线程进入等待队列 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; tryAcquire方法： 12345//由子类来实现//尝试在独占模式下获取，会查询该对象的状态是否允许在独占模式下获取protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125; 使用指定的模式创建一个节点，添加到AQS链表队列中： 12345678910111213141516private Node addWaiter(Node mode) &#123; //当前线程，指定的mode，共享或者独占 Node node = new Node(Thread.currentThread(), mode); //先尝试使用直接添加进队列 Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; //使用添加节点的方法 enq(node); return node;&#125; 向队列中插入节点： 12345678910111213141516171819//会插入节点到对列中private Node enq(final Node node) &#123; for (;;) &#123; //尾节点 Node t = tail; //需要实例化一个队列 if (t == null) &#123; // Must initialize //使用cas创建头节点 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; tryAcquire没有获取到，就会先使用addWaiter添加进队列，然后使用acquireQueued从队列获取，如果这时候获取成功，则替换当前节点为队列头，然后返回： 123456789101112131415161718192021222324252627282930313233343536//独占模式处理正在排队等待的线程。//自旋，直至获取成功才返回final boolean acquireQueued(final Node node, int arg) &#123; //当前获取是否失败 boolean failed = true; try &#123; //获取是否被中断 boolean interrupted = false; for (;;) &#123; //获取当前节点的前驱节点 final Node p = node.predecessor(); //head节点要么是刚才初始化的节点 //要么就是成功获取锁的节点 //如果当前节点的前驱节点是head，当前节点就应该去尝试获取锁了 //当前节点的前驱节点是头节点，就尝试获取 if (p == head &amp;&amp; tryAcquire(arg)) &#123; //获取成功的话，就把当前节点设置为头节点 setHead(node); //之前的head节点的next引用设为null p.next = null; // help GC failed = false; return interrupted; &#125; //查看当前节点是否应该被park //如果应该，就park当前线程 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; //失败了，取消当前线程 if (failed) cancelAcquire(node); &#125;&#125; 设置头节点，只能被获取方法调用： 12345private void setHead(Node node) &#123; head = node; node.thread = null; node.prev = null;&#125; shouldParkAfterFailedAcquire方法，查看是否应该被park： 123456789101112131415161718192021private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; //前驱节点中保存的等待状态 int ws = pred.waitStatus; //等待状态是signal，也就是当前节点在等着被唤醒 //此时当前节点应该park if (ws == Node.SIGNAL) return true; //等待状态大于0表示前驱节点已经取消 //会向前找到一个非取消状态的节点 if (ws &gt; 0) &#123; do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; //将前驱节点的waitStatus设置为signal，表示当前需要被park compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 看下parkAndCheckInterrupt方法： 123456//挂起当前线程，并返回当前中断状态private final boolean parkAndCheckInterrupt() &#123; //挂起当前线程 LockSupport.park(this); return Thread.interrupted();&#125; cancelAcquire取消当前节点： 1234567891011121314151617181920212223242526272829303132333435363738private void cancelAcquire(Node node) &#123; //节点不存在 if (node == null) return; //节点的线程引用设为null node.thread = null; //前驱节点 Node pred = node.prev; //大于0表示前驱节点被取消 while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; //前驱节点的下一个是需要移除的节点 Node predNext = pred.next; //设置节点状态为取消 node.waitStatus = Node.CANCELLED; //如果是尾节点，直接取消，将前一个节点设置为尾节点 if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; compareAndSetNext(pred, predNext, null); &#125; else &#123;//不是尾节点，说明有后继节点，将前驱节点的next纸箱后继节点 int ws; if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); &#125; else &#123; unparkSuccessor(node); &#125; node.next = node; // help GC &#125;&#125; acquireInterruptibly 独占，可中断跟独占忽略中断类似，不再解释。 tryAcquireNanos，独占，可超时，可中断跟上面类似，但是在doAcquireNanos中会获取当前时间，并获取LockSupport.parkNanos之后的时间在做超时时间的重新计算，到了超时时间，就返回false。 独占模式的释放release，独占，忽略中断12345678910111213public final boolean release(int arg) &#123; //尝试释放，修改状态 if (tryRelease(arg)) &#123; //成功释放 //head代表初始化的节点，或者是当前占有锁的节点 //需要unpark后继节点 Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; unparkSuccessor： 1234567891011121314151617181920private void unparkSuccessor(Node node) &#123; //头节点中保存的waitStatus int ws = node.waitStatus; //重置头节点状态为0 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); //后继节点 Node s = node.next; //后继节点为null或者已经取消 if (s == null || s.waitStatus &gt; 0) &#123; s = null; //从最后往前找有效的节点 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; //unpark if (s != null) LockSupport.unpark(s.thread);&#125; 共享模式的获取acquireShared，共享，忽略中断acquireSharedInterruptibly，共享，可中断tryAcquireSharedNanos，共享，可设置超时，可中断共享模式的释放releaseShared共享模式的和独占模式基本差不多，和独占式的acquireQueued方法区别就是在获取成功的节点后会继续unpark后继节点，将共享状态向后传播。 LockSupport用来创建锁和其他同步类的基本线程阻塞原语。每个使用LockSupport的线程都会与一个许可关联，如果该许可可用并且可在进程中使用，则调用park()将会立即返回，否则可能阻塞。如果许可不可用，可调用unpark使其可用。 许可不可重入，只能调用一次park()方法，否则会一直阻塞。 park()和unpark()作用分别是阻塞线程和解除阻塞线程，且park和unpark不会遇到suspend和resume可能引发的死锁问题。 park，如果许可可用，使用该许可，并且该调用立即返回；否则为线程调度禁用当前线程，并在发生以下三种情况之一之前，使其处于休眠状态： * 其他某个线程将当前线程作为目标调用unpark * 其他某个线程中断当前线程 * 该调用不合逻辑的返回 unpark，如果给定的线程尚不可用，则使其可用。如果线程在park上受阻塞，则它将解除其阻塞状态。否则，保证下一次调用park不受阻塞。如果给定线程尚未启动，则无法保证此操作有任何效果。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo中服务消费者和服务提供者之间的请求和响应过程]]></title>
      <url>%2F2017%2F03%2F21%2FDubbo%E4%B8%AD%E6%9C%8D%E5%8A%A1%E6%B6%88%E8%B4%B9%E8%80%85%E5%92%8C%E6%9C%8D%E5%8A%A1%E6%8F%90%E4%BE%9B%E8%80%85%E4%B9%8B%E9%97%B4%E7%9A%84%E8%AF%B7%E6%B1%82%E5%92%8C%E5%93%8D%E5%BA%94%E8%BF%87%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[服务提供者初始化完成之后，对外暴露Exporter。服务消费者初始化完成之后，得到的是Proxy代理，方法调用的时候就是调用代理。 服务消费者经过初始化之后，得到的是一个动态代理类，InvokerInvocationHandler，包含MockClusterInvoker，MockClusterInvoker包含一个RegistryDirectory和FailoverClusterInvoker。 Java动态代理，每一个动态代理类都必须要实现InvocationHandler这个接口，并且每一个代理类的实例都关联到了一个handler，当我们通过代理对象调用一个方法的时候，这个方法就会被转发为由实现了InvocationHandler这个接口的类的invoke方法来进行调用。 服务消费者发起调用请求InvokerInvocationHandler实现了InvocationHandler接口，当我们调用helloService.sayHello();的时候，实际上会调用invoke()方法： 123456789101112131415161718192021222324252627//proxy是代理的真实对象//method调用真实对象的方法//args调用真实对象的方法的参数public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //方法名sayHello String methodName = method.getName(); //参数类型 Class&lt;?&gt;[] parameterTypes = method.getParameterTypes(); if (method.getDeclaringClass() == Object.class) &#123; return method.invoke(invoker, args); &#125; if (&quot;toString&quot;.equals(methodName) &amp;&amp; parameterTypes.length == 0) &#123; return invoker.toString(); &#125; if (&quot;hashCode&quot;.equals(methodName) &amp;&amp; parameterTypes.length == 0) &#123; return invoker.hashCode(); &#125; if (&quot;equals&quot;.equals(methodName) &amp;&amp; parameterTypes.length == 1) &#123; return invoker.equals(args[0]); &#125; //invoker是MockClusterInvoker //首先new RpcInvocation //然后invoker.invoke //最后recreate //返回结果 return invoker.invoke(new RpcInvocation(method, args)).recreate();&#125; 先看下new RpcInvocation，Invocation是会话域，它持有调用过程中的变量，比如方法名，参数类型等。 接着是invoker.invoke()，这里invoker是MockClusterInvoker，进入MockClusterInvoker.invoker()： 123456789101112131415161718192021222324public Result invoke(Invocation invocation) throws RpcException &#123; Result result = null; //获取mock属性的值，我们没有配置，默认false String value = directory.getUrl().getMethodParameter(invocation.getMethodName(), Constants.MOCK_KEY, Boolean.FALSE.toString()).trim(); if (value.length() == 0 || value.equalsIgnoreCase(&quot;false&quot;))&#123; //这里invoker是FailoverClusterInvoker result = this.invoker.invoke(invocation); &#125; else if (value.startsWith(&quot;force&quot;)) &#123; //force:direct mock result = doMockInvoke(invocation, null); &#125; else &#123; //fail-mock try &#123; result = this.invoker.invoke(invocation); &#125;catch (RpcException e) &#123; if (e.isBiz()) &#123; throw e; &#125; else &#123; result = doMockInvoke(invocation, e); &#125; &#125; &#125; return result;&#125; result = this.invoker.invoke(invocation);这里invoker是FailoverClusterInvoker，会首先进入AbstractClusterInvoker的invoke方法： 12345678910111213141516171819public Result invoke(final Invocation invocation) throws RpcException &#123; //检查是否被销毁 checkWheatherDestoried(); LoadBalance loadbalance; //根据invocation中的参数来获取所有的invoker列表 List&lt;Invoker&lt;T&gt;&gt; invokers = list(invocation); if (invokers != null &amp;&amp; invokers.size() &gt; 0) &#123; //我们没有配置负载均衡的参数，默认使用random //这里得到的是RandomLoadBalance loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(invokers.get(0).getUrl() .getMethodParameter(invocation.getMethodName(),Constants.LOADBALANCE_KEY, Constants.DEFAULT_LOADBALANCE)); &#125; else &#123; loadbalance = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(Constants.DEFAULT_LOADBALANCE); &#125; //如果是异步操作默认添加invocation id RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation); //这里是子类实现，FailoverClusterInvoker中，执行调用 return doInvoke(invocation, invokers, loadbalance);&#125; FailoverClusterInvoker.doInvoke()： 1234567891011121314151617181920212223242526272829303132333435363738public Result doInvoke(Invocation invocation, final List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; List&lt;Invoker&lt;T&gt;&gt; copyinvokers = invokers; //检查invokers是否为空 checkInvokers(copyinvokers, invocation); //重试次数 int len = getUrl().getMethodParameter(invocation.getMethodName(), Constants.RETRIES_KEY, Constants.DEFAULT_RETRIES) + 1; if (len &lt;= 0) &#123; len = 1; &#125; // retry loop. RpcException le = null; // last exception. //已经调用过的invoker List&lt;Invoker&lt;T&gt;&gt; invoked = new ArrayList&lt;Invoker&lt;T&gt;&gt;(copyinvokers.size()); // invoked invokers. Set&lt;String&gt; providers = new HashSet&lt;String&gt;(len); for (int i = 0; i &lt; len; i++) &#123; //重试时，进行重新选择，避免重试时invoker列表已发生变化. //注意：如果列表发生了变化，那么invoked判断会失效，因为invoker示例已经改变 if (i &gt; 0) &#123; checkWheatherDestoried(); copyinvokers = list(invocation); //重新检查一下 checkInvokers(copyinvokers, invocation); &#125; //使用负载均衡选择invoker.（负载均衡咱先不做解释） Invoker&lt;T&gt; invoker = select(loadbalance, invocation, copyinvokers, invoked); invoked.add(invoker); //添加到以调用过的列表中 RpcContext.getContext().setInvokers((List)invoked); try &#123; //开始调用，返回结果 Result result = invoker.invoke(invocation); return result; &#125; catch (RpcException e) &#123;。。。 &#125; finally &#123; providers.add(invoker.getUrl().getAddress()); &#125; &#125; throw new RpcException(。。。);&#125; Result result = invoker.invoke(invocation);调用并返回结果，会首先进入InvokerWrapper，然后进入ListenerInvokerWrapper的invoke方法，接着进入AbstractInvoker的invoke： 123456789101112131415161718192021222324public Result invoke(Invocation inv) throws RpcException &#123; if(destroyed) &#123; throw new RpcException(。。。); &#125; //转成RpcInvocation RpcInvocation invocation = (RpcInvocation) inv; invocation.setInvoker(this); if (attachment != null &amp;&amp; attachment.size() &gt; 0) &#123; invocation.addAttachmentsIfAbsent(attachment); &#125; Map&lt;String, String&gt; context = RpcContext.getContext().getAttachments(); if (context != null) &#123; invocation.addAttachmentsIfAbsent(context); &#125; if (getUrl().getMethodParameter(invocation.getMethodName(), Constants.ASYNC_KEY, false))&#123; invocation.setAttachment(Constants.ASYNC_KEY, Boolean.TRUE.toString()); &#125; //异步的话，需要添加id RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation); try &#123; //这里是DubboInvoker return doInvoke(invocation); &#125; catch (InvocationTargetException e) &#123; &#125; &#125; DubboInvoker.doInvoke()： 123456789101112131415161718192021222324252627282930313233343536protected Result doInvoke(final Invocation invocation) throws Throwable &#123; RpcInvocation inv = (RpcInvocation) invocation; final String methodName = RpcUtils.getMethodName(invocation); inv.setAttachment(Constants.PATH_KEY, getUrl().getPath()); inv.setAttachment(Constants.VERSION_KEY, version); ExchangeClient currentClient; //在初始化的时候，引用服务的过程中会保存一个连接到服务端的Client if (clients.length == 1) &#123; currentClient = clients[0]; &#125; else &#123; currentClient = clients[index.getAndIncrement() % clients.length]; &#125; try &#123; //异步标志 boolean isAsync = RpcUtils.isAsync(getUrl(), invocation); //单向标志 boolean isOneway = RpcUtils.isOneway(getUrl(), invocation); int timeout = getUrl().getMethodParameter(methodName, Constants.TIMEOUT_KEY,Constants.DEFAULT_TIMEOUT); //单向的，反送完不管结果 if (isOneway) &#123; boolean isSent = getUrl().getMethodParameter(methodName, Constants.SENT_KEY, false); currentClient.send(inv, isSent); RpcContext.getContext().setFuture(null); return new RpcResult(); &#125; else if (isAsync) &#123;//异步的，发送完需要得到Future ResponseFuture future = currentClient.request(inv, timeout) ; RpcContext.getContext().setFuture(new FutureAdapter&lt;Object&gt;(future)); return new RpcResult(); &#125; else &#123;//同步调用，我们这里使用的这种方式 RpcContext.getContext().setFuture(null); //HeaderExchangeClient return (Result) currentClient.request(inv, timeout).get(); &#125; &#125; catch (TimeoutException e) &#123;。。。&#125;&#125; 我们这里使用的是同步调用，看(Result) currentClient.request(inv, timeout).get();方法，这里的client是ReferenceCountExchangeClient，直接调用HeaderExchangeClient的request方法： 1234public ResponseFuture request(Object request, int timeout) throws RemotingException &#123; //这里的Channel是HeaderExchangeChannel return channel.request(request, timeout);&#125; 进入HeaderExchangeChannel的request方法： 1234567891011121314151617181920212223242526public ResponseFuture request(Object request, int timeout) throws RemotingException &#123; if (closed) &#123; throw new RemotingException(。。。); &#125; //创建一个请求头 Request req = new Request(); req.setVersion(&quot;2.0.0&quot;); req.setTwoWay(true); //这里request参数里面保存着 //methodName = &quot;sayHello&quot; //parameterTypes = &#123;Class[0]@2814&#125; //arguments = &#123;Object[0]@2768&#125; //attachments = &#123;HashMap@2822&#125; size = 4 //invoker = &#123;DubboInvoker@2658&#125; req.setData(request); DefaultFuture future = new DefaultFuture(channel, req, timeout); try&#123; //这里的channel是NettyClient //发送请求 channel.send(req); &#125;catch (RemotingException e) &#123; future.cancel(); throw e; &#125; return future;&#125; channel.send(req)，首先会调用AbstractPeer的send方法： 1234//子类处理，接着是AbstractClient执行发送public void send(Object message) throws RemotingException &#123; send(message, url.getParameter(Constants.SENT_KEY, false));&#125; AbstractClient执行发送： 1234567891011121314public void send(Object message, boolean sent) throws RemotingException &#123; //重连 if (send_reconnect &amp;&amp; !isConnected())&#123; connect(); &#125; //先获取Channel，是在NettyClient中实现的 Channel channel = getChannel(); //TODO getChannel返回的状态是否包含null需要改进 if (channel == null || ! channel.isConnected()) &#123; throw new RemotingException(this, &quot;message can not send, because channel is closed . url:&quot; + getUrl()); &#125; channel是NettyChannel channel.send(message, sent);&#125; channel.send(message, sent);首先经过AbstractChannel的send方法处理，只是判断是否关闭了，然后是NettyChannel的send来继续处理，这里就把消息发送到服务端了： 12345678910111213141516171819202122232425public void send(Object message, boolean sent) throws RemotingException &#123; super.send(message, sent); boolean success = true; int timeout = 0; try &#123; //交给netty处理 ChannelFuture future = channel.write(message); if (sent) &#123; timeout = getUrl().getPositiveParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); success = future.await(timeout); &#125; Throwable cause = future.getCause(); if (cause != null) &#123; throw cause; &#125; &#125; catch (Throwable e) &#123; throw new RemotingException(this, &quot;Failed to send message &quot; + message + &quot; to &quot; + getRemoteAddress() + &quot;, cause: &quot; + e.getMessage(), e); &#125; if(! success) &#123; throw new RemotingException(this, &quot;Failed to send message &quot; + message + &quot; to &quot; + getRemoteAddress() + &quot;in timeout(&quot; + timeout + &quot;ms) limit&quot;); &#125;&#125; 服务提供者处理并响应请求服务端已经打开端口并监听请求的到来，当服务消费者发送调用请求的时候，经过Netty的处理后会到dubbo中的codec相关方法中先进行解码，入口是NettyCodecAdapter.messageReceived()，关于这个方法的代码在dubbo编解码的那篇文章中已经分析过，不再重复。经过解码之后，会进入到NettyHandler.messageReceived()方法： 12345678910public void messageReceived(ChannelHandlerContext ctx, MessageEvent e) throws Exception &#123; //获取channel NettyChannel channel = NettyChannel.getOrAddChannel(ctx.getChannel(), url, handler); try &#123; //这里handler是NettyServer handler.received(channel, e.getMessage()); &#125; finally &#123; NettyChannel.removeChannelIfDisconnected(ctx.getChannel()); &#125;&#125; 接着会进入AbstractPeer的received方法： 1234567public void received(Channel ch, Object msg) throws RemotingException &#123; if (closed) &#123; return; &#125; //这里是MultiMessageHandler handler.received(ch, msg);&#125; 进入MultiMessageHandler的received方法： 123456789101112public void received(Channel channel, Object message) throws RemotingException &#123; //是多消息的话，使用多消息处理器处理 if (message instanceof MultiMessage) &#123; MultiMessage list = (MultiMessage)message; for(Object obj : list) &#123; handler.received(channel, obj); &#125; &#125; else &#123; //这里是HeartbeatHandler handler.received(channel, message); &#125;&#125; 进入HeartbeatHandler的received方法： 12345678910111213141516171819public void received(Channel channel, Object message) throws RemotingException &#123; setReadTimestamp(channel); //心跳请求处理 if (isHeartbeatRequest(message)) &#123; Request req = (Request) message; if (req.isTwoWay()) &#123; Response res = new Response(req.getId(), req.getVersion()); res.setEvent(Response.HEARTBEAT_EVENT); channel.send(res); &#125; return; &#125; //心跳回应消息处理 if (isHeartbeatResponse(message)) &#123; return; &#125; //这里是AllChannelHandler handler.received(channel, message);&#125; 继续进入AllChannelHandler的received方法： 12345678public void received(Channel channel, Object message) throws RemotingException &#123; //获取线程池执行 ExecutorService cexecutor = getExecutorService(); try &#123; //handler是DecodeHandler cexecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message)); &#125; catch (Throwable t) &#123; &#125;&#125; 这里会去启动新线程执行ChannelEventRunnable的run方法，接着去调用DecodeHandler的received方法： 12345678910111213141516public void received(Channel channel, Object message) throws RemotingException &#123; //不清楚啥意思 if (message instanceof Decodeable) &#123; decode(message); &#125; //解码请求类型 if (message instanceof Request) &#123; decode(((Request)message).getData()); &#125; //解码响应类型 if (message instanceof Response) &#123; decode( ((Response)message).getResult()); &#125; //解码之后到HeaderExchangeHandler中处理 handler.received(channel, message);&#125; 解码之后到HeaderExchangeHandler的received方法： 123456789101112131415161718192021222324252627282930313233343536373839public void received(Channel channel, Object message) throws RemotingException &#123; channel.setAttribute(KEY_READ_TIMESTAMP, System.currentTimeMillis()); ExchangeChannel exchangeChannel = HeaderExchangeChannel.getOrAddChannel(channel); try &#123; //request类型的消息 if (message instanceof Request) &#123; Request request = (Request) message; if (request.isEvent()) &#123;//判断心跳还是正常请求 // 处理心跳 handlerEvent(channel, request); &#125; else &#123;//正常的请求 //需要返回 if (request.isTwoWay()) &#123; //处理请求，并构造响应信息 Response response = handleRequest(exchangeChannel, request); //NettyChannel，发送响应信息 channel.send(response); &#125; else &#123;//不需要返回的处理 handler.received(exchangeChannel, request.getData()); &#125; &#125; &#125; else if (message instanceof Response) &#123;//response类型的消息 handleResponse(channel, (Response) message); &#125; else if (message instanceof String) &#123; if (isClientSide(channel)) &#123; Exception e = new Exception(&quot;Dubbo client can not supported string message: &quot; + message + &quot; in channel: &quot; + channel + &quot;, url: &quot; + channel.getUrl()); &#125; else &#123;//telnet类型 String echo = handler.telnet(channel, (String) message); if (echo != null &amp;&amp; echo.length() &gt; 0) &#123; channel.send(echo); &#125; &#125; &#125; else &#123; handler.received(exchangeChannel, message); &#125; &#125; finally &#123; HeaderExchangeChannel.removeChannelIfDisconnected(channel); &#125;&#125; 先看下处理请求，并构造响应信息： 123456789101112131415161718192021222324Response handleRequest(ExchangeChannel channel, Request req) throws RemotingException &#123; Response res = new Response(req.getId(), req.getVersion()); if (req.isBroken()) &#123; Object data = req.getData(); String msg; if (data == null) msg = null; else if (data instanceof Throwable) msg = StringUtils.toString((Throwable) data); else msg = data.toString(); res.setErrorMessage(&quot;Fail to decode request due to: &quot; + msg); res.setStatus(Response.BAD_REQUEST); return res; &#125; // find handler by message class. Object msg = req.getData(); try &#123; //处理请求数据，handler是DubboProtocol中的new的一个ExchangeHandlerAdapter Object result = handler.reply(channel, msg); res.setStatus(Response.OK); res.setResult(result); &#125; catch (Throwable e) &#123; &#125; return res;&#125; 进入DubboProtocol中的ExchangeHandlerAdapter的replay方法： 12345678910111213141516171819202122232425262728293031public Object reply(ExchangeChannel channel, Object message) throws RemotingException &#123; if (message instanceof Invocation) &#123; //Invocation中保存着方法名等 Invocation inv = (Invocation) message; //获取Invoker Invoker&lt;?&gt; invoker = getInvoker(channel, inv); //如果是callback 需要处理高版本调用低版本的问题 if (Boolean.TRUE.toString().equals(inv.getAttachments().get(IS_CALLBACK_SERVICE_INVOKE)))&#123; String methodsStr = invoker.getUrl().getParameters().get(&quot;methods&quot;); boolean hasMethod = false; if (methodsStr == null || methodsStr.indexOf(&quot;,&quot;) == -1)&#123; hasMethod = inv.getMethodName().equals(methodsStr); &#125; else &#123; String[] methods = methodsStr.split(&quot;,&quot;); for (String method : methods)&#123; if (inv.getMethodName().equals(method))&#123; hasMethod = true; break; &#125; &#125; &#125; if (!hasMethod)&#123; return null; &#125; &#125; RpcContext.getContext().setRemoteAddress(channel.getRemoteAddress()); //执行调用，然后返回结果 return invoker.invoke(inv); &#125; throw new RemotingException(。。。); &#125; 先看下getInvoker获取Invoker： 1234567891011121314151617181920212223242526Invoker&lt;?&gt; getInvoker(Channel channel, Invocation inv) throws RemotingException&#123; boolean isCallBackServiceInvoke = false; boolean isStubServiceInvoke = false; int port = channel.getLocalAddress().getPort(); String path = inv.getAttachments().get(Constants.PATH_KEY); //如果是客户端的回调服务. isStubServiceInvoke = Boolean.TRUE.toString().equals(inv.getAttachments().get(Constants.STUB_EVENT_KEY)); if (isStubServiceInvoke)&#123; port = channel.getRemoteAddress().getPort(); &#125; //callback isCallBackServiceInvoke = isClientSide(channel) &amp;&amp; !isStubServiceInvoke; if(isCallBackServiceInvoke)&#123; path = inv.getAttachments().get(Constants.PATH_KEY)+&quot;.&quot;+inv.getAttachments().get(Constants.CALLBACK_SERVICE_KEY); inv.getAttachments().put(IS_CALLBACK_SERVICE_INVOKE, Boolean.TRUE.toString()); &#125; String serviceKey = serviceKey(port, path, inv.getAttachments().get(Constants.VERSION_KEY), inv.getAttachments().get(Constants.GROUP_KEY)); //从之前缓存的exporterMap中查找Exporter //key：dubbo.common.hello.service.HelloService:20880 DubboExporter&lt;?&gt; exporter = (DubboExporter&lt;?&gt;) exporterMap.get(serviceKey); if (exporter == null) throw new RemotingException(。。。）; //得到Invoker，返回 return exporter.getInvoker();&#125; 再看执行调用invoker.invoke(inv);，会先进入InvokerWrapper： 123public Result invoke(Invocation invocation) throws RpcException &#123; return invoker.invoke(invocation);&#125; 接着进入AbstractProxyInvoker： 1234567public Result invoke(Invocation invocation) throws RpcException &#123; try &#123; //先doInvoke //然后封装成结果返回 return new RpcResult(doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments())); &#125; catch (InvocationTargetException e) &#123;。。。&#125;&#125; 这里的doInvoke是在JavassistProxyFactory中的AbstractProxyInvoker实例： 12345678910111213public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; // TODO Wrapper类不能正确处理带$的类名 final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf(&apos;$&apos;) &lt; 0 ? proxy.getClass() : type); return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; //这里就调用了具体的方法 return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &#125; &#125;;&#125; 消息处理完后返回到HeaderExchangeHandler的received方法： 123456789101112131415161718192021222324252627282930313233343536373839public void received(Channel channel, Object message) throws RemotingException &#123; channel.setAttribute(KEY_READ_TIMESTAMP, System.currentTimeMillis()); ExchangeChannel exchangeChannel = HeaderExchangeChannel.getOrAddChannel(channel); try &#123; //request类型的消息 if (message instanceof Request) &#123; Request request = (Request) message; if (request.isEvent()) &#123;//判断心跳还是正常请求 // 处理心跳 handlerEvent(channel, request); &#125; else &#123;//正常的请求 //需要返回 if (request.isTwoWay()) &#123; //处理请求，并构造响应信息，这在上面已经解析过了 Response response = handleRequest(exchangeChannel, request); //NettyChannel，发送响应信息 channel.send(response); &#125; else &#123;//不需要返回的处理 handler.received(exchangeChannel, request.getData()); &#125; &#125; &#125; else if (message instanceof Response) &#123;//response类型的消息 handleResponse(channel, (Response) message); &#125; else if (message instanceof String) &#123; if (isClientSide(channel)) &#123; Exception e = new Exception(&quot;Dubbo client can not supported string message: &quot; + message + &quot; in channel: &quot; + channel + &quot;, url: &quot; + channel.getUrl()); &#125; else &#123;//telnet类型 String echo = handler.telnet(channel, (String) message); if (echo != null &amp;&amp; echo.length() &gt; 0) &#123; channel.send(echo); &#125; &#125; &#125; else &#123; handler.received(exchangeChannel, message); &#125; &#125; finally &#123; HeaderExchangeChannel.removeChannelIfDisconnected(channel); &#125;&#125; 解析完请求，构造完响应消息，就开始发送响应了,channel.send(response);，先经过AbstractPeer: 1234public void send(Object message) throws RemotingException &#123; //NettyChannel send(message, url.getParameter(Constants.SENT_KEY, false));&#125; 进入NettyChannel中，进行响应消息的发送： 12345678910111213141516171819202122232425public void send(Object message, boolean sent) throws RemotingException &#123; //AbstractChannel的处理 super.send(message, sent); boolean success = true; int timeout = 0; try &#123; ChannelFuture future = channel.write(message); if (sent) &#123; timeout = getUrl().getPositiveParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); success = future.await(timeout); &#125; Throwable cause = future.getCause(); if (cause != null) &#123; throw cause; &#125; &#125; catch (Throwable e) &#123; throw new RemotingException(this, &quot;Failed to send message &quot; + message + &quot; to &quot; + getRemoteAddress() + &quot;, cause: &quot; + e.getMessage(), e); &#125; if(! success) &#123; throw new RemotingException(this, &quot;Failed to send message &quot; + message + &quot; to &quot; + getRemoteAddress() + &quot;in timeout(&quot; + timeout + &quot;ms) limit&quot;); &#125;&#125; 消费者接受到服务端返回的响应后的处理服务提供者端接收到消费者端的请求并处理之后，返回给消费者端，消费者这边接受响应的入口跟提供者差不多，也是NettyCodecAdapter.messageReceived()，经过解码，到NettyHandler.messageReceived()处理： 123456789public void messageReceived(ChannelHandlerContext ctx, MessageEvent e) throws Exception &#123; NettyChannel channel = NettyChannel.getOrAddChannel(ctx.getChannel(), url, handler); try &#123; //NettyClient handler.received(channel, e.getMessage()); &#125; finally &#123; NettyChannel.removeChannelIfDisconnected(ctx.getChannel()); &#125;&#125; 先经过AbstractPeer的received方法： 1234567public void received(Channel ch, Object msg) throws RemotingException &#123; if (closed) &#123; return; &#125; //MultiMessageHandler handler.received(ch, msg);&#125; 进入MultiMessageHandler： 1234567891011public void received(Channel channel, Object message) throws RemotingException &#123; if (message instanceof MultiMessage) &#123; MultiMessage list = (MultiMessage)message; for(Object obj : list) &#123; handler.received(channel, obj); &#125; &#125; else &#123; //HeartbeatHandler handler.received(channel, message); &#125;&#125; 进入HeartbeatHandler，根据不同类型进行处理： 1234567891011121314151617181920212223242526272829303132public void received(Channel channel, Object message) throws RemotingException &#123; setReadTimestamp(channel); if (isHeartbeatRequest(message)) &#123; Request req = (Request) message; if (req.isTwoWay()) &#123; Response res = new Response(req.getId(), req.getVersion()); res.setEvent(Response.HEARTBEAT_EVENT); channel.send(res); if (logger.isInfoEnabled()) &#123; int heartbeat = channel.getUrl().getParameter(Constants.HEARTBEAT_KEY, 0); if(logger.isDebugEnabled()) &#123; logger.debug(&quot;Received heartbeat from remote channel &quot; + channel.getRemoteAddress() + &quot;, cause: The channel has no data-transmission exceeds a heartbeat period&quot; + (heartbeat &gt; 0 ? &quot;: &quot; + heartbeat + &quot;ms&quot; : &quot;&quot;)); &#125; &#125; &#125; return; &#125; if (isHeartbeatResponse(message)) &#123; if (logger.isDebugEnabled()) &#123; logger.debug( new StringBuilder(32) .append(&quot;Receive heartbeat response in thread &quot;) .append(Thread.currentThread().getName()) .toString()); &#125; return; &#125; //AllChannelHandler handler.received(channel, message);&#125; 进入AllChannelHandler： 12345678public void received(Channel channel, Object message) throws RemotingException &#123; ExecutorService cexecutor = getExecutorService(); try &#123; cexecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message)); &#125; catch (Throwable t) &#123; throw new ExecutionException(message, channel, getClass() + &quot; error when process received event .&quot;, t); &#125;&#125; 然后在新线程，ChannelEventRunnable的run方法中进入DecodeHandler： 123456789101112131415public void received(Channel channel, Object message) throws RemotingException &#123; if (message instanceof Decodeable) &#123; decode(message); &#125; if (message instanceof Request) &#123; decode(((Request)message).getData()); &#125; //这里进行response类型的处理 if (message instanceof Response) &#123; decode( ((Response)message).getResult()); &#125; handler.received(channel, message);&#125; 进入处理response的decode方法，进行解码response： 1234567private void decode(Object message) &#123; if (message != null &amp;&amp; message instanceof Decodeable) &#123; try &#123; ((Decodeable)message).decode(); &#125; catch (Throwable e) &#123;。。。&#125; // ~ end of catch &#125; // ~ end of if&#125; 接着会进入HeaderExchangerHandler.received () 方法： 123456789101112131415161718192021222324252627282930313233public void received(Channel channel, Object message) throws RemotingException &#123; channel.setAttribute(KEY_READ_TIMESTAMP, System.currentTimeMillis()); ExchangeChannel exchangeChannel = HeaderExchangeChannel.getOrAddChannel(channel); try &#123; if (message instanceof Request) &#123; Request request = (Request) message; if (request.isEvent()) &#123; handlerEvent(channel, request); &#125; else &#123; if (request.isTwoWay()) &#123; Response response = handleRequest(exchangeChannel, request); channel.send(response); &#125; else &#123; handler.received(exchangeChannel, request.getData()); &#125; &#125; &#125; else if (message instanceof Response) &#123; //这里处理response消息 handleResponse(channel, (Response) message); &#125; else if (message instanceof String) &#123; if (isClientSide(channel)) &#123; Exception &#125; else &#123; String echo = handler.telnet(channel, (String) message); if (echo != null &amp;&amp; echo.length() &gt; 0) &#123; channel.send(echo); &#125; &#125; &#125; else &#123; handler.received(exchangeChannel, message); &#125; &#125; finally &#123; HeaderExchangeChannel.removeChannelIfDisconnected(channel); &#125;&#125; handleResponse方法： 12345static void handleResponse(Channel channel, Response response) throws RemotingException &#123; if (response != null &amp;&amp; !response.isHeartbeat()) &#123; DefaultFuture.received(channel, response); &#125;&#125; 这一步设置response到消费者请求的Future中，以供消费者通过DefaultFuture.get()取得提供者的响应，此为同步转异步重要一步，且请求超时也由DefaultFuture控制。 然后就是return (Result) currentClient.request(inv, timeout).get();在DubboInvoker中，这里继续执行，然后执行Filter，最后返回到InvokerInvocationHandler.invoker()方法中，方法得到调用结果，结束！ 注意： 消费者端的DubboInvoker发起请求后，后续的逻辑是异步的或是指定超时时间内阻塞的，直到得到响应结果后，继续执行DubboInvoker中逻辑。 对于异步请求时，消费者得到Future，其余逻辑均是异步的。 消费者还可以通过设置async、sent、return来调整处理逻辑，async指异步还是同步请求，sent指是否等待请求消息发出即阻塞等待是否成功发出请求、return指是否忽略返回值即但方向通信，一般异步时使用以减少Future对象的创建和管理成本。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo中消费者初始化的过程解析]]></title>
      <url>%2F2017%2F03%2F21%2FDubbo%E4%B8%AD%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%9D%E5%A7%8B%E5%8C%96%E7%9A%84%E8%BF%87%E7%A8%8B%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[首先还是Spring碰到dubbo的标签之后，会使用parseCustomElement解析dubbo标签，使用的解析器是dubbo的DubboBeanDefinitionParser，解析完成之后返回BeanDefinition给Spring管理。 服务消费者端对应的是ReferenceBean，实现了ApplicationContextAware接口，Spring会在Bean的实例化那一步回调setApplicationContext方法。也实现了InitializingBean接口，接着会回调afterPropertySet方法。还实现了FactoryBean接口，实现FactoryBean可以在后期获取bean的时候做一些操作，dubbo在这个时候做初始化。另外ReferenceBean还实现了DisposableBean，会在bean销毁的时候调用destory方法。消费者的初始化是在ReferenceBean的init方法中执行，分为两种情况： reference标签中没有配置init属性，此时是延迟初始化的，也就是只有等到bean引用被注入到其他Bean中，或者调用getBean获取这个Bean的时候，才会初始化。比如在这里的例子里reference没有配置init属性，只有等到HelloService helloService = (HelloService) applicationContext.getBean(&quot;helloService&quot;);这句getBean的时候，才会开始调用init方法进行初始化。 另外一种情况是立即初始化，即是如果reference标签中init属性配置为true，会立即进行初始化（也就是上面说到的实现了FactoryBean接口）。 初始化开始这里以没有配置init的reference为例，只要不注入bean或者不调用getBean获取bean的时候，就不会被初始化。HelloService helloService = (HelloService) applicationContext.getBean(&quot;helloService&quot;); 另外在ReferenceBean这个类在Spring中初始化的时候，有几个静态变量会被初始化： 12345private static final Protocol refprotocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();private static final Cluster cluster = ExtensionLoader.getExtensionLoader(Cluster.class).getAdaptiveExtension();private static final ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension(); 这几个变量的初始化是根据dubbo的SPI扩展机制动态生成的代码： refprotocol： 12345678910111213141516171819202122232425262728293031323334353637import com.alibaba.dubbo.common.extension.ExtensionLoader;public class Protocol$Adpative implements com.alibaba.dubbo.rpc.Protocol &#123; public com.alibaba.dubbo.rpc.Invoker refer(java.lang.Class arg0, com.alibaba.dubbo.common.URL arg1) throws java.lang.Class &#123; if (arg1 == null) throw new IllegalArgumentException(&quot;url == null&quot;); com.alibaba.dubbo.common.URL url = arg1; String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); &#125; public com.alibaba.dubbo.rpc.Exporter export(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker &#123; if (arg0 == null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument == null&quot;); if (arg0.getUrl() == null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument getUrl() == null&quot;);com.alibaba.dubbo.common.URL url = arg0.getUrl(); String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName); return extension.export(arg0); &#125; public void destroy() &#123; throw new UnsupportedOperationException(&quot;method public abstract void com.alibaba.dubbo.rpc.Protocol.destroy() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!&quot;); &#125; public int getDefaultPort() &#123; throw new UnsupportedOperationException(&quot;method public abstract int com.alibaba.dubbo.rpc.Protocol.getDefaultPort() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!&quot;); &#125;&#125; cluster： 12345678910111213141516import com.alibaba.dubbo.common.extension.ExtensionLoader;public class Cluster$Adpative implements com.alibaba.dubbo.rpc.cluster.Cluster &#123; public com.alibaba.dubbo.rpc.Invoker join(com.alibaba.dubbo.rpc.cluster.Directory arg0) throws com.alibaba.dubbo.rpc.cluster.Directory &#123; if (arg0 == null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.cluster.Directory argument == null&quot;); if (arg0.getUrl() == null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.cluster.Directory argument getUrl() == null&quot;);com.alibaba.dubbo.common.URL url = arg0.getUrl(); String extName = url.getParameter(&quot;cluster&quot;, &quot;failover&quot;); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.cluster.Cluster) name from url(&quot; + url.toString() + &quot;) use keys([cluster])&quot;); com.alibaba.dubbo.rpc.cluster.Cluster extension = (com.alibaba.dubbo.rpc.cluster.Cluster)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.cluster.Cluster.class).getExtension(extName); return extension.join(arg0); &#125;&#125; proxyFactory： 1234567891011121314151617181920212223242526272829import com.alibaba.dubbo.common.extension.ExtensionLoader;public class ProxyFactory$Adpative implements com.alibaba.dubbo.rpc.ProxyFactory &#123; public java.lang.Object getProxy(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker &#123; if (arg0 == null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument == null&quot;); if (arg0.getUrl() == null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument getUrl() == null&quot;);com.alibaba.dubbo.common.URL url = arg0.getUrl(); String extName = url.getParameter(&quot;proxy&quot;, &quot;javassist&quot;); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.ProxyFactory) name from url(&quot; + url.toString() + &quot;) use keys([proxy])&quot;); com.alibaba.dubbo.rpc.ProxyFactory extension = (com.alibaba.dubbo.rpc.ProxyFactory)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getProxy(arg0); &#125; public com.alibaba.dubbo.rpc.Invoker getInvoker(java.lang.Object arg0, java.lang.Class arg1, com.alibaba.dubbo.common.URL arg2) throws java.lang.Object &#123; if (arg2 == null) throw new IllegalArgumentException(&quot;url == null&quot;); com.alibaba.dubbo.common.URL url = arg2; String extName = url.getParameter(&quot;proxy&quot;, &quot;javassist&quot;); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.ProxyFactory) name from url(&quot; + url.toString() + &quot;) use keys([proxy])&quot;); com.alibaba.dubbo.rpc.ProxyFactory extension = (com.alibaba.dubbo.rpc.ProxyFactory)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getInvoker(arg0, arg1, arg2); &#125;&#125; 初始化入口初始化的入口在ReferenceConfig的get()方法： 123456789public synchronized T get() &#123; if (destroyed)&#123; throw new IllegalStateException(&quot;Already destroyed!&quot;); &#125; if (ref == null) &#123; init(); &#125; return ref;&#125; init()方法会先检查初始化所有的配置信息，然后调用ref = createProxy(map);创建代理，消费者最终得到的是服务的代理。初始化主要做的事情就是引用对应的远程服务，大概的步骤： 监听注册中心 连接服务提供者端进行服务引用 创建服务代理并返回 文档上关于Zookeeper作为注册中心时，服务消费者启动时要做的事情有： 订阅/dubbo/com.foo.BarService/providers目录下的提供者URL地址。并向/dubbo/com.foo.BarService/consumers目录下写入自己的URL地址。 创建代理 引用远程服务 创建代理 init()中createProxy方法： 123456789101112131415161718private T createProxy(Map&lt;String, String&gt; map) &#123; //先判断是否是本地服务引用injvm //判断是否是点对点直连 //判断是否是通过注册中心连接 //然后是服务的引用 //这里url为 //registry://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService? //application=dubbo-consumer&amp;dubbo=2.5.3&amp;pid=12272&amp; //refer=application%3Ddubbo-consumer%26dubbo%3D2.5.3%26 //interface%3Ddubbo.common.hello.service.HelloService%26 //methods%3DsayHello%26pid%3D12272%26side%3D //consumer%26timeout%3D100000%26timestamp%3D1489318676447&amp; //registry=zookeeper&amp;timestamp=1489318676641 //引用远程服务由Protocol的实现来处理 refprotocol.refer(interfaceClass, url); //最后返回服务代理 return (T) proxyFactory.getProxy(invoker);&#125; 这里refprotocol是上面生成的代码，会根据协议不同选择不同的Protocol协议。 引用远程服务对于服务引用refprotocol.refer(interfaceClass, url)会首先进入ProtocolListenerWrapper的refer方法，然后在进入ProtocolFilterWrapper的refer方法，然后再进入RegistryProtocol的refer方法，这里的url协议是registry，所以上面两个Wrapper中不做处理，直接进入了RegistryProtocol，看下RegistryProtocol中： 12345678910111213141516171819202122232425262728293031323334public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; //这里获得的url是 //zookeeper://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService? //application=dubbo-consumer&amp;dubbo=2.5.3&amp;pid=12272&amp; //refer=application%3Ddubbo-consumer%26dubbo%3D2.5.3%26 //interface%3Ddubbo.common.hello.service.HelloService%26 //methods%3DsayHello%26pid%3D12272%26side%3D //consumer%26timeout%3D100000%26 //timestamp%3D1489318676447&amp;timestamp=1489318676641 url = url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY); //根据url获取Registry对象 //先连接注册中心，把消费者注册到注册中心 Registry registry = registryFactory.getRegistry(url); //判断引用是否是注册中心RegistryService，如果是直接返回刚得到的注册中心服务 if (RegistryService.class.equals(type)) &#123; return proxyFactory.getInvoker((T) registry, type, url); &#125; //以下是普通服务，需要进入注册中心和集群下面的逻辑 // group=&quot;a,b&quot; or group=&quot;*&quot; //获取ref的各种属性 Map&lt;String, String&gt; qs = StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY)); //获取分组属性 String group = qs.get(Constants.GROUP_KEY); //先判断引用服务是否需要合并不同实现的返回结果 if (group != null &amp;&amp; group.length() &gt; 0 ) &#123; if ( ( Constants.COMMA_SPLIT_PATTERN.split( group ) ).length &gt; 1 || &quot;*&quot;.equals( group ) ) &#123; //使用默认的分组聚合集群策略 return doRefer( getMergeableCluster(), registry, type, url ); &#125; &#125; //选择配置的集群策略（cluster=&quot;failback&quot;）或者默认策略 return doRefer(cluster, registry, type, url);&#125; 获取注册中心连接注册中心Registry registry = registryFactory.getRegistry(url);首先会到AbstractRegistryFactory的getRegistry方法： 123456789101112131415161718192021222324252627282930313233public Registry getRegistry(URL url) &#123; //这里url是 //zookeeper://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService? //application=dubbo-consumer&amp;dubbo=2.5.3&amp; //interface=com.alibaba.dubbo.registry.RegistryService&amp; //pid=12272&amp;timestamp=1489318676641 url = url.setPath(RegistryService.class.getName()) .addParameter(Constants.INTERFACE_KEY, RegistryService.class.getName()) .removeParameters(Constants.EXPORT_KEY, Constants.REFER_KEY); //这里key是 //zookeeper://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService String key = url.toServiceString(); // 锁定注册中心获取过程，保证注册中心单一实例 LOCK.lock(); try &#123; Registry registry = REGISTRIES.get(key); if (registry != null) &#123; return registry; &#125; //这里用的是ZookeeperRegistryFactory //返回的Registry中封装了已经连接到Zookeeper的zkClient实例 registry = createRegistry(url); if (registry == null) &#123; throw new IllegalStateException(&quot;Can not create registry &quot; + url); &#125; //放到缓存中 REGISTRIES.put(key, registry); return registry; &#125; finally &#123; // 释放锁 LOCK.unlock(); &#125;&#125; ZookeeperRegistryFactory的createRegistry方法： 12345public Registry createRegistry(URL url) &#123; //直接返回一个新的ZookeeperRegistry实例 //这里的zookeeperTransporter代码在下面，动态生成的适配类 return new ZookeeperRegistry(url, zookeeperTransporter);&#125; zookeeperTransporter代码： 12345678910111213141516package com.alibaba.dubbo.remoting.zookeeper;import com.alibaba.dubbo.common.extension.ExtensionLoader;public class ZookeeperTransporter$Adpative implements com.alibaba.dubbo.remoting.zookeeper.ZookeeperTransporter &#123; public com.alibaba.dubbo.remoting.zookeeper.ZookeeperClient connect(com.alibaba.dubbo.common.URL arg0) &#123; if (arg0 == null) throw new IllegalArgumentException(&quot;url == null&quot;); com.alibaba.dubbo.common.URL url = arg0; String extName = url.getParameter(&quot;client&quot;, url.getParameter(&quot;transporter&quot;, &quot;zkclient&quot;)); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.remoting.zookeeper.ZookeeperTransporter) name from url(&quot; + url.toString() + &quot;) use keys([client, transporter])&quot;); com.alibaba.dubbo.remoting.zookeeper.ZookeeperTransporter extension = (com.alibaba.dubbo.remoting.zookeeper.ZookeeperTransporter)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.remoting.zookeeper.ZookeeperTransporter.class).getExtension(extName); return extension.connect(arg0); &#125;&#125; 上面代码中可以看到，如果我们没有指定Zookeeper的client属性，默认使用zkClient，所以上面的zookeeperTransporter是ZkclientZookeeperTransporter。 继续看new ZookeeperRegistry(url, zookeeperTransporter);： 123456789101112131415161718192021222324252627282930public ZookeeperRegistry(URL url, ZookeeperTransporter zookeeperTransporter) &#123; //这里会先经过AbstractRegistry的处理，然后经过FailbackRegistry的处理（解释在下面） super(url); if (url.isAnyHost()) &#123; throw new IllegalStateException(&quot;registry address == null&quot;); &#125; //服务分组，默认dubbo String group = url.getParameter(Constants.GROUP_KEY, DEFAULT_ROOT); if (! group.startsWith(Constants.PATH_SEPARATOR)) &#123; group = Constants.PATH_SEPARATOR + group; &#125; //注册中心的节点 this.root = group; //ZkclientZookeeperTransporter的connect方法 //直接返回一个ZkclientZookeeperClient实例 //具体的步骤是，new一个ZkClient实例，然后订阅了一个状态变化的监听器 zkClient = zookeeperTransporter.connect(url); //添加一个状态改变的监听器 zkClient.addStateListener(new StateListener() &#123; public void stateChanged(int state) &#123; if (state == RECONNECTED) &#123; try &#123; recover(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; &#125; &#125; &#125;);&#125; AbstractRegistry的处理： 1234567891011121314151617181920212223public AbstractRegistry(URL url) &#123; //设置registryUrl setUrl(url); // 启动文件保存定时器 syncSaveFile = url.getParameter(Constants.REGISTRY_FILESAVE_SYNC_KEY, false); //会先去用户主目录下的.dubbo目录下加载缓存注册中心的缓存文件比如：dubbo-registry-127.0.0.1.cache String filename = url.getParameter(Constants.FILE_KEY, System.getProperty(&quot;user.home&quot;) + &quot;/.dubbo/dubbo-registry-&quot; + url.getHost() + &quot;.cache&quot;); File file = null; if (ConfigUtils.isNotEmpty(filename)) &#123; file = new File(filename); if(! file.exists() &amp;&amp; file.getParentFile() != null &amp;&amp; ! file.getParentFile().exists())&#123; if(! file.getParentFile().mkdirs())&#123; throw new IllegalArgumentException(&quot;Invalid registry store file &quot; + file + &quot;, cause: Failed to create directory &quot; + file.getParentFile() + &quot;!&quot;); &#125; &#125; &#125; this.file = file; //缓存文件存在的话就把文件读进内存中 loadProperties(); //先获取backup url //然后通知订阅 notify(url.getBackupUrls());&#125; 获取注册中心时的通知方法notify方法： 123456789101112131415161718192021protected void notify(List&lt;URL&gt; urls) &#123; if(urls == null || urls.isEmpty()) return; //getSubscribed()方法获取订阅者列表 for (Map.Entry&lt;URL, Set&lt;NotifyListener&gt;&gt; entry : getSubscribed().entrySet()) &#123; URL url = entry.getKey(); if(! UrlUtils.isMatch(url, urls.get(0))) &#123; continue; &#125; Set&lt;NotifyListener&gt; listeners = entry.getValue(); if (listeners != null) &#123; for (NotifyListener listener : listeners) &#123; try &#123; //通知每个监听器 notify(url, listener, filterEmpty(url, urls)); &#125; catch (Throwable t) &#123; &#125; &#125; &#125; &#125;&#125; notify(url, listener, filterEmpty(url, urls));代码： 12345678910111213141516171819202122232425262728293031protected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; Map&lt;String, List&lt;URL&gt;&gt; result = new HashMap&lt;String, List&lt;URL&gt;&gt;(); for (URL u : urls) &#123; if (UrlUtils.isMatch(url, u)) &#123; //分类 String category = u.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); List&lt;URL&gt; categoryList = result.get(category); if (categoryList == null) &#123; categoryList = new ArrayList&lt;URL&gt;(); result.put(category, categoryList); &#125; categoryList.add(u); &#125; &#125; if (result.size() == 0) &#123; return; &#125; Map&lt;String, List&lt;URL&gt;&gt; categoryNotified = notified.get(url); if (categoryNotified == null) &#123; notified.putIfAbsent(url, new ConcurrentHashMap&lt;String, List&lt;URL&gt;&gt;()); categoryNotified = notified.get(url); &#125; for (Map.Entry&lt;String, List&lt;URL&gt;&gt; entry : result.entrySet()) &#123; String category = entry.getKey(); List&lt;URL&gt; categoryList = entry.getValue(); categoryNotified.put(category, categoryList); saveProperties(url); //通知 listener.notify(categoryList); &#125;&#125; AbstractRegistry构造完，接着是FailbackRegistry的处理： 123456789101112131415public FailbackRegistry(URL url) &#123; super(url); int retryPeriod = url.getParameter(Constants.REGISTRY_RETRY_PERIOD_KEY, Constants.DEFAULT_REGISTRY_RETRY_PERIOD); //启动失败重试定时器 this.retryFuture = retryExecutor.scheduleWithFixedDelay(new Runnable() &#123; public void run() &#123; // 检测并连接注册中心 try &#123; //重试方法由每个具体子类实现 //获取到注册失败的，然后尝试注册 retry(); &#125; catch (Throwable t) &#123; // 防御性容错 &#125; &#125; &#125;, retryPeriod, retryPeriod, TimeUnit.MILLISECONDS);&#125; 这里会启动一个新的定时线程，主要是有连接失败的话，会进行重试连接retry()，启动完之后返回ZookeeperRegistry中继续处理。接下来下一步是服务的引用。 引用远程服务继续看ref方法中最后一步，服务的引用，返回的是一个Invoker，return doRefer(cluster, registry, type, url)； 1234567891011121314151617181920212223242526272829303132333435private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) &#123; //初始化Directory //组装Directory，可以看成一个消费端的List，可以随着注册中心的消息推送而动态的变化服务的Invoker //封装了所有服务真正引用逻辑，覆盖配置，路由规则等逻辑 //初始化时只需要向注册中心发起订阅请求，其他逻辑均是异步处理，包括服务的引用等 //缓存接口所有的提供者端Invoker以及注册中心接口相关的配置等 RegistryDirectory&lt;T&gt; directory = new RegistryDirectory&lt;T&gt;(type, url); directory.setRegistry(registry); directory.setProtocol(protocol); //此处的subscribeUrl为 //consumer://192.168.1.100/dubbo.common.hello.service.HelloService? //application=dubbo-consumer&amp;dubbo=2.5.3&amp; //interface=dubbo.common.hello.service.HelloService&amp; //methods=sayHello&amp;pid=16409&amp; //side=consumer&amp;timeout=100000&amp;timestamp=1489322133987 URL subscribeUrl = new URL(Constants.CONSUMER_PROTOCOL, NetUtils.getLocalHost(), 0, type.getName(), directory.getUrl().getParameters()); if (! Constants.ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) &#123; //到注册中心注册服务 //此处regist是上面一步获得的registry，即是ZookeeperRegistry，包含zkClient的实例 //会先经过AbstractRegistry的处理，然后经过FailbackRegistry的处理（解析在下面） registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY, Constants.CHECK_KEY, String.valueOf(false))); &#125; //订阅服务 //有服务提供的时候，注册中心会推送服务消息给消费者，消费者再进行服务的引用。 directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, Constants.PROVIDERS_CATEGORY + &quot;,&quot; + Constants.CONFIGURATORS_CATEGORY + &quot;,&quot; + Constants.ROUTERS_CATEGORY)); //服务的引用与变更全部由Directory异步完成 //集群策略会将Directory伪装成一个Invoker返回 //合并所有相同的invoker return cluster.join(directory);&#125; 注册中心接收到消费者发送的订阅请求后，会根据提供者注册服务的列表，推送服务消息给消费者。消费者端接收到注册中心发来的提供者列表后，进行服务的引用。触发Directory监听器的可以是订阅请求，覆盖策略消息，路由策略消息。 注册到注册中心AbstractRegistry的register方法： 123456789101112131415public void register(URL url) &#123; //此时url是 //consumer://192.168.1.100/dubbo.common.hello.service.HelloService? //application=dubbo-consumer&amp; //category=consumers&amp;check=false&amp;dubbo=2.5.3&amp; //interface=dubbo.common.hello.service.HelloService&amp;methods=sayHello //&amp;pid=16409&amp;side=consumer&amp;timeout=100000&amp;timestamp=1489322133987 if (url == null) &#123; throw new IllegalArgumentException(&quot;register url == null&quot;); &#125; if (logger.isInfoEnabled())&#123; logger.info(&quot;Register: &quot; + url); &#125; registered.add(url);&#125; 上面只是把url添加到registered这个set中。 接着看FailbackRegistry的register方法： 1234567891011121314151617181920212223242526272829public void register(URL url) &#123; super.register(url); failedRegistered.remove(url); failedUnregistered.remove(url); try &#123; // 向服务器端发送注册请求 //这里调用的是ZookeeperRegistry中的doRegister方法 doRegister(url); &#125; catch (Exception e) &#123; Throwable t = e; // 如果开启了启动时检测，则直接抛出异常 boolean check = getUrl().getParameter(Constants.CHECK_KEY, true) &amp;&amp; url.getParameter(Constants.CHECK_KEY, true) &amp;&amp; ! Constants.CONSUMER_PROTOCOL.equals(url.getProtocol()); boolean skipFailback = t instanceof SkipFailbackWrapperException; if (check || skipFailback) &#123; if(skipFailback) &#123; t = t.getCause(); &#125; throw new IllegalStateException(&quot;Failed to register &quot; + url + &quot; to registry &quot; + getUrl().getAddress() + &quot;, cause: &quot; + t.getMessage(), t); &#125; else &#123; logger.error(&quot;Failed to register &quot; + url + &quot;, waiting for retry, cause: &quot; + t.getMessage(), t); &#125; // 将失败的注册请求记录到失败列表，定时重试 failedRegistered.add(url); &#125;&#125; 接着看下doRegister(url);方法，向服务器端发送注册请求，在ZookeeperRegistry中： 12345678protected void doRegister(URL url) &#123; try &#123; //直接调用create，在AbstractZookeeperClient类中 zkClient.create(toUrlPath(url), url.getParameter(Constants.DYNAMIC_KEY, true)); &#125; catch (Throwable e) &#123; throw new RpcException(&quot;Failed to register &quot; + url + &quot; to zookeeper &quot; + getUrl() + &quot;, cause: &quot; + e.getMessage(), e); &#125;&#125; zkClient.create()方法： 12345678910111213141516171819202122232425262728293031//path为///dubbo/dubbo.common.hello.service.HelloService/consumers///consumer%3A%2F%2F192.168.1.100%2F//dubbo.common.hello.service.HelloService%3Fapplication%3D//dubbo-consumer%26category%3Dconsumers%26check%3Dfalse%26//dubbo%3D2.5.3%26interface%3D//dubbo.common.hello.service.HelloService%26//methods%3DsayHello%26pid%3D28819%26//side%3Dconsumer%26timeout%3D100000%26timestamp%3D1489332839677public void create(String path, boolean ephemeral) &#123; int i = path.lastIndexOf(&apos;/&apos;); if (i &gt; 0) &#123; create(path.substring(0, i), false); &#125; //循环完得到的path为/dubbo //dynamic=false 表示该数据为持久数据，当注册方退出时，数据依然保存在注册中心 if (ephemeral) &#123; //创建临时的节点 createEphemeral(path); &#125; else &#123; //创建持久的节点，/dubbo/dubbo.common.hello.service.HelloService/consumers/ //consumer%3A%2F%2F192.168.110.197%2F //dubbo.common.hello.service.HelloService%3Fapplication%3Ddubbo-consumer%26 //category%3Dconsumers%26check%3Dfalse%26 //dubbo%3D2.5.3%26interface%3D //dubbo.common.hello.service.HelloService%26 //methods%3DsayHello%26pid%3D6370%26side%3D //consumer%26timeout%3D100000%26timestamp%3D1489367959659 createPersistent(path); &#125;&#125; 经过上面create之后，Zookeeper中就存在了消费者需要订阅的服务的节点： 12345678910111213/dubbo /dubbo.common.hello.service.HelloService /consumers /http://0.0.0.0:4550/?path=dubbo%2F dubbo.common.hello.service.HelloService%2F consumers%2Fconsumer%253A%252F%252F192.168.110.197%252F dubbo.common.hello.service.HelloService%253F application%253Ddubbo-consumer%2526category%253D consumers%2526check%253Dfalse%2526 dubbo%253D2.5.3%2526interface%253D dubbo.common.hello.service.HelloService%2526 methods%253DsayHello%2526pid%253D22392%2526side%253D consumer%2526timeout%253D100000%2526timestamp%253D1490063394184 订阅服务提供者消费者自己注册到注册中心之后，接着是订阅服务提供者，directory.subscribe()： 123456public void subscribe(URL url) &#123; //设置消费者url setConsumerUrl(url); //这里的registry是ZookeeperRegistry registry.subscribe(url, this);&#125; 看下registry.subscribe(url, this);，这里registry是ZookeeperRegistry，会先经过AbstractRegistry的处理，然后是FailbackRegistry的处理。 在AbstractRegistry中： 1234567891011121314//此时url为consumer://192.168.1.100/dubbo.common.hello.service.HelloService?application=dubbo-consumer&amp;//category=providers,configurators,routers&amp;dubbo=2.5.3&amp;interface=dubbo.common.hello.service.HelloService&amp;methods=//sayHello&amp;pid=28819&amp;side=consumer&amp;timeout=100000&amp;timestamp=1489332839677public void subscribe(URL url, NotifyListener listener) &#123; //先根据url获取已注册的监听器 Set&lt;NotifyListener&gt; listeners = subscribed.get(url); //没有监听器，就创建，并添加进去 if (listeners == null) &#123; subscribed.putIfAbsent(url, new ConcurrentHashSet&lt;NotifyListener&gt;()); listeners = subscribed.get(url); &#125; //有监听器，直接把当前RegistryDirectory添加进去 listeners.add(listener);&#125; 然后是FailbackRegistry中： 12345678public void subscribe(URL url, NotifyListener listener) &#123; super.subscribe(url, listener); removeFailedSubscribed(url, listener); try &#123; // 向服务器端发送订阅请求 doSubscribe(url, listener); &#125; catch (Exception e) &#123;...&#125;&#125; 继续看doSubscribe(url, listener);向服务端发送订阅请求，在ZookeeperRegistry中： 1234567891011121314151617181920212223242526272829303132333435363738protected void doSubscribe(final URL url, final NotifyListener listener) &#123; try &#123; if (Constants.ANY_VALUE.equals(url.getServiceInterface())) &#123;... &#125; else &#123; List&lt;URL&gt; urls = new ArrayList&lt;URL&gt;(); for (String path : toCategoriesPath(url)) &#123; ConcurrentMap&lt;NotifyListener, ChildListener&gt; listeners = zkListeners.get(url); if (listeners == null) &#123; zkListeners.putIfAbsent(url, new ConcurrentHashMap&lt;NotifyListener, ChildListener&gt;()); listeners = zkListeners.get(url); &#125; //将zkClient的事件IZkChildListener转换到registry事件NotifyListener ChildListener zkListener = listeners.get(listener); if (zkListener == null) &#123; listeners.putIfAbsent(listener, new ChildListener() &#123; public void childChanged(String parentPath, List&lt;String&gt; currentChilds) &#123; ZookeeperRegistry.this.notify(url, listener, toUrlsWithEmpty(url, parentPath, currentChilds)); &#125; &#125;); zkListener = listeners.get(listener); &#125; //创建三个节点 // /dubbo/dubbo.common.hello.service.HelloService/providers/ // /dubbo/dubbo.common.hello.service.HelloService/configurators/ // /dubbo/dubbo.common.hello.service.HelloService/routers/ //上面三个路径会被消费者端监听，当提供者，配置，路由发生变化之后， //注册中心会通知消费者刷新本地缓存。 zkClient.create(path, false); List&lt;String&gt; children = zkClient.addChildListener(path, zkListener); if (children != null) &#123; urls.addAll(toUrlsWithEmpty(url, path, children)); &#125; &#125; notify(url, listener, urls); &#125; &#125; catch (Throwable e) &#123; throw new RpcException(&quot;Failed to subscribe &quot; + url + &quot; to zookeeper &quot; + getUrl() + &quot;, cause: &quot; + e.getMessage(), e); &#125;&#125; 服务订阅完之后的通知服务订阅完成之后，接着就是notify(url, listener, urls);： 会先经过FailbackRegistry将失败的通知请求记录到失败列表，定时重试。 1234567891011121314protected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; try &#123; doNotify(url, listener, urls); &#125; catch (Exception t) &#123; // 将失败的通知请求记录到失败列表，定时重试 Map&lt;NotifyListener, List&lt;URL&gt;&gt; listeners = failedNotified.get(url); if (listeners == null) &#123; failedNotified.putIfAbsent(url, new ConcurrentHashMap&lt;NotifyListener, List&lt;URL&gt;&gt;()); listeners = failedNotified.get(url); &#125; listeners.put(listener, urls); logger.error(&quot;Failed to notify for subscribe &quot; + url + &quot;, waiting for retry, cause: &quot; + t.getMessage(), t); &#125;&#125; doNotify(url, listener, urls);： 1234protected void doNotify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; //父类实现 super.notify(url, listener, urls);&#125; AbstractRegistry中的doNotify实现： 123456789101112131415161718192021222324252627282930313233protected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; Map&lt;String, List&lt;URL&gt;&gt; result = new HashMap&lt;String, List&lt;URL&gt;&gt;(); for (URL u : urls) &#123; if (UrlUtils.isMatch(url, u)) &#123; //不同类型的数据分开通知，providers，consumers，routers，overrides //允许只通知其中一种类型，但该类型的数据必须是全量的，不是增量的。 String category = u.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); List&lt;URL&gt; categoryList = result.get(category); if (categoryList == null) &#123; categoryList = new ArrayList&lt;URL&gt;(); result.put(category, categoryList); &#125; categoryList.add(u); &#125; &#125; if (result.size() == 0) &#123; return; &#125; Map&lt;String, List&lt;URL&gt;&gt; categoryNotified = notified.get(url); if (categoryNotified == null) &#123; notified.putIfAbsent(url, new ConcurrentHashMap&lt;String, List&lt;URL&gt;&gt;()); categoryNotified = notified.get(url); &#125; //对这里得到的providers，configurators，routers分别进行通知 for (Map.Entry&lt;String, List&lt;URL&gt;&gt; entry : result.entrySet()) &#123; String category = entry.getKey(); List&lt;URL&gt; categoryList = entry.getValue(); categoryNotified.put(category, categoryList); saveProperties(url); //这里的listener是RegistryDirectory listener.notify(categoryList); &#125;&#125; 到RegistryDirectory中查看notify方法： 123456789101112131415161718192021222324252627282930313233343536373839404142public synchronized void notify(List&lt;URL&gt; urls) &#123; List&lt;URL&gt; invokerUrls = new ArrayList&lt;URL&gt;(); List&lt;URL&gt; routerUrls = new ArrayList&lt;URL&gt;(); List&lt;URL&gt; configuratorUrls = new ArrayList&lt;URL&gt;(); for (URL url : urls) &#123; String protocol = url.getProtocol(); String category = url.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); if (Constants.ROUTERS_CATEGORY.equals(category) || Constants.ROUTE_PROTOCOL.equals(protocol)) &#123; routerUrls.add(url); &#125; else if (Constants.CONFIGURATORS_CATEGORY.equals(category) || Constants.OVERRIDE_PROTOCOL.equals(protocol)) &#123; configuratorUrls.add(url); &#125; else if (Constants.PROVIDERS_CATEGORY.equals(category)) &#123; invokerUrls.add(url); &#125; else &#123; logger.warn(&quot;Unsupported category &quot; + category + &quot; in notified url: &quot; + url + &quot; from registry &quot; + getUrl().getAddress() + &quot; to consumer &quot; + NetUtils.getLocalHost()); &#125; &#125; // configurators 更新缓存的服务提供方配置 if (configuratorUrls != null &amp;&amp; configuratorUrls.size() &gt;0 )&#123; this.configurators = toConfigurators(configuratorUrls); &#125; // routers//更新缓存的路由规则配置 if (routerUrls != null &amp;&amp; routerUrls.size() &gt;0 )&#123; List&lt;Router&gt; routers = toRouters(routerUrls); if(routers != null)&#123; // null - do nothing setRouters(routers); &#125; &#125; List&lt;Configurator&gt; localConfigurators = this.configurators; // local reference // 合并override参数 this.overrideDirectoryUrl = directoryUrl; if (localConfigurators != null &amp;&amp; localConfigurators.size() &gt; 0) &#123; for (Configurator configurator : localConfigurators) &#123; this.overrideDirectoryUrl = configurator.configure(overrideDirectoryUrl); &#125; &#125; // providers //重建invoker实例 refreshInvoker(invokerUrls);&#125; 重建invoker实例refreshInvoker(invokerUrls);： 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 根据invokerURL列表转换为invoker列表。转换规则如下： * 1.如果url已经被转换为invoker，则不在重新引用，直接从缓存中获取，注意如果url中任何一个参数变更也会重新引用 * 2.如果传入的invoker列表不为空，则表示最新的invoker列表 * 3.如果传入的invokerUrl列表是空，则表示只是下发的override规则或route规则，需要重新交叉对比，决定是否需要重新引用。 * @param invokerUrls 传入的参数不能为null */private void refreshInvoker(List&lt;URL&gt; invokerUrls)&#123; if (invokerUrls != null &amp;&amp; invokerUrls.size() == 1 &amp;&amp; invokerUrls.get(0) != null &amp;&amp; Constants.EMPTY_PROTOCOL.equals(invokerUrls.get(0).getProtocol())) &#123; this.forbidden = true; // 禁止访问 this.methodInvokerMap = null; // 置空列表 destroyAllInvokers(); // 关闭所有Invoker &#125; else &#123; this.forbidden = false; // 允许访问 Map&lt;String, Invoker&lt;T&gt;&gt; oldUrlInvokerMap = this.urlInvokerMap; // local reference if (invokerUrls.size() == 0 &amp;&amp; this.cachedInvokerUrls != null)&#123; invokerUrls.addAll(this.cachedInvokerUrls); &#125; else &#123; this.cachedInvokerUrls = new HashSet&lt;URL&gt;(); this.cachedInvokerUrls.addAll(invokerUrls);//缓存invokerUrls列表，便于交叉对比 &#125; if (invokerUrls.size() ==0 )&#123; return; &#125; //会重新走一遍服务的引用过程 //给每个提供者创建一个Invoker Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap = toInvokers(invokerUrls) ;// 将URL列表转成Invoker列表 Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; newMethodInvokerMap = toMethodInvokers(newUrlInvokerMap); // 换方法名映射Invoker列表 // state change //如果计算错误，则不进行处理. if (newUrlInvokerMap == null || newUrlInvokerMap.size() == 0 )&#123; logger.error(new IllegalStateException(&quot;urls to invokers error .invokerUrls.size :&quot;+invokerUrls.size() + &quot;, invoker.size :0. urls :&quot;+invokerUrls.toString())); return ; &#125; //服务提供者Invoker保存在这个map中 this.methodInvokerMap = multiGroup ? toMergeMethodInvokerMap(newMethodInvokerMap) : newMethodInvokerMap; this.urlInvokerMap = newUrlInvokerMap; try&#123; destroyUnusedInvokers(oldUrlInvokerMap,newUrlInvokerMap); // 关闭未使用的Invoker &#125;catch (Exception e) &#123; logger.warn(&quot;destroyUnusedInvokers error. &quot;, e); &#125; &#125;&#125; toInvokers(invokerUrls) 方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970private Map&lt;String, Invoker&lt;T&gt;&gt; toInvokers(List&lt;URL&gt; urls) &#123; Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap = new HashMap&lt;String, Invoker&lt;T&gt;&gt;(); if(urls == null || urls.size() == 0)&#123; return newUrlInvokerMap; &#125; Set&lt;String&gt; keys = new HashSet&lt;String&gt;(); String queryProtocols = this.queryMap.get(Constants.PROTOCOL_KEY); for (URL providerUrl : urls) &#123; //此时url是dubbo://192.168.110.197:20880/dubbo.common.hello.service.HelloService?anyhost=true&amp; //application=dubbo-provider&amp;application.version=1.0&amp;dubbo=2.5.3&amp;environment=product&amp; //interface=dubbo.common.hello.service.HelloService&amp;methods=sayHello&amp;organization=china&amp; //owner=cheng.xi&amp;pid=5631&amp;side=provider&amp;timestamp=1489367571986 //从注册中心获取到的携带提供者信息的url //如果reference端配置了protocol，则只选择匹配的protocol if (queryProtocols != null &amp;&amp; queryProtocols.length() &gt;0) &#123; boolean accept = false; String[] acceptProtocols = queryProtocols.split(&quot;,&quot;); for (String acceptProtocol : acceptProtocols) &#123; if (providerUrl.getProtocol().equals(acceptProtocol)) &#123; accept = true; break; &#125; &#125; if (!accept) &#123; continue; &#125; &#125; if (Constants.EMPTY_PROTOCOL.equals(providerUrl.getProtocol())) &#123; continue; &#125; if (! ExtensionLoader.getExtensionLoader(Protocol.class).hasExtension(providerUrl.getProtocol())) &#123; logger.error(new IllegalStateException(&quot;Unsupported protocol &quot; + providerUrl.getProtocol() + &quot; in notified url: &quot; + providerUrl + &quot; from registry &quot; + getUrl().getAddress() + &quot; to consumer &quot; + NetUtils.getLocalHost() + &quot;, supported protocol: &quot;+ExtensionLoader.getExtensionLoader(Protocol.class).getSupportedExtensions())); continue; &#125; URL url = mergeUrl(providerUrl); String key = url.toFullString(); // URL参数是排序的 if (keys.contains(key)) &#123; // 重复URL continue; &#125; keys.add(key); // 缓存key为没有合并消费端参数的URL，不管消费端如何合并参数，如果服务端URL发生变化，则重新refer Map&lt;String, Invoker&lt;T&gt;&gt; localUrlInvokerMap = this.urlInvokerMap; // local reference Invoker&lt;T&gt; invoker = localUrlInvokerMap == null ? null : localUrlInvokerMap.get(key); if (invoker == null) &#123; // 缓存中没有，重新refer try &#123; boolean enabled = true; if (url.hasParameter(Constants.DISABLED_KEY)) &#123; enabled = ! url.getParameter(Constants.DISABLED_KEY, false); &#125; else &#123; enabled = url.getParameter(Constants.ENABLED_KEY, true); &#125; if (enabled) &#123; //根据扩展点加载机制，这里使用的protocol是DubboProtocol invoker = new InvokerDelegete&lt;T&gt;(protocol.refer(serviceType, url), url, providerUrl); &#125; &#125; catch (Throwable t) &#123; logger.error(&quot;Failed to refer invoker for interface:&quot;+serviceType+&quot;,url:(&quot;+url+&quot;)&quot; + t.getMessage(), t); &#125; if (invoker != null) &#123; // 将新的引用放入缓存 newUrlInvokerMap.put(key, invoker); &#125; &#125;else &#123; newUrlInvokerMap.put(key, invoker); &#125; &#125; keys.clear(); return newUrlInvokerMap;&#125; 创建invoker invoker = new InvokerDelegete&lt;T&gt;(protocol.refer(serviceType, url), url, providerUrl);： 先使用DubboProtocol的refer方法，这一步会依次调用ProtocolFIlterListenerWrapper，ProtocolFilterWrapper，DubboProtocol中的refer方法。经过两个Wrapper中，会添加对应的InvokerListener并构建Invoker Filter链，在DubboProtocol中会创建一个DubboInvoker对象，该Invoker对象持有服务Class，providerUrl，负责和服务提供端通信的ExchangeClient。 接着使用得到的Invoker创建一个InvokerDelegete 创建invoker在DubboProtocol中创建DubboInvoker的时候代码如下： 1234567public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; serviceType, URL url) throws RpcException &#123; // create rpc invoker. //这里有一个getClients方法 DubboInvoker&lt;T&gt; invoker = new DubboInvoker&lt;T&gt;(serviceType, url, getClients(url), invokers); invokers.add(invoker); return invoker;&#125; 查看getClients方法： 12345678910111213141516171819202122private ExchangeClient[] getClients(URL url)&#123; //是否共享连接 boolean service_share_connect = false; int connections = url.getParameter(Constants.CONNECTIONS_KEY, 0); //如果connections不配置，则共享连接，否则每服务每连接 if (connections == 0)&#123; service_share_connect = true; connections = 1; &#125; ExchangeClient[] clients = new ExchangeClient[connections]; for (int i = 0; i &lt; clients.length; i++) &#123; if (service_share_connect)&#123; //这里没有配置connections，就使用getSharedClient //getSharedClient中先去缓存中查找，没有的话就会新建，也是调用initClient方法 clients[i] = getSharedClient(url); &#125; else &#123; clients[i] = initClient(url); &#125; &#125; return clients;&#125; 直接看initClient方法： 12345678910111213141516171819202122232425262728293031323334//创建新连接private ExchangeClient initClient(URL url) &#123; // client type setting. String str = url.getParameter(Constants.CLIENT_KEY, url.getParameter(Constants.SERVER_KEY, Constants.DEFAULT_REMOTING_CLIENT)); String version = url.getParameter(Constants.DUBBO_VERSION_KEY); boolean compatible = (version != null &amp;&amp; version.startsWith(&quot;1.0.&quot;)); url = url.addParameter(Constants.CODEC_KEY, Version.isCompatibleVersion() &amp;&amp; compatible ? COMPATIBLE_CODEC_NAME : DubboCodec.NAME); //默认开启heartbeat url = url.addParameterIfAbsent(Constants.HEARTBEAT_KEY, String.valueOf(Constants.DEFAULT_HEARTBEAT)); // BIO存在严重性能问题，暂时不允许使用 if (str != null &amp;&amp; str.length() &gt; 0 &amp;&amp; ! ExtensionLoader.getExtensionLoader(Transporter.class).hasExtension(str)) &#123; throw new RpcException(&quot;Unsupported client type: &quot; + str + &quot;,&quot; + &quot; supported client type is &quot; + StringUtils.join(ExtensionLoader.getExtensionLoader(Transporter.class).getSupportedExtensions(), &quot; &quot;)); &#125; ExchangeClient client ; try &#123; //如果lazy属性没有配置为true（我们没有配置，默认为false）ExchangeClient会马上和服务端建立连接 //设置连接应该是lazy的 if (url.getParameter(Constants.LAZY_CONNECT_KEY, false))&#123; client = new LazyConnectExchangeClient(url ,requestHandler); &#125; else &#123; //立即和服务端建立连接 client = Exchangers.connect(url ,requestHandler); &#125; &#125; catch (RemotingException e) &#123; throw new RpcException(&quot;Fail to create remoting client for service(&quot; + url + &quot;): &quot; + e.getMessage(), e); &#125; return client;&#125; 和服务端建立连接，Exchangers.connect(url ,requestHandler);，其实最后使用的是HeaderExchanger，Exchanger目前只有这一个实现： 1234567public ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException &#123; //先经过HeaderExchangeHandler包装 //然后是DecodeHandler //然后是Transporters.connect //返回一个HeaderExchangerClient，这里封装了client，channel，启动心跳的定时器等 return new HeaderExchangeClient(Transporters.connect(url, new DecodeHandler(new HeaderExchangeHandler(handler))));&#125; Transporters.connect中也是根据SPI扩展获取Transport的具体实现，这里默认使用NettyTransporter.connect()，在NettyTransporter的connect方法中直接返回一个NettyClient(url, listener);，下面看下具体的NettyClient初始化细节，会先初始化AbstractPeer这里只是吧url和handler赋值；然后是AbstractEndpoint初始化： 1234567public AbstractEndpoint(URL url, ChannelHandler handler) &#123; super(url, handler); //获取编解码器，这里是DubboCountCodec this.codec = getChannelCodec(url); this.timeout = url.getPositiveParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); this.connectTimeout = url.getPositiveParameter(Constants.CONNECT_TIMEOUT_KEY, Constants.DEFAULT_CONNECT_TIMEOUT);&#125; 接着是AbstractClient的初始化： 123456789101112131415161718192021public AbstractClient(URL url, ChannelHandler handler) throws RemotingException &#123; super(url, handler); send_reconnect = url.getParameter(Constants.SEND_RECONNECT_KEY, false); shutdown_timeout = url.getParameter(Constants.SHUTDOWN_TIMEOUT_KEY, Constants.DEFAULT_SHUTDOWN_TIMEOUT); //默认重连间隔2s，1800表示1小时warning一次. reconnect_warning_period = url.getParameter(&quot;reconnect.waring.period&quot;, 1800); try &#123; //具体实现在子类中 doOpen(); &#125; catch (Throwable t) &#123;。。。 &#125; try &#123; // 连接 connect(); &#125; catch (RemotingException t) &#123;。。。&#125; // TODO暂没理解 executor = (ExecutorService) ExtensionLoader.getExtensionLoader(DataStore.class) .getDefaultExtension().get(Constants.CONSUMER_SIDE, Integer.toString(url.getPort())); ExtensionLoader.getExtensionLoader(DataStore.class) .getDefaultExtension().remove(Constants.CONSUMER_SIDE, Integer.toString(url.getPort()));&#125; 看下在NettyClient中doOpen()的实现： 1234567891011121314151617181920protected void doOpen() throws Throwable &#123; NettyHelper.setNettyLoggerFactory(); bootstrap = new ClientBootstrap(channelFactory); // config // @see org.jboss.netty.channel.socket.SocketChannelConfig bootstrap.setOption(&quot;keepAlive&quot;, true); bootstrap.setOption(&quot;tcpNoDelay&quot;, true); bootstrap.setOption(&quot;connectTimeoutMillis&quot;, getTimeout()); final NettyHandler nettyHandler = new NettyHandler(getUrl(), this); bootstrap.setPipelineFactory(new ChannelPipelineFactory() &#123; public ChannelPipeline getPipeline() &#123; NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec(), getUrl(), NettyClient.this); ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(&quot;decoder&quot;, adapter.getDecoder()); pipeline.addLast(&quot;encoder&quot;, adapter.getEncoder()); pipeline.addLast(&quot;handler&quot;, nettyHandler); return pipeline; &#125; &#125;);&#125; 这里是Netty3中的客户端连接的一些常规步骤，暂不做具体解析。open之后，就是真正连接服务端的操作了，connect()： 12345678910111213141516protected void connect() throws RemotingException &#123; connectLock.lock(); try &#123; if (isConnected()) &#123; return; &#125; //初始化重连的线程 initConnectStatusCheckCommand(); //连接，在子类中实现 doConnect(); reconnect_count.set(0); reconnect_error_log_flag.set(false); &#125; catch (RemotingException e) &#123;。。。&#125; finally &#123; connectLock.unlock(); &#125;&#125; NettyClient中的doConnect方法： 1234567891011121314151617181920212223242526272829303132333435363738protected void doConnect() throws Throwable &#123; long start = System.currentTimeMillis(); //消费者端开始连接，这一步的时候，服务提供者端就接到了连接请求，开始处理了 ChannelFuture future = bootstrap.connect(getConnectAddress()); try&#123; boolean ret = future.awaitUninterruptibly(getConnectTimeout(), TimeUnit.MILLISECONDS); if (ret &amp;&amp; future.isSuccess()) &#123; Channel newChannel = future.getChannel(); newChannel.setInterestOps(Channel.OP_READ_WRITE); try &#123; // 关闭旧的连接 Channel oldChannel = NettyClient.this.channel; // copy reference if (oldChannel != null) &#123; try &#123; oldChannel.close(); &#125; finally &#123; NettyChannel.removeChannelIfDisconnected(oldChannel); &#125; &#125; &#125; finally &#123; if (NettyClient.this.isClosed()) &#123; try &#123; newChannel.close(); &#125; finally &#123; NettyClient.this.channel = null; NettyChannel.removeChannelIfDisconnected(newChannel); &#125; &#125; else &#123; NettyClient.this.channel = newChannel; &#125; &#125; &#125; else if (future.getCause() != null) &#123; throw。。。 &#125; else &#123;throw 。。。 &#125; &#125;finally&#123; if (! isConnected()) &#123; future.cancel(); &#125; &#125;&#125; 这里连接的细节都交给了netty。 NettyClient初始化完成之后，返回给Transporters，再返回给HeaderExchanger，HeaderExchanger中将NettyClient包装成HeaderExchangeClient返回给DubboProtocol的initClient方法中，到此在getSharedClient中就获取到了一个ExchangeClient，然后包装一下返回client = new ReferenceCountExchangeClient(exchagneclient, ghostClientMap);。 到这里在DubboProtocol的refer方法中这句DubboInvoker&lt;T&gt; invoker = new DubboInvoker&lt;T&gt;(serviceType, url, getClients(url), invokers);创建DubboInvoker就已经解析完成，创建过程中连接了服务端，包含一个ExchangeClient等： 12345678public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; serviceType, URL url) throws RpcException &#123; // create rpc invoker. DubboInvoker&lt;T&gt; invoker = new DubboInvoker&lt;T&gt;(serviceType, url, getClients(url), invokers); //将invoker缓存 invokers.add(invoker); //返回invoker return invoker;&#125; 接着返回ProtocolFilterWrapper的refer方法，在这里会构建invoker链： 123456public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; return protocol.refer(type, url); &#125; return buildInvokerChain(protocol.refer(type, url), Constants.REFERENCE_FILTER_KEY, Constants.CONSUMER);&#125; 接着再返回到ProtocolListenerWrapper的refer方法，这里会初始化监听器，包装： 123456789public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; return protocol.refer(type, url); &#125; return new ListenerInvokerWrapper&lt;T&gt;(protocol.refer(type, url), Collections.unmodifiableList( ExtensionLoader.getExtensionLoader(InvokerListener.class) .getActivateExtension(url, Constants.INVOKER_LISTENER_KEY)));&#125; 接着在返回到toInvokers方法，然后返回refreshInvoker方法的Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap = toInvokers(invokerUrls) ;这就获得了Invoker，接着就是方法名映射Invoker列表：Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; newMethodInvokerMap = toMethodInvokers(newUrlInvokerMap);这里将invokers列表转成与方法的映射关系。到这里refreshInvoker方法就完成了，在往上就返回到AbstractRegistry的notify方法，到这里也完成了。 创建服务代理到这里有关消费者端注册到注册中心和订阅注册中心就完事儿了，这部分是在RegistryProtocol.doRefer方法中，这个方法最后一句是return cluster.join(directory);，这里由Cluster组件创建一个Invoker并返回，这里的cluster默认是用FailoverCluster，最后返回的是经过MockClusterInvoker包装过的FailoverCluster。继续返回到ReferenceConfig中createProxy方法，这时候我们已经完成了消费者端引用服务的Invoker。然后最后返回的是根据我们得到的invoker创建的服务代理return (T) proxyFactory.getProxy(invoker);。这里proxyFactory是我们在最上面列出的动态生成的代码。 首先经过AbstractProxyFactory的处理： 1234567891011121314151617181920public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker) throws RpcException &#123; Class&lt;?&gt;[] interfaces = null; String config = invoker.getUrl().getParameter(&quot;interfaces&quot;); if (config != null &amp;&amp; config.length() &gt; 0) &#123; String[] types = Constants.COMMA_SPLIT_PATTERN.split(config); if (types != null &amp;&amp; types.length &gt; 0) &#123; interfaces = new Class&lt;?&gt;[types.length + 2]; interfaces[0] = invoker.getInterface(); interfaces[1] = EchoService.class; for (int i = 0; i &lt; types.length; i ++) &#123; interfaces[i + 1] = ReflectUtils.forName(types[i]); &#125; &#125; &#125; if (interfaces == null) &#123; interfaces = new Class&lt;?&gt;[] &#123;invoker.getInterface(), EchoService.class&#125;; &#125; //这里默认使用的是JavassistProxyFactory的实现 return getProxy(invoker, interfaces);&#125; 然后经过StubProxyFactoryWrapper的处理： 12345678910111213141516171819202122232425262728293031323334353637383940414243public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker) throws RpcException &#123; T proxy = proxyFactory.getProxy(invoker); if (GenericService.class != invoker.getInterface()) &#123; String stub = invoker.getUrl().getParameter(Constants.STUB_KEY, invoker.getUrl().getParameter(Constants.LOCAL_KEY)); if (ConfigUtils.isNotEmpty(stub)) &#123; Class&lt;?&gt; serviceType = invoker.getInterface(); if (ConfigUtils.isDefault(stub)) &#123; if (invoker.getUrl().hasParameter(Constants.STUB_KEY)) &#123; stub = serviceType.getName() + &quot;Stub&quot;; &#125; else &#123; stub = serviceType.getName() + &quot;Local&quot;; &#125; &#125; try &#123; Class&lt;?&gt; stubClass = ReflectUtils.forName(stub); if (! serviceType.isAssignableFrom(stubClass)) &#123; throw new IllegalStateException(&quot;The stub implemention class &quot; + stubClass.getName() + &quot; not implement interface &quot; + serviceType.getName()); &#125; try &#123; Constructor&lt;?&gt; constructor = ReflectUtils.findConstructor(stubClass, serviceType); proxy = (T) constructor.newInstance(new Object[] &#123;proxy&#125;); //export stub service URL url = invoker.getUrl(); if (url.getParameter(Constants.STUB_EVENT_KEY, Constants.DEFAULT_STUB_EVENT))&#123; url = url.addParameter(Constants.STUB_EVENT_METHODS_KEY, StringUtils.join(Wrapper.getWrapper(proxy.getClass()).getDeclaredMethodNames(), &quot;,&quot;)); url = url.addParameter(Constants.IS_SERVER_KEY, Boolean.FALSE.toString()); try&#123; export(proxy, (Class)invoker.getInterface(), url); &#125;catch (Exception e) &#123; LOGGER.error(&quot;export a stub service error.&quot;, e); &#125; &#125; &#125; catch (NoSuchMethodException e) &#123; throw new IllegalStateException(&quot;No such constructor \&quot;public &quot; + stubClass.getSimpleName() + &quot;(&quot; + serviceType.getName() + &quot;)\&quot; in stub implemention class &quot; + stubClass.getName(), e); &#125; &#125; catch (Throwable t) &#123; LOGGER.error(&quot;Failed to create stub implemention class &quot; + stub + &quot; in consumer &quot; + NetUtils.getLocalHost() + &quot; use dubbo version &quot; + Version.getVersion() + &quot;, cause: &quot; + t.getMessage(), t); // ignore &#125; &#125; &#125; return proxy;&#125; 返回代理。到此HelloService helloService = (HelloService) applicationContext.getBean(&quot;helloService&quot;);就解析完成了，得到了服务的代理，代理会被注册到Spring容器中，可以调用服务方法了。接下来的方法调用过程，是消费者发送请求，提供者处理，然后消费者接受处理结果的请求。 初始化的过程：主要做了注册到注册中心，监听注册中心，连接到服务提供者端，创建代理。这些都是为了下面消费者和提供者之间的通信做准备。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo中编码和解码的解析]]></title>
      <url>%2F2017%2F03%2F19%2FDubbo%E4%B8%AD%E7%BC%96%E7%A0%81%E5%92%8C%E8%A7%A3%E7%A0%81%E7%9A%84%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[（这里做的解析不是很详细，等到走完整个流程再来解析）Dubbo中编解码的工作由Codec2接口的实现来处理，回想一下第一次接触到Codec2相关的内容是在服务端暴露服务的时候，根据具体的协议去暴露服务的步骤中，在DubboProtocol的createServer方法中： 1234567891011private ExchangeServer createServer(URL url) &#123; 。。。 //这里url会添加codec=dubbo url = url.addParameter(Constants.CODEC_KEY, Version.isCompatibleVersion() ? COMPATIBLE_CODEC_NAME : DubboCodec.NAME); ExchangeServer server; try &#123; server = Exchangers.bind(url, requestHandler); &#125; 。。。 return server;&#125; 紧接着进入Exchangers.bind(url, requestHandler);： 12345public static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; //如果url中没有codec属性，就会添加codec=exchange url = url.addParameterIfAbsent(Constants.CODEC_KEY, &quot;exchange&quot;); return getExchanger(url).bind(url, handler);&#125; 然后会继续进入HeaderExchanger的bind方法： 123public ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))));&#125; 在这里会创建一个DecodeHandler实例。继续跟踪Transporters的bind方法，会发现直接返回一个NettyServer实例，在NettyServer的父类AbstractEndpoint构造方法初始的时候，会根据url获取一个ChannelCodec，并将其赋值给codec存放到NettyServer的实例中。 我们先看下getChannelCodec(url);方法： 1234567891011121314protected static Codec2 getChannelCodec(URL url) &#123; //获取codecName，不存在的话，默认为telnet String codecName = url.getParameter(Constants.CODEC_KEY, &quot;telnet&quot;); //先看下是不是Codec2的实现，是的话就根据SPI扩展机制获得Codec2扩展的实现 //我们这里默认使用的是DubboCountCodec if (ExtensionLoader.getExtensionLoader(Codec2.class).hasExtension(codecName)) &#123; return ExtensionLoader.getExtensionLoader(Codec2.class).getExtension(codecName); &#125; else &#123; //如果不是Codec2的实现，就去查找Codec的实现 //然后使用CodecAdapter适配器类来转换成Codec2 return new CodecAdapter(ExtensionLoader.getExtensionLoader(Codec.class) .getExtension(codecName)); &#125;&#125; 这里返回的是Codec2，而Codec这个接口已经被标记为过时。到这里的话，在NettyServer中就会存在一个Codec2的实例了。 在继续往下看到NettyServer中的doOpen()方法，这里是使用Netty的逻辑打开服务并绑定监听服务的地方： 123456789101112131415161718192021222324protected void doOpen() throws Throwable &#123; NettyHelper.setNettyLoggerFactory(); ExecutorService boss = Executors.newCachedThreadPool(new NamedThreadFactory(&quot;NettyServerBoss&quot;, true)); ExecutorService worker = Executors.newCachedThreadPool(new NamedThreadFactory(&quot;NettyServerWorker&quot;, true)); ChannelFactory channelFactory = new NioServerSocketChannelFactory(boss, worker, getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS)); bootstrap = new ServerBootstrap(channelFactory); final NettyHandler nettyHandler = new NettyHandler(getUrl(), this); channels = nettyHandler.getChannels(); bootstrap.setPipelineFactory(new ChannelPipelineFactory() &#123; public ChannelPipeline getPipeline() &#123; //这里的getCodec方法获取到的codec就是在AbstractEndpoint中我们获取到的codec //NettyCodecAdapter，适配器类 NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec() ,getUrl(), NettyServer.this); ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(&quot;decoder&quot;, adapter.getDecoder());//SimpleChannelUpstreamHandler pipeline.addLast(&quot;encoder&quot;, adapter.getEncoder());//OneToOneEncoder pipeline.addLast(&quot;handler&quot;, nettyHandler); return pipeline; &#125; &#125;); // bind channel = bootstrap.bind(getBindAddress());&#125; 这里就在Netty的pipeline中添加了编解码器。这里涉及到Netty的相关流程，可以先了解下Netty3服务端流程简介。 decoder为解码器，是一个SimpleChannelUpstreamHandler，从Socket到Netty中的时候，需要解码，也就是服务提供端接收到消费者的请求的时候，需要解码。 encoder是编码器，是OneToOneEncoder，这个类实现了ChannelDownstreamHandler，从服务提供端发送给服务消费者的时候，需要编码。 nettyHandler实现了ChannelUpstreamHandler, ChannelDownstreamHandler两个，上下的时候都需要处理。 接收到服务消费者的请求的时候，会先执行decoder，然后执行nettyHandler。 发送给消费者的时候，会先执行nettyHandler，然后执行encoder。 dubbo协议头 协议头是16字节的定长数据： 2字节short类型的Magic 1字节的消息标志位 5位序列化id 1位心跳还是正常请求 1位双向还是单向 1位请求还是响应 1字节的状态位 8字节的消息id 4字节数据长度 编码的过程首先会判断是请求还是响应，代码在ExchangeCodec的encode方法： 123456789public void encode(Channel channel, ChannelBuffer buffer, Object msg) throws IOException &#123; if (msg instanceof Request) &#123;//Request类型 encodeRequest(channel, buffer, (Request) msg); &#125; else if (msg instanceof Response) &#123;//Response类型 encodeResponse(channel, buffer, (Response) msg); &#125; else &#123;//telenet类型的 super.encode(channel, buffer, msg); &#125;&#125; 服务提供者对响应信息编码在服务提供者端一般是对响应来做编码，所以这里重点看下encodeResponse。 encodeResponse： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081protected void encodeResponse(Channel channel, ChannelBuffer buffer, Response res) throws IOException &#123; try &#123; //序列化方式 //也是根据SPI扩展来获取，url中没指定的话默认使用hessian2 Serialization serialization = getSerialization(channel); //长度为16字节的数组，协议头 byte[] header = new byte[HEADER_LENGTH]; //魔数0xdabb Bytes.short2bytes(MAGIC, header); //序列化方式 header[2] = serialization.getContentTypeId(); //心跳消息还是正常消息 if (res.isHeartbeat()) header[2] |= FLAG_EVENT; //响应状态 byte status = res.getStatus(); header[3] = status; //设置请求id Bytes.long2bytes(res.getId(), header, 4); //buffer为1024字节的ChannelBuffer //获取buffer的写入位置 int savedWriteIndex = buffer.writerIndex(); //需要再加上协议头的长度之后，才是正确的写入位置 buffer.writerIndex(savedWriteIndex + HEADER_LENGTH); ChannelBufferOutputStream bos = new ChannelBufferOutputStream(buffer); ObjectOutput out = serialization.serialize(channel.getUrl(), bos); // 对响应信息或者错误消息进行编码 if (status == Response.OK) &#123; if (res.isHeartbeat()) &#123; //心跳 encodeHeartbeatData(channel, out, res.getResult()); &#125; else &#123; //正常响应 encodeResponseData(channel, out, res.getResult()); &#125; &#125; //错误消息 else out.writeUTF(res.getErrorMessage()); out.flushBuffer(); bos.flush(); bos.close(); //写出去的消息的长度 int len = bos.writtenBytes(); //查看消息长度是否过长 checkPayload(channel, len); Bytes.int2bytes(len, header, 12); //重置写入的位置 buffer.writerIndex(savedWriteIndex); //向buffer中写入消息头 buffer.writeBytes(header); // write header. //buffer写出去的位置从writerIndex开始，加上header长度，加上数据长度 buffer.writerIndex(savedWriteIndex + HEADER_LENGTH + len); &#125; catch (Throwable t) &#123; // 发送失败信息给Consumer，否则Consumer只能等超时了 if (! res.isEvent() &amp;&amp; res.getStatus() != Response.BAD_RESPONSE) &#123; try &#123; // FIXME 在Codec中打印出错日志？在IoHanndler的caught中统一处理？ logger.warn(&quot;Fail to encode response: &quot; + res + &quot;, send bad_response info instead, cause: &quot; + t.getMessage(), t); Response r = new Response(res.getId(), res.getVersion()); r.setStatus(Response.BAD_RESPONSE); r.setErrorMessage(&quot;Failed to send response: &quot; + res + &quot;, cause: &quot; + StringUtils.toString(t)); channel.send(r); return; &#125; catch (RemotingException e) &#123; logger.warn(&quot;Failed to send bad_response info back: &quot; + res + &quot;, cause: &quot; + e.getMessage(), e); &#125; &#125; // 重新抛出收到的异常 if (t instanceof IOException) &#123; throw (IOException) t; &#125; else if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else if (t instanceof Error) &#123; throw (Error) t; &#125; else &#123; throw new RuntimeException(t.getMessage(), t); &#125; &#125;&#125; 服务消费者对请求信息编码消费者端暂先不做解析 解码的过程服务提供者对请求消息的解码decode方法一次只会解析一个完整的dubbo协议包，但是每次收到的协议包不一定是完整的，或者有可能是多个协议包。看下代码解析，首先看NettyCodecAdapter的内部类InternalDecoder的messageReceived方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public void messageReceived(ChannelHandlerContext ctx, MessageEvent event) throws Exception &#123; Object o = event.getMessage(); if (! (o instanceof ChannelBuffer)) &#123; ctx.sendUpstream(event); return; &#125; ChannelBuffer input = (ChannelBuffer) o; int readable = input.readableBytes(); if (readable &lt;= 0) &#123; return; &#125; com.alibaba.dubbo.remoting.buffer.ChannelBuffer message; if (buffer.readable()) &#123; if (buffer instanceof DynamicChannelBuffer) &#123; buffer.writeBytes(input.toByteBuffer()); message = buffer; &#125; else &#123; int size = buffer.readableBytes() + input.readableBytes(); message = com.alibaba.dubbo.remoting.buffer.ChannelBuffers.dynamicBuffer( size &gt; bufferSize ? size : bufferSize); message.writeBytes(buffer, buffer.readableBytes()); message.writeBytes(input.toByteBuffer()); &#125; &#125; else &#123; message = com.alibaba.dubbo.remoting.buffer.ChannelBuffers.wrappedBuffer( input.toByteBuffer()); &#125; NettyChannel channel = NettyChannel.getOrAddChannel(ctx.getChannel(), url, handler); Object msg; //读索引 int saveReaderIndex; try &#123; do &#123; saveReaderIndex = message.readerIndex(); try &#123; //解码 msg = codec.decode(channel, message); &#125; catch (IOException e) &#123; buffer = com.alibaba.dubbo.remoting.buffer.ChannelBuffers.EMPTY_BUFFER; throw e; &#125; //不完整的协议包 if (msg == Codec2.DecodeResult.NEED_MORE_INPUT) &#123; //重置读索引 message.readerIndex(saveReaderIndex); //跳出循环，之后在finally中把message赋值给buffer保存起来，等到下次接收到数据包的时候会追加到buffer的后面 break; &#125; else &#123;//有多个协议包，触发messageReceived事件 if (saveReaderIndex == message.readerIndex()) &#123; buffer = com.alibaba.dubbo.remoting.buffer.ChannelBuffers.EMPTY_BUFFER; throw new IOException(&quot;Decode without read data.&quot;); &#125; if (msg != null) &#123; Channels.fireMessageReceived(ctx, msg, event.getRemoteAddress()); &#125; &#125; &#125; while (message.readable()); &#125; finally &#123; if (message.readable()) &#123; message.discardReadBytes(); buffer = message; &#125; else &#123; buffer = com.alibaba.dubbo.remoting.buffer.ChannelBuffers.EMPTY_BUFFER; &#125; NettyChannel.removeChannelIfDisconnected(ctx.getChannel()); &#125;&#125; 继续看codec.decode(channel, message);这里是DubboCountCodec的decode方法： 1234567891011121314151617181920212223242526public Object decode(Channel channel, ChannelBuffer buffer) throws IOException &#123; //当前的读索引记录下来 int save = buffer.readerIndex(); //多消息 MultiMessage result = MultiMessage.create(); do &#123; //解码消息 Object obj = codec.decode(channel, buffer); //不是完整的协议包 if (Codec2.DecodeResult.NEED_MORE_INPUT == obj) &#123; buffer.readerIndex(save); break; &#125; else &#123;//多个协议包 result.addMessage(obj); logMessageLength(obj, buffer.readerIndex() - save); save = buffer.readerIndex(); &#125; &#125; while (true); if (result.isEmpty()) &#123; return Codec2.DecodeResult.NEED_MORE_INPUT; &#125; if (result.size() == 1) &#123; return result.get(0); &#125; return result;&#125; 继续看ExchangeCodec的decode方法： 123456789public Object decode(Channel channel, ChannelBuffer buffer) throws IOException &#123; //可读字节数 int readable = buffer.readableBytes(); byte[] header = new byte[Math.min(readable, HEADER_LENGTH)]; //协议头 buffer.readBytes(header); //解码 return decode(channel, buffer, readable, header);&#125; 解码decode： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647protected Object decode(Channel channel, ChannelBuffer buffer, int readable, byte[] header) throws IOException &#123; //检查魔数. if (readable &gt; 0 &amp;&amp; header[0] != MAGIC_HIGH || readable &gt; 1 &amp;&amp; header[1] != MAGIC_LOW) &#123; int length = header.length; if (header.length &lt; readable) &#123; header = Bytes.copyOf(header, readable); buffer.readBytes(header, length, readable - length); &#125; for (int i = 1; i &lt; header.length - 1; i ++) &#123; if (header[i] == MAGIC_HIGH &amp;&amp; header[i + 1] == MAGIC_LOW) &#123; buffer.readerIndex(buffer.readerIndex() - header.length + i); header = Bytes.copyOf(header, i); break; &#125; &#125; //telenet return super.decode(channel, buffer, readable, header); &#125; //不完整的包 if (readable &lt; HEADER_LENGTH) &#123; return DecodeResult.NEED_MORE_INPUT; &#125; //数据长度 int len = Bytes.bytes2int(header, 12); checkPayload(channel, len); int tt = len + HEADER_LENGTH; if( readable &lt; tt ) &#123; return DecodeResult.NEED_MORE_INPUT; &#125; // limit input stream. ChannelBufferInputStream is = new ChannelBufferInputStream(buffer, len); try &#123; //解码数据 return decodeBody(channel, is, header); &#125; finally &#123; if (is.available() &gt; 0) &#123; try &#123; StreamUtils.skipUnusedStream(is); &#125; catch (IOException e) &#123; &#125; &#125; &#125;&#125; decodeBody解析数据部分： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970protected Object decodeBody(Channel channel, InputStream is, byte[] header) throws IOException &#123; byte flag = header[2], proto = (byte) (flag &amp; SERIALIZATION_MASK); //获取序列化方式 Serialization s = CodecSupport.getSerialization(channel.getUrl(), proto); //反序列化 ObjectInput in = s.deserialize(channel.getUrl(), is); //获取请求id long id = Bytes.bytes2long(header, 4); //这里是解码响应数据 if ((flag &amp; FLAG_REQUEST) == 0) &#123; //response的id设为来时候的Request的id，这样才能对上暗号 Response res = new Response(id); //判断是什么类型请求 if ((flag &amp; FLAG_EVENT) != 0) &#123; res.setEvent(Response.HEARTBEAT_EVENT); &#125; //获取状态 byte status = header[3]; res.setStatus(status); if (status == Response.OK) &#123; try &#123; Object data; if (res.isHeartbeat()) &#123; //解码心跳数据 data = decodeHeartbeatData(channel, in); &#125; else if (res.isEvent()) &#123; //事件 data = decodeEventData(channel, in); &#125; else &#123; //响应 data = decodeResponseData(channel, in, getRequestData(id)); &#125; res.setResult(data); &#125; catch (Throwable t) &#123; res.setStatus(Response.CLIENT_ERROR); res.setErrorMessage(StringUtils.toString(t)); &#125; &#125; else &#123; res.setErrorMessage(in.readUTF()); &#125; return res; &#125; else &#123;//这是解码请求数据 // request的id Request req = new Request(id); req.setVersion(&quot;2.0.0&quot;); req.setTwoWay((flag &amp; FLAG_TWOWAY) != 0); if ((flag &amp; FLAG_EVENT) != 0) &#123; req.setEvent(Request.HEARTBEAT_EVENT); &#125; try &#123; Object data; if (req.isHeartbeat()) &#123; //心跳 data = decodeHeartbeatData(channel, in); &#125; else if (req.isEvent()) &#123; //事件 data = decodeEventData(channel, in); &#125; else &#123; //请求 data = decodeRequestData(channel, in); &#125; req.setData(data); &#125; catch (Throwable t) &#123; // bad request req.setBroken(true); req.setData(t); &#125; return req; &#125;&#125; 具体的解码细节交给底层解码器，这里是使用的hessian2。 服务消费者对响应消息的解码暂先不做解释。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Netty3服务端流程简介]]></title>
      <url>%2F2017%2F03%2F19%2FNetty3%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%B5%81%E7%A8%8B%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[在学习Dubbo的时候需要学习Netty的流程等，在此做一个简单的入门学习。Dubbo中使用的是Netty3，所以这里说的都是Netty3。 Netty3可以看成是对Reactor的实现，所以先简单看下Reactor模式。 Reactor模式Reactor模式是基于事件驱动的，有以下几种角色存在： Handle，句柄，用来表示打开的文件，打开的连接等，Java NIO中使用Channel来表示。 Synchronous Event Demultiplexer，阻塞的等待发生在句柄上的一个或多个事件，就是监听事件的到来。Java NIO中使用Selector来表示。 EventHandler接口，来处理不同的请求事件。 Concrete Event Handler，EventHandler实现。 Initiation Dispatcher（Reactor），用来管理EventHandler；有事件到来时分发事件到EventHandler上去处理。 Netty中的Reactor模式Netty中使用了两层Reactor，Main Reactor用于处理连接请求，Sub Reactor用于处理请求连接之后的读写请求。 Netty中各类释义ChannelReactor模式中使用Handle来表示打开的连接，也就是事件源，在java nio中使用Channel来抽象事件源，Netty中的Channel是自己的抽象。 ChannelEvent在Netty中使用ChannelEvent来抽象在事件源中可以产生的各种事件。 ChannelHandler作用就是Reactor模式中的EventHandler，用来处理事件请求。有两个子接口： ChannelDownstreamHandler，处理从Netty内部流向Socket的事件。 ChannelUpstreamHandler，处理从Socket进入Netty内部的事件。 ChannelPipeline每个Channel都会有一个ChannelPipeline，用来管理ChannelHandler。ChannelPipeline内部有一个ChannelHandler的双向链表，以Upstream为正方向，Downstream为负方向。 NioSelector对应的是Reactor模式中的Synchronous Event Demultiplexer，Java NIO使用Selector，每个Channel都会把自己注册到Selector上，Selector就可以监听Channel中发生的事件。当有事件发生的时候，会生成ChannelEvent实例，该事件会被发送到Channel对应的ChannelPipeline中，然后交给ChannelHandler处理。 NioSelector有两个实现： Boss，是Main Reactor，用来处理新连接加入的事件。 Worker，是Sub Reactor，用来处理各个连接的读写事件。 ChannelSinkChannelSink可以看成Handler最后的一个处于末尾的万能handler，只有DownStream包含ChannelSink。 服务端例子1234567891011121314151617181920212223242526public class NettyServerTest &#123; private final int port; public NettyServerTest(int port)&#123; this.port = port; &#125; public void startServer()&#123; ChannelFactory channelFactory = new NioServerSocketChannelFactory(Executors.newCachedThreadPool(),Executors.newCachedThreadPool()); ServerBootstrap serverBootstrap = new ServerBootstrap(channelFactory); serverBootstrap.setPipelineFactory(new ChannelPipelineFactory() &#123; @Override public ChannelPipeline getPipeline() throws Exception &#123; return Channels.pipeline(new ServerHandlerTest()); &#125; &#125;); serverBootstrap.bind(new InetSocketAddress(port)); &#125; public static void main(String[] args) &#123; new NettyServerTest(8888).startServer(); &#125;&#125; 12345678910111213141516171819202122public class ServerHandlerTest extends SimpleChannelUpstreamHandler &#123; @Override public void messageReceived(ChannelHandlerContext ctx, MessageEvent e) throws Exception &#123; ChannelBuffer channelBuffer = (ChannelBuffer)e.getMessage(); String msg = channelBuffer.toString(Charset.defaultCharset()); if(msg != null &amp;&amp; !&quot;&quot;.equals(msg))&#123; System.out.println(&quot;服务端接收到消息：&quot; + msg); ChannelBuffer sendMsg = ChannelBuffers.dynamicBuffer(); sendMsg.writeBytes(&quot;我是服务器，已经接到消息&quot;.getBytes()); e.getChannel().write(sendMsg); &#125;else &#123; e.getChannel().write(&quot;我是服务器，收到了空消息&quot;); &#125; e.getChannel().close(); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, ExceptionEvent e) throws Exception &#123; e.getCause(); e.getChannel().close(); &#125;&#125; ChannelFactory主要是用来产生Channel实例和ChannelSink实例。 ChannelPipelineFactory主要是用于具体传输数据的处理，是我们自己实现具体内容，一般我们是往里面添加Handler实现。 大概的流程是： 首先使用Boss和Worker两个线程池来初始化一个ChannelFactory。 使用ChannelFactory来初始化一个ServerBootstrap实例。 为ServerBootstrap设置pipelineFactory，这里用来添加各种处理用的Handler。 使用Bind方法绑定并监听。 Handler处理顺序Handler跟Servlet中的Filter类似，在Netty中，Handler存在于Pipeline中，是一个链状的。 在Netty中存在两种ChannelHandler，一种是ChannelDownstreamHandler，另外一种是ChannelUpstreamHandler，从Socket流向Netty内部的数据经过ChannelUpstreamHandler处理，而从Netty内部流向Socket的数据由ChannelDownstreamHandler处理。 有关具体的分析和源码分析，等到dubbo分析完成之后，再做。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo中暴露服务的过程解析]]></title>
      <url>%2F2017%2F02%2F19%2FDubbo%E4%B8%AD%E6%9A%B4%E9%9C%B2%E6%9C%8D%E5%8A%A1%E7%9A%84%E8%BF%87%E7%A8%8B%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[dubbo暴露服务有两种情况，一种是设置了延迟暴露（比如delay=”5000”），另外一种是没有设置延迟暴露或者延迟设置为-1（delay=”-1”）： 设置了延迟暴露，dubbo在Spring实例化bean（initializeBean）的时候会对实现了InitializingBean的类进行回调，回调方法是afterPropertySet()，如果设置了延迟暴露，dubbo在这个方法中进行服务的发布。 没有设置延迟或者延迟为-1，dubbo会在Spring实例化完bean之后，在刷新容器最后一步发布ContextRefreshEvent事件的时候，通知实现了ApplicationListener的类进行回调onApplicationEvent，dubbo会在这个方法中发布服务。 但是不管延迟与否，都是使用ServiceConfig的export()方法进行服务的暴露。使用export初始化的时候会将Bean对象转换成URL格式，所有Bean属性转换成URL的参数。以没有设置延迟暴露熟属性的过程为例。 简易的暴露流程 首先将服务的实现封装成一个Invoker，Invoker中封装了服务的实现类。 将Invoker封装成Exporter，并缓存起来，缓存里使用Invoker的url作为key。 服务端Server启动，监听端口。（请求来到时，根据请求信息生成key，到缓存查找Exporter，就找到了Invoker，就可以完成调用。） Spring容器初始化调用当Spring容器实例化bean完成，走到最后一步发布ContextRefreshEvent事件的时候，ServiceBean会执行onApplicationEvent方法，该方法调用ServiceConfig的export方法。 ServiceConfig初始化的时候，会先初始化静态变量protocol和proxyFactory，这两个变量初始化的结果是通过dubbo的spi扩展机制得到的。 生成的protocol实例是： 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.alibaba.dubbo.rpc;import com.alibaba.dubbo.common.extension.ExtensionLoader;public class Protocol$Adpative implements com.alibaba.dubbo.rpc.Protocol &#123; public com.alibaba.dubbo.rpc.Invoker refer(java.lang.Class arg0, com.alibaba.dubbo.common.URL arg1) throws java.lang.Class &#123; if (arg1 == null) throw new IllegalArgumentException(&quot;url == null&quot;); com.alibaba.dubbo.common.URL url = arg1; String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); &#125; public com.alibaba.dubbo.rpc.Exporter export(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker &#123; if (arg0 == null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument == null&quot;); if (arg0.getUrl() == null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument getUrl() == null&quot;);com.alibaba.dubbo.common.URL url = arg0.getUrl(); //根据URL配置信息获取Protocol协议，默认是dubbo String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); //根据协议名，获取Protocol的实现 //获得Protocol的实现过程中，会对Protocol先进行依赖注入，然后进行Wrapper包装，最后返回被修改过的Protocol //包装经过了ProtocolFilterWrapper，ProtocolListenerWrapper，RegistryProtocol com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName); return extension.export(arg0); &#125; public void destroy() &#123; throw new UnsupportedOperationException(&quot;method public abstract void com.alibaba.dubbo.rpc.Protocol.destroy() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!&quot;); &#125; public int getDefaultPort() &#123; throw new UnsupportedOperationException(&quot;method public abstract int com.alibaba.dubbo.rpc.Protocol.getDefaultPort() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!&quot;); &#125;&#125; 生成的proxyFactory实例： 123456789101112131415161718192021222324252627282930313233package com.alibaba.dubbo.rpc;import com.alibaba.dubbo.common.extension.ExtensionLoader;public class ProxyFactory$Adpative implements com.alibaba.dubbo.rpc.ProxyFactory &#123; public com.alibaba.dubbo.rpc.Invoker getInvoker(java.lang.Object arg0, java.lang.Class arg1, com.alibaba.dubbo.common.URL arg2) throws java.lang.Object &#123; if (arg2 == null) throw new IllegalArgumentException(&quot;url == null&quot;); com.alibaba.dubbo.common.URL url = arg2; String extName = url.getParameter(&quot;proxy&quot;, &quot;javassist&quot;); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.ProxyFactory) name from url(&quot; + url.toString() + &quot;) use keys([proxy])&quot;); com.alibaba.dubbo.rpc.ProxyFactory extension = (com.alibaba.dubbo.rpc.ProxyFactory)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getInvoker(arg0, arg1, arg2); &#125; public java.lang.Object getProxy(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker &#123; if (arg0 == null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument == null&quot;); if (arg0.getUrl() == null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument getUrl() == null&quot;);com.alibaba.dubbo.common.URL url = arg0.getUrl(); String extName = url.getParameter(&quot;proxy&quot;, &quot;javassist&quot;); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.ProxyFactory) name from url(&quot; + url.toString() + &quot;) use keys([proxy])&quot;); com.alibaba.dubbo.rpc.ProxyFactory extension = (com.alibaba.dubbo.rpc.ProxyFactory)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getProxy(arg0); &#125;&#125; 生成的代码中可以看到，默认的Protocol实现是dubbo，默认的proxy是javassist。 ServiceConfig的exportexport的步骤简介 首先会检查各种配置信息，填充各种属性，总之就是保证我在开始暴露服务之前，所有的东西都准备好了，并且是正确的。 加载所有的注册中心，因为我们暴露服务需要注册到注册中心中去。 根据配置的所有协议和注册中心url分别进行导出。 进行导出的时候，又是一波属性的获取设置检查等操作。 如果配置的不是remote，则做本地导出。 如果配置的不是local，则暴露为远程服务。 不管是本地还是远程服务暴露，首先都会获取Invoker。 获取完Invoker之后，转换成对外的Exporter，缓存起来。 export方法先判断是否需要延迟暴露（这里我们使用的是不延迟暴露），然后执行doExport方法。 doExport方法先执行一系列的检查方法，然后调用doExportUrls方法。检查方法会检测dubbo的配置是否在Spring配置文件中声明，没有的话读取properties文件初始化。 doExportUrls方法先调用loadRegistries获取所有的注册中心url，然后遍历调用doExportUrlsFor1Protocol方法。对于在标签中指定了registry属性的Bean，会在加载BeanDefinition的时候就加载了注册中心。 获取注册中心url，会把注册的信息都放在一个URL对象中，一个URL内容如下： 1registry://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService?application=dubbo-provider&amp;application.version=1.0&amp;dubbo=2.5.3&amp;environment=product&amp;organization=china&amp;owner=cheng.xi&amp;pid=2939&amp;registry=zookeeper&amp;timestamp=1488898049284 doExportUrlsFor1Protocol根据不同的协议将服务以URL形式暴露。如果scope配置为none则不暴露，如果服务未配置成remote，则本地暴露exportLocal，如果未配置成local，则注册服务registryProcotol。 这里的URL是： 1dubbo://192.168.1.100:20880/dubbo.common.hello.service.HelloService?anyhost=true&amp;application=dubbo-provider&amp;application.version=1.0&amp;delay=5000&amp;dubbo=2.5.3&amp;environment=product&amp;interface=dubbo.common.hello.service.HelloService&amp;methods=sayHello&amp;organization=china&amp;owner=cheng.xi&amp;pid=2939&amp;side=provider&amp;timestamp=1488898464953 本地暴露这时候会先做本地暴露，exportLocal(url);： 1234567891011121314151617181920private void exportLocal(URL url) &#123; if (!Constants.LOCAL_PROTOCOL.equalsIgnoreCase(url.getProtocol())) &#123; //这时候转成本地暴露的url：injvm://127.0.0.1/dubbo.common.hello.service.HelloService?anyhost=true&amp; //application=dubbo-provider&amp;application.version=1.0&amp;dubbo=2.5.3&amp;environment=product&amp; //interface=dubbo.common.hello.service.HelloService&amp;methods=sayHello&amp; //organization=china&amp;owner=cheng.xi&amp;pid=720&amp;side=provider&amp;timestamp=1489716708276 URL local = URL.valueOf(url.toFullString()) .setProtocol(Constants.LOCAL_PROTOCOL) .setHost(NetUtils.LOCALHOST) .setPort(0); //首先还是先获得Invoker //然后导出成Exporter，并缓存 //这里的proxyFactory实际是JavassistProxyFactory //有关详细的获得Invoke以及exporter会在下面的流程解析，在本地暴露这个流程就不再说明。 Exporter&lt;?&gt; exporter = protocol.export( proxyFactory.getInvoker(ref, (Class) interfaceClass, local)); exporters.add(exporter); logger.info(&quot;Export dubbo service &quot; + interfaceClass.getName() +&quot; to local registry&quot;); &#125;&#125; 暴露为远程服务接下来是暴露为远程服务，跟本地暴露的流程一样还是先获取Invoker，然后导出成Exporter： 123456789//根据服务具体实现，实现接口，以及registryUrl通过ProxyFactory将HelloServiceImpl封装成一个本地执行的Invoker//invoker是对具体实现的一种代理。//这里proxyFactory是上面列出的生成的代码 Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString())); //使用Protocol将invoker导出成一个Exporter //暴露封装服务invoker //调用Protocol生成的适配类的export方法 //这里的protocol是上面列出的生成的代码 Exporter&lt;?&gt; exporter = protocol.export(invoker); 关于Invoker，Exporter等的解释参见最下面的内容。 暴露远程服务时的获取Invoker过程服务实现类转换成Invoker，大概的步骤是： 根据上面生成的proxyFactory方法调用具体的ProxyFactory实现类的getInvoker方法获取Invoker。 getInvoker的过程是，首先对实现类做一个包装，生成一个包装后的类。 然后新创建一个Invoker实例，这个Invoker中包含着生成的Wrapper类，Wrapper类中有具体的实现类。 1Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString())); 这行代码中包含服务实现类转换成Invoker的过程，其中proxyFactory是上面列出的动态生成的代码，其中getInvoker的代码为（做了精简，把包都去掉了）： 1234567891011121314public Invoker getInvoker(Object arg0, Class arg1, URL arg2) throws Object &#123; if (arg2 == null) throw new IllegalArgumentException(&quot;url == null&quot;); //传进来的url是dubbo://192.168.110.197:20880/dubbo.common.hello.service.HelloService?anyhost=true&amp;application=dubbo-provider //&amp;application.version=1.0&amp;dubbo=2.5.3&amp;environment=product&amp;interface=dubbo.common.hello.service.HelloService&amp;methods=sayHello&amp;organization=china&amp;owner=cheng.xi //&amp;pid=28191&amp;side=provider&amp;timestamp=1489027396094 URL url = arg2; //没有proxy参数配置，默认使用javassist String extName = url.getParameter(&quot;proxy&quot;, &quot;javassist&quot;); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(ProxyFactory) name from url(&quot; + url.toString() + &quot;) use keys([proxy])&quot;); //这一步就使用javassist来获取ProxyFactory的实现类JavassistProxyFactory ProxyFactory extension = (ProxyFactory)ExtensionLoader.getExtensionLoader(ProxyFactory.class).getExtension(extName); //JavassistProxyFactory的getInvoker方法 return extension.getInvoker(arg0, arg1, arg2);&#125; 使用JavassistProxyFactory获取InvokerJavassistProxyFactory的getInvoker方法： 1234567891011121314151617public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; // TODO Wrapper类不能正确处理带$的类名 //第一步封装一个Wrapper类 //该类是手动生成的 //如果类是以$开头，就使用接口类型获取，其他的使用实现类获取 final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf(&apos;$&apos;) &lt; 0 ? proxy.getClass() : type); //返回一个Invoker实例，doInvoke方法中直接返回上面wrapper的invokeMethod //关于生成的wrapper，请看下面列出的生成的代码，其中invokeMethod方法中就有实现类对实际方法的调用 return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &#125; &#125;;&#125; 生成wrapper类的过程，首先看getWrapper方法： 123456789101112131415public static Wrapper getWrapper(Class&lt;?&gt; c)&#123; while( ClassGenerator.isDynamicClass(c) ) // can not wrapper on dynamic class. c = c.getSuperclass(); //Object类型的 if( c == Object.class ) return OBJECT_WRAPPER; //先去Wrapper缓存中查找 Wrapper ret = WRAPPER_MAP.get(c); if( ret == null ) &#123; //缓存中不存在，生成Wrapper类，放到缓存 ret = makeWrapper(c); WRAPPER_MAP.put(c,ret); &#125; return ret;&#125; makeWrapper方法代码不在列出，太长了。就是生成一个继承自Wrapper的类，最后的结果大概是： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class Wrapper1 extends Wrapper &#123; public static String[] pns; public static Map pts; public static String[] mns; // all method name array. public static String[] dmns; public static Class[] mts0; public String[] getPropertyNames() &#123; return pns; &#125; public boolean hasProperty(String n) &#123; return pts.containsKey($1); &#125; public Class getPropertyType(String n) &#123; return (Class) pts.get($1); &#125; public String[] getMethodNames() &#123; return mns; &#125; public String[] getDeclaredMethodNames() &#123; return dmns; &#125; public void setPropertyValue(Object o, String n, Object v) &#123; dubbo.provider.hello.service.impl.HelloServiceImpl w; try &#123; w = ((dubbo.provider.hello.service.impl.HelloServiceImpl) $1); &#125; catch (Throwable e) &#123; throw new IllegalArgumentException(e); &#125; throw new com.alibaba.dubbo.common.bytecode.NoSuchPropertyException(&quot;Not found property \&quot;&quot; + $2 + &quot;\&quot; filed or setter method in class dubbo.provider.hello.service.impl.HelloServiceImpl.&quot;); &#125; public Object getPropertyValue(Object o, String n) &#123; dubbo.provider.hello.service.impl.HelloServiceImpl w; try &#123; w = ((dubbo.provider.hello.service.impl.HelloServiceImpl) $1); &#125; catch (Throwable e) &#123; throw new IllegalArgumentException(e); &#125; throw new com.alibaba.dubbo.common.bytecode.NoSuchPropertyException(&quot;Not found property \&quot;&quot; + $2 + &quot;\&quot; filed or setter method in class dubbo.provider.hello.service.impl.HelloServiceImpl.&quot;); &#125; public Object invokeMethod(Object o, String n, Class[] p, Object[] v) throws java.lang.reflect.InvocationTargetException &#123; dubbo.provider.hello.service.impl.HelloServiceImpl w; try &#123; w = ((dubbo.provider.hello.service.impl.HelloServiceImpl) $1); &#125; catch (Throwable e) &#123; throw new IllegalArgumentException(e); &#125; try &#123; if (&quot;sayHello&quot;.equals($2) &amp;&amp; $3.length == 0) &#123; w.sayHello(); return null; &#125; &#125; catch (Throwable e) &#123; throw new java.lang.reflect.InvocationTargetException(e); &#125; throw new com.alibaba.dubbo.common.bytecode.NoSuchMethodException(&quot;Not found method \&quot;&quot; + $2 + &quot;\&quot; in class dubbo.provider.hello.service.impl.HelloServiceImpl.&quot;); &#125;&#125; 生成完Wrapper以后，返回一个AbstractProxyInvoker实例。至此生成Invoker的步骤就完成了。可以看到Invoker执行方法的时候，会调用Wrapper的invokeMethod，这个方法中会有真实的实现类调用真实方法的代码。 使用JdkProxyFactory获取invokerJdkProxyFactory的getInvoker方法： 1234567891011public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; Method method = proxy.getClass().getMethod(methodName, parameterTypes); return method.invoke(proxy, arguments); &#125; &#125;;&#125; 直接返回一个AbstractProxyInvoker实例，没有做处理，只是使用反射调用具体的方法。 JdkProxyFactory的getProxy方法： 123public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker, Class&lt;?&gt;[] interfaces) &#123; return (T) Proxy.newProxyInstance(Thread.currentThread().getContextClassLoader(), interfaces, new InvokerInvocationHandler(invoker));&#125; 使用Java的反射机制生成一个代理类。 暴露远程服务时导出Invoker为ExporterInvoker导出为Exporter分为两种情况，第一种是Registry类型的Invoker，第二种是其他协议类型的Invoker，分开解析。 代码入口： 1Exporter&lt;?&gt; exporter = protocol.export(invoker); Registry类型的Invoker处理过程大概的步骤是： 经过两个不用做任何处理的Wrapper类，然后到达RegistryProtocol中。 通过具体的协议导出Invoker为Exporter。 注册服务到注册中心。 订阅注册中心的服务。 生成一个新的Exporter实例，将上面的Exporter进行引入，然后返回。 protocol是上面列出的动态生成的代码，会先调用ProtocolListenerWrapper，这个Wrapper负责初始化暴露和引用服务的监听器。对于Registry类型的不做处理，代码如下： 12345678910public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; //registry类型的Invoker，不需要做处理 if (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123; return protocol.export(invoker); &#125; //非Registry类型的Invoker，需要被监听器包装 return new ListenerExporterWrapper&lt;T&gt;(protocol.export(invoker), Collections.unmodifiableList(ExtensionLoader.getExtensionLoader(ExporterListener.class) .getActivateExtension(invoker.getUrl(), Constants.EXPORTER_LISTENER_KEY)));&#125; 接着调用ProtocolFilterWrapper中的export方法，ProtocolFilterWrapper负责初始化invoker所有的Filter。代码如下： 12345678public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; //Registry类型的Invoker不做处理 if (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123; return protocol.export(invoker); &#125; //非Registry类型的Invoker需要先构建调用链，然后再导出 return protocol.export(buildInvokerChain(invoker, Constants.SERVICE_FILTER_KEY, Constants.PROVIDER));&#125; 这里我们先解析的是Registry类型的Invoker，接着就会调用RegistryProtocol的export方法，RegistryProtocol负责注册服务到注册中心和向注册中心订阅服务。代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public &lt;T&gt; Exporter&lt;T&gt; export(final Invoker&lt;T&gt; originInvoker) throws RpcException &#123; //export invoker //这里就交给了具体的协议去暴露服务（先不解析，留在后面，可以先去后面看下导出过程） final ExporterChangeableWrapper&lt;T&gt; exporter = doLocalExport(originInvoker); //registry provider //根据invoker中的url获取Registry实例 //并且连接到注册中心 //此时提供者作为消费者引用注册中心核心服务RegistryService final Registry registry = getRegistry(originInvoker); //注册到注册中心的URL final URL registedProviderUrl = getRegistedProviderUrl(originInvoker); //调用远端注册中心的register方法进行服务注册 //若有消费者订阅此服务，则推送消息让消费者引用此服务。 //注册中心缓存了所有提供者注册的服务以供消费者发现。 registry.register(registedProviderUrl); // 订阅override数据 // FIXME 提供者订阅时，会影响同一JVM即暴露服务，又引用同一服务的的场景，因为subscribed以服务名为缓存的key，导致订阅信息覆盖。 final URL overrideSubscribeUrl = getSubscribedOverrideUrl(registedProviderUrl); final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl); overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener); //提供者向注册中心订阅所有注册服务的覆盖配置 //当注册中心有此服务的覆盖配置注册进来时，推送消息给提供者，重新暴露服务，这由管理页面完成。 registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener); //保证每次export都返回一个新的exporter实例 //返回暴露后的Exporter给上层ServiceConfig进行缓存，便于后期撤销暴露。 return new Exporter&lt;T&gt;() &#123; public Invoker&lt;T&gt; getInvoker() &#123; return exporter.getInvoker(); &#125; public void unexport() &#123; try &#123; exporter.unexport(); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; try &#123; registry.unregister(registedProviderUrl); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; try &#123; overrideListeners.remove(overrideSubscribeUrl); registry.unsubscribe(overrideSubscribeUrl, overrideSubscribeListener); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; &#125;;&#125; 交给具体的协议去暴露服务先不解析，留在后面，可以先去后面看下导出过程，然后再回来接着看注册到注册中心的过程。具体协议暴露服务主要是打开服务器和端口，进行监听。 连接注册中心并获取Registry实例具体的协议进行暴露并且返回了一个ExporterChangeableWrapper之后，接下来看下一步连接注册中心并注册到注册中心，代码是在RegistryProtocol的export方法： 123456789101112//先假装此步已经分析完final ExporterChangeableWrapper&lt;T&gt; exporter = doLocalExport(originInvoker);//得到具体的注册中心，连接注册中心，此时提供者作为消费者引用注册中心核心服务RegistryServicefinal Registry registry = getRegistry(originInvoker);final URL registedProviderUrl = getRegistedProviderUrl(originInvoker);//调用远端注册中心的register方法进行服务注册//若有消费者订阅此服务，则推送消息让消费者引用此服务registry.register(registedProviderUrl);//提供者向注册中心订阅所有注册服务的覆盖配置registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener);//返回暴露后的Exporter给上层ServiceConfig进行缓存return new Exporter&lt;T&gt;() &#123;。。。&#125; getRegistry(originInvoker)方法： 123456789101112131415161718192021//根据invoker的地址获取registry实例private Registry getRegistry(final Invoker&lt;?&gt; originInvoker)&#123; //获取invoker中的registryUrl URL registryUrl = originInvoker.getUrl(); if (Constants.REGISTRY_PROTOCOL.equals(registryUrl.getProtocol())) &#123; //获取registry的值，这里获得是zookeeper，默认值是dubbo String protocol = registryUrl.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_DIRECTORY); //这里获取到的url为： //zookeeper://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService? //application=dubbo-provider&amp;application.version=1.0&amp;dubbo=2.5.3&amp; //environment=product&amp;export=dubbo%3A%2F%2F192.168.1.100%3A20880%2F //dubbo.common.hello.service.HelloService%3Fanyhost%3Dtrue%26application%3Ddubbo-provider%26 //application.version%3D1.0%26dubbo%3D2.5.3%26environment%3Dproduct%26 //interface%3Ddubbo.common.hello.service.HelloService%26methods%3DsayHello%26 //organization%3Dchina%26owner%3Dcheng.xi%26pid%3D9457%26side%3Dprovider%26timestamp%3D1489807681627&amp;organization=china&amp;owner=cheng.xi&amp; //pid=9457&amp;timestamp=1489807680193 registryUrl = registryUrl.setProtocol(protocol).removeParameter(Constants.REGISTRY_KEY); &#125; //根据SPI机制获取具体的Registry实例，这里获取到的是ZookeeperRegistry return registryFactory.getRegistry(registryUrl);&#125; 这里的registryFactory是动态生成的代码，如下： 12345678910111213141516import com.alibaba.dubbo.common.extension.ExtensionLoader;public class RegistryFactory$Adpative implements com.alibaba.dubbo.registry.RegistryFactory &#123; public com.alibaba.dubbo.registry.Registry getRegistry(com.alibaba.dubbo.common.URL arg0) &#123; if (arg0 == null) throw new IllegalArgumentException(&quot;url == null&quot;); com.alibaba.dubbo.common.URL url = arg0; String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.registry.RegistryFactory) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); com.alibaba.dubbo.registry.RegistryFactory extension = (com.alibaba.dubbo.registry.RegistryFactory)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.registry.RegistryFactory.class).getExtension(extName); return extension.getRegistry(arg0); &#125;&#125; 所以这里registryFactory.getRegistry(registryUrl)用的是ZookeeperRegistryFactory。 先看下getRegistry方法，会发现该方法会在AbstractRegistryFactory中实现： 1234567891011121314151617181920212223242526272829public Registry getRegistry(URL url) &#123; url = url.setPath(RegistryService.class.getName()) .addParameter(Constants.INTERFACE_KEY, RegistryService.class.getName()) .removeParameters(Constants.EXPORT_KEY, Constants.REFER_KEY); //这里key为： //zookeeper://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService String key = url.toServiceString(); // 锁定注册中心获取过程，保证注册中心单一实例 LOCK.lock(); try &#123; //先从缓存中获取Registry实例 Registry registry = REGISTRIES.get(key); if (registry != null) &#123; return registry; &#125; //创建registry，会直接new一个ZookeeperRegistry返回 //具体创建实例是子类来实现的 registry = createRegistry(url); if (registry == null) &#123; throw new IllegalStateException(&quot;Can not create registry &quot; + url); &#125; //放到缓存中 REGISTRIES.put(key, registry); return registry; &#125; finally &#123; // 释放锁 LOCK.unlock(); &#125;&#125; createRegistry(url);是在子类中实现的，这里是ZookeeperRegistry，首先需要经过AbstractRegistry的构造： 123456789101112131415161718192021222324public AbstractRegistry(URL url) &#123; //url保存起来 setUrl(url); // 启动文件保存定时器 // syncSaveFile = url.getParameter(Constants.REGISTRY_FILESAVE_SYNC_KEY, false); //保存的文件为： ///home/xxx/.dubbo/dubbo-registry-127.0.0.1.cache String filename = url.getParameter(Constants.FILE_KEY, System.getProperty(&quot;user.home&quot;) + &quot;/.dubbo/dubbo-registry-&quot; + url.getHost() + &quot;.cache&quot;); File file = null; if (ConfigUtils.isNotEmpty(filename)) &#123; file = new File(filename); if(! file.exists() &amp;&amp; file.getParentFile() != null &amp;&amp; ! file.getParentFile().exists())&#123; if(! file.getParentFile().mkdirs())&#123; throw new IllegalArgumentException(&quot;Invalid registry store file &quot; + file + &quot;, cause: Failed to create directory &quot; + file.getParentFile() + &quot;!&quot;); &#125; &#125; &#125; this.file = file; //加载文件中的属性 loadProperties(); //通知订阅 notify(url.getBackupUrls());&#125; 获取Registry时的订阅notify()方法： 12345678910111213141516171819202122protected void notify(List&lt;URL&gt; urls) &#123; if(urls == null || urls.isEmpty()) return; //getSubscribed()方法获取订阅者列表 //订阅者Entry里每个URL都对应着n个NotifyListener for (Map.Entry&lt;URL, Set&lt;NotifyListener&gt;&gt; entry : getSubscribed().entrySet()) &#123; URL url = entry.getKey(); if(! UrlUtils.isMatch(url, urls.get(0))) &#123; continue; &#125; Set&lt;NotifyListener&gt; listeners = entry.getValue(); if (listeners != null) &#123; for (NotifyListener listener : listeners) &#123; try &#123; //通知每个监听器 notify(url, listener, filterEmpty(url, urls)); &#125; catch (Throwable t) &#123;&#125; &#125; &#125; &#125;&#125; notify(url, listener, filterEmpty(url, urls));代码： 1234567891011121314151617181920212223242526272829303132protected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; Map&lt;String, List&lt;URL&gt;&gt; result = new HashMap&lt;String, List&lt;URL&gt;&gt;(); for (URL u : urls) &#123; if (UrlUtils.isMatch(url, u)) &#123; //分类 String category = u.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); List&lt;URL&gt; categoryList = result.get(category); if (categoryList == null) &#123; categoryList = new ArrayList&lt;URL&gt;(); result.put(category, categoryList); &#125; categoryList.add(u); &#125; &#125; if (result.size() == 0) &#123; return; &#125; Map&lt;String, List&lt;URL&gt;&gt; categoryNotified = notified.get(url); if (categoryNotified == null) &#123; notified.putIfAbsent(url, new ConcurrentHashMap&lt;String, List&lt;URL&gt;&gt;()); categoryNotified = notified.get(url); &#125; for (Map.Entry&lt;String, List&lt;URL&gt;&gt; entry : result.entrySet()) &#123; String category = entry.getKey(); List&lt;URL&gt; categoryList = entry.getValue(); categoryNotified.put(category, categoryList); //保存到主目录下的.dubbo目录下 saveProperties(url); //上面获取到的监听器进行通知 listener.notify(categoryList); &#125;&#125; AbstractRegistry构造器初始化完，接着调用FailbackRegistry构造器初始化： 12345678910111213141516public FailbackRegistry(URL url) &#123; super(url); //重试时间，默认5000ms int retryPeriod = url.getParameter(Constants.REGISTRY_RETRY_PERIOD_KEY, Constants.DEFAULT_REGISTRY_RETRY_PERIOD); //启动失败重试定时器 this.retryFuture = retryExecutor.scheduleWithFixedDelay(new Runnable() &#123; public void run() &#123; // 检测并连接注册中心 try &#123; //重试方法由每个具体子类实现 //获取到注册失败的，然后尝试注册 retry(); &#125; catch (Throwable t) &#123; // 防御性容错&#125; &#125; &#125;, retryPeriod, retryPeriod, TimeUnit.MILLISECONDS);&#125; 最后回到ZookeeperRegistry的构造初始化： 12345678910111213141516171819202122232425262728293031public ZookeeperRegistry(URL url, ZookeeperTransporter zookeeperTransporter) &#123; super(url); if (url.isAnyHost()) &#123; throw new IllegalStateException(&quot;registry address == null&quot;); &#125; //获得到注册中心中的分组，默认dubbo String group = url.getParameter(Constants.GROUP_KEY, DEFAULT_ROOT); if (! group.startsWith(Constants.PATH_SEPARATOR)) &#123; group = Constants.PATH_SEPARATOR + group; &#125; //注册到注册中心的节点 this.root = group; //使用zookeeperTansporter去连接 //ZookeeperTransport这里是生成的自适应实现，默认使用ZkClientZookeeperTransporter //ZkClientZookeeperTransporter的connect去实例化一个ZkClient实例 //并且订阅状态变化的监听器subscribeStateChanges //然后返回一个ZkClientZookeeperClient实例 zkClient = zookeeperTransporter.connect(url); //ZkClientZookeeperClient添加状态改变监听器 zkClient.addStateListener(new StateListener() &#123; public void stateChanged(int state) &#123; if (state == RECONNECTED) &#123; try &#123; recover(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; &#125; &#125; &#125;);&#125; 获取注册到注册中心的url获取到了Registry，Registry实例中保存着连接到了zookeeper的zkClient实例之后，下一步获取要注册到注册中心的url（在RegistryProtocol中）。 123456final URL registedProviderUrl = getRegistedProviderUrl(originInvoker);//得到的URL是：//dubbo://192.168.1.100:20880/dubbo.common.hello.service.HelloService?//anyhost=true&amp;application=dubbo-provider&amp;application.version=1.0&amp;dubbo=2.5.3&amp;environment=product&amp;//interface=dubbo.common.hello.service.HelloService&amp;methods=sayHello&amp;//organization=china&amp;owner=cheng.xi&amp;pid=9457&amp;side=provider&amp;timestamp=1489807681627 注册到注册中心然后调用registry.register(registedProviderUrl)注册到注册中心（在RegistryProtocol中）。register方法的实现在FailbackRegistry中： 123456789101112131415161718192021222324252627public void register(URL url) &#123; super.register(url); failedRegistered.remove(url); failedUnregistered.remove(url); try &#123; // 向服务器端发送注册请求 //调用子类具体实现，发送注册请求 doRegister(url); &#125; catch (Exception e) &#123; Throwable t = e; // 如果开启了启动时检测，则直接抛出异常 boolean check = getUrl().getParameter(Constants.CHECK_KEY, true) &amp;&amp; url.getParameter(Constants.CHECK_KEY, true) &amp;&amp; ! Constants.CONSUMER_PROTOCOL.equals(url.getProtocol()); boolean skipFailback = t instanceof SkipFailbackWrapperException; if (check || skipFailback) &#123; if(skipFailback) &#123; t = t.getCause(); &#125; throw 。。。 &#125; else &#123; &#125; // 将失败的注册请求记录到失败列表，定时重试 failedRegistered.add(url); &#125;&#125; doRegister(url);在这里是ZookeeperRegistry中具体实现的，这里将会注册到注册中心： 12345678910111213141516protected void doRegister(URL url) &#123; try &#123; //这里zkClient就是我们上面调用构造的时候生成的 //ZkClientZookeeperClient //保存着连接到Zookeeper的zkClient实例 //开始注册，也就是在Zookeeper中创建节点 //这里toUrlPath获取到的path为： ///dubbo/dubbo.common.hello.service.HelloService/providers/dubbo%3A%2F%2F192.168.1.100%3A20880%2F //dubbo.common.hello.service.HelloService%3Fanyhost%3Dtrue%26application%3Ddubbo-provider%26 //application.version%3D1.0%26dubbo%3D2.5.3%26environment%3Dproduct%26interface%3D //dubbo.common.hello.service.HelloService%26methods%3DsayHello%26 //organization%3Dchina%26owner%3Dcheng.xi%26pid%3D8920%26side%3Dprovider%26timestamp%3D1489828029449 //默认创建的节点是临时节点 zkClient.create(toUrlPath(url), url.getParameter(Constants.DYNAMIC_KEY, true)); &#125; catch (Throwable e) &#123; &#125;&#125; 经过这一步之后，Zookeeper中就有节点存在了，具体节点为： 12345678910/dubbo dubbo.common.hello.service.HelloService providers /dubbo/dubbo.common.hello.service.HelloService/providers/ dubbo%3A%2F%2F192.168.1.100%3A20880%2Fdubbo.common.hello.service.HelloService%3F anyhost%3Dtrue%26application%3Ddubbo-provider%26 application.version%3D1.0%26dubbo%3D2.5.3%26environment%3Dproduct%26 interface%3Ddubbo.common.hello.service.HelloService%26methods%3DsayHello%26 organization%3Dchina%26owner%3Dcheng.xi%26pid%3D13239%26side%3D provider%26timestamp%3D1489829293525 订阅注册中心的服务在注册到注册中心之后，registry会去订阅覆盖配置的服务，这一步之后就会在/dubbo/dubbo.common.hello.service/HelloService节点下多一个configurators节点。（具体过程暂先不解析）。 返回新Exporter实例最后返回Exporter新实例，返回到ServiceConfig中。服务的发布就算完成了。 交给具体的协议进行服务暴露这里也就是非Registry类型的Invoker的导出过程。主要的步骤是将本地ip和20880端口打开，进行监听。最后包装成exporter返回。 doLocalExport(invoker)： 12345678910111213141516171819202122232425262728293031323334private &lt;T&gt; ExporterChangeableWrapper&lt;T&gt; doLocalExport(final Invoker&lt;T&gt; originInvoker)&#123; //原始的invoker中的url： //registry://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService? //application=dubbo-provider&amp;application.version=1.0&amp;dubbo=2.5.3 //&amp;environment=product&amp;export=dubbo%3A%2F%2F10.42.0.1%3A20880%2F //dubbo.common.hello.service.HelloService%3Fanyhost%3Dtrue%26application%3Ddubbo-provider%26 //application.version%3D1.0%26dubbo%3D2.5.3%26environment%3Dproduct%26 //interface%3Ddubbo.common.hello.service.HelloService%26methods%3DsayHello%26 //organization%3Dchina%26owner%3Dcheng.xi%26pid%3D7876%26side%3Dprovider%26timestamp%3D1489057305001&amp; //organization=china&amp;owner=cheng.xi&amp;pid=7876&amp;registry=zookeeper&amp;timestamp=1489057304900 //从原始的invoker中得到的key： //dubbo://10.42.0.1:20880/dubbo.common.hello.service.HelloService?anyhost=true&amp;application=dubbo-provider&amp; //application.version=1.0&amp;dubbo=2.5.3&amp;environment=product&amp;interface=dubbo.common.hello.service.HelloService&amp; //methods=sayHello&amp;organization=china&amp;owner=cheng.xi&amp;pid=7876&amp;side=provider&amp;timestamp=1489057305001 String key = getCacheKey(originInvoker); ExporterChangeableWrapper&lt;T&gt; exporter = (ExporterChangeableWrapper&lt;T&gt;) bounds.get(key); if (exporter == null) &#123; synchronized (bounds) &#123; exporter = (ExporterChangeableWrapper&lt;T&gt;) bounds.get(key); if (exporter == null) &#123; //得到一个Invoker代理，里面包含原来的Invoker final Invoker&lt;?&gt; invokerDelegete = new InvokerDelegete&lt;T&gt;(originInvoker, getProviderUrl(originInvoker)); //此处protocol还是最上面生成的代码，调用代码中的export方法，会根据协议名选择调用具体的实现类 //这里我们需要调用DubboProtocol的export方法 //这里的使用具体协议进行导出的invoker是个代理invoker //导出完之后，返回一个新的ExporterChangeableWrapper实例 exporter = new ExporterChangeableWrapper&lt;T&gt;((Exporter&lt;T&gt;)protocol.export(invokerDelegete), originInvoker); bounds.put(key, exporter); &#125; &#125; &#125; return (ExporterChangeableWrapper&lt;T&gt;) exporter;&#125; 使用dubbo协议导出这里protocol.export(invokerDelegete)就要去具体的DubboProtocol中执行了，DubboProtocol的外面包裹着ProtocolFilterWrapper，再外面还包裹着ProtocolListenerWrapper。会先经过ProtocolListenerWrapper： 1234567891011121314public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; //Registry类型的Invoker if (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123; return protocol.export(invoker); &#125; //其他具体协议类型的Invoker //先进行导出protocol.export(invoker) //然后获取自适应的监听器 //最后返回的是包装了监听器的Exporter //这里监听器的获取是getActivateExtension，如果指定了listener就加载实现，没有指定就不加载 return new ListenerExporterWrapper&lt;T&gt;(protocol.export(invoker), Collections.unmodifiableList(ExtensionLoader.getExtensionLoader(ExporterListener.class) .getActivateExtension(invoker.getUrl(), Constants.EXPORTER_LISTENER_KEY)));&#125; 再经过ProtocolFilterWrapper： 123456789public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; //Registry类型的Invoker if (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123; return protocol.export(invoker); &#125; //其他具体协议类型的Invoker //先构建Filter链，然后再导出 return protocol.export(buildInvokerChain(invoker, Constants.SERVICE_FILTER_KEY, Constants.PROVIDER));&#125; 查看下构建Invoker链的方法： 1234567891011121314151617181920212223242526272829303132333435363738394041private static &lt;T&gt; Invoker&lt;T&gt; buildInvokerChain(final Invoker&lt;T&gt; invoker, String key, String group) &#123; //我们要处理的那个Invoker作为处理链的最后一个 Invoker&lt;T&gt; last = invoker; //根据key和group获取自动激活的Filter List&lt;Filter&gt; filters = ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group); if (filters.size() &gt; 0) &#123; //把所有的过滤器都挨个连接起来，最后一个是我们真正的Invoker for (int i = filters.size() - 1; i &gt;= 0; i --) &#123; final Filter filter = filters.get(i); final Invoker&lt;T&gt; next = last; last = new Invoker&lt;T&gt;() &#123; public Class&lt;T&gt; getInterface() &#123; return invoker.getInterface(); &#125; public URL getUrl() &#123; return invoker.getUrl(); &#125; public boolean isAvailable() &#123; return invoker.isAvailable(); &#125; public Result invoke(Invocation invocation) throws RpcException &#123; return filter.invoke(next, invocation); &#125; public void destroy() &#123; invoker.destroy(); &#125; @Override public String toString() &#123; return invoker.toString(); &#125; &#125;; &#125; &#125; return last;&#125; 接着就到了DubboProtocol的export方法，这里进行暴露服务： 12345678910111213141516171819202122232425262728293031323334353637383940414243public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; //dubbo://10.42.0.1:20880/dubbo.common.hello.service.HelloService? //anyhost=true&amp;application=dubbo-provider&amp; //application.version=1.0&amp;dubbo=2.5.3&amp;environment=product&amp; //interface=dubbo.common.hello.service.HelloService&amp; //methods=sayHello&amp;organization=china&amp;owner=cheng.xi&amp; //pid=7876&amp;side=provider&amp;timestamp=1489057305001 URL url = invoker.getUrl(); // export service. //key由serviceName，port，version，group组成 //当nio客户端发起远程调用时，nio服务端通过此key来决定调用哪个Exporter，也就是执行的Invoker。 //dubbo.common.hello.service.HelloService:20880 String key = serviceKey(url); //将Invoker转换成Exporter //直接new一个新实例 //没做啥处理，就是做一些赋值操作 //这里的exporter就包含了invoker DubboExporter&lt;T&gt; exporter = new DubboExporter&lt;T&gt;(invoker, key, exporterMap); //缓存要暴露的服务，key是上面生成的 exporterMap.put(key, exporter); //export an stub service for dispaching event //是否支持本地存根 //远程服务后，客户端通常只剩下接口，而实现全在服务器端， //但提供方有些时候想在客户端也执行部分逻辑，比如：做ThreadLocal缓存， //提前验证参数，调用失败后伪造容错数据等等，此时就需要在API中带上Stub， //客户端生成Proxy实，会把Proxy通过构造函数传给Stub， //然后把Stub暴露组给用户，Stub可以决定要不要去调Proxy。 Boolean isStubSupportEvent = url.getParameter(Constants.STUB_EVENT_KEY,Constants.DEFAULT_STUB_EVENT); Boolean isCallbackservice = url.getParameter(Constants.IS_CALLBACK_SERVICE, false); if (isStubSupportEvent &amp;&amp; !isCallbackservice)&#123; String stubServiceMethods = url.getParameter(Constants.STUB_EVENT_METHODS_KEY); if (stubServiceMethods == null || stubServiceMethods.length() == 0 )&#123; &#125; else &#123; stubServiceMethodsMap.put(url.getServiceKey(), stubServiceMethods); &#125; &#125; //根据URL绑定IP与端口，建立NIO框架的Server openServer(url); return exporter;&#125; 上面得到的Exporter会被放到缓存中去，key就是上面生成的，客户端就可以发请求根据key找到Exporter，然后找到invoker进行调用了。接下来是创建服务器并监听端口。 接着调用openServer方法创建NIO Server进行监听： 123456789101112131415161718192021222324private void openServer(URL url) &#123; // find server. //key是IP:PORT //192.168.110.197:20880 String key = url.getAddress(); //client 也可以暴露一个只有server可以调用的服务。 boolean isServer = url.getParameter(Constants.IS_SERVER_KEY,true); if (isServer) &#123; ExchangeServer server = serverMap.get(key); //同一JVM中，同协议的服务，共享同一个Server， //第一个暴露服务的时候创建server， //以后相同协议的服务都使用同一个server if (server == null) &#123; serverMap.put(key, createServer(url)); &#125; else &#123; //同协议的服务后来暴露服务的则使用第一次创建的同一Server //server支持reset,配合override功能使用 //accept、idleTimeout、threads、heartbeat参数的变化会引起Server的属性发生变化 //这时需要重新设置Server server.reset(url); &#125; &#125;&#125; 继续看createServer方法： 12345678910111213141516171819202122232425262728293031323334353637//url为：//dubbo://192.168.110.197:20880/dubbo.common.hello.service.HelloService?//anyhost=true&amp;application=dubbo-provider&amp;//application.version=1.0&amp;dubbo=2.5.3&amp;environment=product&amp;//interface=dubbo.common.hello.service.HelloService&amp;//methods=sayHello&amp;organization=china&amp;owner=cheng.xi&amp;//pid=720&amp;side=provider&amp;timestamp=1489716708276private ExchangeServer createServer(URL url) &#123; //默认开启server关闭时发送readonly事件 url = url.addParameterIfAbsent(Constants.CHANNEL_READONLYEVENT_SENT_KEY, Boolean.TRUE.toString()); //默认开启heartbeat url = url.addParameterIfAbsent(Constants.HEARTBEAT_KEY, String.valueOf(Constants.DEFAULT_HEARTBEAT)); //默认使用netty String str = url.getParameter(Constants.SERVER_KEY, Constants.DEFAULT_REMOTING_SERVER); if (str != null &amp;&amp; str.length() &gt; 0 &amp;&amp; ! ExtensionLoader.getExtensionLoader(Transporter.class).hasExtension(str)) throw new RpcException(&quot;Unsupported server type: &quot; + str + &quot;, url: &quot; + url); url = url.addParameter(Constants.CODEC_KEY, Version.isCompatibleVersion() ? COMPATIBLE_CODEC_NAME : DubboCodec.NAME); ExchangeServer server; try &#123; //Exchangers是门面类，里面封装的是Exchanger的逻辑。 //Exchanger默认只有一个实现HeaderExchanger. //Exchanger负责数据交换和网络通信。 //从Protocol进入Exchanger，标志着程序进入了remote层。 //这里requestHandler是ExchangeHandlerAdapter server = Exchangers.bind(url, requestHandler); &#125; catch (RemotingException e) &#123; &#125; str = url.getParameter(Constants.CLIENT_KEY); if (str != null &amp;&amp; str.length() &gt; 0) &#123; Set&lt;String&gt; supportedTypes = ExtensionLoader.getExtensionLoader(Transporter.class).getSupportedExtensions(); if (!supportedTypes.contains(str)) &#123; throw new RpcException(&quot;Unsupported client type: &quot; + str); &#125; &#125; return server;&#125; Exchangers.bind方法： 123456public static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; url = url.addParameterIfAbsent(Constants.CODEC_KEY, &quot;exchange&quot;); //getExchanger方法根据url获取到一个默认的实现HeaderExchanger //调用HeaderExchanger的bind方法 return getExchanger(url).bind(url, handler);&#125; HeaderExchanger的bind方法： 1234567public ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; //直接返回一个HeaderExchangeServer //先创建一个HeaderExchangeHandler //再创建一个DecodeHandler //最后调用Transporters.bind return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))));&#125; 这里会先创建一个HeaderExchangerHandler，包含着ExchangeHandlerAdapter，接着创建一个DecodeHandler，会包含前面的handler，接下来调用Transporters的bind方法，返回一个Server，接着用HeaderExchangeServer包装一下，就返回给Protocol层了。 在HeaderExchangerServer包装的时候会启动心跳定时器startHeatbeatTimer();，暂不解析。 Transports的bind方法： 123456789101112public static Server bind(URL url, ChannelHandler... handlers) throws RemotingException &#123; ChannelHandler handler; if (handlers.length == 1) &#123; handler = handlers[0]; &#125; else &#123; //如果有多个handler的话，需要使用分发器包装下 handler = new ChannelHandlerDispatcher(handlers); &#125; //getTransporter()获取一个Adaptive的Transporter //然后调用bind方法（默认是NettyTransporter的bind方法） return getTransporter().bind(url, handler);&#125; getTransporter()生成的Transporter的代码如下： 123456789101112131415161718192021222324252627import com.alibaba.dubbo.common.extension.ExtensionLoader;public class Transporter$Adpative implements com.alibaba.dubbo.remoting.Transporter &#123; public com.alibaba.dubbo.remoting.Server bind(com.alibaba.dubbo.common.URL arg0, com.alibaba.dubbo.remoting.ChannelHandler arg1) throws com.alibaba.dubbo.common.URL &#123; if (arg0 == null) throw new IllegalArgumentException(&quot;url == null&quot;); com.alibaba.dubbo.common.URL url = arg0; //Server默认使用netty String extName = url.getParameter(&quot;server&quot;, url.getParameter(&quot;transporter&quot;, &quot;netty&quot;)); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.remoting.Transporter) name from url(&quot; + url.toString() + &quot;) use keys([server, transporter])&quot;); //获取到一个NettyTransporter com.alibaba.dubbo.remoting.Transporter extension = (com.alibaba.dubbo.remoting.Transporter)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.remoting.Transporter.class).getExtension(extName); //调用NettyTransporter的bind方法 return extension.bind(arg0, arg1); &#125; public com.alibaba.dubbo.remoting.Client connect(com.alibaba.dubbo.common.URL arg0, com.alibaba.dubbo.remoting.ChannelHandler arg1) throws com.alibaba.dubbo.common.URL &#123; if (arg0 == null) throw new IllegalArgumentException(&quot;url == null&quot;); com.alibaba.dubbo.common.URL url = arg0; String extName = url.getParameter(&quot;client&quot;, url.getParameter(&quot;transporter&quot;, &quot;netty&quot;)); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.remoting.Transporter) name from url(&quot; + url.toString() + &quot;) use keys([client, transporter])&quot;); com.alibaba.dubbo.remoting.Transporter extension = (com.alibaba.dubbo.remoting.Transporter)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.remoting.Transporter.class).getExtension(extName); return extension.connect(arg0, arg1);&#125;&#125; NettyTransporter的bind方法： 1234 public Server bind(URL url, ChannelHandler listener) throws RemotingException &#123; //创建一个Server return new NettyServer(url, listener);&#125; 12345public NettyServer(URL url, ChannelHandler handler) throws RemotingException&#123; //handler先经过ChannelHandlers的包装方法 //然后再初始化 super(url, ChannelHandlers.wrap(handler, ExecutorUtil.setThreadName(url, SERVER_THREAD_POOL_NAME)));&#125; ChannelHandlers.wrap方法中会根据SPI扩展机制动态生成Dispatcher的自适应类，生成的代码不在列出，默认使用AllDispatcher处理，会返回一个AllChannelHandler，会把线程池和DataStore都初始化了。然后经过HeartbeatHandler封装，再经过MultiMessageHandler封装后返回。 NettyServer构造，会依次经过AbstractPeer，AbstractEndpoint，AbstractServer，NettyServer的初始化。重点看下AbstractServer的构造方法： 123456789101112131415161718public AbstractServer(URL url, ChannelHandler handler) throws RemotingException &#123; super(url, handler); localAddress = getUrl().toInetSocketAddress(); String host = url.getParameter(Constants.ANYHOST_KEY, false) || NetUtils.isInvalidLocalHost(getUrl().getHost()) ? NetUtils.ANYHOST : getUrl().getHost(); bindAddress = new InetSocketAddress(host, getUrl().getPort()); this.accepts = url.getParameter(Constants.ACCEPTS_KEY, Constants.DEFAULT_ACCEPTS); this.idleTimeout = url.getParameter(Constants.IDLE_TIMEOUT_KEY, Constants.DEFAULT_IDLE_TIMEOUT); try &#123; //初始化的时候会打开Server //具体实现这里是NettyServer中 doOpen(); &#125; catch (Throwable t) &#123; &#125; if (handler instanceof WrappedChannelHandler )&#123; executor = ((WrappedChannelHandler)handler).getExecutor(); &#125;&#125; 然后调用doOpen方法： 12345678910111213141516171819202122232425protected void doOpen() throws Throwable &#123; NettyHelper.setNettyLoggerFactory(); //boss线程池 ExecutorService boss = Executors.newCachedThreadPool(new NamedThreadFactory(&quot;NettyServerBoss&quot;, true)); //worker线程池 ExecutorService worker = Executors.newCachedThreadPool(new NamedThreadFactory(&quot;NettyServerWorker&quot;, true)); //ChannelFactory，没有指定工作者线程数量，就使用cpu+1 ChannelFactory channelFactory = new NioServerSocketChannelFactory(boss, worker, getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS)); bootstrap = new ServerBootstrap(channelFactory); final NettyHandler nettyHandler = new NettyHandler(getUrl(), this); channels = nettyHandler.getChannels(); bootstrap.setPipelineFactory(new ChannelPipelineFactory() &#123; public ChannelPipeline getPipeline() &#123; NettyCodecAdapter adapter = new NettyCodecAdapter(getCodec() ,getUrl(), NettyServer.this); ChannelPipeline pipeline = Channels.pipeline(); pipeline.addLast(&quot;decoder&quot;, adapter.getDecoder()); pipeline.addLast(&quot;encoder&quot;, adapter.getEncoder()); pipeline.addLast(&quot;handler&quot;, nettyHandler); return pipeline; &#125; &#125;); // bind之后返回一个Channel channel = bootstrap.bind(getBindAddress());&#125; doOpen方法创建Netty的Server端并打开，具体的事情就交给Netty去处理了，Netty的过程，原理，代码有时间再另行研究。 NIO框架接受到消息后，先由NettyCodecAdapter解码，再由NettyHandler处理具体的业务逻辑，再由NettyCodecAdapter编码后发送。 NettyServer既是Server又是Handler。 HeaderExchangerServer只是Server。 MultiMessageHandler是多消息处理Handler。 HeartbeatHandler是处理心跳事件的Handler。 AllChannelHandler是消息派发器，负责将请求放入线程池，并执行请求。 DecodeHandler是编解码Handler。 HeaderExchangerHandler是信息交换Handler，将请求转化成请求响应模式与同步转异步模式。 RequestHandler是最后执行的Handler，会在协议层选择Exporter后选择Invoker，进而执行Filter与Invoker，最终执行请求服务实现类方法。 Channel直接触发事件并执行Handler，Channel在有客户端连接Server的时候触发创建并封装成NettyChannel，再由HeaderExchangerHandler创建HeaderExchangerChannel，负责请求响应模式的处理。 NettyChannel其实是个Handler，HeaderExchangerChannel是个Channel， 消息的序列化与反序列化工作在NettyCodecAdapter中发起完成。 当有客户端连接Server时的连接过程： NettyHandler.connected() NettyServer.connected() MultiMessageHandler.connected() HeartbeatHandler.connected() AllChannelHandler.connected() DecodeHandler.connected() HeaderExchangerHandler.connected() requestHandler.connected() 执行服务的onconnect事件的监听方法 名词解释Invoker可执行的对象，执行具体的远程调用，能够根据方法名称，参数得到相应的执行结果。 Invocation，包含了需要执行的方法，参数等信息。目前实现类只有RpcInvocation。 有三种类型的Invoker： 本地执行类的Invoker。 远程通信执行类的Invoker。 多个远程通信执行类的Invoker聚合成集群版的Invoker。 以HelloService为例： 本地执行类的Invoker：在Server端有HelloServiceImpl实现，要执行该接口，只需要通过反射执行对应的实现类即可。 远程通信执行类的Invoker：在Client端要想执行该接口的实现方法，需要先进行远程通信，发送要执行的参数信息给Server端，Server端利用本地执行Invoker的方式执行，最后将结果发送给Client。 集群版的Invoker：Client端使用的时候，通过集群版的Invoker操作，Invoker会挑选一个远程通信类型的Invoker来执行。 提供者端的Invoker封装了服务实现类，URL，Type，状态都是只读并且线程安全。通过发起invoke来具体调用服务类。 ProxyFactory在服务提供者端，ProxyFactory主要服务的实现统一包装成一个Invoker，Invoker通过反射来执行具体的Service实现对象的方法。默认的实现是JavassistProxyFactory，代码如下： 123456789101112public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; // TODO Wrapper类不能正确处理带$的类名 final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf(&apos;$&apos;) &lt; 0 ? proxy.getClass() : type); return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &#125; &#125;;&#125; Protocol服务地址的发布和订阅。 Protocol是dubbo中的服务域，只在服务启用时加载，无状态，线程安全，是实体域Invoker暴露和引用的主功能入口，负责Invoker的生命周期管理，是Dubbo中远程服务调用层。 Protocol根据指定协议对外公布服务，当客户端根据协议调用这个服务时，Protocol会将客户端传递过来的Invocation参数交给Invoker去执行。 Protocol加入了远程通信协议，会根据客户端的请求来获取参数Invocation。 12345678910111213141516171819@Extension(&quot;dubbo&quot;)public interface Protocol &#123; int getDefaultPort(); //对于服务提供端，将本地执行类的Invoker通过协议暴漏给外部 //外部可以通过协议发送执行参数Invocation，然后交给本地Invoker来执行 @Adaptive &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException; //这个是针对服务消费端的，服务消费者从注册中心获取服务提供者发布的服务信息 //通过服务信息得知服务提供者使用的协议，然后服务消费者仍然使用该协议构造一个Invoker。这个Invoker是远程通信类的Invoker。 //执行时，需要将执行信息通过指定协议发送给服务提供者，服务提供者接收到参数Invocation，然后交给服务提供者的本地Invoker来执行 @Adaptive &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException; void destroy();&#125; 关于RegistryProtocol和DubboProtocol的疑惑以下是官方文档说明： 暴露服务: (1) 只暴露服务端口： 在没有注册中心，直接暴露提供者的情况下，即：&lt;dubbo:service regisrty=&quot;N/A&quot; /&gt; or &lt;dubbo:registry address=&quot;N/A&quot; /&gt; ServiceConfig解析出的URL的格式为：dubbo://service-host/com.foo.FooService?version=1.0.0 基于扩展点的Adaptive机制，通过URL的”dubbo://“协议头识别，直接调用DubboProtocol的export()方法，打开服务端口。 (2) 向注册中心暴露服务： 在有注册中心，需要注册提供者地址的情况下，即：&lt;dubbo:registry address=&quot;zookeeper://10.20.153.10:2181&quot; /&gt; ServiceConfig解析出的URL的格式为：registry://registry-host/com.alibaba.dubbo.registry.RegistryService?export=URL.encode(&quot;dubbo://service-host/com.foo.FooService?version=1.0.0&quot;) 基于扩展点的Adaptive机制，通过URL的”registry://“协议头识别，就会调用RegistryProtocol的export()方法，将export参数中的提供者URL，先注册到注册中心，再重新传给Protocol扩展点进行暴露：dubbo://service-host/com.foo.FooService?version=1.0.0 基于扩展点的Adaptive机制，通过提供者URL的”dubbo://“协议头识别，就会调用DubboProtocol的export()方法，打开服务端口。 RegistryProtocol，注册中心协议集成，装饰真正暴露引用服务的协议，增强注册发布功能。 ServiceConfig中的protocol是被多层装饰的Protocol，是DubboProtocol+RegistryProtocol+ProtocolListenerWrapper+ProtocolFilterWrapper。 ProtocolFilterWrapper负责初始化invoker所有的Filter。 ProtocolListenerWrapper负责初始化暴露或引用服务的监听器。 RegistryProtocol负责注册服务到注册中心和向注册中心订阅服务。 DubboProtocol负责服务的具体暴露与引用，也负责网络传输层，信息交换层的初始化，以及底层NIO框架的初始化。 Exporter负责invoker的生命周期，包含一个Invoker对象，可以撤销服务。 Exchanger负责数据交换和网络通信的组件。每个Invoker都维护了一个ExchangeClient的 引用，并通过它和远端server进行通信。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo中SPI扩展机制详解]]></title>
      <url>%2F2017%2F02%2F18%2FDubbo%E4%B8%ADSPI%E6%89%A9%E5%B1%95%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[前面我们了解过了Java的SPI扩展机制，对于Java扩展机制的原理以及优缺点也有了大概的了解，这里继续深入一下Dubbo的扩展点加载机制。 Dubbo扩展点加载的功能Dubbo的扩展点加载机制类似于Java的SPI，我们知道Java的SPI在使用的时候，只能通过遍历来进行实现的查找和实例化，有可能会一次性把所有的实现都实例化，这样会造成有些不使用的扩展实现也会被实例化，这就会造成一定的资源浪费。有关Dubbo的改进，参照文档上的说明： JDK标准的SPI会一次性实例化扩展点所有实现，如果有扩展实现初始化很耗时，但如果没用上也加载，会很浪费资源。 如果扩展点加载失败，连扩展点的名称都拿不到了。比如：JDK标准的ScriptEngine，通过getName();获取脚本类型的名称，但如果RubyScriptEngine因为所依赖的jruby.jar不存在，导致RubyScriptEngine类加载失败，这个失败原因被吃掉了，和ruby对应不起来，当用户执行ruby脚本时，会报不支持ruby，而不是真正失败的原因。 增加了对扩展点IoC和AOP的支持，一个扩展点可以直接setter注入其它扩展点。 关于第一点，通过和Java的SPI对比，就能明白；第二点还未做测试，不太清楚其中的缘由；第三点对于IOC和AOP的支持下面简单介绍下。 扩展点自动装配功能（IOC）就是当加载一个扩展点时，会自动的注入这个扩展点所依赖的其他扩展点，如果描述不清楚的话，可以看下下面的例子： 12接口A，实现类A1，A2接口B，实现类B1，B2 其中实现类A1含有setB()方法，当通过扩展机制加载A的实现的时候，会自动的注入一个B的实现类，但是，此时不是注入B1，也不是注入B2，而是注入一个自适应的B的实现类：B$Adpative，该实现类是动态生成的，能够根据参数的不同，自动选择B1或者B2来进行调用。 扩展点自适应上面我们说，在自动装配的时候，并不是注入一个真正的实现，而是注入一个自适应的扩展点实现，其实就是动态的生成的代码，也就是手动拼装的代码，这段代码里会根据SPI上配置的信息来加入对于具体实现的选择功能。生成的代码类似于下面的，代码做了一下精简，把包都去掉了： 12345678910111213141516171819202122232425262728293031323334353637import com.alibaba.dubbo.common.extension.ExtensionLoader;public class Protocol$Adpative implements Protocol &#123; public Invoker refer(Class arg0, URL arg1) throws Class &#123; if (arg1 == null) throw new IllegalArgumentException(&quot;url == null&quot;); URL url = arg1; String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); Protocol extension = (Protocol)ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); &#125; public Exporter export(Invoker arg0) throws Invoker &#123; if (arg0 == null) throw new IllegalArgumentException(&quot;Invoker argument == null&quot;); if (arg0.getUrl() == null) throw new IllegalArgumentException(&quot;Invoker argument getUrl() == null&quot;);URL url = arg0.getUrl(); //这里会根据url中的信息获取具体的实现类名 String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); //根据上面的实现类名，会在运行时，通过Dubbo的扩展机制加载具体实现类 Protocol extension = (Protocol)ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(extName); return extension.export(arg0); &#125; public void destroy() &#123; throw new UnsupportedOperationException(&quot;method public abstract void Protocol.destroy() of interface Protocol is not adaptive method!&quot;); &#125; public int getDefaultPort() &#123; throw new UnsupportedOperationException(&quot;method public abstract int Protocol.getDefaultPort() of interface Protocol is not adaptive method!&quot;); &#125;&#125; 使用这种方式的原因也很容易能想到，在我们加载扩展点实现的时候，并没有调用实现的具体逻辑，那我们注入一个扩展点，也就不知道这个扩展点的实现具体是什么，所以要注入一个自适应的实现。等到运行时候，才根据自适应实现，来调用真正实现。 扩展点自动包装功能（AOP）先看下下面的示例，假如接口A还有另外一个实现者：AWrapper1： 1234567class AWrapper1 implements A&#123; private A a; AWrapper1(A a)&#123; this.a = a; &#125; &#125; AWrapper1相当于A的包装类，类似于AOP的功能，AWrapper1增加了A的功能。当我们获取接口A的实现类的时候，得到的就是包装过的类。 Dubbo扩展点加载的实现首先还是定义接口，然后是接口的具体实现类，配置文件类似于Java的SPI配置文件，Dubbo的配置文件放在META-INF/dubbo/目录下，配置文件名为接口的全限定名，配置文件内容是配置名=扩展实现类的全限定名，加载实现类的功能是通过ExtensionLoader来实现，类似于Java中的ServiceLoader的作用。 另外，扩展点使用单一实例加载，需要确保线程安全性。 Dubbo扩展点加载的一些定义 @SPI注解，被此注解标记的接口，就表示是一个可扩展的接口。 @Adaptive注解，有两种注解方式：一种是注解在类上，一种是注解在方法上。 注解在类上，而且是注解在实现类上，目前dubbo只有AdaptiveCompiler和AdaptiveExtensionFactory类上标注了此注解，这是些特殊的类，ExtensionLoader需要依赖他们工作，所以得使用此方式。 注解在方法上，注解在接口的方法上，除了上面两个类之外，所有的都是注解在方法上。ExtensionLoader根据接口定义动态的生成适配器代码，并实例化这个生成的动态类。被Adaptive注解的方法会生成具体的方法实现。没有注解的方法生成的实现都是抛不支持的操作异常UnsupportedOperationException。被注解的方法在生成的动态类中，会根据url里的参数信息，来决定实际调用哪个扩展。 比如说这段代码： 1private static final Protocol refprotocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); 当上面代码执行的时候，我们其实还不知道要真正使用的Protocol是什么，可能是具体的实现DubboProtocol，也可能是其他的具体实现的Protocol，那么这时候refprotocol到底是什么呢？refprotocol其实是在调用getAdaptiveExtension()方法时候，自动生成的一个类，代码如下： 12345678910111213141516171819202122232425262728293031323334353637import com.alibaba.dubbo.common.extension.ExtensionLoader;public class Protocol$Adpative implements Protocol &#123; public Invoker refer(Class arg0, URL arg1) throws Class &#123; if (arg1 == null) throw new IllegalArgumentException(&quot;url == null&quot;); URL url = arg1; String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); Protocol extension = (Protocol)ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); &#125; public Exporter export(Invoker arg0) throws Invoker &#123; if (arg0 == null) throw new IllegalArgumentException(&quot;Invoker argument == null&quot;); if (arg0.getUrl() == null) throw new IllegalArgumentException(&quot;Invoker argument getUrl() == null&quot;);URL url = arg0.getUrl(); String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); Protocol extension = (Protocol)ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(extName); return extension.export(arg0); &#125; public void destroy() &#123; throw new UnsupportedOperationException(&quot;method public abstract void Protocol.destroy() of interface Protocol is not adaptive method!&quot;); &#125; public int getDefaultPort() &#123; throw new UnsupportedOperationException(&quot;method public abstract int Protocol.getDefaultPort() of interface Protocol is not adaptive method!&quot;); &#125;&#125; 可以看到被@Adaptive注解的方法都生成了具体的实现，并且实现逻辑都相同。而没有被注解的方法直接抛出不支持操作的异常。 当我们使用refprotocol调用方法的时候，其实是调用生成的类Protocol$Adpative中的方法，这里面的方法根据url中的参数配置来找到具体的实现类，找具体实现类的方式还是通过dubbo的扩展机制。比如url中可能会有protocol=dubbo，此时就可以根据这个dubbo来确定我们要找的类是DubboProtocol。可以查看下生成的代码中getExtension(extName)这里是根据具体的名字去查找实现类。 @Activate注解，此注解需要注解在类上或者方法上，并注明被激活的条件，以及所有的被激活实现类中的排序信息。 ExtensionLoader，是dubbo的SPI机制的查找服务实现的工具类，类似与Java的ServiceLoader，可做类比。dubbo约定扩展点配置文件放在classpath下的/META-INF/dubbo，/META-INF/dubbo/internal，/META-INF/services目录下，配置文件名为接口的全限定名，配置文件内容为配置名=扩展实现类的全限定名。 Dubbo扩展点加载的源码解析重点解析下ExtensionLoader这个类。Dubbo的扩展点使用单一实例去加载，缓存在ExtensionLoader中。每一个ExtensionLoader实例仅负责加载特定SPI扩展的实现，想要获得某个扩展的实现，首先要获得该扩展对应的ExtensionLoader实例。 以Protocol为例进行分析扩展点的加载： 1234//这样使用，先获取ExtensionLoader实例，然后加载自适应的Protocol扩展点Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();//使用protocol.refer(Class&lt;T&gt; type, URL url))； 可以看到，使用扩展点加载的步骤大概有三步： 获取ExtensionLoader实例。 获取自适应实现。 使用获取到的实现。 下面我们就以这三步作为分界，来深入源码的解析。 获取ExtensionLoader实例第一步，getExtensionLoader(Protocol.class)，根据要加载的接口Protocol，创建出一个ExtensionLoader实例，加载完的实例会被缓存起来，下次再加载Protocol的ExtensionLoader的时候，会使用已经缓存的这个，不会再新建一个实例： 1234567891011121314151617181920212223242526public static &lt;T&gt; ExtensionLoader&lt;T&gt; getExtensionLoader(Class&lt;T&gt; type) &#123; //扩展点类型不能为空 if (type == null) throw new IllegalArgumentException(); //扩展点类型只能是接口类型的 if(!type.isInterface()) &#123; throw new IllegalArgumentException(); &#125; //没有添加@SPI注解，只有注解了@SPI的才会解析 if(!withExtensionAnnotation(type)) &#123; throw new IllegalArgumentException(); &#125; //先从缓存中获取指定类型的ExtensionLoader //EXTENSION_LOADERS是一个ConcurrentHashMap，缓存了所有已经加载的ExtensionLoader的实例 //比如这里加载Protocol.class，就以Protocol.class作为key，以新创建的ExtensionLoader作为value //每一个要加载的扩展点只会对应一个ExtensionLoader实例，也就是只会存在一个Protocol.class在缓存中 ExtensionLoader&lt;T&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); //缓存中不存在 if (loader == null) &#123; //创建一个新的ExtensionLoader实例，放到缓存中去 //对于每一个扩展，dubbo中只有一个对应的ExtensionLoader实例 EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader&lt;T&gt;(type)); loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); &#125; return loader;&#125; 上面代码返回一个ExtensionLoader实例，getExtensionLoader(Protocol.class)这一步没有进行任何的加载工作，只是获得了一个ExtensionLoader的实例。 ExtensionLoader的构造方法上面获取的是一个ExtensionLoader实例，接着看下构造实例的时候到底做了什么，我们发现在ExtensionLoader中只有一个私有的构造方法： 1234567891011private ExtensionLoader(Class&lt;?&gt; type) &#123; //接口类型 this.type = type; //对于扩展类型是ExtensionFactory的，设置为null //getAdaptiveExtension方法获取一个运行时自适应的扩展类型 //每个Extension只能有一个@Adaptive类型的实现，如果么有，dubbo会自动生成一个类 //objectFactory是一个ExtensionFactory类型的属性，主要用于加载需要注入的类型的实现 //objectFactory主要用在注入那一步，详细说明见注入时候的说明 //这里记住非ExtensionFactory类型的返回的都是一个AdaptiveExtensionFactory objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());&#125; 不难理解，ExtensionFactory是主要是用来加载被注入的类的实现，分为SpiExtensionFactory和SpringExtensionFactory两个，分别用来加载SPI扩展实现和Spring中bean的实现。 获取自适应实现上面返回一个ExtensionLoader的实例之后，开始加载自适应实现，加载是在调用getAdaptiveExtension()方法中进行的： 12345getAdaptiveExtension()--&gt; createAdaptiveExtension()--&gt; getAdaptiveExtensionClass()--&gt; getExtensionClasses()--&gt; loadExtensionClasses() 先看下getAdaptiveExtension()方法，用来获取一个扩展的自适应实现类，最后返回的自适应实现类是一个类名为Protocol$Adaptive的类，并且这个类实现了Protocol接口： 123456789101112131415161718192021222324public T getAdaptiveExtension() &#123; //先从实例缓存中查找实例对象 //private final Holder&lt;Object&gt; cachedAdaptiveInstance = new Holder&lt;Object&gt;(); //在当前的ExtensionLoader中保存着一个Holder实例，用来缓存自适应实现类的实例 Object instance = cachedAdaptiveInstance.get(); if (instance == null) &#123;//缓存中不存在 if(createAdaptiveInstanceError == null) &#123; synchronized (cachedAdaptiveInstance) &#123; //获取锁之后再检查一次缓存中是不是已经存在 instance = cachedAdaptiveInstance.get(); if (instance == null) &#123; try &#123; //缓存中没有，就创建新的AdaptiveExtension实例 instance = createAdaptiveExtension(); //新实例加入缓存 cachedAdaptiveInstance.set(instance); &#125; catch (Throwable t) &#123;createAdaptiveInstanceError = t; &#125; &#125; &#125; &#125; &#125; return (T) instance;&#125; 创建自适应扩展缓存中不存在自适应扩展的实例，表示还没有创建过自适应扩展的实例，接下来就是创建自适应扩展实现，createAdaptiveExtension()方法，用来创建自适应扩展类的实例： 12345678private T createAdaptiveExtension() &#123; try &#123; //先通过getAdaptiveExtensionClass获取AdaptiveExtensionClass //然后获取其实例 //最后进行注入处理 return injectExtension((T) getAdaptiveExtensionClass().newInstance()); &#125; catch (Exception e) &#123;&#125;&#125; 获取自适应扩展类接着查看getAdaptiveExtensionClass()方法，用来获取一个自适应扩展的Class，这个Class将会在下一步被实例化： 123456789101112131415private Class&lt;?&gt; getAdaptiveExtensionClass() &#123; //加载当前Extension的所有实现（这里举例是Protocol，只会加载Protocol的所有实现类），如果有@Adaptive类型的实现类，会赋值给cachedAdaptiveClass //目前只有AdaptiveExtensionFactory和AdaptiveCompiler两个实现类是被注解了@Adaptive //除了ExtensionFactory和Compiler类型的扩展之外，其他类型的扩展都是下面动态创建的的实现 getExtensionClasses(); //加载完所有的实现之后，发现有cachedAdaptiveClass不为空 //也就是说当前获取的自适应实现类是AdaptiveExtensionFactory或者是AdaptiveCompiler，就直接返回，这两个类是特殊用处的，不用代码生成，而是现成的代码 if (cachedAdaptiveClass != null) &#123; return cachedAdaptiveClass; &#125; //没有找到Adaptive类型的实现，动态创建一个 //比如Protocol的实现类，没有任何一个实现是用@Adaptive来注解的，只有Protocol接口的方法是有注解的 //这时候就需要来动态的生成了，也就是生成Protocol$Adaptive return cachedAdaptiveClass = createAdaptiveExtensionClass();&#125; 加载扩展类实现先看下getExtensionClasses()这个方法，加载所有的扩展类的实现： 123456789101112131415161718192021private Map&lt;String, Class&lt;?&gt;&gt; getExtensionClasses() &#123; //从缓存中获取，cachedClasses也是一个Holder，Holder这里持有的是一个Map，key是扩展点实现名，value是扩展点实现类 //这里会存放当前扩展点类型的所有的扩展点的实现类 //这里以Protocol为例，就是会存放Protocol的所有实现类 //比如key为dubbo，value为com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol //cachedClasses扩展点实现名称对应的实现类 Map&lt;String, Class&lt;?&gt;&gt; classes = cachedClasses.get(); //如果为null，说明没有被加载过，就会进行加载，而且加载就只会进行这一次 if (classes == null) &#123; synchronized (cachedClasses) &#123; classes = cachedClasses.get(); if (classes == null) &#123; //如果没有加载过Extension的实现，进行扫描加载，完成后缓存起来 //每个扩展点，其实现的加载只会这执行一次 classes = loadExtensionClasses(); cachedClasses.set(classes); &#125; &#125; &#125; return classes;&#125; 看下loadExtensionClasses()方法，这个方法中加载扩展点的实现类： 12345678910111213141516171819202122232425262728private Map&lt;String, Class&lt;?&gt;&gt; loadExtensionClasses() &#123; final SPI defaultAnnotation = type.getAnnotation(SPI.class); if(defaultAnnotation != null) &#123; //当前Extension的默认实现名字 //比如说Protocol接口，注解是@SPI(&quot;dubbo&quot;) //这里dubbo就是默认的值 String value = defaultAnnotation.value(); //只能有一个默认的名字，如果多了，谁也不知道该用哪一个实现了。 if(value != null &amp;&amp; (value = value.trim()).length() &gt; 0) &#123; String[] names = NAME_SEPARATOR.split(value); if(names.length &gt; 1) &#123; throw new IllegalStateException(); &#125; //默认的名字保存起来 if(names.length == 1) cachedDefaultName = names[0]; &#125; &#125; //下面就开始从配置文件中加载扩展实现类 Map&lt;String, Class&lt;?&gt;&gt; extensionClasses = new HashMap&lt;String, Class&lt;?&gt;&gt;(); //从META-INF/dubbo/internal目录下加载 loadFile(extensionClasses, DUBBO_INTERNAL_DIRECTORY); //从META-INF/dubbo/目录下加载 loadFile(extensionClasses, DUBBO_DIRECTORY); //从META-INF/services/下加载 loadFile(extensionClasses, SERVICES_DIRECTORY); return extensionClasses;&#125; 从各个位置的配置文件中加载实现类，对于Protocol来说加载的文件是以com.alibaba.dubbo.rpc.Protocol为名称的文件，文件的内容是（有好几个同名的配置文件，这里直接把内容全部写在了一起）： 1234567891011121314151617181920212223registry=com.alibaba.dubbo.registry.integration.RegistryProtocolfilter=com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapperlistener=com.alibaba.dubbo.rpc.protocol.ProtocolListenerWrappermock=com.alibaba.dubbo.rpc.support.MockProtocoldubbo=com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocolhessian=com.alibaba.dubbo.rpc.protocol.hessian.HessianProtocolcom.alibaba.dubbo.rpc.protocol.http.HttpProtocolinjvm=com.alibaba.dubbo.rpc.protocol.injvm.InjvmProtocolmemcached=memcom.alibaba.dubbo.rpc.protocol.memcached.MemcachedProtocolredis=com.alibaba.dubbo.rpc.protocol.redis.RedisProtocolrmi=com.alibaba.dubbo.rpc.protocol.rmi.RmiProtocolthrift=com.alibaba.dubbo.rpc.protocol.thrift.ThriftProtocolcom.alibaba.dubbo.rpc.protocol.webservice.WebServiceProtocol 看下loadFile()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126private void loadFile(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, String dir) &#123; //配置文件的名称 //这里type是扩展类，比如com.alibaba.dubbo.rpc.Protocol类 String fileName = dir + type.getName(); try &#123; Enumeration&lt;java.net.URL&gt; urls; //获取类加载器 ClassLoader classLoader = findClassLoader(); //获取对应配置文件名的所有的文件 if (classLoader != null) &#123; urls = classLoader.getResources(fileName); &#125; else &#123; urls = ClassLoader.getSystemResources(fileName); &#125; if (urls != null) &#123; //遍历文件进行处理 while (urls.hasMoreElements()) &#123; //配置文件路径 java.net.URL url = urls.nextElement(); try &#123; BufferedReader reader = new BufferedReader(new InputStreamReader(url.openStream(), &quot;utf-8&quot;)); try &#123; String line = null; //每次处理一行 while ((line = reader.readLine()) != null) &#123; //#号以后的为注释 final int ci = line.indexOf(&apos;#&apos;); //注释去掉 if (ci &gt;= 0) line = line.substring(0, ci); line = line.trim(); if (line.length() &gt; 0) &#123; try &#123; String name = null; //=号之前的为扩展名字，后面的为扩展类实现的全限定名 int i = line.indexOf(&apos;=&apos;); if (i &gt; 0) &#123; name = line.substring(0, i).trim(); line = line.substring(i + 1).trim(); &#125; if (line.length() &gt; 0) &#123; //加载扩展类的实现 Class&lt;?&gt; clazz = Class.forName(line, true, classLoader); //查看类型是否匹配 //type是Protocol接口 //clazz就是Protocol的各个实现类 if (! type.isAssignableFrom(clazz)) &#123; throw new IllegalStateException(); &#125; //如果实现类是@Adaptive类型的，会赋值给cachedAdaptiveClass，这个用来存放被@Adaptive注解的实现类 if (clazz.isAnnotationPresent(Adaptive.class)) &#123; if(cachedAdaptiveClass == null) &#123; cachedAdaptiveClass = clazz; &#125; else if (! cachedAdaptiveClass.equals(clazz)) &#123; throw new IllegalStateException(); &#125; &#125; else &#123;//不是@Adaptice类型的类，就是没有注解@Adaptive的实现类 try &#123;//判断是否是wrapper类型 //如果得到的实现类的构造方法中的参数是扩展点类型的，就是一个Wrapper类 //比如ProtocolFilterWrapper，实现了Protocol类， //而它的构造方法是这样public ProtocolFilterWrapper(Protocol protocol) //就说明这个类是一个包装类 clazz.getConstructor(type); //cachedWrapperClasses用来存放当前扩展点实现类中的包装类 Set&lt;Class&lt;?&gt;&gt; wrappers = cachedWrapperClasses; if (wrappers == null) &#123; cachedWrapperClasses = new ConcurrentHashSet&lt;Class&lt;?&gt;&gt;(); wrappers = cachedWrapperClasses; &#125; wrappers.add(clazz); &#125; catch (NoSuchMethodException e) &#123; //没有上面提到的构造器，则说明不是wrapper类型 //获取无参构造 clazz.getConstructor(); //没有名字，就是配置文件中没有xxx=xxxx.com.xxx这种 if (name == null || name.length() == 0) &#123; //去找@Extension注解中配置的值 name = findAnnotationName(clazz); //如果还没找到名字，从类名中获取 if (name == null || name.length() == 0) &#123; //比如clazz是DubboProtocol，type是Protocol //这里得到的name就是dubbo if (clazz.getSimpleName().length() &gt; type.getSimpleName().length() &amp;&amp; clazz.getSimpleName().endsWith(type.getSimpleName())) &#123; name = clazz.getSimpleName().substring(0, clazz.getSimpleName().length() - type.getSimpleName().length()).toLowerCase(); &#125; else &#123; throw new IllegalStateException(&quot;); &#125; &#125; &#125; //有可能配置了多个名字 String[] names = NAME_SEPARATOR.split(name); if (names != null &amp;&amp; names.length &gt; 0) &#123; //是否是Active类型的类 Activate activate = clazz.getAnnotation(Activate.class); if (activate != null) &#123; //第一个名字作为键，放进cachedActivates这个map中缓存 cachedActivates.put(names[0], activate); &#125; for (String n : names) &#123; if (! cachedNames.containsKey(clazz)) &#123; //放入Extension实现类与名称映射的缓存中去，每个class只对应第一个名称有效 cachedNames.put(clazz, n); &#125; Class&lt;?&gt; c = extensionClasses.get(n); if (c == null) &#123; //放入到extensionClasses缓存中去，多个name可能对应一份extensionClasses extensionClasses.put(n, clazz); &#125; else if (c != clazz) &#123; throw new IllegalStateException(); &#125; &#125; &#125; &#125; &#125; &#125; &#125; catch (Throwable t) &#123; &#125; &#125; &#125; // end of while read lines &#125; finally &#123; reader.close(); &#125; &#125; catch (Throwable t) &#123; &#125; &#125; // end of while urls &#125; &#125; catch (Throwable t) &#123; &#125;&#125; 到这里加载当前Extension的所有实现就已经完成了，继续返回getAdaptiveExtensionClass中，在调用完getExtensionClasses()之后，会首先检查是不是已经有@Adaptive注解的类被解析并加入到缓存中了，如果有就直接返回，这里的cachedAdaptiveClass中现在只能是AdaptiveExtensionFactory或者AdaptiveCompiler中的一个，如果没有，说明是一个普通扩展点，就动态创建一个，比如会创建一个Protocol$Adaptive。 创建自适应扩展类的代码看下createAdaptiveExtensionClass()这个方法，用来动态的创建自适应扩展类： 12345678910111213141516private Class&lt;?&gt; createAdaptiveExtensionClass() &#123; //组装自适应扩展点类的代码 String code = createAdaptiveExtensionClassCode(); //获取到应用的类加载器 ClassLoader classLoader = findClassLoader(); //获取编译器 //dubbo默认使用javassist //这里还是使用扩展点机制来找具体的Compiler的实现 //现在就知道cachedAdaptiveClass是啥意思了，如果没有AdaptiveExtensionFactory和AdaptiveCompiler这两个类，这里又要去走加载流程然后来生成扩展点类的代码，不就死循环了么。 //这里解析Compiler的实现类的时候，会在getAdaptiveExtensionClass中直接返回 //可以查看下AdaptiveCompiler这个类，如果我们没有指定，默认使用javassist //这里Compiler是JavassistCompiler实例 com.alibaba.dubbo.common.compiler.Compiler compiler = ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.common.compiler.Compiler.class).getAdaptiveExtension(); //将代码转换成Class return compiler.compile(code, classLoader);&#125; 接着看下createAdaptiveExtensionClassCode()方法，用来组装自适应扩展类的代码（拼写源码，代码比较长不在列出），这里列出生成的Protocol$Adaptive： 12345678910111213141516171819202122232425262728293031323334353637import com.alibaba.dubbo.common.extension.ExtensionLoader;public class Protocol$Adpative implements com.alibaba.dubbo.rpc.Protocol &#123; public com.alibaba.dubbo.rpc.Invoker refer(java.lang.Class arg0, com.alibaba.dubbo.common.URL arg1) throws java.lang.Class &#123; if (arg1 == null) throw new IllegalArgumentException(&quot;url == null&quot;); com.alibaba.dubbo.common.URL url = arg1; String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); &#125; public com.alibaba.dubbo.rpc.Exporter export(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker &#123; if (arg0 == null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument == null&quot;); if (arg0.getUrl() == null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument getUrl() == null&quot;);com.alibaba.dubbo.common.URL url = arg0.getUrl(); String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName); return extension.export(arg0); &#125; public void destroy() &#123; throw new UnsupportedOperationException(&quot;method public abstract void com.alibaba.dubbo.rpc.Protocol.destroy() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!&quot;); &#125; public int getDefaultPort() &#123; throw new UnsupportedOperationException(&quot;method public abstract int com.alibaba.dubbo.rpc.Protocol.getDefaultPort() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!&quot;); &#125;&#125; 其他具体的扩展点的生成也类似。在生成完代码之后，是找到ClassLoader，然后获取到Compiler的自适应实现，这里得到的就是AdaptiveCompiler，最后调用compiler.compile(code, classLoader);来编译上面生成的类并返回，先进入AdaptiveCompiler的compile方法： 123456789101112131415public Class&lt;?&gt; compile(String code, ClassLoader classLoader) &#123; Compiler compiler; //得到一个ExtensionLoader ExtensionLoader&lt;Compiler&gt; loader = ExtensionLoader.getExtensionLoader(Compiler.class); //默认的Compiler名字 String name = DEFAULT_COMPILER; // copy reference //有指定了Compiler名字，就使用指定的名字来找到Compiler实现类 if (name != null &amp;&amp; name.length() &gt; 0) &#123; compiler = loader.getExtension(name); &#125; else &#123;//没有指定Compiler名字，就查找默认的Compiler的实现类 compiler = loader.getDefaultExtension(); &#125; //调用具体的实现类来进行编译 return compiler.compile(code, classLoader);&#125; 获取指定名字的扩展先看下根据具体的名字来获取扩展的实现类loader.getExtension(name);，loader是ExtensionLoader&lt;Compiler&gt;类型的。这里就是比Java的SPI要方便的地方，Java的SPI只能通过遍历所有的实现类来查找，而dubbo能够指定一个名字查找。代码如下： 1234567891011121314151617181920212223242526272829303132public T getExtension(String name) &#123; if (name == null || name.length() == 0) throw new IllegalArgumentException(&quot;Extension name == null&quot;); //如果name指定为true，则获取默认实现 if (&quot;true&quot;.equals(name)) &#123; //默认实现查找在下面解析 return getDefaultExtension(); &#125; //先从缓存获取Holder，cachedInstance是一个ConcurrentHashMap，键是扩展的name，值是一个持有name对应的实现类实例的Holder。 Holder&lt;Object&gt; holder = cachedInstances.get(name); //如果当前name对应的Holder不存在，就创建一个，添加进map中 if (holder == null) &#123; cachedInstances.putIfAbsent(name, new Holder&lt;Object&gt;()); holder = cachedInstances.get(name); &#125; //从Holder中获取保存的实例 Object instance = holder.get(); //不存在，就需要根据这个name找到实现类，实例化一个 if (instance == null) &#123; synchronized (holder) &#123; instance = holder.get(); if (instance == null) &#123; //缓存不存在，创建实例 instance = createExtension(name); //加入缓存 holder.set(instance); &#125; &#125; &#125; //存在，就直接返回 return (T) instance;&#125; 创建扩展实例，createExtension(name);： 1234567891011121314151617181920212223242526272829private T createExtension(String name) &#123; //getExtensionClasses加载当前Extension的所有实现 //上面已经解析过，返回的是一个Map，键是name，值是name对应的Class //根据name查找对应的Class Class&lt;?&gt; clazz = getExtensionClasses().get(name); //如果这时候class还不存在，说明在所有的配置文件中都没找到定义，抛异常 if (clazz == null) &#123; throw findException(name); &#125; try &#123; //从已创建实例缓存中获取 T instance = (T) EXTENSION_INSTANCES.get(clazz); //不存在的话就创建一个新实例，加入到缓存中去 if (instance == null) &#123; EXTENSION_INSTANCES.putIfAbsent(clazz, (T) clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); &#125; //属性注入 injectExtension(instance); //Wrapper的包装 Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; if (wrapperClasses != null &amp;&amp; wrapperClasses.size() &gt; 0) &#123; for (Class&lt;?&gt; wrapperClass : wrapperClasses) &#123; instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); &#125; &#125; return instance; &#125; catch (Throwable t) &#123; &#125;&#125; 有关属性注入和Wrapper的包装，下面再讲。到这里Compiler就能获得到一个指定name的具体实现类的实例了，然后就是调用实例的compile()方法对生成的代码进行编译。 获取默认扩展实现如果在AdaptiveCompiler中没有找到指定的名字，就会找默认的扩展实现loader.getDefaultExtension();： 123456789101112public T getDefaultExtension() &#123; //首先还是先去加载所有的扩展实现 //加载的时候会设置默认的名字cachedDefaultName，这个名字是在@SPI中指定的，比如Compiler就指定了@SPI(&quot;javassist&quot;)，所以这里是javassist getExtensionClasses(); if(null == cachedDefaultName || cachedDefaultName.length() == 0 || &quot;true&quot;.equals(cachedDefaultName)) &#123; return null; &#125; //根据javassist这个名字去查找扩展实现 //具体的过程上面已经解析过了 return getExtension(cachedDefaultName);&#125; 关于javassist编译Class的过程暂先不说明。我们接着流程看： 12345678 private T createAdaptiveExtension() &#123; try &#123; //先通过getAdaptiveExtensionClass获取AdaptiveExtensionClass（在上面这一步已经解析了，获得到了一个自适应实现类的Class） //然后获取其实例，newInstance进行实例 //最后进行注入处理injectExtension return injectExtension((T) getAdaptiveExtensionClass().newInstance()); &#125; catch (Exception e) &#123; &#125;&#125; 扩展点注入接下来就是有关扩展点的注入的问题了，injectExtension，关于注入的解释查看最上面扩展点自动装配（IOC）的说明，injectExtension方法： 1234567891011121314151617181920212223242526272829303132333435//这里的实例是Xxxx$Adaptiveprivate T injectExtension(T instance) &#123; try &#123; //关于objectFactory的来路，先看下面的解析 //这里的objectFactory是AdaptiveExtensionFactory if (objectFactory != null) &#123; //遍历扩展实现类实例的方法 for (Method method : instance.getClass().getMethods()) &#123; //只处理set方法 //set开头，只有一个参数，public if (method.getName().startsWith(&quot;set&quot;) &amp;&amp; method.getParameterTypes().length == 1 &amp;&amp; Modifier.isPublic(method.getModifiers())) &#123; //set方法参数类型 Class&lt;?&gt; pt = method.getParameterTypes()[0]; try &#123; //setter方法对应的属性名 String property = method.getName().length() &gt; 3 ? method.getName().substring(3, 4).toLowerCase() + method.getName().substring(4) : &quot;&quot;; //根据类型和名称信息从ExtensionFactory中获取 //比如在某个扩展实现类中会有setProtocol(Protocol protocol)这样的set方法 //这里pt就是Protocol，property就是protocol //AdaptiveExtensionFactory就会根据这两个参数去查找对应的扩展实现类 //这里就会返回Protocol$Adaptive Object object = objectFactory.getExtension(pt, property); if (object != null) &#123;//说明set方法的参数是扩展点类型，进行注入 //为set方法注入一个自适应的实现类 method.invoke(instance, object); &#125; &#125; catch (Exception e) &#123; &#125; &#125; &#125; &#125; &#125; catch (Exception e) &#123;&#125; return instance;&#125; 有关AdaptiveExtensionFactory中获取Extension的过程，会首先在实例化的时候得到ExtensionFactory的具体实现类，然后遍历每个ExtensionFactory的实现类，分别在每个ExtensionFactory的实现类中获取Extension。 这里使用SpiExtensionFactory的获取扩展的方法为例，getExtension，也是先判断给定类是否是注解了@SPI的接口，然后根据类去获取ExtensionLoader，在使用得到的ExtensionLoader去加载自适应扩展。 objectFactory的来历objectFactory的来路，在ExtensionLoader中有个私有构造器： 123456789101112131415//当我们调用getExtensionLoader这个静态方法的时候，会触发ExtensionLoader类的实例化，会先初始化静态变量和静态块，然后是构造代码块，最后是构造器的初始化private ExtensionLoader(Class&lt;?&gt; type) &#123; this.type = type; //这里会获得一个AdaptiveExtensionFactory //根据类型和名称信息从ExtensionFactory中获取 //获取实现 //为什么要使用对象工厂来获取setter方法中对应的实现？ //不能通过spi直接获取自适应实现吗？比如ExtensionLoader.getExtension(pt); //因为setter方法中有可能是一个spi，也有可能是普通的bean //所以此时不能写死通过spi获取，还需要有其他方式来获取实现进行注入 // dubbo中有两个实现，一个是spi的ExtensionFactory，一个是spring的ExtensionFactory //如果还有其他的，我们可以自定义ExtensionFactory //objectFactory是AdaptiveExtensionFactory实例 objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());&#125; 到此为止createAdaptiveExtension方法解析完成，接着返回上层getAdaptiveExtension()方法中，发现创建完自适应扩展实例之后，就会加入到cachedAdaptiveInstance缓存起来，然后就会返回给调用的地方一个Xxx$Adaptive实例。 走到这里，下面的代码就解析完了： 1private static final Protocol refprotocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); 得到扩展之后的使用我们得到了一个Protocol$Adaptive实例，接着就是调用了，比如说我们要调用refprotocol.refer(Class&lt;T&gt; type, URL url))方法，由于这里refprotocol是一个Protocol$Adaptive实例，所以就先调用这个实例的refer方法，这里的实例的代码在最上面： 12345678910111213//这里为了好看，代码做了精简，包名都去掉了public Invoker refer(Class arg0, URL arg1) throws Class &#123; if (arg1 == null) throw new IllegalArgumentException(); URL url = arg1; String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName == null) throw new IllegalStateException(); Protocol extension = (Protocol)ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); &#125; 可以看到这里首先根据url中的参数获取扩展名字，如果url中没有就使用默认的扩展名，然后根据扩展名去获取具体的实现。关于getExtension(String name)上面已经解析过一次，这里再次列出： 1234567891011121314151617181920212223242526272829303132public T getExtension(String name) &#123; if (name == null || name.length() == 0) throw new IllegalArgumentException(&quot;Extension name == null&quot;); //如果name指定为true，则获取默认实现 if (&quot;true&quot;.equals(name)) &#123; //默认实现查找在下面解析 return getDefaultExtension(); &#125; //先从缓存获取Holder，cachedInstance是一个ConcurrentHashMap，键是扩展的name，值是一个持有name对应的实现类实例的Holder。 Holder&lt;Object&gt; holder = cachedInstances.get(name); //如果当前name对应的Holder不存在，就创建一个，添加进map中 if (holder == null) &#123; cachedInstances.putIfAbsent(name, new Holder&lt;Object&gt;()); holder = cachedInstances.get(name); &#125; //从Holder中获取保存的实例 Object instance = holder.get(); //不存在，就需要根据这个name找到实现类，实例化一个 if (instance == null) &#123; synchronized (holder) &#123; instance = holder.get(); if (instance == null) &#123; //缓存不存在，创建实例 instance = createExtension(name); //加入缓存 holder.set(instance); &#125; &#125; &#125; //存在，就直接返回 return (T) instance;&#125; 创建扩展实例，createExtension(name);： 12345678910111213141516171819202122232425262728293031323334353637383940private T createExtension(String name) &#123; //getExtensionClasses加载当前Extension的所有实现 //上面已经解析过，返回的是一个Map，键是name，值是name对应的Class //根据name查找对应的Class //比如name是dubbo，Class就是com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol Class&lt;?&gt; clazz = getExtensionClasses().get(name); //如果这时候class还不存在，说明在所有的配置文件中都没找到定义，抛异常 if (clazz == null) &#123; throw findException(name); &#125; try &#123; //从已创建实例缓存中获取 T instance = (T) EXTENSION_INSTANCES.get(clazz); //不存在的话就创建一个新实例，加入到缓存中去 if (instance == null) &#123; EXTENSION_INSTANCES.putIfAbsent(clazz, (T) clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); &#125; //这里实例就是具体实现的实例了比如是DubboProtocol的实例 //属性注入，在上面已经解析过了，根据实例中的setXxx方法进行注入 injectExtension(instance); //Wrapper的包装 //cachedWrapperClasses存放着所有的Wrapper类 //cachedWrapperClasses是在加载扩展实现类的时候放进去的 //Wrapper类的说明在最上面扩展点自动包装（AOP） Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; if (wrapperClasses != null &amp;&amp; wrapperClasses.size() &gt; 0) &#123; for (Class&lt;?&gt; wrapperClass : wrapperClasses) &#123; //比如在包装之前的instance是DubboProtocol实例 //先使用构造器来实例化当前的包装类 //包装类中就已经包含了我们的DubboProtocol实例 //然后对包装类进行injectExtension注入，注入过程在上面 //最后返回的Instance就是包装类的实例。 instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); &#125; &#125; //这里返回的是经过所有的包装类包装之后的实例 return instance; &#125; catch (Throwable t) &#123; &#125;&#125; 获取的Extension是经过层层包装的扩展实现，然后就是调用经过包装的refer方法了，这就到了具体的实现中的方法了。 到此为止调用refprotocol.refer(Class&lt;T&gt; type, URL url))方法的过程也解析完了。 关于getActivateExtension方法的解析，等下再添加。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring ApplicationContext事件机制]]></title>
      <url>%2F2017%2F02%2F15%2FSpring-ApplicationContext%E4%BA%8B%E4%BB%B6%E6%9C%BA%E5%88%B6%2F</url>
      <content type="text"><![CDATA[ApplicationContext中事件处理是由ApplicationEvent类和ApplicationListener接口来提供的。如果一个Bean实现了ApplicationListener接口，并且已经发布到容器中去，每次ApplicationContext发布一个ApplicationEvent事件，这个Bean就会接到通知。Spring事件机制是观察者模式的实现。 Spring中提供的标准事件： ContextRefreshEvent，当ApplicationContext容器初始化完成或者被刷新的时候，就会发布该事件。比如调用ConfigurableApplicationContext接口中的refresh()方法。此处的容器初始化指的是所有的Bean都被成功装载，后处理（post-processor）Bean被检测到并且激活，所有单例Bean都被预实例化，ApplicationContext容器已经可以使用。只要上下文没有被关闭，刷新可以被多次触发。XMLWebApplicationContext支持热刷新，GenericApplicationContext不支持热刷新。 ContextStartedEvent，当ApplicationContext启动的时候发布事件，即调用ConfigurableApplicationContext接口的start方法的时候。这里的启动是指，所有的被容器管理生命周期的Bean接受到一个明确的启动信号。在经常需要停止后重新启动的场合比较适用。 ContextStoppedEvent，当ApplicationContext容器停止的时候发布事件，即调用ConfigurableApplicationContext的close方法的时候。这里的停止是指，所有被容器管理生命周期的Bean接到一个明确的停止信号。 ContextClosedEvent，当ApplicationContext关闭的时候发布事件，即调用ConfigurableApplicationContext的close方法的时候，关闭指的是所有的单例Bean都被销毁。关闭上下后，不能重新刷新或者重新启动。 RequestHandledEvent，只能用于DispatcherServlet的web应用，Spring处理用户请求结束后，系统会触发该事件。 实现ApplicationEvent，容器事件，必须被ApplicationContext发布。 ApplicationListener，监听器，可由容器中任何监听器Bean担任。 实现了ApplicationListener接口之后，需要实现方法onApplicationEvent()，在容器将所有的Bean都初始化完成之后，就会执行该方法。 观察者模式观察者模式，Observer Pattern也叫作发布订阅模式Publish/Subscribe。定义对象间一对多的依赖关系，使得每当一个对象改变状态，则所有依赖与它的对象都会得到通知，并被自动更新。 观察者模式的几角色名称： Subject被观察者，定义被观察者必须实现的职责，它能动态的增加取消观察者，它一般是抽象类或者是实现类，仅仅完成作为被观察者必须实现的职责：管理观察者并通知观察者。 Observer观察者，观察者接受到消息后，即进行更新操作，对接收到的信息进行处理。 ConcreteSubject具体的被观察者，定义被观察者自己的业务逻辑，同时定义对哪些事件进行通知。 ConcreteObserver具体的观察者，每个观察者接收到消息后的处理反应是不同的，每个观察者都有自己的处理逻辑。 观察者模式的优点 观察者和被观察者之间是抽象耦合，不管是增加观察者还是被观察者都非常容易扩展。 建立一套触发机制。 观察者模式的缺点观察者模式需要考虑开发效率和运行效率问题，一个被观察者，多个观察者，开发和调试比较复杂，Java消息的通知默认是顺序执行的，一个观察者卡壳，会影响整体的执行效率。这种情况一般考虑异步的方式。 使用场景 关联行为场景，关联是可拆分的。 事件多级触发场景。 跨系统的消息交换场景，如消息队列的处理机制。 Java中的观察者模式java.util.Observable类和java.util.Observer接口。 订阅发布模型观察者模式也叫作发布/订阅模式。 Spring中的观察者模式Spring在事件处理机制中使用了观察者模式： 事件，ApplicationEvent，该抽象类继承了EventObject，EventObject是JDK中的类，并建议所有的事件都应该继承自EventObject。 事件监听器，ApplicationListener，是一个接口，该接口继承了EventListener接口。EventListener接口是JDK中的，建议所有的事件监听器都应该继承EventListener。 事件发布，ApplicationEventPublisher，ApplicationContext继承了该接口，在ApplicationContext的抽象实现类AbstractApplicationContext中做了实现 AbstractApplicationContext类中publishEvent方法实现： 1234567891011public void publishEvent(ApplicationEvent event) &#123; Assert.notNull(event, &quot;Event must not be null&quot;); if (logger.isTraceEnabled()) &#123; logger.trace(&quot;Publishing event in &quot; + getDisplayName() + &quot;: &quot; + event); &#125; //事件发布委托给ApplicationEventMulticaster来执行 getApplicationEventMulticaster().multicastEvent(event); if (this.parent != null) &#123; this.parent.publishEvent(event); &#125;&#125; ApplicationEventMulticaster的multicastEvent方法的实现在SimpleApplicationEventMulticaster类中： 12345678910111213141516public void multicastEvent(final ApplicationEvent event) &#123; //获得监听器集合，遍历监听器，可支持同步和异步的广播事件 for (final ApplicationListener listener : getApplicationListeners(event)) &#123; Executor executor = getTaskExecutor(); if (executor != null) &#123; executor.execute(new Runnable() &#123; public void run() &#123; listener.onApplicationEvent(event); &#125; &#125;); &#125; else &#123; listener.onApplicationEvent(event); &#125; &#125;&#125; 这就执行了了onApplicationEvent方法，这里是事件发生的地方。 Spring如何根据事件找到事件对应的监听器在Spring容器初始化的时候，也就是在refresh方法中： 1234567891011121314151617public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; ...... try &#123; ...... // Initialize event multicaster for this context. //初始化一个事件注册表 initApplicationEventMulticaster(); ...... // Check for listener beans and register them. //注册事件监听器 registerListeners(); ...... &#125; &#125;&#125; initApplicationEventMulticaster方法初始化事件注册表： 12345678910111213protected void initApplicationEventMulticaster() &#123; //获得beanFactory ConfigurableListableBeanFactory beanFactory = getBeanFactory(); //先查找BeanFactory中是否有ApplicationEventMulticaster if (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) &#123; this.applicationEventMulticaster = beanFactory.getBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class); &#125; else &#123;//如果BeanFactory中不存在，就创建一个SimpleApplicationEventMulticaster this.applicationEventMulticaster = new SimpleApplicationEventMulticaster(beanFactory); beanFactory.registerSingleton(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.applicationEventMulticaster); &#125;&#125; 在AbstractApplicationEventMulticaster类中有如下属性： 123456//注册表private final ListenerRetriever defaultRetriever = new ListenerRetriever(false);//注册表的缓存private final Map&lt;ListenerCacheKey, ListenerRetriever&gt; retrieverCache = new ConcurrentHashMap&lt;ListenerCacheKey, ListenerRetriever&gt;(64);private BeanFactory beanFactory; ListenerRetriever的结构如下： 123456//用来存放监听事件public final Set&lt;ApplicationListener&gt; applicationListeners;//存放监听事件的类名称public final Set&lt;String&gt; applicationListenerBeans;private final boolean preFiltered; 初始化注册表之后，就会把事件注册到注册表中，registerListeners()： 12345678910111213protected void registerListeners() &#123; //获取所有的Listener，把事件的bean放到ApplicationEventMulticaster中 for (ApplicationListener&lt;?&gt; listener : getApplicationListeners()) &#123; getApplicationEventMulticaster().addApplicationListener(listener); &#125; // Do not initialize FactoryBeans here: We need to leave all regular beans // uninitialized to let post-processors apply to them! String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false); //把事件的名称放到ApplicationListenerBean里去。 for (String lisName : listenerBeanNames) &#123; getApplicationEventMulticaster().addApplicationListenerBean(lisName); &#125;&#125; Spring使用反射机制，通过方法getBeansOfType获取所有继承了ApplicationListener接口的监听器，然后把监听器放到注册表中，所以我们可以在Spring配置文件中配置自定义监听器，在Spring初始化的时候，会把监听器自动注册到注册表中去。 ApplicationContext发布事件可以参考上面的内容。发布事件的时候的一个方法，getApplicationListeners： 12345678910111213141516171819202122232425262728293031323334353637383940414243protected Collection&lt;ApplicationListener&gt; getApplicationListeners(ApplicationEvent event) &#123; //获取事件类型 Class&lt;? extends ApplicationEvent&gt; eventType = event.getClass(); //或去事件源类型 Class sourceType = event.getSource().getClass(); ListenerCacheKey cacheKey = new ListenerCacheKey(eventType, sourceType); //从缓存中查找ListenerRetriever ListenerRetriever retriever = this.retrieverCache.get(cacheKey); //缓存中存在，直接返回对应的Listener if (retriever != null) &#123; return retriever.getApplicationListeners(); &#125; else &#123;//缓存中不存在，就获取相应的Listener retriever = new ListenerRetriever(true); LinkedList&lt;ApplicationListener&gt; allListeners = new LinkedList&lt;ApplicationListener&gt;(); Set&lt;ApplicationListener&gt; listeners; Set&lt;String&gt; listenerBeans; synchronized (this.defaultRetriever) &#123; listeners = new LinkedHashSet&lt;ApplicationListener&gt;(this.defaultRetriever.applicationListeners); listenerBeans = new LinkedHashSet&lt;String&gt;(this.defaultRetriever.applicationListenerBeans); &#125; //根据事件类型，事件源类型，获取所需要的监听事件 for (ApplicationListener listener : listeners) &#123; if (supportsEvent(listener, eventType, sourceType)) &#123; retriever.applicationListeners.add(listener); allListeners.add(listener); &#125; &#125; if (!listenerBeans.isEmpty()) &#123; BeanFactory beanFactory = getBeanFactory(); for (String listenerBeanName : listenerBeans) &#123; ApplicationListener listener = beanFactory.getBean(listenerBeanName, ApplicationListener.class); if (!allListeners.contains(listener) &amp;&amp; supportsEvent(listener, eventType, sourceType)) &#123; retriever.applicationListenerBeans.add(listenerBeanName); allListeners.add(listener); &#125; &#125; &#125; OrderComparator.sort(allListeners); this.retrieverCache.put(cacheKey, retriever); return allListeners; &#125;&#125; 根据事件类型，事件源类型获取所需要的监听器supportsEvent(listener, eventType, sourceType)： 1234567protected boolean supportsEvent( ApplicationListener listener, Class&lt;? extends ApplicationEvent&gt; eventType, Class sourceType) &#123; SmartApplicationListener smartListener = (listener instanceof SmartApplicationListener ? (SmartApplicationListener) listener : new GenericApplicationListenerAdapter(listener)); return (smartListener.supportsEventType(eventType) &amp;&amp; smartListener.supportsSourceType(sourceType));&#125; 这里没有进行实际的处理，实际处理在smartListener.supportsEventType(eventType)和smartListener.supportsSourceType(sourceType)方法中。 smartListener.supportsEventType(eventType)： 12345678910public boolean supportsEventType(Class&lt;? extends ApplicationEvent&gt; eventType) &#123; Class typeArg = GenericTypeResolver.resolveTypeArgument(this.delegate.getClass(), ApplicationListener.class); if (typeArg == null || typeArg.equals(ApplicationEvent.class)) &#123; Class targetClass = AopUtils.getTargetClass(this.delegate); if (targetClass != this.delegate.getClass()) &#123; typeArg = GenericTypeResolver.resolveTypeArgument(targetClass, ApplicationListener.class); &#125; &#125; return (typeArg == null || typeArg.isAssignableFrom(eventType));&#125; 该方法主要的逻辑就是根据事件类型判断是否和监听器参数泛型的类型是否一致。 smartListener.supportsSourceType(sourceType)方法的实现为： 123public boolean supportsSourceType(Class&lt;?&gt; sourceType) &#123; return true;&#125; 定义自己的监听器要明确指定参数泛型，表明该监听器支持的事件，如果不指明具体的泛型，则没有监听器监听事件。 还可以定义自己的事件暂先不做解析。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring中Bean的生命周期]]></title>
      <url>%2F2017%2F02%2F12%2FSpring%E4%B8%ADBean%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%2F</url>
      <content type="text"><![CDATA[BeanFactory和ApplicationContext是Spring中两种很重要的容器，前者提供了最基本的依赖注入的支持，后者在继承前者的基础上进行了功能的拓展，增加了事件传播，资源访问，国际化的支持等功能。同时两者的生命周期也稍微有些不同。 BeanFactory中Bean的生命周期 容器寻找Bean的定义信息，并将其实例化。 使用依赖注入，Spring按照Bean定义信息配置Bean的所有属性。 如果Bean实现了BeanNameAware接口，工厂调用Bean的setBeanName()方法传递Bean的id。 如果实现了BeanFactoryAware接口，工厂调用setBeanFactory()方法传入工厂自身。 如果BeanPostProcessor和Bean关联，那么它们的postProcessBeforeInitialization()方法将被调用。（需要手动进行注册！） 如果Bean实现了InitializingBean接口，则会回调该接口的afterPropertiesSet()方法。 如果Bean指定了init-method方法，就会调用init-method方法。 如果BeanPostProcessor和Bean关联，那么它的postProcessAfterInitialization()方法将被调用。（需要手动注册！） 现在Bean已经可以使用了。 scope为singleton的Bean缓存在Spring IOC容器中。 scope为prototype的Bean生命周期交给客户端。 销毁。 如果Bean实现了DisposableBean接口，destory()方法将会被调用。 如果配置了destory-method方法，就调用这个方法。 ApplicationContext中Bean的生命周期 容器寻找Bean的定义信息，并将其实例化。会对scope为singleton且非懒加载的bean进行实例化 使用依赖注入，Spring按照Bean定义信息配置Bean的所有属性。 如果Bean实现了BeanNameAware接口，工厂调用Bean的setBeanName()方法传递Bean的id。 如果实现了BeanFactoryAware接口，工厂调用setBeanFactory()方法传入工厂自身。 如果实现了ApplicationContextAware接口，会调用该接口的setApplicationContext()方法，传入该Bean的ApplicationContext，这样该Bean就获得了自己所在的ApplicationContext。 如果Bean实现了BeanPostProcessor接口，则调用postProcessBeforeInitialization()方法。 如果Bean实现了InitializingBean接口，则会回调该接口的afterPropertiesSet()方法。 如果Bean制定了init-method方法，就会调用init-method方法。 如果Bean实现了BeanPostProcessor接口，则调用postProcessAfterInitialization()方法。 现在Bean已经可以使用了。 scope为singleton的Bean缓存在Spring IOC容器中。 scope为prototype的Bean生命周期交给客户端。 销毁。 如果Bean实现了DisposableBean接口，destory()方法将会被调用。 如果配置了destory-method方法，就调用这个方法。 两种容器中的不同之处 BeanFactory容器中不会调用ApplicationContext接口的setApplicationContext()方法。 BeanFactory中BeanPostProcessor接口的postProcessBeforeInitialzation()方法和postProcessAfterInitialization()方法不会自动调用，必须自己通过代码手动注册。 BeanFactory容器启动的时候，不会去实例化所有Bean,包括所有scope为singleton且非懒加载的Bean也是一样，而是在调用的时候去实例化。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring中IOC容器的初始化过程]]></title>
      <url>%2F2017%2F02%2F10%2FSpring%E4%B8%ADIOC%E5%AE%B9%E5%99%A8%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[Spring IOC容器初始化过程分为Resource定位，载入解析，注册。IOC容器初始化过程中不包含Bean的依赖注入。Bean的依赖注入一般会发生在第一次通过getBean向容器索取Bean的时候。 ClassPathXmlApplicationContext初始化过程实际的构造方法： 12345678910111213public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException &#123; //super方法为容器设置好Bean资源加载器 //该方法最终会调用到AbstractApplicationContext的无参构造方法 //这里会默认设置解析路径的模式为Ant-style super(parent); //设置Bean定义资源文件的路径 setConfigLocations(configLocations); if (refresh) &#123; //调用容器的refresh，载入BeanDefinition的入口 refresh(); &#125;&#125; refresh()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // 调用容器准备刷新的方法，此方法中会获取容器的当前时间，给容器设置同步标识 //初始化前的准备工作，例如对系统属性或环境变量进行准备以及验证。 prepareRefresh(); //通知子类启动refreshBeanFactory的调用 //初始化BeanFactory，并进行XML文件读取 //ClassPathXmlApplicationContext包含着BeanFactory所提供的一切特征 //这一步会复用BeanFactory中的配置文件读取解析以及其他功能 //这一步之后ClassPathXmlApplicationContext已经包含了BeanFactory所提供的功能，可以进行Bean的提取等基础操作了。 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); //准备当前上下文用的BeanFactory，为BeanFactory配置容器特性，例如类加载器，事件处理器等各种功能填充。 //对BeanFactory各种功能的填充，比如@Qualifier和@Autowired注解就是在这一步增加的支持 prepareBeanFactory(beanFactory); try &#123; //为子类设置BeanFactory的后置处理器 //子类覆盖方法做额外的处理。 postProcessBeanFactory(beanFactory); //调用BeanFactoryPostProcessor，激活各种BeanFactory处理器 invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. //注册拦截Bean创建的Bean处理器，这里只是注册，真正调用实在getBean的时候。 registerBeanPostProcessors(beanFactory); // Initialize message source for this context. //为上下文初始化Message源，国际化处理 initMessageSource(); // Initialize event multicaster for this context. //初始化应用消息广播器，并放入applicationEventMulticaster bean中 initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. 留给子类来初始化其他的Bean onRefresh(); // Check for listener beans and register them. 在所有注册的bean中查找Listener bean，注册到消息广播器中 registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. //初始化剩下的单实例，非惰性的 finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. 完成刷新过程，通知生命周期处理器lifecycleProcessor刷新过程，同时发出ContextRefreshEvent通知别人 finishRefresh(); &#125; catch (BeansException ex) &#123; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset &apos;active&apos; flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; &#125;&#125; 重点看下ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();这句，告诉子类启动refreshBeanFactory方法以及通过getBeanFactory获得BeanFactory： 12345678protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; refreshBeanFactory(); ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Bean factory for &quot; + getDisplayName() + &quot;: &quot; + beanFactory); &#125; return beanFactory;&#125; refreshBeanFactory方法在AbstractRefreshableApplicationContext实现： 123456789101112131415161718192021protected final void refreshBeanFactory() throws BeansException &#123; //如果已经存在BeanFactory，销毁并关闭 if (hasBeanFactory()) &#123; destroyBeans(); closeBeanFactory(); &#125; try &#123; //创建IOC容器，创建了DefaultListableBeanFactory容器，给ApplicationContext使用 DefaultListableBeanFactory beanFactory = createBeanFactory(); beanFactory.setSerializationId(getId()); customizeBeanFactory(beanFactory); //启动对BeanDefinitions的载入 loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) &#123; this.beanFactory = beanFactory; &#125; &#125; catch (IOException ex) &#123; throw new ApplicationContextException(&quot;I/O error parsing bean definition source for &quot; + getDisplayName(), ex); &#125;&#125; 对BeanDefinition的载入，loadBeanDefinitions方法： 1234567891011121314protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; //创建bean读取器，容器使用该读取器去读取Bean定义资源 XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); //配置bean读取器 beanDefinitionReader.setEnvironment(this.getEnvironment()); beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); //当Bean读取器读取Bean定义的xml资源文件时，启用xml的校验机制 initBeanDefinitionReader(beanDefinitionReader); //通过beanDefinitionReader加载BeanDefinitions loadBeanDefinitions(beanDefinitionReader);&#125; loadBeanDefinitions(beanDefinitionReader)方法： 123456789101112protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws BeansException, IOException &#123; //获得Bean配置文件的资源位置 Resource[] configResources = getConfigResources(); if (configResources != null) &#123; reader.loadBeanDefinitions(configResources); &#125; String[] configLocations = getConfigLocations(); if (configLocations != null) &#123; //最终还是转换成Resource的形式去加载资源 reader.loadBeanDefinitions(configLocations); &#125;&#125; 在AbstractBeanDefinitionReader中的loadBeanDefinitions(configResources)方法： 12345678910public int loadBeanDefinitions(Resource... resources) throws BeanDefinitionStoreException &#123; Assert.notNull(resources, &quot;Resource array must not be null&quot;); int counter = 0; for (Resource resource : resources) &#123; //此处loadBeanDefinitions并没有实现，具体实现在各个子类中 //比如XmlBeanDefinitionReader中 counter += loadBeanDefinitions(resource); &#125; return counter;&#125; XmlBeanDefinitionReader中的loadBeanDefinitions方法： 12345678910111213141516171819202122232425public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException &#123; Set&lt;EncodedResource&gt; currentResources = this.resourcesCurrentlyBeingLoaded.get(); if (currentResources == null) &#123; currentResources = new HashSet&lt;EncodedResource&gt;(4); this.resourcesCurrentlyBeingLoaded.set(currentResources); &#125; try &#123; //得到xml文件的InputStream InputStream inputStream = encodedResource.getResource().getInputStream(); try &#123; //得到InputSource InputSource inputSource = new InputSource(inputStream); if (encodedResource.getEncoding() != null) &#123; inputSource.setEncoding(encodedResource.getEncoding()); &#125; //doLoadBeanDefinitions是从xml文件中加载BeanDefinitions return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); &#125; finally &#123; inputStream.close(); &#125; &#125; catch (IOException ex) &#123;......&#125; finally &#123;......&#125;&#125; xml配置文件的读取以及转化为Bean对象的过程当Spring定位到xml之后，将xml转换为文件流的形式，作为InputSource和Resource对象传递给文档解析器进行解析，文档解析的开始是XmlDefinitionReader的doLoadBeanDefinitions方法。 1234567891011121314//inputSource是SAX的InputSource//resource对象是对xml文件描述的一个对象protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &#123; try &#123; //xml的解析模式 int validationMode = getValidationModeForResource(resource); //将inputResource解析为Document对象 Document doc = this.documentLoader.loadDocument( inputSource, getEntityResolver(), this.errorHandler, validationMode, isNamespaceAware()); //Document传递给registerBeanDefinitions方法 //此方法才是真正把Document对象解析为BeanDefinition对象的具体实现 return registerBeanDefinitions(doc, resource); &#125;&#125; registerBeanDefinitions方法： 1234567891011121314151617public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException &#123; // Support old XmlBeanDefinitionParser SPI for backwards-compatibility. if (this.parserClass != null) &#123; XmlBeanDefinitionParser parser = (XmlBeanDefinitionParser) BeanUtils.instantiateClass(this.parserClass); return parser.registerBeanDefinitions(this, doc, resource); &#125; //先实例化一个BeanDefinitionDocumentReader，这个对象是通过BeanUtils.instantiateClass方法实例化出来的 //实际上BeanUtils.instantiateClass中是封装了Java的反射的一些方法，通过基本的Java反射来构造实例。 BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); //记录下注册之前BeanDefinition中对象的个数。 int countBefore = getRegistry().getBeanDefinitionCount(); //开始解析Document documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); return getRegistry().getBeanDefinitionCount() - countBefore;&#125; DefaultBeanDefinitionDocumentReader类中的registerBeanDefinitions方法： 1234567//在这里解析Documentpublic void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) &#123; this.readerContext = readerContext; logger.debug(&quot;Loading bean definitions&quot;); Element root = doc.getDocumentElement(); doRegisterBeanDefinitions(root);&#125; doRegisterBeanDefinitions方法： 1234567891011121314151617181920212223protected void doRegisterBeanDefinitions(Element root) &#123; String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE); if (StringUtils.hasText(profileSpec)) &#123; Assert.state(this.environment != null, &quot;environment property must not be null&quot;); String[] specifiedProfiles = StringUtils.tokenizeToStringArray(profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS); if (!this.environment.acceptsProfiles(specifiedProfiles)) &#123; return; &#125; &#125; //BeanDefinitionParserDelegate对象描述了Spring中bean节点中定义的所有属性和子节点 BeanDefinitionParserDelegate parent = this.delegate; this.delegate = createHelper(readerContext, root, parent); //xml解析的预处理，可以自己定义一些节点属性等，此方法Spring默认实现为空 preProcessXml(root); //把Document对象解析为BeanDefinition对象 parseBeanDefinitions(root, this.delegate); //xml解析的后处理，可以在解析完xml之后，实现自己的逻辑。Spring默认实现为空。 postProcessXml(root); this.delegate = parent;&#125; parseBeanDefinitions方法： 12345678910111213141516171819202122232425262728//解析在root级别的元素，比如import，alias，beanprotected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; //校验是不是Spring的默认命名空间。 //默认命名空间是http://www.springframework.org/schema/beans //如果是Spring的默认命名空间，就按照默认命名空间来解析，否则就按照自定义标签来解析 if (delegate.isDefaultNamespace(root)) &#123; NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element) node; //查看子节点是不是默认命名空间，是就按照默认解析，不是就按照自定义标签进行解析 if (delegate.isDefaultNamespace(ele)) &#123; //解析Spring默认的标签 parseDefaultElement(ele, delegate); &#125; else &#123; //解析自定义标签 delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123; //解析自定义标签 delegate.parseCustomElement(root); &#125;&#125; 解析默认的标签，parseDefaultElement方法： 12345678910111213141516//此方法会依次解析文档中的import，alias，bean，beans标签private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) &#123; if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) &#123; importBeanDefinitionResource(ele); &#125; else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) &#123; processAliasRegistration(ele); &#125; else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) &#123; processBeanDefinition(ele, delegate); &#125; else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) &#123; // recurse doRegisterBeanDefinitions(ele); &#125;&#125; import标签的解析，importBeanDefinitionResource方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950protected void importBeanDefinitionResource(Element ele) &#123; //获取import标签中的resource属性，此属性表示资源地址 //resource属性不可为空 String location = ele.getAttribute(RESOURCE_ATTRIBUTE); if (!StringUtils.hasText(location)) &#123; getReaderContext().error(&quot;Resource location must not be empty&quot;, ele); return; &#125; // 解析resource中的占位符为真正的路径，比如&quot;$&#123;user.dir&#125;&quot; location = environment.resolveRequiredPlaceholders(location); Set&lt;Resource&gt; actualResources = new LinkedHashSet&lt;Resource&gt;(4); // 解析路径，判断是相对路径还是绝对路径 boolean absoluteLocation = false; try &#123; absoluteLocation = ResourcePatternUtils.isUrl(location) || ResourceUtils.toURI(location).isAbsolute(); &#125; catch (URISyntaxException ex) &#123;...&#125; //绝对路径 if (absoluteLocation) &#123; try &#123; //递归调用Bean的解析过程 int importCount = getReaderContext().getReader().loadBeanDefinitions(location, actualResources); &#125; &#125; else &#123;//相对路径，计算出绝对路径，进行递归调用解析过程 try &#123; int importCount; Resource relativeResource = getReaderContext().getResource().createRelative(location); if (relativeResource.exists()) &#123; importCount = getReaderContext().getReader().loadBeanDefinitions(relativeResource); actualResources.add(relativeResource); &#125; else &#123; String baseLocation = getReaderContext().getResource().getURL().toString(); importCount = getReaderContext().getReader().loadBeanDefinitions( StringUtils.applyRelativePath(baseLocation, location), actualResources); &#125; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Imported &quot; + importCount + &quot; bean definitions from relative location [&quot; + location + &quot;]&quot;); &#125; &#125; catch (IOException ex) &#123;......&#125; &#125; //解析完成后进行监听器激活处理 Resource[] actResArray = actualResources.toArray(new Resource[actualResources.size()]); getReaderContext().fireImportProcessed(location, actResArray, extractSource(ele));&#125; 总结 IOC容器初始化入口是在构造方法中调用refresh开始的。 通过ResourceLoader来完成资源文件位置的定位，DefaultResourceLoader是默认的实现，同时上下文本身就给除了ResourceLoader的实现。 创建的IOC容器是DefaultListableBeanFactory。 IOC对Bean的管理和依赖注入功能的实现是通过对其持有的BeanDefinition进行相关操作来完成的。 通过BeanDefinitionReader来完成定义信息的解析和Bean信息的注册。 XmlBeanDefinitionReader是BeanDefinitionReader的实现了，通过它来解析xml配置中的bean定义。 实际的处理过程是委托给BeanDefinitionParserDelegate来完成的。得到Bean的定义信息，这些信息在Spring中使用BeanDefinition对象来表示。 BeanDefinition的注册是由BeanDefinitionRegistry实现的registerBeanDefiition方法进行的。内部使用ConcurrentHashMap来保存BeanDefiition。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SNMP-MIB-SNMP4J简介]]></title>
      <url>%2F2016%2F12%2F27%2FSNMP-MIB-SNMP4J%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[SNMP全称Simple Network Management Protocol，简单网络管理协议。是TCP/IP协议的一部分，属于应用层协议。SNMP协议主要用来解决网络设备的管理，大多数的网络管理系统都是基于SNMP协议。通过该协议可以实现在被管理的设备上获取各种参数，还可以设置修改这些参数。 SNMP系统的组成一般SNMP系统组成大致有4个部分： 网络管理软件，也就是客户端，网络管理员或者是你和我可以通过管理软件对网络设备进行管理。也就是相当于我们平时使用的系统的后台管理。 网络设备，也就是被管理的设备，比如服务器，路由器，交换机等网络设备。 代理程序，代理程序运行在被管理的设备中，相当于服务器的角色。 MIB库，全称Management Information Base，相当于数据库。存储了被监控设备的各种参数和状态信息等。 SNMP协议就是用在网络管理软件和被管理的网络设备之间的协议，通过此协议被管理的网络设备才会听我们的话。 一般情况下做开发，比如我是做Java开发的，所需要做的就是开发网络管理软件，也就是客户端；服务器端的设备运行着代理程序，所有的信息都存储在MIB库中；我们要做的就是通过SNMP协议去读取和设置这些MIB库存的数据。 SNMP协议的结构SNMP使用UDP进行无连接操作，主要包括SNMP报头和协议数据单元： 版本标识符 团体名 PDU SNMP定义了五种报文，用来在管理软件和代理程序之间进行通信： get-request，从代理程序处获取信息 get-next-request，从代理程序处获取下一个参数值 set-request，设置代理程序的值 get-response，代理程序返回值，上面三种请求都会使代理程序返回参数值 trap，代理程序主动发送的报文 MIB库简介Management Information Base 管理信息库，每个被管理的设备都需要有MIB库的存在，我们才能对设备进行管理。 MIB库中定义了可访问的网络设备及其属性，通过OID，Object Identifer来区别。MIB采用分级树形结构，以下是结构图：![mib]MIB.png)结构类似于DNS和Unix的文件系统，例如1.3.6.1.2.1就代表iso.org.dod.internet.mgmt.mib。 net-snmpnet-snmp是一种开放源代码的简单网络管理协议（Simple Network Management Protocol）软件，可以安装在linux系统，unix以及windows上。作用就是上面提到的代理程序。 安装使用本次在Centos7上面安装使用net-snmp软件，具体步骤如下： 安装net-snmp： 1sudo yum install net-snmp* 安装完成之后，修改net-snmp配置文件/etc/snmp/snmpd.conf，在下面代码后面添加两行： 123## sec.name source community#com2sec local localhost COMMUNITY#com2sec mynetwork NETWORK/24 COMMUNITY 添加两行如下： 12com2sec local localhost publiccom2sec mynet 192.168.0.0/24 public 上面的192.168.0.0/24根据你的实际情况添加，我的局域网网段是192.168.1.xxx，所以上面写的是192.168.0.0，后面的24是子网掩码255.255.255.0。 修改完配置文件后，启动net-snmp服务： 1systemctl start snmpd.service 启动后可以使用以下命令查看启动是否有错： 1systemctl status snmpd.service -l 如果没有提示错误啥的，现在服务应该就已经起来了，可以使用以下命令测试下： 1snmpwalk -v1 -c public 192.168.110.198 后面的ip写net-snmp安装的那台机器的ip。回车后会输出以下信息(不会跟我的完全一样，只是类似的就对了)： 1234567891011SNMPv2-MIB::sysDescr.0 = STRING: Linux localhost.localdomain 3.10.0-514.2.2.el7.x86_64 #1 SMP Tue Dec 6 23:06:41 UTC 2016 x86_64SNMPv2-MIB::sysObjectID.0 = OID: NET-SNMP-MIB::netSnmpAgentOIDs.10DISMAN-EVENT-MIB::sysUpTimeInstance = Timeticks: (4549) 0:00:45.49SNMPv2-MIB::sysContact.0 = STRING: Root &lt;root@localhost&gt; (configure /etc/snmp/snmp.local.conf)SNMPv2-MIB::sysName.0 = STRING: localhost.localdomainSNMPv2-MIB::sysLocation.0 = STRING: Unknown (edit /etc/snmp/snmpd.conf)SNMPv2-MIB::sysORLastChange.0 = Timeticks: (4) 0:00:00.04SNMPv2-MIB::sysORID.1 = OID: SNMP-MPD-MIB::snmpMPDComplianceSNMPv2-MIB::sysORID.2 = OID: SNMP-USER-BASED-SM-MIB::usmMIBComplianceSNMPv2-MIB::sysORID.3 = OID: SNMP-FRAMEWORK-MIB::snmpFrameworkMIBCompliance........还有很多输出，省略了...... 使用SNMP4J开发简单的例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class GetCentosSystemInformation &#123; private final static String REMOTE_ADDRESS = &quot;udp:192.168.110.198/161&quot;; public static void main(String[] args) throws IOException &#123; //初始化 Address remoteAddress = GenericAddress.parse(REMOTE_ADDRESS); System.out.println(&quot;SNMP地址：&quot; + REMOTE_ADDRESS + &quot;；有效：&quot; + remoteAddress.isValid()); TransportMapping transportMapping = new DefaultUdpTransportMapping(); Snmp snmp = new Snmp(transportMapping); snmp.listen(); //构造发送目标 CommunityTarget target = new CommunityTarget(); target.setCommunity(new OctetString(&quot;public&quot;)); target.setAddress(remoteAddress); target.setVersion(SnmpConstants.version2c); target.setRetries(10); target.setTimeout(1500); //构造发送内容 PDU pdu = new PDU(); OID oid = new OID(&quot;1.3.6.1.2.10&quot;); pdu.add(new VariableBinding(oid)); pdu.setType(PDU.GETNEXT); //异步监听响应 ResponseListener responseListener = new ResponseListener() &#123; @Override public void onResponse(ResponseEvent event) &#123; ((Snmp)event.getSource()).cancel(event.getRequest(),this); PDU response = event.getResponse(); PDU request = event.getRequest(); if(response == null)&#123; System.out.println(&quot;请求超时：&quot; + response + &quot;，请求的内容：&quot; + request); &#125;else &#123; System.out.println(&quot;获取到信息：&quot; + response); &#125; &#125; &#125;; //发送 snmp.send(pdu,target,null,responseListener); //由于是异步获取信息，在这里需要程序不能结束运行，否则接收不到异步获取的消息。 System.in.read(); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[volatile简介]]></title>
      <url>%2F2016%2F12%2F15%2Fvolatile%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[Java允许线程访问共享变量。作为规则，为了确保共享变量被一致的和可靠的更新，线程应该确保它获得一个排它锁单独的获取这个变量。Java提供了第二种机制即volatile关键字，在某些情况下比锁更加方便。一个字段可以被声明为volatile，在这种情况下，Java内存模型确保所有线程看到的变量值都一样。（Java语言规范） 一个变量被volatile修饰后，这个变量就具备了可见性和禁止指令重排序的特性。 可见性Java内存模型中分为主存和线程的工作内存，线程的工作内存是私有的，其他线程无法看到。变量都存储在主存中，当线程需要一个变量的时候，首先会从主存中复制变量的副本到工作内存中，所以每个线程都拥有同一个变量得副本，他们对该变量副本的修改并不会影响到其他线程，修改后的变量副本需要写回主内存，这样就会导致有可能写回的值不一样，造成错误。此时可用volatile关键字修饰变量，保证每个线程对变量的修改，其他线程都是立即可见的。 禁止指令重排序Java执行语句的顺序可能和代码中写的顺序不同，使用volatile关键字，能保证它的执行顺序不会改变。 Volatile和Synchronizedvolatile修饰的变量具有可见性和禁止指令重排序特性，只能修饰变量。不具有原子性，使用在类似i++这种操作上是无效的。 synchronized修饰方法和代码块，具有互斥性，内存可见性，原子性。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ThreadLocal简介]]></title>
      <url>%2F2016%2F12%2F05%2FThreadLocal%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[ThreadLocal简介Java中的ThreadLocal类给每个线程分配一个只属于该线程的变量副本，可以用来实现线程间的数据隔离，当前线程的变量不能被其他线程访问。 ThreadLocal使用创建ThreadLocal变量1private ThreadLocal myThreadLocal = new ThreadLocal(); 访问ThreadLocal变量设置需要保存的值：myThreadLocal.set(&quot;ThreadLocal value&quot;); 读取保存在ThreadLocal变量中的值：String threadLocalVlaue = (String) myThreadLocal.get(); ThreadLocal范型private ThreadLocal myThreadLocal = new ThreadLocal&lt;String&gt;() 初始化ThreadLocal的值12345private ThreadLocal myThreadLocal = new ThreadLocal&lt;String&gt;()&#123; protected String initialVlaue()&#123; return &quot;initial value&quot;; &#125;&#125;; 源码分析源码版本： jdk7u80 最常用的方法就是get和set方法，所以先从这两个方法入手，分析下使用。 set(T value)将当前的线程局部变量的副本的值设置为指定的值。子类一般不需要重写该方法，只需要使用initialValue方法去设置初始值。 123456789101112public void set(T value) &#123; //获取当前线程 Thread t = Thread.currentThread(); //从当前线程中得到当前线程的ThreadLocalMap ThreadLocalMap map = getMap(t); if (map != null) //不为空的话，调用ThreadLocalMap的set方法设置值 map.set(this, value); else //ThreadLocalMap为null，还没有被初始化，创建新的map createMap(t, value);&#125; getMap(Thread t)获取指定的线程t的ThreadLocalMap123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; createMap(t, value)为当前线程t初始化一个ThreadLocalMap用来存储值，初始值是value。 在Thread类中ThreadLocal.ThreadLocalMap threadLocals = null;是用来存储当前线程对应的ThreadLocalMap，属于线程私有的。所以createMap方法使用t.threadLocals = new ThreadLocalMap(this, firstValue);来设置。 123void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; ThreadLocal用来把变量的副本存储到线程中，变量的副本就只能是当前线程私有，而在线程中是通过ThreadLocalMap来存储副本的，所以有必要了解下ThreadLocalMap是怎么实现的。 ThreadLocalMapThreadLocalMap是一个自定义的HashMap，用来存储线程本地变量的值，类似与Map。ThreadLocalMap内部是使用Entry对象来存储。 EntryEntry继承了WeakReference，使用ThreadLocal作为key，value为ThreadLocal的值。 123456789static class Entry extends WeakReference&lt;ThreadLocal&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal k, Object v) &#123; super(k); value = v; &#125;&#125; private static final int INITIAL_CAPACITY = 16;ThreadLocalMap的初始容量为16。 private Entry[] table;存放线程本地变量的数组。 private int size = 0; 线程本地变量的数目。 private int threshold 扩容的阈值。 扩容的阈值为指定长度的三分之二 123private void setThreshold(int len) &#123; threshold = len * 2 / 3;&#125; //构造方法，当我们第一次使用的时候会构造一个新的ThreadLocalMap 123456789101112ThreadLocalMap(ThreadLocal firstKey, Object firstValue) &#123; //存放线程本地变量的数组，初始容量16 table = new Entry[INITIAL_CAPACITY]; //得到存放Entry的数组下标 int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); //在得出的位置处新建一个Entry对象 table[i] = new Entry(firstKey, firstValue); //大小设为1 size = 1; //设置阈值 16*2/3 setThreshold(INITIAL_CAPACITY);&#125; 使用给定的父map来构造一个ThreadLocalMap 1234567891011121314151617181920212223242526private ThreadLocalMap(ThreadLocalMap parentMap) &#123; //父map中存放的线程本地变量数据 Entry[] parentTable = parentMap.table; //父map的长度 int len = parentTable.length; //设置阈值 setThreshold(len); //新建长度为len的Entry数组 table = new Entry[len]; //循环把父map的数组的元素放到新数组中去，中间需要重新计算数组下标。 for (int j = 0; j &lt; len; j++) &#123; Entry e = parentTable[j]; if (e != null) &#123; ThreadLocal key = e.get(); if (key != null) &#123; Object value = key.childValue(e.value); Entry c = new Entry(key, value); int h = key.threadLocalHashCode &amp; (len - 1); while (table[h] != null) h = nextIndex(h, len); table[h] = c; size++; &#125; &#125; &#125;&#125; 根据key获取Entry 1234567891011private Entry getEntry(ThreadLocal key) &#123; //计算数组下标 int i = key.threadLocalHashCode &amp; (table.length - 1); //获取元素 Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else //没有找到key的时候的处理 return getEntryAfterMiss(key, i, e);&#125; //当没有找到对应的key时候 123456789101112131415161718192021222324//key ThreadLocal对象//i 计算出来的数组下标//e 在i处的entryprivate Entry getEntryAfterMiss(ThreadLocal key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; //获取key ThreadLocal k = e.get(); //找到key，返回e if (k == key) return e; //key为null，找不到，清除掉 if (k == null) expungeStaleEntry(i); else //key不为null，计算下一个数组下标 i = nextIndex(i, len); //返回下一个entry e = tab[i]; &#125; return null;&#125; //存放指定的key和value 1234567891011121314151617181920212223242526272829303132333435private void set(ThreadLocal key, Object value) &#123; //当前存放的数组 Entry[] tab = table; //数组长度 int len = tab.length; //根据key获取存放的数组下标 int i = key.threadLocalHashCode &amp; (len-1); //从第i个元素开始挨个遍历 for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; //获取到i处的key ThreadLocal k = e.get(); //i处的key和要存放的key相等，将原来的值替换成新的值，返回。 if (k == key) &#123; e.value = value; return; &#125; //i处key为null if (k == null) &#123; //替换原来的Entry replaceStaleEntry(key, value, i); return; &#125; &#125; //不存在key，新建一个Entry tab[i] = new Entry(key, value); //size加1 int sz = ++size; //不能移除一些旧的entry并且新的size已经大于等于阈值了，需要重新扩容 if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125; //rehash() 12345678private void rehash() &#123; //首先清除旧的entry expungeStaleEntries(); // size大于等于阈值的四分之三，将容量扩展为两倍 if (size &gt;= threshold - threshold / 4) resize();&#125; ThreadLocalMap内部的Entry的get和set基本就这些，接下来继续看ThreadLocal的get方法 public T get()12345678910111213public T get() &#123; //获取当前线程 Thread t = Thread.currentThread(); //获取当前线程的ThreadLocalMap ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) return (T)e.value; &#125; //map为空，设置初始值，并返回 return setInitialValue();&#125; private T setInitialValue()1234567891011private T setInitialValue() &#123; //这里初始值为null T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; remove()移除当前线程的ThreadLocalMap中的值 12345public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this); &#125; 总结一下get和set方法get方法： 首先获取到当前线程，然后获取当前线程内部的ThreadLocalMap，如果map不为空，就查找到Entry中的值，返回；如果map为空，设置初始值，并返回。 set方法： 首先获取到当前线程，然后获取当前线程内部的ThreadLocalMap，如果map不为空，直接使用Entry的set设置值，此方法会替换原来的值；如果map为空，说明没有使用过，新建一个map并使用当前线程和指定的值初始化。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java创建对象的过程简介]]></title>
      <url>%2F2016%2F12%2F01%2FJava%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1%E7%9A%84%E8%BF%87%E7%A8%8B%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[Java创建对象的过程简单记录一下Java创建对象的过程，就是new一个对象的时候发生了哪些事情。Java程序执行的过程在此不作说明，对象的创建过程只是程序执行过程的一部分。有关整个程序执行的过程，等熟悉了虚拟机之后在作说明。 对象创建过程简述Java中对象的创建就是在堆上分配内存空间的过程，此处说的对象创建仅限于new关键字创建的普通Java对象，不包括数组对象的创建。 大致过程如下： 检测类是否被加载 为对象分配内存 为分配的内存空间初始化零值 对对象进行其他设置 执行init方法 检测类是否被加载当虚拟机执行到new时，会先去常量池中查找这个类的符号引用。如果能找到符号引用，说明此类已经被加载到方法区（方法区存储虚拟机已经加载的类的信息），可以继续执行；如果找不到符号引用，就会使用类加载器执行类的加载过程，类加载完成后继续执行。 为对象分配内存类加载完成以后，虚拟机就开始为对象分配内存，此时所需内存的大小就已经确定了。只需要在堆上分配所需要的内存即可。 具体的分配内存有两种情况：第一种情况是内存空间绝对规整，第二种情况是内存空间是不连续的。 对于内存绝对规整的情况相对简单一些，虚拟机只需要在被占用的内存和可用空间之间移动指针即可，这种方式被称为指针碰撞。 对于内存不规整的情况稍微复杂一点，这时候虚拟机需要维护一个列表，来记录哪些内存是可用的。分配内存的时候需要找到一个可用的内存空间，然后在列表上记录下已被分配，这种方式成为空闲列表。 分配内存的时候也需要考虑线程安全问题，有两种解决方案： 第一种是采用同步的办法，使用CAS来保证操作的原子性。 另一种是每个线程分配内存都在自己的空间内进行，即是每个线程都在堆中预先分配一小块内存，称为本地线程分配缓冲（TLAB），分配内存的时候再TLAB上分配，互不干扰。 为分配的内存空间初始化零值对象的内存分配完成后，还需要将对象的内存空间都初始化为零值，这样能保证对象即使没有赋初值，也可以直接使用。 对对象进行其他设置分配完内存空间，初始化零值之后，虚拟机还需要对对象进行其他必要的设置，设置的地方都在对象头中，包括这个对象所属的类，类的元数据信息，对象的hashcode，GC分代年龄等信息。 执行init方法执行完上面的步骤之后，在虚拟机里这个对象就算创建成功了，但是对于Java程序来说还需要执行init方法才算真正的创建完成，因为这个时候对象只是被初始化零值了，还没有真正的去根据程序中的代码分配初始值，调用了init方法之后，这个对象才真正能使用。 到此为止一个对象就产生了，这就是new关键字创建对象的过程。过程如下： 检测类是否被加载–&gt;为对象分配内存空间–&gt;初始零值–&gt;进行必要的设置–&gt;调用init方法进行初始化。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java运行时数据区域简介]]></title>
      <url>%2F2016%2F11%2F30%2FJava%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%9F%9F%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[Java运行时数据区域在此讨论的内容是根据Java虚拟机规范（Java SE 7）相关内容做的总结。可能有不对的地方。 Java虚拟机定义了程序运行期间使用到的运行时数据区域，其中一些与虚拟机生命周期相同，另外一些与线程的生命周期相同。 Java运行时数据区域分为： 程序计数器（Program Counter） Java虚拟机栈（Java Virtual Machine Stack） 堆（Heap） 方法区（Method Area） 本地方法栈（Native Method Stack） 程序计数器（Program Counter）程序计数器是线程私有的，每条线程都有自己的程序计数器。如果一个线程正在执行的方法是Java方法，程序计数器保存的是Java虚拟机正在执行的字节码指令的地址；如果正在执行的方法是native的，程序计数器的值为undefined。 Java虚拟机栈（Java Virtual Machine Stack）Java虚拟机栈也是线程私有的，与线程同时创建，用于存储栈帧（Fremas），栈帧用来存储局部变量表等信息。方法从调用到执行完成的过程就对应着一个栈帧从入栈到出栈的过程。 Java虚拟机栈可以被实现为固定大小的，此时每一条线程的Java虚拟机栈在线程创建的时候容量就已经确定；还可以被实现为根据计算动态扩展和收缩的。 Java虚拟机栈可能会发生异常： 如果线程请求的栈容量超过Java虚拟机栈允许的最大容量，会抛出StackOverflowError异常。 如果虚拟机栈可动态扩展，申请不到足够的内存去完成扩展，或者建立新线程时没有足够的内存去创建虚拟机栈，会抛出OutOfMemoryError异常。 堆（Heap）堆是各个线程共享的运行时内存区域，也是所有的类实例和数组对象分配内存的区域。堆在虚拟机启动的时候被创建。 堆的容量可以是固定大小的，也可以是动态扩展和自动收缩的。Java堆的内存不需要保证是连续的。 Java堆可能发生异常情况： 实际所需的堆超过了最大容量，抛出OutOfMemoryError异常。 方法区（Method Area）方法区也是被各个线程所共享的运行时内存区域。用于存储类的结构信息，例如运行时常量池，字段，方法数据，构造函数，普通方法的字节码内容，还包括一些在类，实例，接口初始化时用到的特殊方法。 方法区在虚拟机启动的时候被创建。方法区的容量可以是固定大小的，也可以是动态扩展和自动收缩的。内存空间不需要保证是连续的。 方法区可能发生异常的情况： 方法区的内存不能满足内存分配时，会抛出OutOfMemoryError异常。 本地方法栈（Native Method Stack）用来支持native方法。跟虚拟机栈功能类似。抛出的异常情况也类似。 简要总结程序计数器为线程私有，用来指示程序运行时的位置。 Java虚拟机栈是线程私有的，用来存储局部变量表等，出栈入栈对应着方法的结束开始。 堆是线程共享的区域，虚拟机启动时创建，创建的实例对象和数组都分配在堆上。 方法区是线程共享的区域，虚拟机启动时创建，用来存储类的信息，常量字段等等。 本地方法栈用来执行本地方法的。 其他相关的内容运行时常量池运行时常量池分配在方法区中，在类和接口被加载到虚拟机后，运行时常量池就会被创建出来。是类或者接口的常量池表示形式，用于存储编译期生成的各种字面量和符号引用。 可能会发生异常的情况： 构造运行时常量池所需的内存空间超过了方法区能提供的最大值，会抛出OutOfMemoryError异常。 栈帧栈帧是线程私有的，随着方法的调用而创建，随着方法的结束而销毁。栈帧分配在Java虚拟机栈中，存储着局部变量表，操作数栈，和指向当前方法所属类的运行时常量池的引用。 局部变量表和操作数栈的容量是编译期确定的。 局部变量表局部变量表存在于栈帧中，长度由编译器确定。局部变量表可以保存基本数据类型（boolean，byte，char，short，float，long，double），reference类型，returnAddress类型。long和double类型使用两个局部变量保存。 局部变量表用来完成方法调用时的参数传递。当方法被调用时，参数会传递到从0开始的连续局部变量表位置上。当实例方法被调用时，第0个局部变量存储的是this。 操作数栈操作数栈存在于栈帧内部，长度由编译期确定。作用是计算时候临时数据的存储区域。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java同步简介]]></title>
      <url>%2F2016%2F11%2F30%2FJava%E5%90%8C%E6%AD%A5%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[Java同步Java中同步一直都是很重要的问题，对于初学者来说也是不太容易能理解的问题。特在此记录一下有关Java中同步和锁的知识。主要涉及到同步的概念以及Java中解决的办法和简单的例子。有关锁Lock中的内容不在此做说明。 同步为什么需要同步这个问题不难回答。当牵扯到同步问题的时候，就离不开多线程了。简单举个例子，桌子上有一台2016新款MacBook pro，我和女朋友都想要去玩，我们俩同时伸向了那台电脑，后果可想而知（当然是我地上坐着玩手机去了！），我们俩都在抢那台电脑，谁也玩不了。这时候该怎么办？我们会约定好，一人半个小时，我在玩电脑的时候你拿着手机玩……就这样一人一段时间的玩。分析一下，电脑就是被竞争的资源，我和女朋友是两个线程，关于怎么玩电脑就需要同步来解决了，要不然不就打起来了么。 同步就是要多个运行的线程在一起良好的工作，在访问同一个资源时不会造成资源的错误或者混乱。 Java中同步的解决办法Java中内置了synchronized关键字来控制线程的同步。synchronized关键字可以修饰方法或者代码块，当有一个线程进入到了synchronized方法或者代码块中的时候，其他的线程就不能进入到此方法或者代码块中，必须等待刚才的线程完成退出synchronized方法或者代码块之后，等待的方法才能去执行。就是我女票玩电脑的时候，我就不能玩，必须等着。 锁synchronized其实就是实现锁的功能。Java中每个对象都有一个内置锁，每次需要访问同步方法或者同步块的时候，必须获得相应的锁。要不然等待的线程怎么能知道这块代码是不是被其他线程在用呢。 同步的几种情况synchronized修饰一个方法修饰一个方法时，能够保证同一时刻最多只有一个线程执行该方法中的代码。此时锁的是当前实例对象，如果该对象还有其他的synchronized方法，也不能被其他线程访问，因为当前对象的锁只有一个。但是对于该对象其他的非synchronized方法其他线程则可以访问。 synchronized修饰代码块此时代码块应该用synchronized(this)来修饰，锁的也是当前实例对象，该对象其他的同步方法和同步块也不能被其他线程访问。 synchronized修饰静态方法静态方法是属于类的而不属于对象的，所以静态方法的锁是类对象。一个synchronized静态方法被访问时，其他线程不能访问这个类的所有对象的同步方法。这个锁是类级别的。 synchronized(.class)修饰的代码块线程进入synchronized(.class)修饰的代码块，会将整个类的所有这个synchronized(.class) 同步代码块锁定，其他线程没有办法访问synchronized(.class)修饰的代码块。属于class级别的。但是其他线程可以访问非静态的同步方法或者代码块。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java多线程简介]]></title>
      <url>%2F2016%2F11%2F29%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[Java多线程简介Java中内置了对多线程的支持，让多线程的开发方便很多，但同时也带来了另外的复杂，线程间的交互以及很多的不确定性让多线程又显得很复杂。在此只是针对Java中多线程的基础做些说明，有关线程和进程的区别，以及多线程的好处和更深层的暂不多说。 线程的状态线程的状态定义在Thread类中一个State枚举类型： 新建状态（NEW），通过new Thread新建的线程处于新建状态，通常会调用start()方法来启动线程。 就绪状态（RUNNABLE），此时线程并没有在执行，而是可执行，在等待CPU调度去真正执行。就绪状态的线程有可能是刚调用start()方法进入就绪队列的线程，也有可能是等待其他资源的状态的线程。 阻塞状态（BLOCKED），等待锁的线程会处于阻塞状态，线程等待进入synchronized块或方法时候处于阻塞状态；线程调用了wait()方法后等待重新获取锁的时候也会处于阻塞状态。 等待状态（WAITING），线程调用了wait()方法并且没有设置超时时间会一直处于等待状态；线程调用了join()方法并且没有设置超时时间会一直处于等待状态；线程调用了LockSupport.park()方法会处于等待状态。 有等待时间的等待状态（TIMED_WAITING），线程调用了以下方法，并且设置了等待的时间，会处于等待状态：1. Thread.sleep;2. wait(long)设置了超时时间；3. join(long)设置了超时时间；4. LockSupport.parkNanos()方法；5. LockSupport.parkUntil()方法。 终止状态（TERMINATED），线程处于终止状态，已经完成了执行。 线程的生命周期线程的生命周期分为：新建（New），就绪（Runnable），运行（Running），阻塞（Blocked），死亡（Dead）五个阶段。 生命周期五个阶段之间的转换如图所示： 新建（New）使用new关键字和Thread类创建一个线程之后，该线程就处于新建状态。新建跟普通Java对象的创建一样，由虚拟机分配内存，初始化成员变量等。接下来就等待调用start()方法。 就绪（Runnable）当已经新建的线程对象调用了start()方法，该线程就处于就绪状态。此时线程并没有直接运行，而是处于就绪队列中，需要等待JVM线程调度器的调用。 运行状态（Running）处于就绪状态的线程如果获取到了CPU，就可以执行进入运行状态。此时线程可以变成阻塞状态，就绪状态，死亡状态。 从运行状态转换到其他状态的几个条件： 失去CPU资源或者调用了yield()方法后线程进入就绪状态。 调用了sleep()方法，调用了阻塞IO方法，试图获取同步锁，等待通知notify或者调用了线程的suspend()方法后线程进入阻塞状态。 调用了stop()方法，遇到错误Error，遇到异常Exception，或者线程执行完成后线程进入死亡状态。 阻塞状态当线程调用了sleep()方法，调用了阻塞IO方法，试图获取同步锁，等待通知notify或者调用了线程的suspend()方法后，线程进入阻塞状态。被阻塞的线程会进入就绪状态，等待CPU调度重新进入运行状态。 从阻塞状态进入到就绪状态的几个条件： 调用了sleep()方法后时间已经到了。 调用的IO操作已经完成。 获取到了同步锁。 获得到了通知。 调用到了resume()方法。 死亡状态 遇到Error或者Exception，线程死亡 直接调用了stop()方法 线程执行完成，正常结束 Thread源码分析 源码版本：jdk7u80 yield() 字面意思是让出，让步。使当前线程从运行状态变成就绪状态。调用此方法之后，当前线程会把CPU执行时间让出去，供其他线程或者自己去获得CPU运行。 sleep(long millis)，sleep(long millis, int nanos) sleep方法强制使当前正在执行的方法暂停执行，会阻塞当前线程，让出CPU。这样可以让其他线程获取执行的机会。当睡眠时间到了之后，线程进入就绪状态。 在一个synchronized块中调用sleep()方法，对象持有的锁不会被释放，仍然占有该锁。 currentThread() 返回当前正在执行的线程对象。 start()该方法用来启动一个线程，线程启动后会执行run()方法中的代码。start()方法不能被重复调用。 stop()该方法可以用来停止一个线程的执行。该方法已经被弃用。 interrupt()该方法用来中断线程，设置中断状态为true。并没有被直接中断，而是设置了中断状态。 interrupted()测试当前线程是否已经中断，该方法还负责清除中断状态。 isInterrupted()判断中断状态。 isAlive()测试线程是否处于活动的状态。 suspend()把一个线程挂起，使线程处于阻塞状态，必须调用对应的resume()方法才能使线程进入可执行状态。已被废弃。 resume()把一个挂起的线程恢复执行。已被废弃。 setPriority()设置线程的优先级。 getPriority()获取线程的优先级。 setName(String)设置线程的名字。 getName()获取线程的名字。 getThreadGroup()获取线程组。 activeCount()获取当前线程所在线程组中活跃的线程数。 join(),join(long),join(long,int) 该方法可以把指定的线程加入到当前线程中。比如在线程A中调用线程B的join()方法，线程A会阻塞，直到线程B完成后，线程A才能继续执行。 setDaemon(boolean) 标记此线程为守护线程，此方法必须在start()方法之前调用。 isDaemon()判断是否是守护线程。 holdsLock(Object) 判断当前线程是否持有给定对象的锁。 getId()获得线程的id。 getState()获得当前线程的状态。 创建线程的方法主要有三种方法： 继承Thread类来创建线程，继承Thread类重写run方法，创建子类实例，调用start方法。 实现Runnable接口来创建线程，实现Runnable接口并实现run方法，创建Runnable实现类的实例，new一个Thread的实例，并以Runnable实现类的实例作为target，调用thread的start方法。 使用Callable和Future来创建线程，实现Callable接口并实现call方法，创建Callable实现类的实例并使用FutureTask类来包装Callable对象，使用FutureTask对象作为Thread的target创建启动新线程，最后调用FutureTask对象的get方法来获得子线程执行结束后的返回值。 前面两个不再举例子，最后一种代码如下： CallableDemo： 123456public class CallableDemo implements Callable&lt;Integer&gt;&#123; @Override public Integer call() throws Exception &#123; return new Random().nextInt(1000); &#125;&#125; CallableAndFutureTest： 12345678910111213141516public class CallableAndFutureTest &#123; public static void main(String[] args) &#123; Callable&lt;Integer&gt; callable = new CallableDemo(); FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(callable); new Thread(futureTask).start(); try &#123; Thread.sleep(5000); System.out.println(futureTask.get()); &#125;catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 线程间协作线程之间的通信协作可以使用Object对象中的wait()方法，notify()方法，notifyAll()方法来实现。 wait(),wait(long),wait(long,int) 该方法将当前线程进入休眠状态，wait()方法只能使用在同步方法或者同步块中调用。调用wait()方法后，当前线程释放锁。该线程处于该对象的等待池中。 notify()，notifyAll() 该方法用来通知那些可能在等待该对象的对象锁的其他线程。notify()方法必须在同步方法或代码块中调用。被唤醒的对象进入该对象的锁池中，锁池中的线程会去竞争该对象锁。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MVC简介]]></title>
      <url>%2F2016%2F11%2F28%2FMVC%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[MVC简介面试的时候被问到关于MVC相关的知识，才发现自己只会说出来什么叫MVC，但是其详细的东西自己却无法顺利的表述出来，特在此记录下。 MVC基础MVC是Model-View-Controller的简称，是一种软件架构模式，也是经过很多人的长期实践最后得出来的很适合软件开发的一种模式。 M（Model）模型层，这应该是最底层的一层，这一层中我们需要处理的是业务逻辑和数据等等方面的东西，包括核心业务代码的编写，访问数据库或者文件进行数据处理，数据库等很多方面。 V（View）视图层，这一层是最上面的一层，用户可以看到并且进行操作的地方。 C（Controller）控制层，这部分处于中间，负责转发和处理请求，接收来自视图层用户的操作等，负责处理和转发；会根据情况传递到模型层，模型层做完处理之后，再由控制层根据实际情况返回到视图层去展示。另外一种情况是在模型层处理完之后，可以直接将结果返回给视图层。 Web MVCWeb开发中的MVC模式跟标准的MVC模式一样，但是Web MVC不能在模型层将结果主动推送给视图层，因为Web模式下是基于请求-响应模型的。其他的定义和流程都和标准MVC模式是一样的。 Web如何进化到MVC这里的Web进化主要利用Java开发方面的历程作说明，当然最开始的CGI不算是Java中的过程，但是还是需要它作为开头。 大致的历程为：CGI --&gt; Servlet --&gt; JSP --&gt; Model1 --&gt; Model2 CGI由于没有使用过CGI这种技术做过开发，只能使用维基上的定义来简单说明下。CGI是通用网关接口（Common Gateway Interface）的简称，多使用Perl语言编写，接受用户的请求，然后根据请求的返回给用户HTML页面。但是每次CGI请求都会生成一个新的进程去处理，对服务器来说压力太大，请求大的时候很快就会垮掉。 ServletServlet技术和CGI技术的作用是一样的，但是Servlet是Java体系中最早用来解决Web的技术。Java是平台无关的，同样Servlet也是，它比CGI更加的高高效，CGI针对请求生成的是进程级别的，而Servlet生成的是线程级别的。 Servlet的生命周期 加载和实例化 Servlet容器负责加载和实例化Servlet。 初始化 Servlet在实例化之后，会调用init()方法初始化。 服务 Servlet的service()方法对请求进行处理。 销毁 Servlet的destory()方法用来销毁Servlet实例，释放资源等。 Servlet缺点Servlet技术让Java有了Web方面的更好的选择，后来的技术很大一部分都是在Servlet的基础上发展来的。但是Servlet直接做开发还是显得很繁琐，我在使用Servlet做开发的时候遇到过很多的弊端，直接点说就是Servlet做开发时，把MVC的分层直接放到一起了，甚至html代码也得在Servlet里面直接输出。这样的做法对于后期维护修改或者页面的调试很是麻烦。现在直接用Servlet做开发已经很少用了，但是还是得作为必须要去学习的基础知识。 JSPJSP技术使用在html页面中嵌入脚本语言的方式来处理Servlet技术的不足，相对于Servlet来说有了很多进步，开发页面更加方便简单。但是实质上JSP最后还是被编译成了Servlet，表现逻辑以及控制和模型等方面的逻辑还是混杂在了一起，看起来好像是跟Servlet反过来一样。这种做法同样不可取。 Model1这种技术是JSP和JavaBean的组合，相对于JSP来说只是将业务逻辑放到了单独的JavaBean中去，可以理解为是JSP的增强，对JSP页面进行了简化，但是JSP页面仍然将表现逻辑，控制逻辑，业务逻辑等混杂到一起。这种做法仍然不可取。 Model2Model2采用JSP+Servlet+JavaBean来实现，其实这时候就可以认为是我们的Web MVC模型了，在实际使用中也是使用的这种模式。 JSP 使用html和jsp的标签来负责实现表现层；Servlet负责接收用户的请求，转交给模型层进行处理，返回结果给视图层等功能；JavaBean负责业务逻辑的处理，也就是模型层的功能。 到这里为止，开发过程中遇到的方式都已经介绍完了，也走到了MVC模式这一步。下面会简单介绍下MVC的框架相关知识。 Spring Web MVC先看一下Spring官方的一张请求处理流程图：再看一下具体的流程： 第一步，用户发送请求（Incoming request）到前端控制器（Front controller） 前端控制器（Front controller）根据实际的请求信息来决定把请求委托给具体的页面控制器（Controller）。页面控制器用来处理实际的请求内容，直接返回或者需要Model层进行数据处理。 页面控制器（Controller）接收到请求后进行处理，处理完成后返回model数据，并委托给前端控制器（Front controller）进行渲染。 前端控制器（Front controller）根据逻辑视图名和model数据选择视图模板（View template）进行渲染，渲染完成后返回给前端控制器（Front controller）。 最后前端控制器将渲染后的最终结果返回给用户。 对应具体的源码分析不在此做过多说明。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Executor框架简介]]></title>
      <url>%2F2016%2F08%2F11%2FExecutor%E6%A1%86%E6%9E%B6%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[Executor框架是在Java5中引入的，可以通过该框架来控制线程的启动，执行，关闭，简化并发编程。Executor框架把任务提交和执行解耦，要执行任务的人只需要把任务描述清楚提交即可，任务的执行提交人不需要去关心。 通过Executor框架来启动线程比使用Thread更好，更易管理，效率高，避免this逃逸问题。 Executor的实现还提供了对生命周期的支持，以及统计信息收集，应用程序管理机制和性能监视等机制。 Executor框架源码版本： jdk1.7.0_71 Executor框架由3大部分组成： 任务：被执行任务需要实现接口Runnable、Callable。 任务执行：任务执行机制的核心接口Executor，继承Executor的ExecutorService。CompletionService等。 异步计算的结果：Future和实现了Future接口的FutureTask类。 Executor是一个接口，只定义了一个方法void execute(Runnable command);该方法接受一个Runnable实例，作用就是执行提交的任务，实现在子类中。 ExecutorService也是一个接口，继承自Executor接口，提供了更多的方法，提供了生命周期的管理方法，以及可跟踪一个或多个异步任务执行状况的方法。 ExecutorService的生命周期包括三种状态：运行，关闭，终止。创建后便进入运行状态，当调用了shutdown()方法时，进入关闭状态，此时不再接受新任务，但是它还在执行已经提交了的任务，当所有的任务执行完后，便达到了终止状态。 shutdown()关闭当前服务，当调用此方法时，它将不再接受新的任务，已经提交的任务，还要继续执行完毕。 shutdownNow()1List&lt;Runnable&gt; shutdownNow(); 关闭当前服务，尚未执行的任务，不再执行；正在执行的任务，通过线程中断thread.interrupt。方法返回等待执行的任务列表。 isShutdown()程序是否已经关闭。 isTerminated()程序是否已经终止。已经关闭并且所有的任务都执行完成，返回true，其他返回false。 awaitTermination()12boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; 请求关闭、发生超时或者当前线程中断，无论哪一个首先发生之后，都将导致阻塞，直到所有任务完成执行。如果程序终止，返回true，如果超时，返回false，等待时发生中断，抛出异常。 submit(Callable task)1&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); 向Executor提交一个Clallable任务，并返回一个Future； submit(Runnable task, T result)1&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); 向Executor提交一个Runnable任务，并返回一个Future； submit(Runnable task)1Future&lt;?&gt; submit(Runnable task); 向Executor提交一个Runnable任务，并返回一个Future； invokeAll（）执行所有任务列表，当所有任务执行完成之后，返回Future列表。 invokeAny()在执行的任务集合中，任何一个完成就返回。 Executors提供了一系列静态工厂方法用于创建各种线程池。返回的线程池都实现了ExecutorService接口。 如果没有特殊要求，请尽量使用此类中提供的静态方法生成线程池。 大部分方法的底层实现都在ThreadPoolExecutor类中，有关ThreadPoolExecutor介绍请往下翻。ThreadPoolExecutor的构造函数如下： 1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) newFixedThreadPool(int nThreads)创建一个可重用的固定线程数的线程池，以共享无界队列方式来运行这些线程。 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; corePoolSize和maximumPoolSize大小一样，使用无界queue的话maximumPoolSize参数是没有意义的。改方法使用的是LinkedBlockingQueue无界队列。keepAliveTime为0. newFixedThreadPool(nThreads, ThreadFactory)使用给定的ThreadFactory创建一个可重用的固定线程数的线程池，以共享无界队列方式运行这些线程。 newSingleThreadExecutor创建一个使用单个线程的线程池，使用无界队列来运行该线程。 newSingleThreadExecutor(ThreadFactory)使用给定的ThreadFactory创建一个单个线程的线程池，使用无界队列来运行该线程。 newCachedThreadPool创建一个可根据需要创建新线程的线程池，以前构造的线程可用时将重用它们。对于执行很多短期异步任务的程序而言，这些线程池通常可提高程序性能。 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; maximumPoolSize为最大，是一个无界线程池。workqueue使用SynchronousQueue，该queue中每个插入操作必须等待另一个线程的对应移除操作。它的主要提供的功能是线程复用，但不能控制线程数量。 newCachedThreadPool(ThreadFactory)使用给定的ThreadFactory创建一个可根据需要创建新线程的线程池，以前构造的线程可用时将重用它们。对于执行很多短期异步任务的程序而言，这些线程池通常可提高程序性能。 newSingleThreadScheduledExecutor创建一个使用单个线程的线程池，该线程池支持定时以及周期性执行任务的功能。 newScheduledThreadPool(corePoolSize)创建一个指定数量的线程的线程池，该线程池支持定时以及周期性执行任务的功能。 AbstractExecutorServiceExecutorService方法的默认实现类。 ScheduledExecutorService一个可定时调度任务的接口。扩展了ExecutorService。支持Future和定期执行任务。 ScheduledThreadPoolExecutorScheduledExecutorService的实现，一个可定时调度任务的线程池。 ThreadPoolExecutor线程池，可以通过调用Executors的静态工厂方法来创建线程池并返回一个ExecutorService对象。 ThreadPoolExecutor是Executors的底层实现，看Executors源码可知，大部分的生成线程池的方法内部都是调用此类的方法。 该类继承了AbstractExecutorService。 构造方法123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; corePoolSize 池中所保存的核心线程数，包括空闲线程。 maximumPoolSize池中允许创建的最大线程数。当workqueue使用无界队列LinkedBlockingQueue等时，此参数无效。 keepAliveTime当前线程池线程总数大于核心线程数时，终止多余的空闲线程时间。 unitkeepAliveTime参数的时间单位 workQueue工作队列，如果当前线程池达到核心线程数时，且当前所有线程都处于活动状态，则将新加入的任务放到此队列中。仅保持由execute方法提交的Runnable任务。 ArrayBlockingQueue 基于数组结构有界队列，FIFO原则对任务进行排序，队列满了之后的任务，调用拒绝策略。 LinkedBlockingQueue 基于链表结构的无界队列，FIFO原则对任务进行排序。 SynchronousQueue 直接将任务提交给线程而不是将它加入到队列，实际上此队列是空的。每个插入的操作必须等到另一个调用移除的操作；如果新任务来了线程池没有任何可用线程处理的话，则调用拒绝策略。 PriorityBlockingQueue 具有优先级的队列的有界队列，可以自定义优先级；默认是按自然排序。 threadFactory 执行程序创建新线程时使用的工厂。 handler 超出线程范围和队列容量时，执行被阻塞，此时可以选择用此handler进行处理。 Callable，Future与FutureTask在之前创建线程的时候都是继承Thread或者实现Runnable接口，这种方法在任务完成后无法获取执行结果。而在Java5之后有了Runnable和Future，可以在任务执行完之后得到任务执行结果。 CallableCallable能产生结果，Future能拿到结果。Callable和Runnable接口类似，Runnable不会返回结果，也无法抛出返回结果的异常，而Callable可以返回值，这个值可被Future拿到。 Callable一般和ExecutorService一起使用，ExecutorService的submit方法提交的是Runnable或者是Callable类型的Task。 FutureFuture对具体提交的Callable任务执行结果进行取消，查询是否完成，获取结果。可以通过get方法获取执行结果，该方法会阻塞直到任务返回结果。Future接口的具体实现都在FutureTask中。 cancel()方法1boolean cancel(boolean mayInterruptIfRunning); 可以取消任务，成功返回true，失败返回false。 参数mayInterruptIfRunning表示是否取消正在执行但是没有执行完成的任务，true可以取消，false不取消 如果任务已经完成，无论参数是true或false，都返回false 如果任务正在执行，若参数为true，返回true；若参数为false，返回false； 如果任务还未执行，无论参数是true或false，都返回true。 isCancelled()方法表示任务是否被取消成功。 isDone()方法表示任务是否已经完成。 get()方法1V get() throws InterruptedException, ExecutionException; 用来获取执行结果，会一直阻塞等到任务执行完成之后返回。 get(timeout,unit)方法12V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; 用来获取执行结果，指定时间内获取不到结果，返回null FutureTaskFutureTask实现了RunnableFuture接口，RunnableFuture接口继承了Runnable和Future接口。 是Future接口的唯一实现。 FutureTask是为了弥补Thread的不足而设计的，它可以让程序员准确地知道线程什么时候执行完成并获得到线程执行完成后返回的结果（如果有需要） 可用于要异步获取执行结果或取消执行任务的场景。 FutureTask是一种可以取消的异步的计算任务。它的计算是通过Callable实现的，它等价于可以携带结果的Runnable，并且有三个状态：等待、运行和完成。完成包括所有计算以任意的方式结束，包括正常结束、取消和异常。 利用开始和取消计算的方法、查询计算是否完成的方法和获取计算结果的方法，此类提供了对 Future 的基本实现。仅在计算完成时才能获取结果；如果计算尚未完成，则阻塞 get 方法。一旦计算完成，就不能再重新开始或取消计算。 CompletionService我们可以通过线程池的submit方法提交一个Callable任务，利用返回的Future的get方法来获取任务运行的结果，但是这种方法需要自己循环获取task，而且get方法会阻塞。 还可以用CompletionService来实现，CompletionService维护一个保存Future对象的BlockQueue，当Future对象状态是结束的时候，会加入到队列中，可以通过take方法，取出Future对象。 submit()方法，用于提交任务。 take()方法，获取任务结果。获取并移除表示下一个已完成任务的Future，如果任务不存在，则等待。 poll()方法，获取任务结果。获取并移除表示下一个已完成任务的Future，如果不存在，则返回null。 方法的实现都在ExecutorCompletionService中。 ExecutorCompletionServiceExecutorCompletionService是CompletionService的实现类，在submit任务时，会创建一个QueueingFuture，然后将创建的QueueingFuture交给executor去完成任务的执行。 QueueingFuture继承自FutureTask类。 内部维护了一个可阻塞的队列，具体实现使用LinkedBlockingQueue。 提交到ExecutorCompletionService的任务会在内部被包装成QueueingFuture，并由内部的executor来执行这个任务，当任务执行完成后，会被加入到内部的队列里面，外部程序就可以通过take或者poll方法来获取完成的任务了。 实例摘自线程池实例：使用Executors和ThreadPoolExecutor这篇文章，如有需要点击标题查看全文。 首先创建一个实现Runable接口的类： 123456789101112131415161718192021222324252627282930package com.journaldev.threadpool; public class WorkerThread implements Runnable &#123; private String command; public WorkerThread(String s)&#123; this.command=s; &#125; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()+&quot; Start. Command = &quot;+command); processCommand(); System.out.println(Thread.currentThread().getName()+&quot; End.&quot;); &#125; private void processCommand() &#123; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; @Override public String toString()&#123; return this.command; &#125;&#125; 测试程序： 1234567891011121314151617181920package com.journaldev.threadpool; import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors; public class SimpleThreadPool &#123; public static void main(String[] args) &#123; ExecutorService executor = Executors.newFixedThreadPool(5); for (int i = 0; i &lt; 10; i++) &#123; Runnable worker = new WorkerThread(&quot;&quot; + i); executor.execute(worker); &#125; executor.shutdown(); while (!executor.isTerminated()) &#123; &#125; System.out.println(&quot;Finished all threads&quot;); &#125; &#125; 上面的代码中，创建了一个能包含5个线程的固定大小的线程池，for循环向线程池提交10个任务。首先启动5个线程，其他的任务等待，当其中的任务执行完成，等待的任务会被选中一个执行。 参考http://my.oschina.net/smartsales/blog/529044 http://blog.csdn.net/ns_code/article/details/17465497 http://www.cnblogs.com/MOBIN/p/5436482.html http://www.infoq.com/cn/articles/executor-framework-thread-pool-task-execution-part-01 http://my.oschina.net/pingpangkuangmo/blog/666762 http://blog.csdn.net/gemmem/article/details/8956703 http://uule.iteye.com/blog/1539084 http://brokendreams.iteye.com/blog/2252800]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ConcurrentLinkedQueue简介]]></title>
      <url>%2F2016%2F08%2F05%2FConcurrentLinkedQueue%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[ConcurrentLinkedQueue是一个基于链表的无界线程安全队列，非阻塞实现方式，先进先出，适合高并发的场景。 非阻塞的性能较好，采用CAS，避免加锁的时间，保证数据一致性。 采用“wait-free”算法实现。 （此部分源码看的比较吃力，很多不懂的地方，还有很多不知道的地方，希望不要误导读者，有好的文章之类的，希望能推荐下，谢谢） 定义ConcurrentLinkedQueue继承AbstractQueue，实现 Queue, Serializable接口。内部通过链表实现。 ConcurrentLinkedQueue链表节点Node的数据item是volatile类型的，next节点也是volatile类型的。 默认构造一个空的ConcurrentLinkedQueue，head=tail= new Node(null) 源码分析 jdk1.7.0_71 add(E)方法添加元素到队列尾部，实现是用offer，下面会说offer方法。 123public boolean add(E e) &#123; return offer(e);&#125; offer(E)方法添加元素到队列尾部。 123456789101112131415161718192021222324252627282930313233public boolean offer(E e) &#123; checkNotNull(e); //创建新节点 final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e); //循环开始，tail赋值给t，t赋值给p，此处是死循环，保证该入队操作能够一直重试，直到入队成功 for (Node&lt;E&gt; t = tail, p = t;;) &#123; //p的next赋值给q Node&lt;E&gt; q = p.next; //如果q是null，说明tail的next是null，tail指向的是队列尾部，所以tail的next应该始终是null，此处表示p是最后一个节点 if (q == null) &#123; // p是尾节点，则p的next节点是要入队列的节点 //cas操作，若失败表示其他线程对尾节点进行了修改，重新循环 //将p（p指向tail）的next指向新节点，若成功，进入if语句 if (p.casNext(null, newNode)) &#123; //cas操作成功后，判断p是否等于t，p不等于t，设置newNode为新的尾节点,p不等于t表示什么？(此处有不明白，希望高手帮帮忙。) if (p != t) // hop two nodes at a time casTail(t, newNode); // Failure is OK. return true; &#125; // p和q相等（这部分不是太理解，希望高手帮忙下） &#125; else if (p == q) // We have fallen off list. If tail is unchanged, it // will also be off-list, in which case we need to // jump to head, from which all live nodes are always // reachable. Else the new tail is a better bet. p = (t != (t = tail)) ? t : head; else // Check for tail updates after two hops. p = (p != t &amp;&amp; t != (t = tail)) ? t : q; &#125;&#125; poll()方法删除并返回头部元素 12345678910111213141516171819202122232425public E poll() &#123; //设置循环标记 restartFromHead: for (;;) &#123; for (Node&lt;E&gt; h = head, p = h, q;;) &#123; E item = p.item; //表头数据不为null，cas操作设置表头数据为null成功进入if if (item != null &amp;&amp; p.casItem(item, null)) &#123; //p不等于h，队列头发生了变化，更新队列头为p，返回原来队列头的item if (p != h) // hop two nodes at a time updateHead(h, ((q = p.next) != null) ? q : p); return item; &#125; //队列头下一个节点为null，更新头尾p返回null else if ((q = p.next) == null) &#123; updateHead(h, p); return null; &#125; else if (p == q) continue restartFromHead; else p = q; &#125; &#125;&#125; peek()方法返回队列头部的元素，跟poll方法类似 12345678910111213141516public E peek() &#123; restartFromHead: for (;;) &#123; for (Node&lt;E&gt; h = head, p = h, q;;) &#123; E item = p.item; if (item != null || (q = p.next) == null) &#123; updateHead(h, p); return item; &#125; else if (p == q) continue restartFromHead; else p = q; &#125; &#125;&#125; size()方法需要遍历队列，不推荐使用，尽量使用isEmpty() 123456789public int size() &#123; int count = 0; for (Node&lt;E&gt; p = first(); p != null; p = succ(p)) if (p.item != null) // Collection.size() spec says to max out if (++count == Integer.MAX_VALUE) break; return count;&#125; 参考http://www.infoq.com/cn/articles/ConcurrentLinkedQueue http://www.cnblogs.com/skywang12345/p/3498995.html http://vickyqi.com/2015/10/29/JDK%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E2%80%94%E2%80%94ConcurrentLinkedQueue/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[LinkedBlockingQueue简介]]></title>
      <url>%2F2016%2F08%2F05%2FLinkedBlockingQueue%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[LinkedBlockingQueue是一个单向链表实现的阻塞队列，先进先出的顺序。支持多线程并发操作。 相比于数组实现的ArrayBlockingQueue的有界，LinkedBlockingQueue可认为是无界队列。多用于任务队列。 定义LinkedBlockingQueue继承AbstractQueue，实现了BlockingQueue，Serializable接口。内部使用单向链表存储数据。 默认初始化容量是Integer最大值。 插入和取出使用不同的锁，putLock插入锁，takeLock取出锁，添加和删除数据的时候可以并行。多CPU情况下可以同一时刻既消费又生产。 源码分析 jdk1.7.0_71 put(E)方法向队列尾部添加元素，队列已满的时候，阻塞等待。 1234567891011121314151617181920212223public void put(E e) throws InterruptedException &#123; if (e == null) throw new NullPointerException(); int c = -1; Node&lt;E&gt; node = new Node(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try &#123; while (count.get() == capacity) &#123; notFull.await(); &#125; enqueue(node); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) signalNotEmpty();&#125; offer(E)方法向队列尾部添加元素，队列已满的时候，直接返回false。 1234567891011121314151617181920212223public boolean offer(E e) &#123; if (e == null) throw new NullPointerException(); final AtomicInteger count = this.count; if (count.get() == capacity) return false; int c = -1; Node&lt;E&gt; node = new Node(e); final ReentrantLock putLock = this.putLock; putLock.lock(); try &#123; if (count.get() &lt; capacity) &#123; enqueue(node); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); &#125; &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) signalNotEmpty(); return c &gt;= 0;&#125; 不做过多分析，发现下面参考处的文章写得不错，建议看下。 参考http://www.jianshu.com/p/cc2281b1a6bc]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[我的计算机之路]]></title>
      <url>%2F2016%2F07%2F29%2F%E6%88%91%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B9%8B%E8%B7%AF%2F</url>
      <content type="text"><![CDATA[从03年接触第一本计算机相关的书，到第一次接触计算机申请第一个qq，到第一台手机，第一台智能机，在手机上做开发学习，到第二次高考报志愿的毫不犹豫的选择计算机，到现在找工作都感觉困难，到现在的感觉迷茫，有时候很想退回去03年，不去翻看那几本书！ 2003年，3本书和一张光盘家里很穷，我还在上初中。有关这3本书和光盘的来历有点记不清楚了，但是这三本书和光盘的主人我记得，是我一个从小就很崇拜的堂叔的。堂叔长得帅气，很稳重，那时候技校到处都是招计算机，厨师之类的，他去培训了计算机。这书有可能就是他不用了，不知道怎么的就到我手里了。（现在还在馋涎他的7位QQ）。 关于三本书记得都不太清楚了，一本大概是Frontpage2000，一本是网页制作与网站之类的，一本是有关电脑维修之类的，还有一张至今藏在老家快要坍塌的房子里的光盘，内容我到现在都不知道是啥。 就是这三本书，带我走上了‘歧途’。简单的看了一点之后，发现这东西好神奇！然后就在我长大的那间屋子里，我看完了这三本书。从此一发不可收拾，电脑变成了我唯一的梦想，什么社会主义接班人，什么科学家的我都不在乎了。 后来街上有了网吧，但是对于我来说那地方仍然是个只有贵族才能去的地方。终于有一天，我另外一个叔带我去了网吧，第一次摸到了电脑，申请了第一个qq，激动的不行！在那之后，也和同学去了几次网吧，他们都是去玩游戏聊天，但是我却一点兴趣都有，在网上翻看各种电脑计算机网络网站网页等等的一些信息，不知道为什么我要看这些，但是我却一直这样，直到后来上高中也是如此。 第一台手机和编程差不多应该是04年的时候，家里买了第一台手机，摩托罗拉v8088，没几天便玩的烂熟，闭着眼都能直到我操作的是啥。唯一一个功能是我不敢碰的：Internet，很想点，但是又怕收费挨揍。后来又接触到了很多很多的手机三星的抽拉天线的那种老式手机，诺基亚，波导，摩托罗拉等等~直到遇到了三星D908，哇好神奇，可以安装Java软件游戏！还可以刷机！刷机！刷机！扩大运存等等。 从此便进入了一个新天地里，到处找资源破解刷机发布出去等等。随着知道的越来越多，也越来约不满足，饿着肚子攒钱，终于到手一台神器：二手的多普达D9000，这是神器，这是智能机，这是全键盘，这是触屏，这是小型电脑，这是砖头块！运行wm6.0，相当智能。 进入WM时代，也正是他将要没落的时候，也正是那时候让我知道了外面更精彩的世界。用这台手机，我自学了c/pocket c,开始用手机写了程序，知道了python，也了解了诺基亚更多的东西，用各种模拟器体验了Android和IOS系统等等。 当我开始刷了WM6.5的时候，也体验了诺基亚的智能操作系统，那时候便感觉s60和wm即将被Android代替！但是没想到IOS会和Android平分天下。 就这样，我意外的考上了二本，报志愿的时候，其他的专业一眼没看，全部计算机。 2010沈阳化工大学，网络工程大学就正式开始了我的计算机生涯，协会面试，给自己和同学做了很多自我介绍的作品，网页等等，顺利进入各种协会。不就便成了老师手下的得力干将，各种做网站，给学校维护网站，计算机，做项目，去外地做实施。大学生活就这么很快的过去了，我感觉什么都没有做好，什么都还没体验。 2013大三结束来到上海大三结束来到上海！开始了我的Java~~~~好迷茫！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringBoot简易教程]]></title>
      <url>%2F2016%2F07%2F08%2FSpringBoot%E7%AE%80%E6%98%93%E6%95%99%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[此为个人学习所用,从pom文件配置,datasource,log配置,到集成druid以及dubbo等都只做了简单的介绍.顺序按照个人习惯,从建立项目,到每项配置挨个进行.SpringBoot零配置,但是此项目还是用到了xml进行配置dubbo等,注解方式暂时没有去做.源码请点此查看 构建工具配置Maven可以使用两种方式:继承starter parent或者使用依赖管理器配置. 继承spring-boot-starter-parent12345&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.3.6.RELEASE&lt;/version&gt; &lt;/parent&gt; 接着下面的依赖可以指定导入其他的starter. 使用依赖管理注意加上&lt;scope&gt;import&lt;/scope&gt; 123456789101112&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;!-- Import dependency management from Spring Boot --&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.3.6.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 接着下面的依赖可以指定导入其他的starter. Gradle直接添加各个starter依赖,无需配置parent之类的. 123dependencies &#123; compile(&quot;org.springframework.boot:spring-boot-starter-web:1.3.6.RELEASE&quot;)&#125; spring-boot-starter列表 名称 描述 spring-boot-starter 核心starter,包含自动配置支持,日志和 YAML配置文件的支持 spring-boot-starter-actuator 生产环境,监控和管理应用程序 spring-boot-starter-amqp 通过 spring-rabbit 支持 AMQP spring-boot-starter-aop 包含 spring-aop 和 AspectJ 来支持面向切面编程（AOP） spring-boot-starter-artemis 通过Apache Artemis支持JMS API spring-boot-starter-batch 支持Spring Batch包括HSQLDB spring-boot-starter-cache 支持Spring Cache抽象化 spring-boot-starter-cloud-connectors 对Spring Cloud Connectors的支持，简化在云平台下（例如，Cloud Foundry 和Heroku）服务的连接 spring-boot-starter-data-elasticsearch 对Elasticsearch搜索和分析引擎的支持，包括spring-data-elasticsearch spring-boot-starter-data-gemfire 对GemFire分布式数据存储的支持，包括spring-data-gemfire spring-boot-starter-data-jpa 包含spring-data-jpa,spring-orm和Hibernate来支持JPA spring-boot-starter-data-mongodb 包含spring-data-mongodb来支持MongoDB spring-boot-starter-data-rest 通过spring-data-rest-webmvc支持以REST方式暴露Spring Data仓库 spring-boot-starter-data-solr 包含spring-data-solr支持Apache Solr搜索平台 spring-boot-starter-freemarker 支持使用FreeMarker作为模板引擎 spring-boot-starter-groovy-templates 支持使用groovy作为模板引擎 spring-boot-starter-hateoas 通过spring-hateoas支持基于HATEOAS的RESTful服务 spring-boot-starter-hornetq 通过HornetQ支持JMS API spring-boot-starter-integration 支持通用spring-integration模块 spring-boot-starter-jdbc 支持JDBC spring-boot-starter-jersey 对Jersey RESTful Web服务框架的支持 spring-boot-starter-jta-atomikos 通过Atomikos支持JTA分布式事务 spring-boot-starter-jta-bitronix 通过Bitronix支持JTA分布式事务 spring-boot-starter-mail 对javax.mail的支持 spring-boot-starter-mobile 对spring-mobile的支持 spring-boot-starter-mustache 支持使用Mustache作为模板引擎 spring-boot-starter-redis 包含spring-redis支持REDIS键值数据存储 spring-boot-starter-security 支持spring-security spring-boot-starter-social-facebook 支持spring-social-facebook spring-boot-starter-social-linkedin 支持spring-social-linkedin spring-boot-starter-social-twitter 支持spring-social-twitter spring-boot-starter-test 对常用测试依赖的支持,包括JUnit, Hamcrest和Mockito,还有spring-test模块 spring-boot-starter-thymeleaf 对Thymeleaf模板引擎的支持,包括和Spring的集成 spring-boot-starter-velocity 支持velocity模板引擎 spring-boot-starter-web 对全栈web开发的支持,包括Tomcat和spring-webmvc spring-boot-starter-websocket 支持WebSocket开发支持 spring-boot-starter-ws 支持Spring Web Services 生产准备的starts 名称 描述 spring-boot-starter-actuator 生产环境,监控和管理应用程序 spring-boot-starter-remote-shell 支持远程ssh shell 可替换spring boot中默认的starters 名称 描述 spring-boot-starter-jetty 导入Jetty HTTP引擎,作为Tomcat的替代 spring-boot-starter-log4j 对Log4J日志系统的支持 spring-boot-starter-logging 导入Spring Boot的默认日志系统Logback spring-boot-starter-tomcat 导入Spring Boot的默认HTTP引擎Tomcat spring-boot-starter-undertow 导入Undertow HTTP引擎,作为Tomcat的替代 注意:其他Starters的支持可参考官方文档说明,Starters 日志记录##Logback日志记录两种方式: 在src/main/resources(以Maven项目为例)下面创建logback.xml 12345&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration&gt; &lt;include resource=&quot;org/springframework/boot/logging/logback/base.xml&quot;/&gt; &lt;logger name=&quot;org.springframework.web&quot; level=&quot;DEBUG&quot;/&gt;&lt;/configuration&gt; 在application.properties或者application.yml中配置 application.properties: 1logging.level.org.springframework.web=DEBUG application.yml: 1234spring:logging: level: org.springframework.web: DEBUG ##Logback多环境配置(yml)参考 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253spring: profiles: #可在此处选择环境的配置,dev,prod,test #也可以在启动时添加参数-Dspring.profiles.active=dev active: dev---#dev环境spring: profiles: dev# 日志,logback配置logging: #日志文件 file: logs/spring-boot-setup.log pattern: #控制台输出格式 console: &quot;%d %-5level %logger : %msg%n&quot; #文件输出格式 file: &quot;%d %-5level [%thread] %logger : %msg%n&quot; #日志级别 level: org.springframework.web: DEBUG---#prod环境spring: profiles: prod# 日志,logback配置logging: #日志文件 file: logs/spring-boot-setup.log pattern: #控制台无输出 #文件输出格式 file: &quot;%d %-5level [%thread] %logger : %msg%n&quot; #日志级别 level: org.springframework.web: WARN---#test环境spring: profiles: test# 日志,logback配置logging: #日志文件 file: logs/spring-boot-setup.log pattern: #控制台输出格式 console: &quot;%d %-5level %logger : %msg%n&quot; #文件输出格式 file: &quot;%d %-5level [%thread] %logger : %msg%n&quot; #日志级别 level: org.springframework.web: INFO 数据库数据源以mysql为例: 注意:使用数据库需要在pom文件中添加spring-boot-starter-jdbc和mysql-connector-java的依赖 123456#数据源 datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/xxx-test username: root password: 123456 数据库连接池默认Tomcat JDBC连接池Spring Boot默认采用Tomcat JDBC连接池 12345678910datasource: max-idle: 10 max-wait: 10000 min-idle: 5 initial-size: 5 validation-query: SELECT 1 test-on-borrow: false test-while-idle: true time-between-eviction-runs-millis: 18800 jdbc-interceptors: ConnectionState;SlowQueryReport(threshold=0) Druid首先添加上druid的依赖: 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.18&lt;/version&gt;&lt;/dependency&gt; 使用其他的连接池,需要配置自己的DataSource bean: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697@Component@ConfigurationProperties(prefix = &quot;spring.datasource&quot;)public class DruidConfig &#123; private String url; private String username; private String password; private String driverClassName; private int initialSize; private int maxActive; private int minIdle; private int maxWait; private long timeBetweenEvictionRunsMillis; private long minEvictableIdleTimeMillis; private String validationQuery; private boolean testWhileIdle; private boolean testOnBorrow; private boolean testOnReturn; private boolean poolPreparedStatements; private int maxPoolPreparedStatementPerConnectionSize; private String filters; public DruidConfig() &#123; &#125; public DruidConfig(String url, String username, String password, String driverClassName, int initialSize, int maxActive, int minIdle, int maxWait, long timeBetweenEvictionRunsMillis, long minEvictableIdleTimeMillis, String validationQuery, boolean testWhileIdle, boolean testOnBorrow, boolean testOnReturn, boolean poolPreparedStatements, int maxPoolPreparedStatementPerConnectionSize, String filters) &#123; this.url = url; this.username = username; this.password = password; this.driverClassName = driverClassName; this.initialSize = initialSize; this.maxActive = maxActive; this.minIdle = minIdle; this.maxWait = maxWait; this.timeBetweenEvictionRunsMillis = timeBetweenEvictionRunsMillis; this.minEvictableIdleTimeMillis = minEvictableIdleTimeMillis; this.validationQuery = validationQuery; this.testWhileIdle = testWhileIdle; this.testOnBorrow = testOnBorrow; this.testOnReturn = testOnReturn; this.poolPreparedStatements = poolPreparedStatements; this.maxPoolPreparedStatementPerConnectionSize = maxPoolPreparedStatementPerConnectionSize; this.filters = filters; &#125; @Bean @Primary public DataSource dataSource() throws Exception&#123; DruidDataSource druidDataSource = new DruidDataSource(); druidDataSource.setUrl(this.url); druidDataSource.setUsername(this.username); druidDataSource.setPassword(this.password); druidDataSource.setDriverClassName(this.driverClassName); druidDataSource.setInitialSize(this.initialSize); druidDataSource.setMaxActive(this.maxActive); druidDataSource.setMinIdle(this.minIdle); druidDataSource.setMaxWait(this.maxWait); druidDataSource.setTimeBetweenEvictionRunsMillis(this.timeBetweenEvictionRunsMillis); druidDataSource.setMinEvictableIdleTimeMillis(this.minEvictableIdleTimeMillis); druidDataSource.setValidationQuery(this.validationQuery); druidDataSource.setTestWhileIdle(this.testWhileIdle); druidDataSource.setTestOnBorrow(this.testOnBorrow); druidDataSource.setTestOnReturn(this.testOnReturn); druidDataSource.setPoolPreparedStatements(this.poolPreparedStatements); druidDataSource.setMaxPoolPreparedStatementPerConnectionSize(this.maxPoolPreparedStatementPerConnectionSize); druidDataSource.setFilters(this.filters); try &#123; if(null != druidDataSource) &#123; druidDataSource.setFilters(&quot;wall,stat&quot;); druidDataSource.setUseGlobalDataSourceStat(true); druidDataSource.init(); &#125; &#125; catch (Exception e) &#123; throw new RuntimeException(&quot;load datasource error, dbProperties is :&quot;, e); &#125; return druidDataSource; &#125; ... geter and setter ... 配置druid的数据监控页面路径和拦截路径: 1234567891011121314@Bean public ServletRegistrationBean druidServlet() &#123; return new ServletRegistrationBean(new StatViewServlet(), &quot;/druid/*&quot;); &#125; @Bean public FilterRegistrationBean filterRegistrationBean() &#123; FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(); filterRegistrationBean.setFilter(new WebStatFilter()); filterRegistrationBean.addUrlPatterns(&quot;/*&quot;); filterRegistrationBean.addInitParameter(&quot;exclusions&quot;, &quot;*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*&quot;); return filterRegistrationBean; &#125; 然后浏览器访问http://localhost:8080/druid即可看到界面. Mybatis集成添加依赖12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt;&lt;/dependency&gt; 配置application.yml1234#Mybatis配置mybatis: mapperLocations: classpath*:me.cxis.springboot.setup.mapper/*.xml typeAliasesPackage: me.cxis.springboot.setup.dto 编写UserMapper接口和UserMapper.xml文件UserMapper接口: 1234@Mapperpublic interface UserMapper &#123; List&lt;User&gt; getUserList();&#125; UserMapper.xml文件: 12345&lt;mapper namespace=&quot;me.cxis.springboot.setup.mapper.UserMapper&quot;&gt; &lt;select id=&quot;getUserList&quot; resultType=&quot;me.cxis.springboot.setup.dto.User&quot;&gt; select * from t_user; &lt;/select&gt;&lt;/mapper&gt; 事务管理在Application中添加注解@EnableTransactionManagement启用事务管理,在需要开启事务的地方使用注解@Transactional FreeMarker模板引擎添加依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt;&lt;/dependency&gt; 添加配置在application.yml中添加freemarker配置 123456789#freemarker配置 freemarker: cache: false charset: UTF-8 check-template-location: true content-type: text/html expose-request-attributes: true expose-session-attributes: true request-context-attribute: request 创建templates目录src/main/resources 创建目录 templates,接着在此目录下创建模板文件test.ftl 1234567891011121314&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Freemarker&lt;/title&gt;&lt;/head&gt;&lt;body&gt; Date: $&#123;time?date&#125; &lt;br&gt; Time: $&#123;time?time&#125; &lt;br&gt; Message: $&#123;message&#125;&lt;/body&gt;&lt;/html&gt; 编写Controller代码: 123456@RequestMapping(value = &quot;test&quot;) public String testFreeMarker(ModelMap modelMap)&#123; modelMap.put(&quot;time&quot;,new Date()); modelMap.put(&quot;message&quot;,&quot;测试Freemarker&quot;); return &quot;test&quot;; &#125; 集成dubbo添加依赖分别添加dubbo,zookeeper,zkclient的依赖,同时需要排除依赖中的spring,log4j等 12345678910111213141516171819202122232425262728293031&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.5.3&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.1&lt;/version&gt; &lt;/dependency&gt; 服务提供方添加dubbo.properties文件 12345678910111213dubbo.container=log4j,springdubbo.application.name=tb-coredubbo.application.owner=#dubbo.registry.address=multicast://224.5.6.7:1234dubbo.registry.address=zookeeper\://127.0.0.1\:2181#dubbo.registry.address=redis://127.0.0.1:6379#dubbo.registry.address=dubbo://127.0.0.1:9090dubbo.monitor.protocol=registrydubbo.protocol.name=dubbodubbo.protocol.port=20881dubbo.service.loadbalance=roundrobindubbo.log4j.file=logs/SpringBootDubboProvider.logdubbo.log4j.level=DEBUG 添加dubbo-provider.xml 1234567891011&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;bean id=&quot;userService&quot; class=&quot;me.cxis.springboot.setup.service.impl.UserServiceImpl&quot;&gt;&lt;/bean&gt; &lt;dubbo:service timeout=&quot;3000&quot; retries=&quot;0&quot; interface=&quot;me.cxis.springboot.setup.service.UserService&quot; ref=&quot;userService&quot;/&gt;&lt;/beans&gt; 在application添加注解,导入dubbo配置文件 123456@ImportResource(&quot;classpath*:dubbo-provider.xml&quot;)public class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class,args); &#125;&#125; 服务消费方添加dubbo.properties文件 12345678910111213dubbo.container=log4j,springdubbo.application.name=SpringBootDubboConsumerdubbo.application.owner=#dubbo.registry.address=multicast://224.5.6.7:1234dubbo.registry.address=zookeeper\://127.0.0.1\:2181#dubbo.registry.address=redis://127.0.0.1:6379#dubbo.registry.address=dubbo://127.0.0.1:9090dubbo.monitor.protocol=registrydubbo.protocol.name=dubbodubbo.protocol.port=20884dubbo.service.loadbalance=roundrobindubbo.log4j.file=logs/SpringBootDubboConsumer.logdubbo.log4j.level=DEBUG 添加dubbo-consumer.xml 12345678910&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xsi:schemaLocation=&quot; http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;dubbo:reference id=&quot;userService&quot; interface=&quot;me.cxis.springboot.setup.service.UserService&quot;/&gt;&lt;/beans&gt; 在application添加注解,导入dubbo配置文件 123456@ImportResource(&quot;classpath*:dubbo-consumer.xml&quot;)public class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class,args); &#125;&#125; 参考http://docs.spring.io/spring-boot/docs/current/reference/htmlsingle https://www.ibm.com/developerworks/cn/java/j-lo-spring-boot/ https://qbgbook.gitbooks.io/spring-boot-reference-guide-zh/content/ https://springframework.guru/using-yaml-in-spring-boot-to-configure-logback/ http://blog.csdn.net/catoop/article/details/50501714 http://my.oschina.net/angerbaby/blog/552936 http://www.voidcn.com/blog/yingxiake/article/p-5930835.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[tomcat与memcached-session-manager共享session测试]]></title>
      <url>%2F2016%2F07%2F01%2Ftomcat-%E4%B8%8Ememcached-session-manager%E5%85%B1%E4%BA%ABsession%E6%B5%8B%E8%AF%95%2F</url>
      <content type="text"><![CDATA[简介看书刚好看到集群session共享,总觉得只看不做,不能确定这到底是怎么运行的.所以就做了这个测试.有关Memcached-Session-Manager,Memcached,以及集群session共享等相关知识,请自行补充.本次就简单记录下测试过程.有关其他的方式以及其他的情况,本文不做说明,有需要的话,会再写其他情况和方式下的文章. 环境说明 本机OSX 10.11,tomca7.0.57,memcached-1.4.24 虚拟机Ubuntu16.04,tomca7.0.57,memcached-1.4.24 使用non-sticky sessions（非粘性session） 序列化:使用默认,java进行序列化，由memcached-session-manager.jar这个jar包来提供方法. 有关粘性和非粘性的区别以及序列化等不做解释. 具体步骤安装jdk,memcached,tomcat不做详细说明 放jar包将如下相关jar包分别放置到两台机器的tomcat $CATALINA_HOME/lib/目录中. memcached-session-manager-${version}.jar memcached-session-manager-tc7-${version}.jar spymemcached-2.11.1.jar 修改tomcat配置文件两台机器分别修改tomcat $CATALINA_HOME/conf/context.xml文件,添加如下代码到Context节点下: 123456&lt;Manager className=&quot;de.javakaffee.web.msm.MemcachedBackupSessionManager&quot; memcachedNodes=&quot;n1:192.168.110.197:11211,n2:192.168.110.198:11211&quot; sticky=&quot;false&quot; sessionBackupAsync=&quot;false&quot; requestUriIgnorePattern=&quot;.*\.(ico|png|gif|jpg|css|js)$&quot; /&gt; 部署Web项目到tomcat新建测试用的web项目,并部署到两台tomcat中.测试代码简单如下: 12345&lt;body&gt; Session ID:&lt;%=session.getId()%&gt; &lt;br&gt; IP:&lt;%=request.getServerName()%&gt; &lt;br&gt; Port:&lt;%=request.getServerPort()%&gt;&lt;/body&gt; 启动两台机器的memcached1memcached -m 32 -p 11211 -d 启动两台机器的tomcat查看tomcat信息tail -f catalina.out未报错,看到类似如下信息就启动成功 12345678信息: --------- finished initialization:- sticky: false- operation timeout: 1000- node ids: [n1, n2]- failover node ids: []- storage key prefix: null-------- 访问测试页面分别访问两台机器的测试页面: 同一个浏览器 两个浏览器 结束掉一个机器的memcached进程在访问等等 同一个浏览器不同标签页访问192.168.110.197和192.168.110.198 得到的sessionid都是一样的: 1234567Session ID:39D5E175513B4496C136F5E1554478CD-n1 IP:192.168.110.197 Port:8080Session ID:39D5E175513B4496C136F5E1554478CD-n1 IP:192.168.110.198 Port:8080 关闭ip为197的memcached进程之后,刷新页面:1234567Session ID:39D5E175513B4496C136F5E1554478CD-n2 IP:192.168.110.197 Port:8080Session ID:39D5E175513B4496C136F5E1554478CD-n2 IP:192.168.110.198 Port:8080 测试成功. 参考https://github.com/magro/memcached-session-manager/wiki/SetupAndConfiguration#introduction http://laoxu.blog.51cto.com/4120547/1566477]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[一次简单的持久带内存溢出java.lang.OutOfMemoryError: PermGen space]]></title>
      <url>%2F2016%2F06%2F28%2F%E4%B8%80%E6%AC%A1%E7%AE%80%E5%8D%95%E7%9A%84%E6%8C%81%E4%B9%85%E4%BB%A3%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BAjava-lang-OutOfMemoryError-PermGen-space%2F</url>
      <content type="text"><![CDATA[简介昨天拿到服务器之后,便部署新开发的项目上去.顺带测试,运行不久,发现程序运行缓慢,随即提示java.lang.OutOfMemoryError: PermGen space.以前没遇到过这种情况,记录下来.服务器上的软件以及设置是一个酱油弄的,没仔细去查看,不知道是不是有问题. 查看tomcat pid1234jps -l 发现两个tomcatjps -v找到我部署程序的那个tomcat pid 32365 查看虚拟机相关信息查看jstat -gc123jstat -gc 32365S0C S1C S0U S1U EC EU OC OU PC PU YGC YGCT FGC FGCT GCT6848.0 6848.0 0.0 0.0 54976.0 742.8 137236.0 75708.3 65536.0 65535.9 115 1.345 688 172.945 174.290 发现PC和PU两个数值相同了,持久代已经使用完. 参数代表含义如下: 123456789101112131415S0C 年轻代中第一个survivor（幸存区）的容量 (字节)S1C 年轻代中第二个survivor（幸存区）的容量 (字节)S0U 年轻代中第一个survivor（幸存区）目前已使用空间 (字节)S1U 年轻代中第二个survivor（幸存区）目前已使用空间 (字节)EC 年轻代中Eden（伊甸园）的容量 (字节)EU 年轻代中Eden（伊甸园）目前已使用空间 (字节)OC Old代的容量 (字节)OU Old代目前已使用空间 (字节)PC Perm(持久代)的容量 (字节)PU Perm(持久代)目前已使用空间 (字节)YGC 从应用程序启动到采样时年轻代中gc次数YGCT 从应用程序启动到采样时年轻代中gc所用时间(s)FGC 从应用程序启动到采样时old代(全gc)gc次数FGCT 从应用程序启动到采样时old代(全gc)gc所用时间(s)GCT 从应用程序启动到采样时gc用的总时间(s) 查看jstat -gcpermcapacity123jstat -gcpermcapacity 32365PGCMN PGCMX PGC PC YGC FGC FGCT GCT12288.0 65536.0 65536.0 65536.0 115 610 153.078 154.423 持久代初始大小(PGCMN)12M,最大(PGCMX)64M,上面一步显示,64M已经用完.可以考虑增加持久代大小64M增大到256M. 参数代表含义如下: 12345678PGCMN perm代中初始化(最小)的大小 (字节)PGCMX perm代的最大容量 (字节)PGC perm代当前新生成的容量 (字节)PC Perm(持久代)的容量 (字节)YGC 从应用程序启动到采样时年轻代中gc次数FGC 从应用程序启动到采样时old代(全gc)gc次数FGCT 从应用程序启动到采样时old代(全gc)gc所用时间(s)GCT 从应用程序启动到采样时gc用的总时间(s) 设置tomcat tomcat bin 目录下找到setenv.sh,没有的话新建一个 添加如下内容到setenv.sh export CATALINA_OPTS=&quot;$CATALINA_OPTS -XX:PermSize=256m -XX:MaxPermSize=256m&quot; 重启tomcat 参考http://stackoverflow.com/questions/19769675/tomcat-7-outofmemoryerror-from-uncaughtexceptionhandler http://tdcq.iteye.com/blog/1990666]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring事务简介]]></title>
      <url>%2F2016%2F06%2F13%2FSpring%E4%BA%8B%E5%8A%A1%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[事务的传播行为Spring事务有7种传播行为: PROPAGATION_REQUIRED 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。 PROPAGATION_SUPPORTS 支持当前事务，如果当前没有事务，就以非事务方式执行。 PROPAGATION_MANDATORY 支持当前事务，如果当前没有事务，就抛出异常。 PROPAGATION_REQUIRES_NEW 新建事务，如果当前存在事务，把当前事务挂起。 PROPAGATION_NOT_SUPPORTED 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER 以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED 如果一个活动的事务存在，则运行在一个嵌套的事务中. 如果没有活动事务, 则按PROPAGATION_REQUIRED 属性执行 事务隔离级别Spring事务有5种隔离级别 ISOLATION_DEFAULT 这是一个PlatfromTransactionManager默认的隔离级别，使用数据库默认的事务隔离级别. ISOLATION_READ_UNCOMMITTED 这是事务最低的隔离级别，允许读取尚未提交的更改。可能导致脏读、幻影读或不可重复读。 ISOLATION_READ_COMMITTED 允许从已经提交的并发事务读取。可防止脏读，但幻影读和不可重复读仍可能会发生。 ISOLATION_REPEATABLE_READ 对相同字段的多次读取的结果是一致的，除非数据被当前事务本身改变。可防止脏读和不可重复读，但幻影读仍可能发生。 ISOLATION_SERIALIZABLE 这是花费最高代价但是最可靠的事务隔离级别。事务被处理为顺序执行。除了防止脏读，不可重复读外，还避免了幻像读。 只读事务超时回滚规则Spring默认情况下会对RunTimeException进行事务回滚。这个异常是unchecked,如果遇到checked意外就不回滚。 改变默认规则： 让checked例外也回滚：在整个方法前加上 @Transactional(rollbackFor=Exception.class) 让unchecked例外不回滚： @Transactional(notRollbackFor=RunTimeException.class) 不需要事务管理的(只查询的)方法：@Transactional(propagation=Propagation.NOT_SUPPORTED) 如果不添加rollbackFor等属性，Spring碰到Unchecked Exceptions都会回滚，不仅是RuntimeException，也包括Error。 注意:如果异常被try｛｝catch｛｝了，事务就不回滚了，如果想让事务回滚必须再往外抛try｛｝catch｛throw Exception｝。 参考http://fhjxp.iteye.com/blog/124978 http://liubingwwww.blog.163.com/blog/static/3048510720091842335402/ http://www.cnblogs.com/zhishan/p/3195219.html http://www.cnblogs.com/0201zcr/p/4678649.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[synchronized和volatile简介]]></title>
      <url>%2F2016%2F06%2F08%2Fsynchronized%E5%92%8Cvolatile%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[简介(转)这个可能是最好的对比volatile和synchronized作用的文章了。 volatile是一个变量修饰符，而synchronized是一个方法或块的修饰符。所以我们使用这两种关键字来指定三种简单的存取变量的方式。 12345678int i1;int geti1() &#123;return i1;&#125;volatile int i2;int geti2() &#123;return i2;&#125;int i3;synchronized int geti3() &#123;return i3;&#125; geti1()在当前线程中立即获取在i1变量中的值。线程可以获得变量的本地拷贝，而所获得的变量的值并不一定与其他线程所获得的值相同。特别是，如果其他的线程修改了i1的值，那么当前线程获得的i1的值可能与修改后的值有所差别。 实际上，Java有一种主内存的机制，使用一个主内存来保存变量当前的正确的值。线程将变量的值拷贝到自己独立的内存中，而这些线程的内存拷贝可能与主内存中的值不同。所以实际当中可能发生这样的情况，在主内存中i1的值为1，线程1和线程2都更改了i1，但是却没把更新的值传回给主内存或其他线程中，那么可能在线程1中i1的值为2，线程2中i1的值却为3。 另一方面，geti2()可以有效的从主内存中获取i2的值。一个volatile类型的变量不允许线程从主内存中将变量的值拷贝到自己的存储空间。因此，一个声明为volatile类型的变量将在所有的线程中同步的获得数据，不论你在任何线程中更改了变量，其他的线程将立即得到同样的结果。由于线程存取或更改自己的数据拷贝有更高的效率，所以volatile类型变量在性能上有所消耗。 那么如果volatile变量已经可以使数据在线程间同步，那么synchronizes用来干什么呢？两者有两方面的不同。首先，synchronized获取和释放由监听器控制的锁，如果两个线程都使用一个监听器(即相同对象锁)，那么监听器可以强制在一个时刻只有一个线程能处理代码块，这是最一般的同步。 另外，synchronized还能使内存同步。在实际当中，synchronized使得所有的线程内存与主内存相同步。所以geti3()的执行过程如下： 线程从监听器获取对象的锁。(这里假设监听器非锁，否则线程只有等到监听器解锁才能获取对象锁) 线程内存更新所有的变量，也就是说他将读取主内存中的变量使自己的变量保证有效。(JVM会使用一个“脏”标志来最优化过程，使得仅仅具有“脏”标志变量被更新。详细的情况查询JAVA规范的17.9) 代码块被执行(在这个例子中，设置返回值为刚刚从主内存重置的i3当前的值。) 任何变量的变更将被写回到主内存中。但是这个例子中geti3()没有什么变化。 线程释放对象的锁给监听器。所以volatile只能在线程内存和主内存之间同步一个变量的值，而synchronized则同步在线程内存和主内存之间的所有变量的值，并且通过锁住和释放监听器来实现。显然，synchronized在性能上将比volatile更加有所消耗。 关于两者的区别 volatile本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取；synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。 volatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别的 volatile仅能实现变量的修改可见性，不能保证原子性；而synchronized则可以保证变量的修改可见性和原子性 volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞。 volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化 参考http://blog.csdn.net/wanghai__/article/details/6260178]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[乐观锁与悲观锁简介]]></title>
      <url>%2F2016%2F06%2F03%2F%E4%B9%90%E8%A7%82%E9%94%81%E4%B8%8E%E6%82%B2%E8%A7%82%E9%94%81%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[悲观锁 在关系数据库管理系统里，悲观并发控制（又名“悲观锁”，Pessimistic Concurrency Control，缩写“PCC”）是一种并发控制的方法。它可以阻止一个事务以影响其他用户的方式来修改数据。如果一个事务执行的操作都某行数据应用了锁，那只有当这个事务把锁释放，其他事务才能够执行与该锁冲突的操作。悲观并发控制主要用于数据争用激烈的环境，以及发生并发冲突时使用锁保护数据的成本要低于回滚事务的成本的环境中。 悲观锁，正如其名，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度(悲观)，因此，在整个数据处理过程中，将数据处于锁定状态。 悲观锁的实现，往往依靠数据库提供的锁机制 （也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）. 悲观锁,假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。悲观锁假定其他用户企图访问或者改变你正在访问、更改的对象的概率是很高的，因此在悲观锁的环境中，在你开始改变此对象之前就将该对象锁住，并且直到你提交了所作的更改之后才释放锁。悲观的缺陷是不论是页锁还是行锁，加锁的时间可能会很长，这样可能会长时间的限制其他用户的访问，也就是说悲观锁的并发访问性不好。 悲观锁应用 需要使用数据库的锁机制 乐观锁 在关系数据库管理系统里，乐观并发控制（又名“乐观锁”，Optimistic Concurrency Control，缩写“OCC”）是一种并发控制的方法。它假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，正在提交的事务会进行回滚。乐观事务控制最早是由孔祥重（H.T.Kung）教授提出。 乐观锁（ Optimistic Locking ） 相对悲观锁而言，乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。 乐观锁,假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。乐观锁不能解决脏读的问题。乐观锁则认为其他用户企图改变你正在更改的对象的概率是很小的，因此乐观锁直到你准备提交所作的更改时才将对象锁住，当你读取以及改变该对象时并不加锁。可见乐观锁加锁的时间要比悲观锁短，乐观锁可以用较大的锁粒度获得较好的并发访问性能。但是如果第二个用户恰好在第一个用户提交更改之前读取了该对象，那么当他完成了自己的更改进行提交时，数据库就会发现该对象已经变化了，这样，第二个用户不得不重新读取该对象并作出更改。这说明在乐观锁环境中，会增加并发用户读取对象的次数。 乐观锁应用 使用版本号 使用时间戳 乐观锁与悲观锁的优点和缺点悲观并发控制实际上是“先取锁再访问”的保守策略，为数据处理的安全提供了保证。但是在效率方面，处理加锁的机制会让数据库产生额外的开销，还有增加产生死锁的机会；另外，在只读型事务处理中由于不会产生冲突，也没必要使用锁，这样做只能增加系统负载；还有会降低了并行性，一个事务如果锁定了某行数据，其他事务就必须等待该事务处理完才可以处理那行数 乐观并发控制相信事务之间的数据竞争(data race)的概率是比较小的，因此尽可能直接做下去，直到提交的时候才去锁定，所以不会产生任何锁和死锁。但如果直接简单这么做，还是有可能会遇到不可预期的结果，例如两个事务都读取了数据库的某一行，经过修改以后写回数据库，这时就遇到了问题。 从数据库厂商的角度看，使用乐观的页锁是比较好的，尤其在影响很多行的批量操作中可以放比较少的锁，从而降低对资源的需求提高数据库的性能。再考虑聚集索引。在数据库中记录是按照聚集索引的物理顺序存放的。如果使用页锁，当两个用户同时访问更改位于同一数据页上的相邻两行时，其中一个用户必须等待另一个用户释放锁，这会明显地降低系统的性能。interbase和大多数关系数据库一样，采用的是乐观锁，而且读锁是共享的，写锁是排他的。可以在一个读锁上再放置读锁，但不能再放置写锁；你不能在写锁上再放置任何锁。锁是目前解决多用户并发访问的有效手段。 在实际生产环境里边,如果并发量不大且不允许脏读，可以使用悲观锁解决并发问题；但如果系统的并发非常大的话,悲观锁定会带来非常大的性能问题,所以我们就要选择乐观锁定的方法. 参考http://www.cnblogs.com/Bob-FD/p/3352216.html http://www.hollischuang.com/archives/934]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CyclicBarrier简介]]></title>
      <url>%2F2016%2F06%2F01%2FCyclicBarrier%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[CyclicBarrier简介 CyclicBarrier和CountDownLatch不同,是当await的数量达到了设定的数量之后,才继续往下执行 CyclicBarrier数的是调用了CyclicBarrier.await()进入等待的线程数,当线程数达到了CyclicBarrier初始时规定的数目时，所有进入等待状态的线程被唤醒并继续。 CyclicBarrier就象它名字的意思一样，可看成是个障碍，所有的线程必须到齐后才能一起通过这个障碍。 CyclicBarrier初始时还可带一个Runnable的参数，此Runnable任务在CyclicBarrier的数目达到后，所有其它线程被唤醒前被执行。 源码分析 jdk1.7.0_71 参考http://xijunhu.iteye.com/blog/713433 http://www.cnblogs.com/techyc/archive/2013/03/13/2957059.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CountDownLatch简介]]></title>
      <url>%2F2016%2F06%2F01%2FCountDownLatch%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[CountDownLatch是并发包中提供的一个可用于控制多个线程同时开始某动作的类，可以看做是一个计数器，计数器操作是院子操作，同时只能有一个线程去操作这个计数器。可以向CountDownLatch对象设置一个初始的数字作为计数值，任何调用这个对象上的await()方法都会阻塞，直到这个计数器的计数值被其他的线程减为0为止。 CountDownLatch的一个非常典型的应用场景是：有一个任务想要往下执行，但必须要等到其他的任务执行完毕后才可以继续往下执行。假如我们这个想要继续往下执行的任务调用一个CountDownLatch对象的await()方法，其他的任务执行完自己的任务后调用同一个CountDownLatch对象上的countDown()方法，这个调用await()方法的任务将一直阻塞等待，直到这个CountDownLatch对象的计数值减到0为止。 源码分析 jdk1.7.0_71 await()countDown()参考http://zapldy.iteye.com/blog/746458 http://www.cnblogs.com/skywang12345/p/3533887.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Semaphore简介]]></title>
      <url>%2F2016%2F06%2F01%2FSemaphore%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[Semaphore简介 Semaphore是并发包中提供的用于控制某资源同时被访问的个数 操作系统的信号量是个很重要的概念，在进程控制方面都有应用。Java 并发库 的Semaphore 可以很轻松完成信号量控制，Semaphore可以控制某个资源可被同时访问的个数，通过 acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。 Semaphore维护了当前访问的个数，提供同步机制，控制同时访问的个数 Semaphore类只是一个资源数量的抽象表示,并不负责管理资源对象本身,可能有多个线程同时获取到资源使用许可,因此需要使用同步机制避免数据竞争. 源码分析 jdk1.7.0_71 Semaphore(int permits)1234//指定许可数初始化,非公平模式public Semaphore(int permits) &#123; sync = new NonfairSync(permits); &#125; Semaphore(int permits,boolean fair)1234//可在初始化时指定第二个参数为true,使用公平模式public Semaphore(int permits, boolean fair) &#123; sync = fair ? new FairSync(permits) : new NonfairSync(permits); &#125; acquire() 阻塞,获取许可,可以被中断123public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; acquireUninterruptibly()获取许可,不可中断123public void acquireUninterruptibly() &#123; sync.acquireShared(1); &#125; tryAcquire()非阻塞,获取许可123public boolean tryAcquire() &#123; return sync.nonfairTryAcquireShared(1) &gt;= 0; &#125; tryAcquire(long timeout,TimeUnit unit)非阻塞,获取许可1234public boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout)); &#125; release()释放许可123public void release() &#123; sync.releaseShared(1); &#125; 参考http://www.cnblogs.com/whgw/archive/2011/09/29/2195555.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ThreadPoolExecutor简介]]></title>
      <url>%2F2016%2F05%2F30%2FThreadPoolExecutor%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[ThreadPoolExecutor简介 并发包中提供的一个线程池服务 线程池的工作过程 线程池刚创建,里面没有线程.任务队列是作为参数传进来的.线程池不会立即执行任务. 调用execute()方法添加一个任务,线程池会做如下判断: 如果正在运行的线程数量小于corePoolSize,马上创建线程运行这个任务 如果正在运行的线程数量大于或等于corePoolSize,这个任务放入队列 如果队列满了,且正在运行的线程数量小于maximumPoolSize,就要创建线程运行这个任务 如果队列满了,而且正在运行的线程数量大于或等于maximumPoolSize,通过 handler所指定的策略来处理此任务 当一个线程完成任务时,会从队列取下一个任务来执行 当一个线程空闲时,超过keepAliveTime,线程池会判断,如果当前运行的线程数大于corePoolSize,这个线程会被停掉. 任务队列选择 ArrayBlockingQueue LinkedBlockingQueue 没有大小限制 handler选择 ThreadPoolExecutor.AbortPolicy() 抛出java.util.concurrent.RejectedExecutionException异常 ThreadPoolExecutor.CallerRunsPolicy() 重试添加当前的任务，他会自动重复调用execute()方法 ThreadPoolExecutor.DiscardOldestPolicy() 抛弃旧的任务 ThreadPoolExecutor.DiscardPolicy() 抛弃当前的任务 源码分析 jdk1.7.0_71 构造123456789public ThreadPoolExecutor(int corePoolSize,//线程池维护线程的最少数量int maximumPoolSize,//线程池维护线程的最大数量 long keepAliveTime,//线程池维护线程所允许的空闲时间TimeUnit unit,//线程池维护线程所允许的空闲时间的单位 BlockingQueue&lt;Runnable&gt; workQueue,//线程池所使用的缓冲队列ThreadFactory threadFactory,//执行程序创建新线程时使用的工厂RejectedExecutionHandler handler//线程池对拒绝任务的处理策略 )&#123;&#125; execute(Runnable command) 添加任务到线程池123456public void execute(Runnable command) &#123;//command为空抛异常//如果正在运行的线程数量小于corePoolSize,会立即addWorker(),创建新线程运行//如果正在执行的数量大于等于corePoolSize,将任务放到阻塞队列.如果阻塞队列没有满并且是运行着的,直接放入阻塞队列.放入队列之后还要再做一次检查,如果线程池不在运行状态,把刚才的任务移除,调用reject方法,否则查看worker数量,若为0起一个新的worker去执行任务//加入队列失败的话,会addWorker尝试一个新的worker去执行任务,新worker创建失败,调用reject方法&#125; addWorker(Runnable firstTask, boolean core) 详细查看此文章 123firstTask表示需要跑的任务。boolean类型的core参数为true的话表示使用线程池的基本大小为false使用线程池最大大小 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // 线程池当前状态 // 这个判断转换成 rs &gt;= SHUTDOWN &amp;&amp; (rs != SHUTDOWN || firstTask != null || workQueue.isEmpty)。 // 概括为3个条件： // 1. 线程池不在RUNNING状态并且状态是STOP、TIDYING或TERMINATED中的任意一种状态 // 2. 线程池不在RUNNING状态，线程池接受了新的任务 // 3. 线程池不在RUNNING状态，阻塞队列为空。 满足这3个条件中的任意一个的话，拒绝执行任务 if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); // 线程池线程个数 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) // 如果线程池线程数量超过线程池最大容量或者线程数量超过了基本大小(core参数为true，core参数为false的话判断超过最大大小) return false; // 超过直接返回false if (compareAndIncrementWorkerCount(c)) // 没有超过各种大小的话，cas操作线程池线程数量+1，cas成功的话跳出循环 break retry; c = ctl.get(); // 重新检查状态 if (runStateOf(c) != rs) // 如果状态改变了，重新循环操作 continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; // 走到这一步说明cas操作成功了，线程池线程数量+1 boolean workerStarted = false; // 任务是否成功启动标识 boolean workerAdded = false; // 任务是否添加成功标识 Worker w = null; try &#123; final ReentrantLock mainLock = this.mainLock; // 得到线程池的可重入锁 w = new Worker(firstTask); // 基于任务firstTask构造worker final Thread t = w.thread; // 使用Worker的属性thread，这个thread是使用ThreadFactory构造出来的 if (t != null) &#123; // ThreadFactory构造出的Thread有可能是null，做个判断 mainLock.lock(); // 锁住，防止并发 try &#123; // 在锁住之后再重新检测一下状态 int c = ctl.get(); int rs = runStateOf(c); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; // 如果线程池在RUNNING状态或者线程池在SHUTDOWN状态并且任务是个null if (t.isAlive()) // 判断线程是否还活着，也就是说线程已经启动并且还没死掉 throw new IllegalThreadStateException(); // 如果存在已经启动并且还没死的线程，抛出异常 workers.add(w); // worker添加到线程池的workers属性中，是个HashSet int s = workers.size(); // 得到目前线程池中的线程个数 if (s &gt; largestPoolSize) // 如果线程池中的线程个数超过了线程池中的最大线程数时，更新一下这个最大线程数 largestPoolSize = s; workerAdded = true; // 标识一下任务已经添加成功 &#125; &#125; finally &#123; mainLock.unlock(); // 解锁 &#125; if (workerAdded) &#123; // 如果任务添加成功，运行任务，改变一下任务成功启动标识 t.start(); // 启动线程，这里的t是Worker中的thread属性，所以相当于就是调用了Worker的run方法 workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) // 如果任务启动失败，调用addWorkerFailed方法 addWorkerFailed(w); &#125; return workerStarted;&#125; 参考http://fulong258.blog.163.com/blog/static/17895044201082951820935 http://www.oschina.net/question/12_2656 http://coach.iteye.com/blog/855850 http://fangjian0423.github.io/2016/03/22/java-threadpool-analysis/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[AtomicInteger简介]]></title>
      <url>%2F2016%2F05%2F30%2FAtomicInteger%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[AtomicInteger简介 支持原子操作的Integer类 主要用于在高并发环境下的高效程序处理。使用非阻塞算法来实现并发控制。 源码分析 jdk1.7.0_71 123456//在更新操作时提供“比较并替换”的作用private static final Unsafe unsafe = Unsafe.getUnsafe();//用来记录value本身在内存的偏移地址private static final long valueOffset;//用来存储整数的时间变量，这里被声明为volatile，就是为了保证在更新操作时，当前线程可以拿到value最新的值private volatile int value; AtomicInteger(int initialValue) 初始化1public AtomicInteger(int initialValue)&#123;&#125; AtomicInteger()1public AtomicInteger()&#123;&#125; get()获取当前值123public final int get() &#123; return value; &#125; set(int value)设置值123public final void set(int newValue) &#123; value = newValue; &#125; lazySet(int newValue)1234567//lazySet延时设置变量值，这个等价于set()方法，但是由于字段是//volatile类型的，因此次字段的修改会比普通字段（非volatile//字段）有稍微的性能延时（尽管可以忽略），所以如果不是//想立即读取设置的新值，允许在“后台”修改值，那么此方法就很有用。public final void lazySet(int newValue) &#123; unsafe.putOrderedInt(this, valueOffset, newValue); &#125; getAndSet(int newValue)设定新数据,返回旧数据1public final int getAndSet(int newValue) &#123;&#125; compareAndSet(int expect,int update)比较并设置12345public final boolean compareAndSet(int expect, int update) &#123;//使用unsafe的native方法，实现高效的硬件级别CAS//native方法return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125; weakCompareAndSet(int expect,int update)比较并设置123public final boolean weakCompareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125; getAndIncrement()以原子方式将当前值加 1，相当于线程安全的i++操作12345678public final int getAndIncrement() &#123; for (;;) &#123; int current = get(); int next = current + 1; if (compareAndSet(current, next)) return current; &#125; &#125; incrementAndGet( )以原子方式将当前值加 1， 相当于线程安全的++i操作。1public final int incrementAndGet() &#123;&#125; getAndDecrement( )以原子方式将当前值减 1， 相当于线程安全的i–操作。1public final int getAndDecrement() &#123;&#125; decrementAndGet ( )以原子方式将当前值减 1，相当于线程安全的–i操作。1234public final int decrementAndGet() &#123;&#125;``` ## addAndGet( )： 以原子方式将给定值与当前值相加， 实际上就是等于线程安全的i =i+delta操作。 public final int addAndGet(int delta) {}12## getAndAdd( )：以原子方式将给定值与当前值相加， 相当于线程安全的t=i;i+=delta;return t;操作 public final int getAndAdd(int delta) {}``` 参考http://www.itzhai.com/the-introduction-and-use-of-atomicinteger.html#read-more http://hittyt.iteye.com/blog/1130990 http://chenzehe.iteye.com/blog/1759884]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ArrayBlockingQueue简介]]></title>
      <url>%2F2016%2F05%2F29%2FArrayBlockingQueue%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[ArrayBlockingQueue基于数组，先进先出，从尾部插入到队列，从头部开始返回。 线程安全的有序阻塞队列，内部通过“互斥锁”保护竞争资源。 指定时间的阻塞读写 容量可限制 定义ArrayBlockingQueue继承AbstractQueue，实现了BlockingQueue，Serializable接口，内部元素使用Object[]数组保存。初始化时候需要指定容量ArrayBlockingQueue(int capacity)，ArrayBlockingQueue默认会使用非公平锁。 ArrayBlockingQueue只使用一把锁，造成在存取两种操作时会竞争同一把锁，而使得性能相对低下。 add(E)方法和offer(E)调用父类中的add方法，查看源码可知父类中的add方法是调用offer方法实现,所以查看offer方法源码，如下： 1234567891011121314151617181920public boolean offer(E e) &#123; //检查元素不为null checkNotNull(e); //加锁，独占锁保护竞态资源。 final ReentrantLock lock = this.lock; lock.lock(); try &#123; //队列已满，返回false if (count == items.length) return false; else &#123; //插入元素,返回true insert(e); return true; &#125; &#125; finally &#123; //释放锁 lock.unlock(); &#125;&#125; insert源码如下： 12345678910private void insert(E x) &#123; //将元素添加到队列中 items[putIndex] = x; //putIndex表示下一个被添加元素的索引，设置下一个被添加元素的索引，若队列满了，就设置下一个被添加元素索引为0 putIndex = inc(putIndex); //队列的元素数加1 ++count; //唤醒notEmpty上的等待线程,也就是取元素的线程。 notEmpty.signal();&#125; take()方法123456789101112131415public E take() throws InterruptedException &#123; //获取独占锁，加锁，线程是中断状态的话会抛异常 final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; //队列为空，会一直等待 while (count == 0) notEmpty.await(); //取元素的方法 return extract(); &#125; finally &#123; //释放锁 lock.unlock(); &#125;&#125; 12345678910111213private E extract() &#123; final Object[] items = this.items; E x = this.&lt;E&gt;cast(items[takeIndex]); //取完之后，删除元素 items[takeIndex] = null; //设置下一个被取出的元素索引，若是最后一个元素，下一个被取出的元素索引为0 takeIndex = inc(takeIndex); //元素数减1 --count; //唤醒添加元素的线程 notFull.signal(); return x;&#125; 源码分析 jdk1.7.0_71 1234567891011121314//队列元素final Object[] items;//下次被take,poll,remove的索引int takeIndex;//下次被put,offer,add的索引int putIndex;//队列中元素的个数int count;//保护所有访问的主锁final ReentrantLock lock;//等待take锁,读线程条件private final Condition notEmpty;//等待put锁,写线程条件private final Condition notFull; ArrayBlockingQueue(int capacity) 给定容量和默认的访问规则初始化1public ArrayBlockingQueue(int capacity)&#123;&#125; ArrayBlockingQueue(int capacity, boolean fair)知道你跟容量和访问规则123456789//fair为true,在插入和删除时,线程的队列访问会阻塞,并且按照先进先出的顺序,false,访问顺序是不确定的public ArrayBlockingQueue(int capacity, boolean fair) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition(); &#125; ArrayBlockingQueue(int capacity, boolean fair,Collection&lt;? extends E&gt; c) 指定容量,访问规则,集合来初始化12public ArrayBlockingQueue(int capacity, boolean fair, Collection&lt;? extends E&gt; c) &#123;&#125; add(E e) 添加元素到队列末尾,成功返回true,队列满了抛异常IllegalStateException123public boolean add(E e) &#123; return super.add(e); &#125; offer(E e)添加元素到队列末尾,成功返回true,队列满了返回false1public boolean offer(E e) &#123;&#125; put(E e) 添加元素到队列末尾,队列满了,等待.1public void put(E e) throws InterruptedException &#123;&#125; offer(E e, long timeout, TimeUnit unit)添加元素到队列末尾,如果队列满了,等待指定的时间1public boolean offer(E e, long timeout, TimeUnit unit)&#123;&#125; poll() 移除队列头1public E poll() &#123;&#125; take() 移除队列头,队列为空的话就等待1public E take() throws InterruptedException &#123;&#125; poll(long timeout, TimeUnit unit)移除队列头,队列为空,等待指定的时间1public E poll(long timeout, TimeUnit unit) throws InterruptedException &#123;&#125; peek()返回队列头,不删除1public E peek() &#123;&#125; size()1public int size()&#123;&#125; remainingCapacity() 返回无阻塞情况下队列能接受容量的大小1public int remainingCapacity() &#123;&#125; remove(Object o)从队列中删除元素1public boolean remove(Object o) &#123;&#125; contains(Object o) 是否包含元素1public boolean contains(Object o) &#123;&#125; toArray()1public Object[] toArray()&#123;&#125; toArray(T[] a)1public &lt;T&gt; T[] toArray(T[] a) &#123;&#125; toString()1public String toString()&#123;&#125; clear()1public void clear()&#123;&#125; drainTo(Collection&lt;? super E&gt; c)移除队列中可用元素,添加到集合中1public int drainTo(Collection&lt;? super E&gt; c) &#123;&#125; drainTo(Collection&lt;? super E&gt; c, int maxElements)移除队列中给定数量的可用元素,添加到集合中1public int drainTo(Collection&lt;? super E&gt; c, int maxElements) &#123;&#125; iterator() 返回一个迭代器123public Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; 参考http://www.jianshu.com/p/9a652250e0d1]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CopyOnWriteArraySet简介]]></title>
      <url>%2F2016%2F05%2F27%2FCopyOnWriteArraySet%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[基于CopyOnWriteArrayList实现，线程安全无需集合。 add调用的是CopyOnWriteArraylist的addIfAbsent方法。 CopyOnWriteArraySet每次add要进行遍历数组,性能略低于CopyOnWriteArrayList。 适用于set大小一般很小，读操作远远多于写操作的场景。 定义CopyOnWriteArraySet集成AbstractSet，实现Serializable接口。是基于CopyOnWriteArrayList实现。 add方法通过CopyOnWriteArrayList的addIfAbsent实现。基本方法都在CopyOnWriteArrayList中说明过，不做过多讲解。 源码分析 jdk1.7.0_71 1//基于CopyOnWriteArrayList 参考]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[TreeSet简介]]></title>
      <url>%2F2016%2F05%2F27%2FTreeSet%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[TreeSet简介 TreeSet支持排序 基于TreeMap实现 非线程安全的 不支持get(int)来获取指定位置的元素 源码分析 jdk1.7.0_71 1//基于TreeMap 参考]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HashSet简介]]></title>
      <url>%2F2016%2F05%2F27%2FHashSet%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[HashSet简介 HashSet是Set接口的实现,不允许元素重复 元素不重复是基于HashMap实现 非线程安全的 不支持通过get(int)获取指定位置的元素,只能通过Iterator方法来获取 源码分析 jdk1.7.0_71 1// 空构造 实际是new 一个HashMap123public HashSet() &#123; map = new HashMap&lt;&gt;(); &#125; 参考]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[TreeMap简介]]></title>
      <url>%2F2016%2F05%2F27%2FTreeMap%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[TreeMap是支持排序的map，基于红黑树，无容量限制，TreeMap非线程安全。 TreeMap继承AbstractMap，实现NavigableMap、Cloneable、Serializable三个接口。其中AbstractMap表明TreeMap为一个Map即支持key-value的集合， NavigableMap则意味着它支持一系列的导航方法，具备针对给定搜索目标返回最接近匹配项的导航方法 。 TreeMap put()方法源码分析 jdk1.7.0_71 12345678//用于排序的comparatorprivate final Comparator&lt;? super K&gt; comparator;//根节点private transient Entry&lt;K,V&gt; root = null;//TreeMap的元素数量private transient int size = 0;//结构修改次数private transient int modCount = 0; 空构造123public TreeMap() &#123; comparator = null; &#125; 使用给定的comparator初始化空的TreeMap123public TreeMap(Comparator&lt;? super K&gt; comparator) &#123; this.comparator = comparator; &#125; 使用给定的map初始化TreeMap1234public TreeMap(Map&lt;? extends K, ? extends V&gt; m) &#123; comparator = null; putAll(m); &#125; 使用SortedMap初始化1public TreeMap(SortedMap&lt;K, ? extends V&gt; m) &#123;&#125; 参考]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ConcurrentHashMap简介]]></title>
      <url>%2F2016%2F05%2F26%2FConcurrentHashMap%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[ConcurrentHashMap为了高并发而设计，相比于HashTable和HashMap有更多优势。HashTable是同步的，在多线程环境下，能保证程序执行的正确性，每次同步执行的时候都要锁住整个结构。HashMap不是同步的，在单线程情况下效率高。 ConcurrentHashMap锁方式是稍微细粒度的，内部采用分离锁的设计。它默认将Hash表分为16个分段，get，put，remove等常用操作只锁当前需要用到的分段。对于每个Segment，采用final和volatile关键字。 concurrenthashmap采用了二次hash的方式，第一次hash将key映射到对应的segment，而第二次hash则是映射到segment的不同桶中。 原来只能一个线程进入，现在却能同时16个写线程进入，写线程需要锁定，读线程几乎不受限制，并发性是显而易见的。只有size等操作才需要锁定整个表。 定义ConcurrentHashMap继承AbstractMap，实现了ConcurrentMap,Serializable接口。ConcurrentMap继承了Map，添加了一些原子性方法，如putIfAbsent，remove，replace等。 数据结构ConcurrentHashMap是由Segment数组结构，HashEntry数组结构和链表组成。Segment是可重入锁ReentrantLock，扮演锁角色。每个Segment的结构和HashMap类似，数组加链表存储结构。 HashEntry的key，hash采用final，可以避免并发修改问题，HashEntry链的尾部是不能修改的，而next和value采用volatile，可以避免使用同步造成的并发性能灾难。 SegmentSegment是ConcurrentHashMap的内部类，继承ReentrantLock，实现了Serializable接口。操作基本上都在Segment上，Segment中的table是一个HashEntry数组，数据就存放到这个数组中。看到这里对比下HashMap的存储结构，就大概能明白。具体方法在接下来的ConcurrentHashMap的具体方法中讲解。 初始化ConcurrentHashMap初始化是通过initialCapacity，loadFactor，concurrencyLevel等参数来初始化Segment数组，段偏移量segmentShift，段掩码segmentMask和每个segment里的HashEntry数组。 123456789101112131415161718192021222324252627282930313233public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; //校验参数 if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); //并发级别数大于最大Segment数量 if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; // Find power-of-two sizes best matching arguments int sshift = 0; int ssize = 1; while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1; &#125; this.segmentShift = 32 - sshift; this.segmentMask = ssize - 1; if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; int c = initialCapacity / ssize; if (c * ssize &lt; initialCapacity) ++c; int cap = MIN_SEGMENT_TABLE_CAPACITY; while (cap &lt; c) cap &lt;&lt;= 1; // create segments and segments[0] Segment&lt;K,V&gt; s0 = new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V&gt;[])new HashEntry[cap]); Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])new Segment[ssize]; UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0] this.segments = ss;&#125; segments数组的长度ssize通过concurrencyLevel计算得出。为了能通过按位与的哈希算法来定位segments数组的索引，必须保证segments数组的长度是2的N次方（power-of-two size），所以必须计算出一个是大于或等于concurrencyLevel的最小的2的N次方值来作为segments数组的长度。假如concurrencyLevel等于14，15或16，ssize都会等于16，即容器里锁的个数也是16。注意concurrencyLevel的最大大小是65535，意味着segments数组的长度最大为65536，对应的二进制是16位。 初始化segmentShift和segmentMask。 这两个全局变量在定位segment时的哈希算法里需要使用，sshift等于ssize从1向左移位的次数，在默认情况下concurrencyLevel等于16，1需要向左移位移动4次，所以sshift等于4。segmentShift用于定位参与hash运算的位数，segmentShift等于32减sshift，所以等于28，这里之所以用32是因为ConcurrentHashMap里的hash()方法输出的最大数是32位的，后面的测试中我们可以看到这点。segmentMask是哈希运算的掩码，等于ssize减1，即15，掩码的二进制各个位的值都是1。因为ssize的最大长度是65536，所以segmentShift最大值是16，segmentMask最大值是65535，对应的二进制是16位，每个位都是1。 初始化每个Segment。输入参数initialCapacity是ConcurrentHashMap的初始化容量，loadfactor是每个segment的负载因子，在构造方法里需要通过这两个参数来初始化数组中的每个segment。 变量cap就是segment里HashEntry数组的长度，它等于initialCapacity除以ssize的倍数c，如果c大于1，就会取大于等于c的2的N次方值，所以cap不是1，就是2的N次方。segment的容量threshold＝(int)cap*loadFactor，默认情况下initialCapacity等于16，loadfactor等于0.75，通过运算cap等于1，threshold等于零。 put(key,value)方法123456789101112131415public V put(K key, V value) &#123; Segment&lt;K,V&gt; s; if (value == null) throw new NullPointerException(); //计算key的哈希值 int hash = hash(key); //定位segment需要用到这个计算的数值 int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject // nonvolatile; recheck (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) // in ensureSegment //获取指定segment，若不存在新建一个，并记录在Segment数组中 s = ensureSegment(j); //put方法，在Segment内部类中实现 return s.put(key, hash, value, false);&#125; Segment内部类中的put方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; //tryLock(): 如果锁可用, 则获取锁, 并立即返回true, 否则返回false。 //该方法和lock()的区别在于, tryLock()只是&quot;试图&quot;获取锁, 如果锁不可用, 不会导致当前线程被禁用, 当前线程仍然继续往下执行代码。而lock()方法则是一定要获取到锁, 如果锁不可用, 就一直等待, 在未获得锁之前,当前线程并不继续向下执行。 //scanAndLockForPut扫描指定key的节点，并获取锁，如果不存在就新建一个HashEntry HashEntry&lt;K,V&gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value); V oldValue; try &#123; HashEntry&lt;K,V&gt;[] tab = table; int index = (tab.length - 1) &amp; hash; HashEntry&lt;K,V&gt; first = entryAt(tab, index); for (HashEntry&lt;K,V&gt; e = first;;) &#123; if (e != null) &#123; K k; if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; oldValue = e.value; if (!onlyIfAbsent) &#123; e.value = value; ++modCount; &#125; break; &#125; e = e.next; &#125; else &#123; if (node != null) node.setNext(first); else node = new HashEntry&lt;K,V&gt;(hash, key, value, first); int c = count + 1; if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); else setEntryAt(tab, index, node); ++modCount; count = c; oldValue = null; break; &#125; &#125; &#125; finally &#123; unlock(); &#125; return oldValue;&#125; put操作开始，首先定位到Segment，为了线程安全，锁定当前Segment；然后在Segment里进行插入操作，首先判断是否需要扩容，然后在定位添加元素的位置放在HashEntry数组里。 扩容：在插入元素前会先判断Segment里的HashEntry数组是否超过容量（threshold），如果超过阀值，数组进行扩容。值得一提的是，Segment的扩容判断比HashMap更恰当，因为HashMap是在插入元素后判断元素是否已经到达容量的，如果到达了就进行扩容，但是很有可能扩容之后没有新元素插入，这时HashMap就进行了一次无效的扩容。 扩容的时候首先会创建一个两倍于原容量的数组，然后将原数组里的元素进行再hash后插入到新的数组里。为了高效ConcurrentHashMap不会对整个容器进行扩容，而只对某个segment进行扩容。 get(key)方法1234567891011121314151617public V get(Object key) &#123; Segment&lt;K,V&gt; s; // manually integrate access methods to reduce overhead HashEntry&lt;K,V&gt;[] tab; int h = hash(key); long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp; (tab = s.table) != null) &#123; for (HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE); e != null; e = e.next) &#123; K k; if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k))) return e.value; &#125; &#125; return null;&#125; size()方法我们要统计整个ConcurrentHashMap里元素的大小，就必须统计所有Segment里元素的大小后求和。Segment里的全局变量count是一个volatile变量，那么在多线程场景下，我们是不是直接把所有Segment的count相加就可以得到整个ConcurrentHashMap大小了呢？不是的，虽然相加时可以获取每个Segment的count的最新值，但是拿到之后可能累加前使用的count发生了变化，那么统计结果就不准了。所以最安全的做法，是在统计size的时候把所有Segment的put，remove和clean方法全部锁住，但是这种做法显然非常低效。 因为在累加count操作过程中，之前累加过的count发生变化的几率非常小，所以ConcurrentHashMap的做法是先尝试2次通过不锁住Segment的方式来统计各个Segment大小，如果统计的过程中，容器的count发生了变化，则再采用加锁的方式来统计所有Segment的大小。 迭代ConcurrentHashMap使用了不同于传统集合的快速失败迭代器的另一种迭代方式，我们称为弱一致迭代器。在这种迭代方式中，当iterator被创建后集合再发生改变就不再是抛出 ConcurrentModificationException，取而代之的是在改变时new新的数据从而不影响原有的数 据，iterator完成后再将头指针替换为新的数据，这样iterator线程可以使用原来老的数据，而写线程也可以并发的完成改变，更重要的，这保证了多个线程并发执行的连续性和扩展性，是性能提升的关键。 源码分析 jdk1.7.0_71 12345678910111213141516171819202122232425262728//默认容量static final int DEFAULT_INITIAL_CAPACITY = 16;//默认负载因子static final float DEFAULT_LOAD_FACTOR = 0.75f;//并发级别static final int DEFAULT_CONCURRENCY_LEVEL = 16;//最大容量static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;//每个segment最小容量static final int MIN_SEGMENT_TABLE_CAPACITY = 2;//最大segment数量static final int MAX_SEGMENTS = 1 &lt;&lt; 16;//lock之前尝试的次数static final int RETRIES_BEFORE_LOCK = 2;//计算哈希值时候用到private transient final int hashSeed = randomHashSeed(this);//segment的掩码值,用于计算key所在segments索引值final int segmentMask;//segment的偏移值,用于计算key所在segments索引值final int segmentShift;//segment数组,其内部是由HashEntry数组实现,正因为有了多个segment，才提高了并发度final Segment&lt;K,V&gt;[] segments;//transient Set&lt;K&gt; keySet;//transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;//transient Collection&lt;V&gt; values; Holder 静态内部类,存放一些在虚拟机启动后才能初始化的值容量阈值，初始化hashSeed的时候会用到该值1static final int ALTERNATIVE_HASHING; static静态块1获取系统变量jdk.map.althashing.threshold ConcurrentHashMap(int initialCapacity,float loadFactor, int concurrencyLevel) 构造 传入的参数有initialCapacity，loadFactor，concurrencyLevel这三个。 initialCapacity表示新创建的这个ConcurrentHashMap的初始容量，也就是上面的结构图中的Entry数量。默认值为static final int DEFAULT_INITIAL_CAPACITY = 16; loadFactor表示负载因子，就是当ConcurrentHashMap中的元素个数大于loadFactor * 最大容量时就需要rehash，扩容。默认值为static final float DEFAULT_LOAD_FACTOR = 0.75f; concurrencyLevel表示并发级别，这个值用来确定Segment的个数，Segment的个数是大于等于concurrencyLevel的第一个2的n次方的数。比如，如果concurrencyLevel为12，13，14，15，16这些数，则Segment的数目为16(2的4次方)。默认值为static final int DEFAULT_CONCURRENCY_LEVEL = 16;。理想情况下ConcurrentHashMap的真正的并发访问量能够达到concurrencyLevel，因为有concurrencyLevel个Segment，假如有concurrencyLevel个线程需要访问Map，并且需要访问的数据都恰好分别落在不同的Segment中，则这些线程能够无竞争地自由访问（因为他们不需要竞争同一把锁），达到同时访问的效果。这也是为什么这个参数起名为“并发级别”的原因。 初始化的一些动作： 验证参数的合法性，如果不合法，直接抛出异常。 concurrencyLevel也就是Segment的个数不能超过规定的最大Segment的个数，默认值为static final int MAX_SEGMENTS = 1 &lt;&lt; 16;，如果超过这个值，设置为这个值。 然后使用循环找到大于等于concurrencyLevel的第一个2的n次方的数ssize，这个数就是Segment数组的大小，并记录一共向左按位移动的次数sshift，并令segmentShift = 32 - sshift，并且segmentMask的值等于ssize - 1，segmentMask的各个二进制位都为1，目的是之后可以通过key的hash值与这个值做&amp;运算确定Segment的索引。 检查给的容量值是否大于允许的最大容量值，如果大于该值，设置为该值。最大容量值为static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;。 然后计算每个Segment平均应该放置多少个元素，这个值c是向上取整的值。比如初始容量为15，Segment个数为4，则每个Segment平均需要放置4个元素。 最后创建一个Segment实例，将其当做Segment数组的第一个元素。 12345678910111213141516171819202122232425262728if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; // Find power-of-two sizes best matching arguments int sshift = 0; int ssize = 1; while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1; &#125; this.segmentShift = 32 - sshift; this.segmentMask = ssize - 1; if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; int c = initialCapacity / ssize; if (c * ssize &lt; initialCapacity) ++c; int cap = MIN_SEGMENT_TABLE_CAPACITY; while (cap &lt; c) cap &lt;&lt;= 1; // create segments and segments[0] Segment&lt;K,V&gt; s0 = new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V&gt;[])new HashEntry[cap]); Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])new Segment[ssize]; UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0] this.segments = ss; ConcurrentHashMap(int initialCapacity, float loadFactor) 指定初始容量和负载因子123public ConcurrentHashMap(int initialCapacity, float loadFactor) &#123; this(initialCapacity, loadFactor, DEFAULT_CONCURRENCY_LEVEL); &#125; ConcurrentHashMap(int initialCapacity) 指定初始容量123public ConcurrentHashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL); &#125; ConcurrentHashMap(int initialCapacity) 空构造123public ConcurrentHashMap() &#123; this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL); &#125; ConcurrentHashMap(Map&lt;? extends K, ? extends V&gt; m) 使用map初始化1public ConcurrentHashMap(Map&lt;? extends K, ? extends V&gt; m) &#123;&#125; isEmpty() 是否为空12//为了避免错误统计,会把每个segment的modCount都加起来进行判断public boolean isEmpty() &#123;&#125; size() 返回大小1public int size() &#123;&#125; get(Object key) 根据key获取value1public V get(Object key) &#123;&#125; containsKey(Object key) 是否包含key1public boolean containsKey(Object key) &#123;&#125; containsValue(Object value) 是否包含value12//思路和size()相同public boolean containsValue(Object value)&#123;&#125; put(K key, V value)1public V put(K key, V value) &#123;&#125; putIfAbsent(K key, V value) 如果不存在对应的key,就放进去1public V putIfAbsent(K key, V value) &#123;&#125; putAll(Map&lt;? extends K, ? extends V&gt; m) 把指定map放进去1public void putAll(Map&lt;? extends K, ? extends V&gt; m)&#123;&#125; remove(Object key) 删除1public V remove(Object key)&#123;&#125; remove(Object key, Object value)删除1public boolean remove(Object key, Object value)&#123;&#125; replace(K key, V oldValue, V newValue) 替换1public boolean replace(K key, V oldValue, V newValue) &#123;&#125; replace(K key, V value) 替换1public V replace(K key, V value)&#123;&#125; clear() 清空1public void clear()&#123;&#125; Segment (–重要–)123456789101112//最大的尝试加锁的次数static final int MAX_SCAN_RETRIES =Runtime.getRuntime().availableProcessors() &gt; 1 ? 64 : 1;//每个segment存放数据的tabletransient volatile HashEntry&lt;K,V&gt;[] table;//segment元素的数量transient int count;//segment的修改数transient int modCount;//扩容的临界值transient int threshold;//负载因子final float loadFactor; put(K key, int hash, V value, boolean onlyIfAbsent)12345final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; //加锁 //修改 //解锁&#125; 参考http://my.oschina.net/indestiny/blog/209458 http://qifuguang.me/2015/09/10/[Java%E5%B9%B6%E5%8F%91%E5%8C%85%E5%AD%A6%E4%B9%A0%E5%85%AB]%E6%B7%B1%E5%BA%A6%E5%89%96%E6%9E%90ConcurrentHashMap/ http://www.importnew.com/20952.html http://www.importnew.com/16147.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HashTable简介]]></title>
      <url>%2F2016%2F05%2F26%2FHashTable%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[HashTable继承Dictionary类，实现Map接口。其中Dictionary类是任何可将键映射到相应值的类（如 Hashtable）的抽象父类。每个键和每个值都是一个对象。在任何一个 Dictionary 对象中，每个键至多与一个值相关联。Map是”key-value键值对”接口。 HashTable与HashMap的区别 HashTable基于Dictionary类，而HashMap是基于AbstractMap。Dictionary是什么？它是任何可将键映射到相应值的类的抽象父类，而AbstractMap是基于Map接口的骨干实现，它以最大限度地减少实现此接口所需的工作。 HashMap可以允许存在一个为null的key和任意个为null的value，但是HashTable中的key和value都不允许为null。当HashMap遇到为null的key时，它会调用putForNullKey方法来进行处理。对于value没有进行任何处理，只要是对象都可以。而当HashTable遇到null时，他会直接抛出NullPointerException异常信息。 Hashtable的方法是同步的，而HashMap的方法不是。所以有人一般都建议如果是涉及到多线程同步时采用HashTable，没有涉及就采用HashMap。 源码分析 jdk1.7.0_71 123456789101112//用于存储数据的表private transient Entry&lt;K,V&gt;[] table;//表中键值对的数private transient int count;//下次扩充的临界值 capacity * loadFactorprivate int threshold;//哈希表的负载因子private float loadFactor;//在使用迭代器遍历的时候，用来检查列表中的元素是否发生结构性变化（列表元素数量发生改变的一个计数）了，主要在多线程环境下需要使用，防止一个线程正在迭代遍历，另一个线程修改了这个列表的结构。private transient int modCount;//容量阈值，默认大小为Integer.MAX_VALUEstatic final int ALTERNATIVE_HASHING_THRESHOLD_DEFAULT = Integer.MAX_VALUE; Holder 静态内部类,存放一些在虚拟机启动后才能初始化的值容量阈值，初始化hashSeed的时候会用到该值1static final int ALTERNATIVE_HASHING_THRESHOLD; static静态块12获取系统变量jdk.map.althashing.thresholdjdk.map.althashing.threshold系统变量默认为-1，如果为-1，则将阈值设为Integer.MAX_VALUE Hashtable(int initialCapacity, float loadFactor) 指定容量和负载因子 构造1234public Hashtable(int initialCapacity, float loadFactor) &#123; ... initHashSeedAsNeeded();&#125; Hashtable(int initialCapacity) 指定初始容量的构造,负载因子为0.75f1public Hashtable(int initialCapacity) &#123;&#125; Hashtable() 默认初始容量11和默认负载因子0.75f的构造1public Hashtable()&#123;&#125; Hashtable(Map&lt;? extends K, ? extends V&gt; m) 用map初始化12345public Hashtable(Map&lt;? extends K, ? extends V&gt; m) &#123; this(Math.max(2*t.size(), 11), 0.75f); //把元素放入到Hashtable中 putAll(t);&#125; size() key-value映射个数123public synchronized int size() &#123; return size; &#125; isEmpty()是否为空123public synchronized boolean isEmpty() &#123; return size == 0; &#125; keys() 返回keys枚举123public synchronized Enumeration&lt;K&gt; keys() &#123; return this.&lt;K&gt;getEnumeration(KEYS); &#125; elements() 返回values枚举123public synchronized elements&lt;V&gt; keys() &#123; return this.&lt;V&gt;getEnumeration(VALUES); &#125; contains(Object value)是否包含指定value1public synchronized boolean contains(Object value) &#123;&#125; containsValue(Object value) 是否包含value1public boolean containsValue(Object value) &#123;&#125; containsKey(Object key) 是否包含key123public boolean containsKey(Object key) &#123; return getEntry(key) != null; &#125; get(Object key) 根据key获取value1234public synchronized V get(Object key) &#123;&#125;``` ## put(K key, V value) 将指定的key value放入Hashtable中,若已存在key,就替换旧值 public synchronized V put(K key, V value) {}12## remove(Object key) 根据key删除 public synchronized V remove(Object key) { removeEntryForKey(key);}12## putAll(Map&lt;? extends K, ? extends V&gt; m) 把指定的元素 全部放入HashMap中,已经存在的key,会把旧value覆盖掉 public synchronized void putAll(Map&lt;? extends K, ? extends V&gt; m) {}12## clear() 清空 public synchronized void clear(){}12## clone() 浅拷贝 public Object clone() {}12## toString() public synchronized String toString() {}``` 参考]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HashMap简介]]></title>
      <url>%2F2016%2F05%2F25%2FHashMap%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[HashMap基于哈希表的Map接口实现，是以key-value存储形式存在。 系统会根据hash算法来计算key-value的存储位置，可以通过key快速存取value。 HashMap基于hashing原理，我们通过put()和get()方法储存和获取对象。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，然后找到bucket位置来储存值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。 HashMap使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中。 HashMap在每个链表节点中储存键值对对象。 当两个不同的键对象的hashcode相同时会发生什么？ 它们会储存在同一个bucket位置的链表中。键对象的equals()方法用来找到键值对。 定义HashMap实现了Map接口，Map接口定义了键映射到值的规则。HashMap继承了AbstractMap，AbstractMap提供接口的主要实现，以最大限度的减少HashMap实现Map接口所需的工作。 初始容量和负载因子默认初始容量16，默认负载因子0.75。这两个参数是影响HashMap性能的重要参数，其中容量表示哈希表中桶的数量，初始容量是创建哈希表时的容量，负载因子是哈希表在其容量自动增加之前可以达到多满的一种尺度，它衡量的是一个散列表的空间的使用程度，负载因子越大表示散列表的装填程度越高，反之愈小。对于使用链表法的散列表来说，查找一个元素的平均时间是O(1+a)，因此如果负载因子越大，对空间的利用更充分，然而后果是查找效率的降低；如果负载因子太小，那么散列表的数据将过于稀疏，对空间造成严重浪费。系统默认负载因子为0.75，一般情况下我们是无需修改的。 数据结构Java中最常用的两种结构是数组和模拟指针(引用)，几乎所有的数据结构都可以利用这两种来组合实现，HashMap也是如此。实际上HashMap是一个“链表散列”，如下是它数据结构： HashMap底层实现还是数组，只是数组的每一项都是一条链。其中参数initialCapacity就代表了该数组的长度。 1234//空表static final Entry&lt;?,?&gt;[] EMPTY_TABLE = &#123;&#125;;//用于存储的表，长度可以调整，且必须是2的n次幂transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE; 每次新建一个HashMap时，都会初始化一个table数组。table数组的元素为Entry节点。 其中Entry为HashMap的内部类，它包含了键key、值value、下一个节点next，以及hash值，这是非常重要的，正是由于Entry才构成了table数组的项为链表。 存储实现：put(key,value)1234567891011121314151617181920212223242526272829public V put(K key, V value) &#123; //当表为空表时，扩展表 if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; //当key为null时，保存null在table第一个位置中 if (key == null) return putForNullKey(value); //计算key的hash值 int hash = hash(key); //计算key hash值在table数组中的位置 int i = indexFor(hash, table.length); //在i处开始迭代e，找到key保存的位置 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; //判断该条链上是否有hash值相同的（key相同），若存在相同的，则直接覆盖value，返回旧value if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; //修改次数加1 modCount++; //将key，value添加到i位置处 addEntry(hash, key, value, i); return null;&#125; 通过源码我们可以清晰看到HashMap保存数据的过程为：首先判断表是否为空，为空的话，先扩展表；然后判断key是否为null，若为null，则直接调用putForNullKey方法。若不为空则先计算key的hash值，然后根据hash值搜索在table数组中的索引位置，如果table数组在该位置处有元素，则通过比较是否存在相同的key，若存在则覆盖原来key的value，否则将该元素保存在链头（最先保存的元素放在链尾）。若table在该处没有元素，则直接保存。 迭代：此处迭代原因就是为了防止存在相同的key值，若发现两个hash值（key）相同时，HashMap的处理方式是用新value替换旧value，这里并没有处理key，这就解释了HashMap中没有两个相同的key。 int hash = hash(key); hash方法，计算key的hash值，代码如下： 1234567891011121314final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; 对于HashMap的table而言，数据分布需要均匀（最好每项都只有一个元素，这样就可以直接找到），不能太紧也不能太松，太紧会导致查询速度慢，太松则浪费空间。计算hash值后，怎么才能保证table元素分布均与呢？我们会想到取模，但是由于取模的消耗较大，HashMap是这样处理的：调用indexFor方法。 1234static int indexFor(int h, int length) &#123; // assert Integer.bitCount(length) == 1 : &quot;length must be a non-zero power of 2&quot;; return h &amp; (length-1); &#125; HashMap的底层数组长度总是2的n次方，在构造函数中存在：capacity &lt;&lt;= 1;这样做总是能够保证HashMap的底层数组长度为2的n次方。当length为2的n次方时，h&amp;(length - 1)就相当于对length取模，而且速度比直接取模快得多，这是HashMap在速度上的一个优化。 indexFor方法，该方法仅有一条语句：h&amp;(length - 1)，这句话除了上面的取模运算外还有一个非常重要的责任：均匀分布table数据和充分利用空间。 当length = 2^n时，不同的hash值发生碰撞的概率比较小，这样就会使得数据在table数组中分布较均匀，查询速度也较快。 这里我们再来复习put的流程：当我们想往一个HashMap中添加一对key-value时，系统首先会计算key的hash值，然后根据hash值确认在table中存储的位置。若该位置没有元素，则直接插入。否则迭代该处元素链表并依此比较其key的hash值。如果两个hash值相等且key值相等(e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))),则用新的Entry的value覆盖原来节点的value。如果两个hash值相等但key值不等 ，则将该节点插入该链表的链头。具体的实现过程见addEntry方法，如下： 12345678910void addEntry(int hash, K key, V value, int bucketIndex) &#123; //HashMap元素超过极限，则扩容为两倍 if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; //创建新的Entry createEntry(hash, key, value, bucketIndex);&#125; 1234567void createEntry(int hash, K key, V value, int bucketIndex) &#123; //获取bucketIndex处的Entry Entry&lt;K,V&gt; e = table[bucketIndex]; //将新创建的 Entry 放入 bucketIndex 索引处，并让新的 Entry 指向原来的 Entry table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125; 链的产生：这是一个非常优雅的设计。系统总是将新的Entry对象添加到bucketIndex处。如果bucketIndex处已经有了对象，那么新添加的Entry对象将指向原有的Entry对象，形成一条Entry链，但是若bucketIndex处没有Entry对象，也就是e==null,那么新添加的Entry对象指向null，也就不会产生Entry链了。 扩容问题：随着HashMap中元素的数量越来越多，发生碰撞的概率就越来越大，所产生的链表长度就会越来越长，这样势必会影响HashMap的速度，为了保证HashMap的效率，系统必须要在某个临界点进行扩容处理。该临界点在当HashMap中元素的数量等于table数组长度*加载因子。但是扩容是一个非常耗时的过程，因为它需要重新计算这些数据在新table数组中的位置并进行复制处理。所以如果我们已经预知HashMap中元素的个数，那么预设元素的个数能够有效的提高HashMap的性能。 读取实现：get(key)通过key的hash值找到在table数组中的索引处的Entry，然后返回该key对应的value即可。 123456789public V get(Object key) &#123; //若为null，获取null对应的value if (key == null) return getForNullKey(); //getEntry(key)为真正获取方法 Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue();&#125; 123456789101112131415161718final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125; //根据key获取hash值 int hash = (key == null) ? 0 : hash(key); //取出table数组中指定索引处的值 for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; //key相同，返回对应的value if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125; 在这里能够根据key快速的取到value除了和HashMap的数据结构密不可分外，还和Entry有莫大的关系，在前面就提到过，HashMap在存储过程中并没有将key，value分开来存储，而是当做一个整体key-value来处理的，这个整体就是Entry对象。同时value也只相当于key的附属而已。在存储的过程中，系统根据key的hashcode来决定Entry在table数组中的存储位置，在取的过程中同样根据key的hashcode取出相对应的Entry对象。 源码分析 jdk1.7.0_71 1234567891011121314151617181920212223//默认初始化容量static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4;//最大容量static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;//系统默认负载因子static final float DEFAULT_LOAD_FACTOR = 0.75f;//空表static final Entry&lt;?,?&gt;[] EMPTY_TABLE = &#123;&#125;;//用于存储的表，长度可以调整，且必须是2的n次幂transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE;//map的sizetransient int size;//下次扩充的临界值 capacity * load factorint threshold;//哈希表的负载因子final float loadFactor;//在使用迭代器遍历的时候，用来检查列表中的元素是否发生结构性变化（列表元素数量发生改变的一个计数）了，主要在多线程环境下需要使用，防止一个线程正在迭代遍历，另一个线程修改了这个列表的结构。transient int modCount;//容量阈值，默认大小为Integer.MAX_VALUEstatic final int ALTERNATIVE_HASHING_THRESHOLD_DEFAULT = Integer.MAX_VALUE;//计算哈希值得时候用transient int hashSeed = 0; Holder 静态内部类,存放一些在虚拟机启动后才能初始化的值容量阈值，初始化hashSeed的时候会用到该值1static final int ALTERNATIVE_HASHING_THRESHOLD; static静态块12获取系统变量jdk.map.althashing.thresholdjdk.map.althashing.threshold系统变量默认为-1，如果为-1，则将阈值设为Integer.MAX_VALUE HashMap(int initialCapacity, float loadFactor) 指定容量和负载因子 构造1234public HashMap(int initialCapacity, float loadFactor) &#123; ... init();&#125; HashMap(int initialCapacity) 指定初始容量的构造,负载因子为默认1public HashMap(int initialCapacity) &#123;&#125; HashMap() 默认初始容量和默认负载因子的构造1public HashMap()&#123;&#125; HashMap(Map&lt;? extends K, ? extends V&gt; m) 用map初始化123456789public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; //调用构造,初始化空的hashMap this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR); //扩容 inflateTable(threshold); //把元素放入到HashMap中 putAllForCreate(m);&#125; size() key-value映射个数123public int size() &#123; return size; &#125; isEmpty()是否为空123public boolean isEmpty() &#123; return size == 0; &#125; get(Object key) 根据key获取value123456public V get(Object key) &#123; //获取key为null的 getForNullKey(); //获取其他的key,利用hash值查找 getEntry(Object key);&#125; containsKey(Object key) 是否包含key123public boolean containsKey(Object key) &#123; return getEntry(key) != null; &#125; put(K key, V value) 将指定的key value放入HashMap中,若已存在key,就替换旧值1public V put(K key, V value) &#123;&#125; resize(int newCapacity) 重新设置大小1void resize(int newCapacity)&#123;&#125; transfer(Entry[] newTable, boolean rehash)现有的table放入新的table12345void transfer(Entry[] newTable, boolean rehash) &#123;&#125;``` ## putAll(Map&lt;? extends K, ? extends V&gt; m) 把指定的元素 全部放入HashMap中,已经存在的key,会把旧value覆盖掉 public void putAll(Map&lt;? extends K, ? extends V&gt; m) {}12## remove(Object key) 根据key删除 public V remove(Object key) { removeEntryForKey(key);}12## clear() 清空 public void clear(){}12## containsValue(Object value) 是否包含value public boolean containsValue(Object value) {}12## clone() 浅拷贝 public Object clone() {}12345## static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; 内部类## addEntry(int hash, K key, V value, int bucketIndex) 添加一个键值对 void addEntry(int hash, K key, V value, int bucketIndex) {}12## createEntry(int hash, K key, V value, int bucketIndex) 添加一个键值对 void createEntry(int hash, K key, V value, int bucketIndex) {}``` 参考http://www.cnblogs.com/chenpi/p/5280304.html http://www.cnblogs.com/justany/archive/2013/02/01/2889335.html http://tangyanbo.iteye.com/blog/1756536 http://www.importnew.com/7099.html http://www.cnblogs.com/chenssy/p/3521565.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CopyOnWriteArrayList简介]]></title>
      <url>%2F2016%2F05%2F25%2FCopyOnWriteArrayList%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[CopyOnWriteArrayList，写数组的拷贝，支持高效率并发且是线程安全的,读操作无锁的ArrayList。所有可变操作都是通过对底层数组进行一次新的复制来实现。 CopyOnWriteArrayList适合使用在读操作远远大于写操作的场景里，比如缓存。它不存在扩容的概念，每次写操作都要复制一个副本，在副本的基础上修改后改变Array引用。CopyOnWriteArrayList中写操作需要大面积复制数组，所以性能肯定很差 在迭代器上进行的元素更改操作（remove、set和add）不受支持。这些方法将抛出UnsupportedOperationException。 定义CopyOnWriteArrayList跟ArrayList一样实现了List, RandomAccess, Cloneable, Serializable接口，但是没有继承AbstractList。 初始化时候新建一个容量为0的数组。 add(E e)方法123456789101112131415161718192021public boolean add(E e) &#123; //获得锁，添加的时候首先进行锁定 final ReentrantLock lock = this.lock; lock.lock(); try &#123; //获取当前数组 Object[] elements = getArray(); //获取当前数组的长度 int len = elements.length; //这个是重点，创建新数组，容量为旧数组长度加1，将旧数组拷贝到新数组中 Object[] newElements = Arrays.copyOf(elements, len + 1); //要添加的数据添加到新数组的末尾 newElements[len] = e; //将数组引用指向新数组，完成了添加元素操作 setArray(newElements); return true; &#125; finally &#123; //解锁 lock.unlock(); &#125;&#125; 从上面来说，每次添加一个新元素都会长度加1，然后复制整个旧数组，由此可见对于写多的操作，效率肯定不会很好。所以CopyOnWriteArrayList适合读多写少的场景。 add(int index, E element)方法12345678910111213141516171819202122232425262728293031323334public void add(int index, E element) &#123; //同样也是先加锁 final ReentrantLock lock = this.lock; lock.lock(); try &#123; //获取旧数组 Object[] elements = getArray(); //获取旧数组长度 int len = elements.length; //校验指定的index if (index &gt; len || index &lt; 0) throw new IndexOutOfBoundsException(&quot;Index: &quot;+index+ &quot;, Size: &quot;+len); Object[] newElements; int numMoved = len - index; if (numMoved == 0)//需要插入的位置正好等于数组长度，数组长度加1，旧数据拷贝到新数组 newElements = Arrays.copyOf(elements, len + 1); else &#123; //新数组长度增加1 newElements = new Object[len + 1]; //分两次拷贝，第一次拷贝旧数组0到index处的到新数组0到index，第二次拷贝旧数组index到最后的数组到新数组index+1到最后 System.arraycopy(elements, 0, newElements, 0, index); System.arraycopy(elements, index, newElements, index + 1, numMoved); &#125; //index初插入数据 newElements[index] = element; //新数组指向全局数组 setArray(newElements); &#125; finally &#123; //解锁 lock.unlock(); &#125;&#125; set(int index, E element)方法1234567891011121314151617181920212223242526272829public E set(int index, E element) &#123; //修改元素之前首先加锁 final ReentrantLock lock = this.lock; lock.lock(); try &#123; //获取原来的数组 Object[] elements = getArray(); //index位置的元素 E oldValue = get(elements, index); //新旧值不相等才进行替换 if (oldValue != element) &#123; //原来的长度 int len = elements.length; //拷贝一份到新数组 Object[] newElements = Arrays.copyOf(elements, len); //替换元素 newElements[index] = element; //新数组指向全局数组 setArray(newElements); &#125; else &#123; // Not quite a no-op; ensures volatile write semantics setArray(elements); &#125; return oldValue; &#125; finally &#123; //解锁 lock.unlock(); &#125;&#125; get(int index)方法读的时候不加锁，代码如下： 123public E get(int index) &#123; return get(getArray(), index);&#125; 123private E get(Object[] a, int index) &#123; return (E) a[index];&#125; remove（）remove方法不再过多介绍，看完add和set方法应该就能理解。 迭代内部类COWIterator 实现了ListIterator接口。迭代的时候不能进行remove，add，set等方法，会抛异常。 迭代速度快，迭代时是迭代的数组快照。 12/** Snapshot of the array */private final Object[] snapshot; 源码分析 jdk1.7.0_71 123456//锁,保护所有存取器transient final ReentrantLock lock = new ReentrantLock();//保存数据的数组private volatile transient Object[] array;final Object[] getArray() &#123;return array;&#125;final void setArray(Object[] a) &#123;array = a;&#125; 空构造,初始化一个长度为0的数组123public CopyOnWriteArrayList() &#123; setArray(new Object[0]); &#125; 利用集合初始化一个CopyOnWriteArrayList1public CopyOnWriteArrayList(Collection&lt;? extends E&gt; c) &#123;&#125; 利用数组初始化一个CopyOnWriteArrayList1public CopyOnWriteArrayList(E[] toCopyIn) &#123;&#125; size() 大小1public int size() &#123;&#125; isEmpty()是否为空1public boolean isEmpty()&#123;&#125; indexOf(Object o, Object[] elements,int index, int fence) 元素索引1private static int indexOf(Object o, Object[] elements,int index, int fence) &#123;&#125; indexOf() 元素索引1public int indexOf(Object o)&#123;&#125; indexOf(E e, int index) 元素索引1public int indexOf(E e, int index) &#123;&#125; lastIndexOf(Object o, Object[] elements, int index) 元素索引,最后一个1private static int lastIndexOf(Object o, Object[] elements, int index) &#123;&#125; lastIndexOf(Object o) 元素索引,最后一个1public int indexOf(E e, int index) &#123;&#125; lastIndexOf(E e, int index) 元素索引,最后一个1public int lastIndexOf(E e, int index) &#123;&#125; contains(Object o) 是否包含元素1public boolean contains(Object o)&#123;&#125; clone() 浅拷贝1public Object clone() &#123;&#125; toArray() 转换成数组1public Object[] toArray()&#123;&#125; toArray(T a[]) 转换成指定类型的数组1public &lt;T&gt; T[] toArray(T a[]) &#123;&#125; E get(int index)获取指定位置的元素1public E get(int index)&#123;&#125; set(int index, E element) 指定位置设置元素 写元素的时候,先获得锁,finall块中释放锁 123456789101112131415161718192021public E set(int index, E element) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); E oldValue = get(elements, index); if (oldValue != element) &#123; int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len); newElements[index] = element; setArray(newElements); &#125; else &#123; // Not quite a no-op; ensures volatile write semantics setArray(elements); &#125; return oldValue; &#125; finally &#123; lock.unlock(); &#125; &#125; add(E e) 元素添加到末尾1public boolean add(E e) &#123;&#125; add(int index, E element) 指定位置之后插入元素1public void add(int index, E element)&#123;&#125; remove(int index)删除指定位置的元素1public E remove(int index) &#123;&#125; remove(Object o) 删除第一个匹配的元素1public boolean remove(Object o) &#123;&#125; removeRange(int fromIndex, int toIndex) 删除指定区间的元素1private void removeRange(int fromIndex, int toIndex) &#123;&#125; addIfAbsent(E e) 如果元素不存在就添加进list中1public boolean addIfAbsent(E e)&#123;&#125; containsAll(Collection&lt;?&gt; c)是否包含全部1public boolean containsAll(Collection&lt;?&gt; c)&#123;&#125; removeAll(Collection&lt;?&gt; c) 移除全部包含在集合中的元素1public boolean removeAll(Collection&lt;?&gt; c)&#123;&#125; retainAll(Collection&lt;?&gt; c) 保留指定集合的元素,其他的删除1public boolean retainAll(Collection&lt;?&gt; c)&#123;&#125; addAllAbsent(Collection&lt;? extends E&gt; c) 如果不存在就添加进去1public int addAllAbsent(Collection&lt;? extends E&gt; c) &#123;&#125; clear() 清空list1public void clear()&#123;&#125; addAll(Collection&lt;? extends E&gt; c)添加集合中的元素到尾部1public void addAll(Collection&lt;? extends E&gt; c)&#123;&#125; addAll(int index, Collection&lt;? extends E&gt; c) 添加集合中元素到指定位置之后1public boolean addAll(int index, Collection&lt;? extends E&gt; c)&#123;&#125; toString()1public String toString()&#123;&#125; equals(Object o)1234567891011121314151617public boolean equals(Object o) &#123; if (o == this) return true; if (!(o instanceof List)) return false; List&lt;?&gt; list = (List&lt;?&gt;)(o); Iterator&lt;?&gt; it = list.iterator(); Object[] elements = getArray(); int len = elements.length; for (int i = 0; i &lt; len; ++i) if (!it.hasNext() || !eq(elements[i], it.next())) return false; if (it.hasNext()) return false; return true; &#125; hashCode()1public int hashCode&#123;&#125; listIterator(final int index)和 listIterator() 返回一个迭代器,支持向前和向后遍历123public ListIterator&lt;E&gt; listIterator(final int index) &#123;&#125;public ListIterator&lt;E&gt; listIterator() &#123;&#125; iterator() 只能向后遍历1public Iterator&lt;E&gt; iterator() &#123;&#125; subList() 返回部分list12345public List&lt;E&gt; subList(int fromIndex, int toIndex) &#123; ... return new COWSubList&lt;E&gt;(this, fromIndex, toIndex); ...&#125; 参考http://www.cnblogs.com/sunwei2012/archive/2010/10/08/1845656.html http://my.oschina.net/jielucky/blog/167198]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Stack简介]]></title>
      <url>%2F2016%2F05%2F25%2FStack%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[Stack简介 Stack基于Vector实现,支持LIFO 后进先出 源码分析 jdk1.7.0_71 默认构造12public Stack() &#123; &#125; push(E item)将元素压入顶端12345public E push(E item) &#123; addElement(item); return item; &#125; pop() 删除顶部的元素,同步方法123456789public synchronized E pop() &#123; E obj; int len = size(); obj = peek(); removeElementAt(len - 1); return obj; &#125; peek() 获取顶端元素1234567public synchronized E peek() &#123; int len = size(); if (len == 0) throw new EmptyStackException(); return elementAt(len - 1); &#125; empty() 是否为空1public boolean empty()&#123;&#125; search(Object o) 查询当前o距离栈底的距离12345678public synchronized int search(Object o) &#123; int i = lastIndexOf(o); if (i &gt;= 0) &#123; return size() - i; &#125; return -1; &#125; 参考]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Vector简介]]></title>
      <url>%2F2016%2F05%2F24%2FVector%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[Vector简介 Vector和ArrayList类似,基于Object数组方式实现 Vector是同步访问的,操作是线程安全的 源码分析 jdk1.7.0_71 123456//保存Vector中的元素protected Object[] elementData;//Vector中存储的元素个数protected int elementCount;//Vector容量自动增长的大小,此数值小于等于0,容量增长为2倍protected int capacityIncrement; Vector(int initialCapacity, int capacityIncrement) 初始容量和初始自动增长 构造1public Vector(int initialCapacity, int capacityIncrement)&#123;&#125; Vector(int initialCapacity) 初始容量 ,自动增长2倍 构造1public Vector(int initialCapacity)&#123;&#125; Vector() 初始容量10,自动增长2倍 构造1public Vector()&#123;&#125; Vector(Collection&lt;? extends E&gt; c) 使用集合初始化1public Vector(Collection&lt;? extends E&gt; c)&#123;&#125; copyInto(Object[] anArray) 将Vector中的元素拷到Object数组中1public synchronized void copyInto(Object[] anArray) &#123;&#125; trimToSize()1public synchronized void trimToSize() &#123;&#125; ensureCapacity(int minCapacity) 增加容量1public synchronized void ensureCapacity(int minCapacity) &#123;&#125; grow(int minCapacity) 真正增长容量的方法1private void grow(int minCapacity) &#123;&#125; setSize(int newSize) 设置大小1public synchronized void setSize(int newSize) &#123;&#125; capacity() Vector的容量1public synchronized int capacity() &#123;&#125; size() Vector包含元素的数量1public synchronized int size() &#123;&#125; isEmpty()是否为空1public synchronized boolean isEmpty() &#123;&#125; elements()返回一个枚举123456789101112131415161718public Enumeration&lt;E&gt; elements() &#123; return new Enumeration&lt;E&gt;() &#123; int count = 0; public boolean hasMoreElements() &#123; return count &lt; elementCount; &#125; public E nextElement() &#123; synchronized (Vector.this) &#123; if (count &lt; elementCount) &#123; return elementData(count++); &#125; &#125; throw new NoSuchElementException(&quot;Vector Enumeration&quot;); &#125; &#125;;&#125; contains(Object o) 是否包含指定元素1public boolean contains(Object o) &#123;&#125; indexOf(Object o) 返回第一个匹配的索引1public int indexOf(Object o) &#123;&#125; indexOf(Object o, int index) 返回第一个从index开始的匹配的Object1public synchronized int indexOf(Object o, int index)&#123;&#125; lastIndexOf(Object o) 返回最后一个匹配的索引1public synchronized int lastIndexOf(Object o) &#123;&#125; lastIndexOf(Object o, int index)返回最后一个从index开始的匹配的Object1public synchronized int lastIndexOf(Object o, int index) &#123;&#125; elementAt(int index) 返回指定位置的元素1public synchronized E elementAt(int index) &#123;&#125; firstElement() 第一个元素1public synchronized E firstElement()&#123;&#125; lastElement() 最后一个元素1public synchronized E lastElement() &#123;&#125; setElementAt(E obj, int index) 设置指定位置的元素1public synchronized void setElementAt(E obj, int index) &#123;&#125; removeElementAt(int index) 移除指定位置的元素1public synchronized void removeElementAt(int index) &#123;&#125; insertElementAt(E obj,int index)指定位置之后插入元素1public synchronized void insertElementAt(E obj, int index) &#123;&#125; addElement(E obj) 添加元素到最后1public synchronized void addElement(E obj) &#123;&#125; removeElement(Object obj) 删除第一个匹配的元素1public synchronized boolean removeElement(Object obj) &#123;&#125; removeAllElements() 删除所有元素1public synchronized void removeAllElements() &#123;&#125; clone() 深拷贝1public synchronized Object clone() &#123;&#125; toArray() 返回Object数组1public synchronized Object[] toArray() &#123;&#125; toArray(T[] a) 返回指定类型的数组1public synchronized &lt;T&gt; T[] toArray(T[] a) &#123;&#125; elementData(int index) 返回指定位置的元素1E elementData(int index) &#123;&#125; get(int index) 获取指定位置的元素1public synchronized E get(int index) &#123;&#125; set(int index, E element) 替换指定位置的元素1public synchronized E set(int index, E element) &#123;&#125; add(E e) 添加元素到末尾1public synchronized boolean add(E e) &#123;&#125; remove(Object o) 删除第一个匹配的元素1public boolean remove(Object o) &#123;&#125; add(int index, E element) 指定位置后面插入元素1public void add(int index, E element)&#123;&#125; remove(int index) 删除指定位置的元素1public synchronized E remove(int index) &#123;&#125; clear() 清空vector1public void clear() &#123;&#125; containsAll(Collection&lt;?&gt; c) 是否包含指定的集合1public synchronized boolean containsAll(Collection&lt;?&gt; c) &#123;&#125; addAll(Collection&lt;? extends E&gt; c) 把集合添加到vector的末尾1public synchronized boolean addAll(Collection&lt;? extends E&gt; c) &#123;&#125; removeAll(Collection&lt;?&gt; c) 删除vector中所有的指定集合中的元素1public synchronized boolean removeAll(Collection&lt;?&gt; c) &#123;&#125; retainAll(Collection&lt;?&gt; c)保留指定的集合元素,其他的删除1public synchronized boolean retainAll(Collection&lt;?&gt; c) &#123;&#125; addAll(int index, Collection&lt;? extends E&gt; c) 添加指定的集合元素到指定的位置之后1public synchronized boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123;&#125; equals(Object o)1public synchronized boolean equals(Object o) &#123;&#125; hashCode()1public synchronized int hashCode() &#123;&#125; toString()1public synchronized String toString() &#123;&#125; subList(int fromIndex, int toIndex)返回一个子list1public synchronized List&lt;E&gt; subList(int fromIndex, int toIndex) &#123;&#125; removeRange(int fromIndex, int toIndex) 删除指定区间的元素1protected synchronized void removeRange(int fromIndex, int toIndex) &#123;&#125; listIterator(int index)/listIterator() 返回一个ListIterator12345public synchronized ListIterator&lt;E&gt; listIterator(int index) &#123;&#125;public synchronized ListIterator&lt;E&gt; listIterator() &#123; return new ListItr(0); &#125; iterator() 返回一个Iterator123public synchronized Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; 参考http://www.cnblogs.com/skywang12345/p/3308833.html http://www.runoob.com/java/java-vector-class.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[LinkedList简介]]></title>
      <url>%2F2016%2F05%2F23%2FLinkedList%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[LinkedList简介 LinkedList基于双向链表实现 LinkedList相对于Arraylist来说,get和set等随机访问会比较慢,LinkedList需要移动指针；add和remove会比较快。 LinkedList类还为在列表开头和结尾的get，remove，insert元素提供统一的命名方法，这些操作允许将链表用做堆栈、队列或者双端队列。此类实现 Deque 接口，为 add、poll 提供先进先出队列操作，以及其他堆栈和双端队列操作。 非线程安全，不同步。 定义LinkedList集成AbstractSequentialList，实现了List，Deque，Cloneable，Serializable接口。AbstractSequentialList提供了骨干实现。Deque一个线性 collection，支持在两端插入和移除元素，定义了双端队列的操作。 源码分析 jdk1.7.0_71 123456//节点个数transient int size = 0;//前驱节点transient Node&lt;E&gt; first;//后继节点transient Node&lt;E&gt; last; 无参构造1public LinkedList() &#123;&#125; 根据其他容器进行构造1public LinkedList(Collection&lt;? extends E&gt; c) &#123;&#125; getFirst()/getLast() 获取第一个/获取最后一个12public E getFirst() &#123;&#125;public E getLast() &#123;&#125; removeFirst()/removeLast() 删除第一个/删除最后一个12public E removeFirst() &#123;&#125;public E removeLast() &#123;&#125; addFirst(E e)/addLast(E e) 添加到头/尾12public void addFirst(E e) &#123;&#125;public void addLast(E e) &#123;&#125; 是否包含指定的元素123public boolean contains(Object o) &#123; return indexOf(o) != -1;&#125; 指定元素的位置索引1public int indexOf(Object o) &#123;&#125; 指定元素的最后的位置索引1public int lastIndexOf(Object o) &#123;&#125; list的大小123public int size() &#123; return size;&#125; add() 添加到末尾1public boolean add(E e) &#123;&#125; remove(Object o)/removeFirstOccurrence(Object o) 移除第一个o123public boolean remove(Object o) &#123;&#125;public boolean removeFirstOccurrence(Object o)&#123;&#125; addAll(Collection&lt;? extends E&gt; c) 添加到list结尾1public boolean addAll(Collection&lt;? extends E&gt; c) &#123;&#125; addAll(int index, Collection&lt;? extends E&gt; c) 指定的位置以后添加全部1public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123;&#125; clear() 清空1public void clear() &#123;&#125; get(int index) 获取指定位置的元素1public E get(int index) &#123;&#125; 指定位置替换成新元素,返回旧元素1public E set(int index, E element) &#123;&#125; add(int index, E element)指定位置插入指定元素1public void add(int index, E element) &#123;&#125; remove(int index) 移除指定位置的元素1public E remove(int index) &#123;&#125; peek()/peekFirst() 获取list头123public E peek() &#123;&#125;public E peekFirst() &#123;&#125; element() 获取list头1public E element() &#123;&#125; poll()/pollFirst() 获取list头,并删除123public E poll() &#123;&#125;public E pollFirst() &#123;&#125; remove() 删除第一个1public E remove() &#123;&#125; offer(E e)/offerLast(E e) 添加e到尾部123public boolean offer(E e) &#123;&#125;public boolean offerLast(E e) &#123;&#125; offerFirst(E e)/push(E e) 添加e到头部123public boolean offerFirst(E e) &#123;&#125;public void push(E e)&#123;&#125; peekLast() 获取list尾1public E peekLast() &#123;&#125; pollLast() 获取list尾,并删除1public E pollLast pop() 删除头1public E pop()&#123;&#125; removeLastOccurrence(Object o)从后面开始删除第一个匹配的元素1public boolean removeLastOccurrence(Object o) &#123;&#125; listIterator(int index)从指定的位置开始返回一个listIterator1public ListIterator&lt;E&gt; listIterator(int index) &#123;&#125; descendingIterator() 逆序迭代器1234public Iterator&lt;E&gt; descendingIterator() &#123; //内部类 return new DescendingIterator(); &#125; clone() 浅拷贝1public Object clone() &#123;&#125; toArray() 转换成Object数组1public Object[] toArray() &#123;&#125; toArray(T[] a) 转换成指定类型的数组1234567891011121314public &lt;T&gt; T[] toArray(T[] a) &#123; if (a.length &lt; size) a = (T[])java.lang.reflect.Array.newInstance( a.getClass().getComponentType(), size); int i = 0; Object[] result = a; for (Node&lt;E&gt; x = first; x != null; x = x.next) result[i++] = x.item; if (a.length &gt; size) a[size] = null; return a; &#125; 参考https://www.zybuluo.com/pastqing/note/208830 http://blog.csdn.net/u013256816/article/details/50916689]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ArrayList简介]]></title>
      <url>%2F2016%2F05%2F20%2FArrayList%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[ArrayList简介ArrayList实现了List接口，内部以数组存储数据，允许重复的值。由于内部是数组实现，所以ArrayList具有数组所有的特性，通过索引支持随机访问，查询速度快，但是插入和删除的效率比较低。 ArrayList默认初始容量为10，每次添加新元素时都会检查是否需要扩容操作。扩容操作需要重新拷贝数组，比较耗时，所以如果预先能知道数组的大小，在初始化时候可以指定一个初始容量。 ArrayList不是线程安全的，使用时应注意。 源码分析 jdk1.7.0_71 12345678//默认容量private static final int DEFAULT_CAPACITY = 10;//默认空的数组,定义空的ArrayListprivate static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;//保存ArrayList中元素的数组，以下基本操作都是基于该数组private transient Object[] elementData;//ArrayList中元素数组的容量private int size; 无参构造函数12//构造一个空的Object数组，初始容量为10 public ArrayList() &#123;&#125; 指定容量大小的构造函数12//指定初始容量public ArrayList(int initialCapacity) &#123;&#125; 指定初始值为继承Collection接口的集合的构造函数1public ArrayList(Collection&lt;? extends E&gt; c) &#123;&#125; trimToSize1234567//ArrayList每次增长会预申请1.5倍+1的空间,//举个例子就是当size() = 1000的时候，ArrayList已经申请了1200空间//trimToSize 的作用是删除多余的200public void trimToSize() &#123; modCount++; ... &#125; 关于modCount modCount定义在抽象类AbstratList中， 源码的注释基本说明了它的用处:在使用迭代器遍历的时候，用来检查列表中的元素是否发生结构性变化（列表元素数量发生改变的一个计数）了，主要在多线程环境下需要使用，防止一个线程正在迭代遍历，另一个线程修改了这个列表的结构。 ensureCapacity12//增加此ArrayList实例的容量，如果需要，以确保其能容纳至少由最小容量参数指定的元素数public void ensureCapacity(int minCapacity) &#123;&#125; grow()方法,实际的扩容方法,扩充为原来的1.5倍1234567891011121314//数组最大值private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125; size() ArrayList的大小1public int size() &#123;&#125; isEmpty() 不包含元素,返回true1public boolean isEmpty() &#123;&#125; contains()包含指定的元素,返回true1public boolean contains(Object o) &#123;&#125; indexOf()1public int indexOf(Object o) &#123;&#125; lastIndexOf()1public int lastIndexOf(Object o) &#123;&#125; clone() 浅拷贝1public Object clone() &#123;&#125; toArray() 返回Object数组1public Object[] toArray() &#123;&#125; toArray(T[] a)123456//返回数组的运行时类型是指定数组的。如果列表中指定的数组能容纳，则在其中返回。//否则，一个新的数组分配具有指定数组的运行时类型和此列表的大小。//如果列表中指定的数组能容纳更加节省空间(即数组的元素比列表元素多)，//那么会将紧挨着collection尾部的元素设置为null。public &lt;T&gt; T[] toArray(T[] a) &#123;&#125; elementData() 根据索引返回数据1E elementData(int index) &#123;&#125; get(int index) 根据索引获取1234public E get(int index) &#123; rangeCheck(index);//范围检查,看是否给定的index是否超出数组大小 ... &#125; set(int index, E element) 根据索引替换1234public E set(int index, E element) &#123; rangeCheck(index); ... &#125; add(E e) 添加元素到元素末尾1234public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! ... &#125; add(int index,E element) 添加元素到指定位置1234public void add(int index, E element) &#123; rangeCheckForAdd(index); ... &#125; remove(int index)删除指定位置的元素12345public E remove(int index) &#123; ... elementData[--size] = null; // clear to let GC do its work ...&#125; remove(Object o) 删除指定元素12345public boolean remove(Object o) &#123; ... fastRemove(index); ... &#125; fastRemove(int index)快速删除,不检查边界,无返回值1private void fastRemove(int index) &#123;&#125; clear() 清空123456789public void clear() &#123; modCount++; // clear to let GC do its work for (int i = 0; i &lt; size; i++) elementData[i] = null; size = 0; &#125; addAll(Collection&lt;? extends E&gt; c) 添加指定的集合到末尾1public boolean addAll(Collection&lt;? extends E&gt; c) &#123;&#125; addAll(int index, Collection&lt;? extends E&gt; c) 添加指定元素到指定的位置1public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123;&#125; removeRange(int fromIndex, int toIndex) 删除指定区间的元素1protected void removeRange(int fromIndex, int toIndex) &#123;&#125; removeAll(Collection&lt;?&gt; c) 删除指定的集合元素123public boolean removeAll(Collection&lt;?&gt; c) &#123; return batchRemove(c, false); &#125; retainAll(Collection&lt;?&gt; c) 保留指定集合元素123public boolean retainAll(Collection&lt;?&gt; c) &#123; return batchRemove(c, true); &#125; listIterator(int index)和 listIterator() 返回一个迭代器,支持向前和向后遍历123public ListIterator&lt;E&gt; listIterator(int index) &#123;&#125;public ListIterator&lt;E&gt; listIterator() &#123;&#125; iterator() 只能向后遍历1public Iterator&lt;E&gt; iterator() &#123;&#125; subList() 返回部分list1public List&lt;E&gt; subList(int fromIndex, int toIndex) &#123;&#125; http://blog.csdn.net/crave_shy/article/details/17436773 http://www.importnew.com/19233.html https://www.zybuluo.com/pastqing/note/200073 http://www.cnblogs.com/sipher/articles/2429812.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用Hexo在GitHub上搭建个人博客]]></title>
      <url>%2F2016%2F05%2F03%2Fuse-hexo-build-personal-blog-on-github%2F</url>
      <content type="text"><![CDATA[本机环境 系统：Ubuntu 16.04 LTS Hexo:3.2.0 NodeJS:v5.11.0 Git:2.7.4 重要环境 安装nodejs 安装git 注册github 使用github搭建个人博客，详细参考：GitHub pages 安装Hexo1. mkdir hexo #新建hexo目录 2. cd hexo #进入hexo目录 3. npm install -g hexo #如果不成功使用npm install -g hexo --registry=https://registry.npm.taobao.org 4. hexo init #如果还是卡，不成功，请使用npm config set registry &quot;https://registry.npm.taobao.org&quot;（详细请搜索npm代理之类的文章，国内npm被墙，所以很慢，可使用阿里的npm镜像） 5. hexo g #或者hexo generate 6. hexo s #或者hexo server 7. 使用http://localhost:4000查看是否启动成功 安装hexo主题此处使用hexo-theme-next主题，详情：hexo-theme-next，如有需要可选择其他的主题。 1. hexo clean 2. git clone https://github.com/iissnan/hexo-theme-next themes/next 启用主题修改hexo目录下的站点配置文件_config.yml，将theme: landscape修改为theme: next 查看主题1.hexo g 2.hexo s #启动服务，输入http://127.0.0.1:4000查看 3.启动成功之后，关于主题配置请查看：[主题配置](http://theme-next.iissnan.com/getting-started.html) 生成静态文件hexo generate 发布到github 修改站点配置文件_config.yml,找到下面内容： 123456789# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy:type:修改为：deploy:type: gitrepository: https://github.com/你的用户名/你的用户名.github.com.git # 这是你自己的仓库地址，注意换成自己的用户名branch: master 执行hexo deploy 查看http://dachengxi.github.com 写博客或添加页面123451. hexo new &quot;postName&quot; #新建文章2. hexo new page &quot;pageName&quot; #新建页面3. hexo generate #生成静态页面至public目录4. hexo server #开启预览访问端口（默认端口4000，&apos;ctrl + c&apos;关闭server）5. hexo deploy #将.deploy目录部署到GitHub 错误解决参考 http://codepub.cn/2015/04/06/Github-Pages-personal-blog-from-Octopress-to-Hexo/ http://www.cnblogs.com/zhcncn/p/4097881.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[数据库索引简介]]></title>
      <url>%2F2015%2F06%2F07%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[数据库索引的定义数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。提高数据库表数据访问速度的数据库对象. 索引简介索引可以避免全表扫描，多数查询可以仅扫描少量索引页及数据页,而不是遍历所有数据页，可以大大加快数据的检索速度，这也是创建索引的最主要的原因。索引还可以用于避免排序操作。通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。 索引分类 聚集索引 非聚集索引 聚集索引 索引键值的逻辑顺序与索引所服务的表中相应行的物理顺序相同。 一个表只能包含一个聚集索引。 聚集索引对经常要搜索范围值的列特别有效。 聚集索引表记录的排列顺序与索引的排列顺序一样，查询速度快，但是对表进行修改速度较慢。 聚集索引 非聚集索引 该索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同。 一个表中可以存在多个非聚集索引。 非聚集索引的顺序和表中记录的顺序不一致。 参考https://zh.wikipedia.org/wiki/数据库索引 http://blog.csdn.net/kennyrose/article/details/7532032 http://www.cnblogs.com/aspnethot/articles/1504082.html http://www.cnblogs.com/morvenhuang/archive/2009/03/30/1425534.html http://blog.csdn.net/pang040328/article/details/4164874 http://www.ituring.com.cn/article/986]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[分库分表简介]]></title>
      <url>%2F2015%2F06%2F03%2F%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[分库分表简介 此部分简介都是参考别人已经有的文章,目前还没在实际中使用分库分表,对此部分知识的理解还不够透彻.以后会添加自己的经验. 基于业务垂直划分 基于数据水平拆分 两者结合 参考http://leibinhui.iteye.com/blog/1949056 http://www.voidcn.com/blog/stubborn_cow/article/p-5046773.html http://my.oschina.net/cmcm/blog/175104 http://www.infoq.com/cn/articles/yupoo-partition-database]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>%2F2014%2F05%2F02%2Fhello-world%2F</url>
      <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
    </entry>

    
  
  
</search>
