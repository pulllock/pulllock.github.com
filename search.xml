<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Spring中Placeholder的解析过程]]></title>
      <url>%2F2020%2F05%2F05%2FSpring%E4%B8%ADPlaceholder%E7%9A%84%E8%A7%A3%E6%9E%90%E8%BF%87%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[Spring中Placeholder的解析过程简单梳理。 Spring版本是3.2.18.RELEASE 使用定义application.properties文件： 1placeholder.user.prefix=UserPrefix_ 在applicationContext.xml中引入application.properties文件： 1&lt;context:property-placeholder location="application.properties"/&gt; 在实际使用的地方注入，这里使用@Value注解： 12@Value("$&#123;placeholder.user.prefix&#125;")private String userPrefix; 解析 容器启动，读取xml配置文件，开始加载并解析成BeanDefinition 在解析成BeanDefinition的时候读取到&lt;context:property-placeholder，发现是自定义标签，使用ContextNamespaceHandler来处理，注册一个针对property-placeholder的处理器：PropertyPlaceholderBeanDefinitionParser PropertyPlaceholderBeanDefinitionParser解析&lt;context:property-placeholder location=&quot;application.properties&quot;/&gt;，转换为BeanDefinition，这个BeanDefinition里面持有了location，并且这个BeanDefinition对应的BeanClass是PropertyPlaceholderConfigurer PropertyPlaceholderConfigurer查看继承关系，会发现它实现了BeanFactoryPostProcessor接口，在容器启动的invokeBeanFactoryPostProcessors这一步，会调用BeanFactoryPostProcessor的postProcessBeanFactory方法，该方法PropertyResourceConfigurer中有个实现 PropertyResourceConfigurer的postProcessBeanFactory方法中会把application.properties文件中的属性解析出来：key=placeholder.user.prefix, value=UserPrefix_ 接下来会继续调用PropertyPlaceholderConfigurer的processProperties方法，会遍历BeanFactory中的每个BeanDefinition，尝试使用从properties中解析到的key和value来替换BeanDefinition中对应的属性的${}占位符。这一步不是处理我们声明的@Value注解位置的占位符。 在processProperties解析的最后会添加一个EmbeddedValueResolver到BeanFactory中，具体类型是：PlaceholderResolvingStringValueResolver，这个在Spring3.0新增的功能，用来解析embedded values的占位符，比如：注解的属性。 接下来在容器启动的finishBeanFactoryInitialization这一步，会初始化所有的非懒加载的单例Bean，在populateBean这一步填充属性，在应用属性值之前，会调用实现了InstantiationAwareBeanPostProcessor接口的实现类的postProcessPropertyValues方法，这一步可以在应用属性值到Bean之前改变属性，比如可以替换我们的@Value中的占位符为真正的值 AutowiredAnnotationBeanPostProcessor实现了InstantiationAwareBeanPostProcessor接口，用来处理@Autowired、@Value、@Inject注解，这里的postProcessPropertyValues方法就用来处理我们@Value注解 获取到注解元数据@Value(&quot;${placeholder.user.prefix}&quot;)以及要注入的属性private String userPrefix;，并且使用上面获得的PlaceholderResolvingStringValueResolver来替换占位符。 替换占位符的过程就是将前缀${和后缀}截取掉，获得真正的placeholder.user.prefix，这样就可以根据这个key在上面解析的属性中找到对应的值了。 解析出来key：placeholder.user.prefix之后，会调用PropertyPlaceholderConfigurer的resolvePlaceholder方法从上面解析的属性中根据key获取真正的值，这里会返回UserPrefix_ 接下来还有对表达式的解析，我们没使用，直接跳过。 拿到真正的值UserPrefix_后，使用反射将值赋值给private String userPrefix，这时候就完成了。 总结 在解析xml成BeanDefinition的时候拿到application.properties文件的位置 在调用BeanFactoryPostProcessor实现类的postProcessBeanFactory方法的时候会把application.properties文件中的内容解析key和value对应关系 在实例化Bean的时候会调用AutowiredAnnotationBeanPostProcessor来处理@Value注解，将占位符替换为上面解析到的key对应的value，使用反射设置值。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[DynamicConfigCenter中基于Spring的Schema扩展功能]]></title>
      <url>%2F2020%2F05%2F04%2FDynamicConfigCenter%E4%B8%AD%E5%9F%BA%E4%BA%8ESpring%E7%9A%84Schema%E6%89%A9%E5%B1%95%E5%8A%9F%E8%83%BD%2F</url>
      <content type="text"><![CDATA[集成Spring，使用Spring的scheme扩展机制。 Spring的Schema扩展机制介绍可以自定义xml标签，将我们自定义的功能集成到Spring中去，大概步骤如下： classpath下的META-INF中定义文件：spring.handlers、spring.schemas，用来识别配置 编写xml的xsd文件描述自定义元素 编写NamespaceHandler实现类，来注册自定义标签的解析器 编写BeanDefinitionParser实现类，具体解析标签 DynamicConfigCenter中对Schema扩展机制的使用和实现实际使用 在xml配置文件中定义&lt;dcc:config .../&gt;用来启用自己写的解析placeholder的方法 在代码中使用@Value(&quot;${TestProject.user.prefix}&quot;)注入配置 如果本地配置文件有要使用的配置，优先使用本地配置文件中的配置 具体实现定义spring.schemas文件： 1https\://www.cxis.me/schema/dcc/dcc-config-1.0.xsd=me/cxis/dcc/spring/config/dcc-config.xsd 定义spring.handlers文件： 1https\://www.cxis.me/schema/dcc=me.cxis.dcc.spring.DccConfigNamespaceHandler 定义dcc-config.xsd文件 123456789101112131415161718192021&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;xsd:schema xmlns="https://www.cxis.me/schema/dcc" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:beans="http://www.springframework.org/schema/beans" targetNamespace="https://www.cxis.me/schema/dcc" elementFormDefault="qualified" attributeFormDefault="unqualified"&gt; &lt;xsd:import namespace="http://www.springframework.org/schema/beans" schemaLocation="https://www.springframework.org/schema/beans/spring-beans.xsd"/&gt; &lt;xsd:element name="config"&gt; &lt;xsd:complexType&gt; &lt;xsd:complexContent&gt; &lt;xsd:extension base="beans:identifiedType"&gt; &lt;/xsd:extension&gt; &lt;/xsd:complexContent&gt; &lt;/xsd:complexType&gt; &lt;/xsd:element&gt;&lt;/xsd:schema&gt; 定义DccConfigNamespaceHandler： 1234567public class DccConfigNamespaceHandler extends NamespaceHandlerSupport &#123; @Override public void init() &#123; registerBeanDefinitionParser("config", new DccConfigDefinitionParser()); &#125;&#125; 定义DccConfigDefinitionParser： 1234567public class DccConfigDefinitionParser implements BeanDefinitionParser &#123; @Override public BeanDefinition parse(Element element, ParserContext parserContext) &#123; return null; &#125;&#125; 运行时监听zookeeper的变更，使用反射更新@Value注解的字段值。 具体代码参照https://github.com/dachengxi/DynamicConfigCenter中DynamicConfigCenter-client下的`me.cxis.dcc.spring.DccConfigPlaceholderConfigurer`。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[DynamicConfigCenter中的监听器模式]]></title>
      <url>%2F2020%2F04%2F28%2FDynamicConfigCenter%E4%B8%AD%E7%9A%84%E7%9B%91%E5%90%AC%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[监听器模式运用。 观察者模式观察者模式，定义了一对多的依赖关系，多个观察者对象同时监听某一个主题对象，主题对象发生变化时，会通知所有观察者。 Subject，抽象主题，定义添加和移除观察中对象的方法、定义保存观察者对象的容器、定义通知观察者对象的方法 ConcreteSubject，实际主题，对抽象主题的实现 Observer，观察者对象抽象，定义被通知的接口 ConcreteObserver，观察者实现 代码示例： 12345678910111213141516public abstract class Subject &#123; protected List&lt;Observer&gt; observers = new ArrayList&lt;&gt;(); public void addObserver(Observer observer) &#123; observers.add(observer); &#125; public void removeObserver(Observer observer) &#123; observers.remove(observer); &#125; public void notifyObservers() &#123; observers.forEach(Observer::receiveUpdateFromSubject); &#125;&#125; 123456public class ConcreteSubject extends Subject &#123; public void update() &#123; this.notifyObservers(); &#125;&#125; 1234public interface Observer &#123; void receiveUpdateFromSubject();&#125; 1234567public class ConcreteObserver implements Observer &#123; @Override public void receiveUpdateFromSubject() &#123; System.out.println("receive update form subject......"); &#125;&#125; 12345678910public class Client &#123; public static void main(String[] args) &#123; ConcreteSubject concreteSubject = new ConcreteSubject(); Observer concreteObserver = new ConcreteObserver(); concreteSubject.addObserver(concreteObserver);; concreteSubject.update(); &#125;&#125; 监听器模式监听器模式是观察者模式的一种实现。 事件源，事件发生的源头、触发事件的地方，事件源是被监听的对象 事件，事件源产生的事件 监听器，监听事件的发生，属于观察者 代码示例： 1234567891011121314151617181920212223242526272829303132333435363738394041public class Event &#123; private String key; private String value; private String eventType; public String getKey() &#123; return key; &#125; public void setKey(String key) &#123; this.key = key; &#125; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125; public String getEventType() &#123; return eventType; &#125; public void setEventType(String eventType) &#123; this.eventType = eventType; &#125; @Override public String toString() &#123; return "Event&#123;" + "key='" + key + '\'' + ", value='" + value + '\'' + ", eventType='" + eventType + '\'' + '&#125;'; &#125;&#125; 1234public interface EventListener &#123; public void receiveEventFromEventSource(Event event);&#125; 1234567public class ConcreteEventListener implements EventListener &#123; @Override public void receiveEventFromEventSource(Event event) &#123; System.out.println("receive event from event source: " + event); &#125;&#125; 12345678910111213141516public abstract class EventSource &#123; protected List&lt;EventListener&gt; eventListeners = new ArrayList&lt;&gt;(); public void addEventListener(EventListener eventListener) &#123; eventListeners.add(eventListener); &#125; public void removeEventListener(EventListener eventListener) &#123; eventListeners.remove(eventListener); &#125; public void notifyListeners(Event event) &#123; eventListeners.forEach(eventListener -&gt; eventListener.receiveEventFromEventSource(event)); &#125;&#125; 12345678910public class ConcreteEventSource extends EventSource &#123; public void eventHappened() &#123; Event event = new Event(); event.setKey("user.prefix"); event.setValue("UserDev_"); event.setEventType("Type_DateChanged"); notifyListeners(event); &#125;&#125; 12345678910public class Client &#123; public static void main(String[] args) &#123; ConcreteEventSource concreteEventSource = new ConcreteEventSource(); EventListener eventListener = new ConcreteEventListener(); concreteEventSource.addEventListener(eventListener); concreteEventSource.eventHappened(); &#125;&#125; DynamicConfigCenter中的应用 使用Zookeeper的Watcher机制，发生变更的时候主动更新DynamicConfigCenter-client本地缓存 自定义ConfigListener，项目使用的时候可以自定义对某个key设置监听器，Zookeeper通知变更的时候，会回调用户自定的监听器进行通知。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[DynamicConfigCenter中Zookeeper监听机制使用]]></title>
      <url>%2F2020%2F04%2F28%2FDynamicConfigCenter%E4%B8%ADZookeeper%E7%9B%91%E5%90%AC%E6%9C%BA%E5%88%B6%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[重新温习一下Zookeeper监听机制。 Zookeeper节点可被监控，包括节点数据修改、子节点变化。 Watch机制是一次性的，一次事件监听完成后，如果需要继续监听，需要重新注册。 Watch通知事件是异步的，但是Zookeeper保证一个客户端在看到Watch事件前是不会看到节点数据变化的。 Zookeeper中所有的读操作都可以设置监听：getData()、getChildren()、exists()。 Zookeeper事件 Created event，创建事件，如果调用exists方法设置了监听，将会接到这个创建事件 Deleted event，删除事件，如果调用exists、getData、getChildren方法时设置了监听，将会接收到这个删除事件 Changed event，变更事件，如果调用exists、getData方法时设置了监听，将会接收到这个变更事件 Child event，子节点事件，如果调用getChildren方法时设置了监听，将会接收到这个子节点事件 Child Remove event，子节点监听移除事件，如果调用getChildren方法的时候注册了一个Watcher，之后又取消了这个监听，将会收到一个子节点监听移除事件 Data Remove event，数据监听移除事件，如果调用exists、getData方法的时候注册了一个Watcher，之后又取消了这个监听，将会收到一个数据监听移除事件 操作和事件 create(“/path”)，对于exists(“/path”)的监听会产生一个EventType.NodeCreated事件 delete(“/path”)，对于exists(“/path”)、getData(“/path”)、getChildren(“/path”)的监听会产生一个EventType.NodeDeleted事件 setData(“/path”)，对于exists(“/path”)、getData(“/path”)的监听会产生一个EventType.NodeDataChanged事件 create(“/path/child”)，对于getChildren(“/path”)的监听会产生一个EventType.NodeChildrenChanged事件；对于exists(“/path/child”)的监听会产生一个EventType.NodeCreated事件 delete(“/path/child”)，对于getChildren(“/path”)的监听会产生一个EventType.NodeChildrenChanged事件；对于exists(“/path/child”)、getData(“/path/child”)、getChildren(“/path/child”)的监听会产生一个EventType.NodeDeleted事件 setData(“/path/child”)，对于”/path”的监听不会产生事件，因为修改子节点的数据，对父节点无影响；对于exists(“/path/child”)、getData(“/path/child”)的监听会产生一个EventType.NodeDataChanged事件 Curator监听Cutator的Watcher包装 NodeCache，监听一个节点，监听事件为指定路径的增、删、改操作 PathChildrenCache，监听指定路径的一级子目录，不监听该路径，监听子目录的增、删、改操作 TreeCache，综合NodeCache和PathChildrenCache，对整个目录进行监听，可设置监听深度 Listener ConnectionStateListener，连接状态监听器 CuratorListener，主要针对background异步通知和一些错误通知，配合inBackground使用 NodeCacheListener，配合NodeCache使用 PathChildrenCacheListener，配合PathChildrenCache使用 TreeCacheListener，配合TreeCache使用]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[DynamicConfigCenter中Zookeeper相关操作]]></title>
      <url>%2F2020%2F04%2F27%2FDynamicConfigCenter%E4%B8%ADZookeeper%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%2F</url>
      <content type="text"><![CDATA[重新温习一下操作Zookeeper的一些方法。 创建节点、删除节点、修改节点数据、监听事件等等，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140public class CuratorBasicOperation &#123; private static final String SERVER_ADDR = "127.0.0.1:2181"; public static void main(String[] args) throws Exception &#123; /** * 会话超时时间5s * 连接超时时间5s * 重试策略：最多重试3次，每次重试间隔1s */ CuratorFramework curatorClient = CuratorFrameworkFactory .builder() .connectString(SERVER_ADDR) .sessionTimeoutMs(5000) .connectionTimeoutMs(5000) .retryPolicy(new RetryNTimes(3, 1000)) .build(); // 连接状态监听 curatorClient .getConnectionStateListenable() .addListener(new ConnectionStateListener() &#123; @Override public void stateChanged(CuratorFramework curatorFramework, ConnectionState connectionState) &#123; System.out.println("连接状态监听ConnectionState: " + connectionState); if (connectionState == ConnectionState.RECONNECTED) &#123; System.out.println("连接状态监听reconnect, redo something"); &#125; &#125; &#125;); /** * 主要针对background通知和错误通知， * 对于节点的创建或修改则不会触发监听事件 */ curatorClient .getCuratorListenable() .addListener(new CuratorListener() &#123; @Override public void eventReceived(CuratorFramework curatorFramework, CuratorEvent curatorEvent) throws Exception &#123; System.out.println("监听CuratorEvent: " + curatorEvent); if (curatorEvent.getType() == CuratorEventType.WATCHED) &#123; System.out.println("监听watched, do something"); &#125; &#125; &#125;); curatorClient.start(); // 节点事件监听 NodeCache nodeCache = new NodeCache(curatorClient, "/my_root/cxis_2/config"); nodeCache.start(); nodeCache .getListenable() .addListener(new NodeCacheListener() &#123; @Override public void nodeChanged() throws Exception &#123; String result = new String(nodeCache.getCurrentData().getData()); System.out.println("节点事件监听nodeChanged: " + result); &#125; &#125;); // 子节点事件监听 PathChildrenCache childrenCache = new PathChildrenCache(curatorClient, "/my_root", true); childrenCache.start(); childrenCache .getListenable() .addListener(new PathChildrenCacheListener() &#123; @Override public void childEvent(CuratorFramework curatorFramework, PathChildrenCacheEvent pathChildrenCacheEvent) throws Exception &#123; System.out.println("子节点事件监听PathChildrenCacheEvent: " + pathChildrenCacheEvent); &#125; &#125;); // 创建节点 String result1 = curatorClient .create() .creatingParentsIfNeeded() .withMode(CreateMode.PERSISTENT) .forPath("/my_root/cxis_1/config", "this is value for cxis_1".getBytes()); System.out.println("创建节点result1: " + result1); String result2 = curatorClient .create() .creatingParentsIfNeeded() .withMode(CreateMode.PERSISTENT) .forPath("/my_root/cxis_2/config", "this is value for cxis_2".getBytes()); System.out.println("创建节点result2: " + result2); String result3 = curatorClient .create() .creatingParentsIfNeeded() .withMode(CreateMode.PERSISTENT) .forPath("/my_root/cxis_3/config", "this is value for cxis_3".getBytes()); System.out.println("创建节点result3: " + result3); // 获取子节点 List&lt;String&gt; children = curatorClient.getChildren().forPath("/my_root"); System.out.println("获取子节点children: " + children); // 获取节点数据 String value3 = new String(curatorClient.getData().forPath("/my_root/cxis_3/config")); System.out.println("获取节点数据value3: " + value3); // 获取节点数据和状态 Stat stat = new Stat(); String value3WithStat = new String(curatorClient.getData().storingStatIn(stat).forPath("/my_root/cxis_3/config")); System.out.println("获取节点数据和状态value3WithStat: " + value3WithStat + ", stat: " + stat); // 获取节点数据 String value1 = new String(curatorClient.getData().forPath("/my_root/cxis_1/config")); System.out.println("获取节点数据value1: " + value1); // 判断结点是否存在 Stat stat1 = curatorClient.checkExists().forPath("/my_root/cxis_1/config"); System.out.println("判断结点是否存在stat1: " + stat1); // 删除节点和子节点 curatorClient.delete().guaranteed().deletingChildrenIfNeeded().withVersion(-1).forPath("/my_root/cxis_1"); // 判断结点是否存在 Stat stat2 = curatorClient.checkExists().forPath("/my_root/cxis_1/config"); System.out.println("判断结点是否存在stat2: " + stat2); // 修改节点数据 Stat stat3 = curatorClient.setData().forPath("/my_root/cxis_2/config", "this is value for cxis_2_new".getBytes()); System.out.println("修改节点数据stat3: " + stat3); // 获取节点数据 String value2AfterUpdate = new String(curatorClient.getData().forPath("/my_root/cxis_2/config")); System.out.println("获取节点数据value2AfterUpdate: " + value2AfterUpdate); Thread.sleep(1000); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[DynamicConfigCenter设计文档]]></title>
      <url>%2F2020%2F04%2F26%2FDynamicConfigCenter%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3%2F</url>
      <content type="text"><![CDATA[大概列一下动态配置中心需要实现的功能。 DynamicConfigCenter-admin，配置等的管理 DynamicConfigCenter-client，应用依赖的客户端包 都是使用draw io画的图，源文件可以导入修改。 整体架构架构图源文件：DynamicConfigCenter架构.drawio 数据库设计 dcc_group，配置组，可以以应用作为组 dcc_env，环境，区分开发、测试等环境 dcc_config，配置 dcc_config_inst，配置实例，不同环境的配置值 draw io源文件：DynamicConfigCenter数据库设计 dcc_group 名称 类型 是否为空 索引 默认值 备注 id bigint(20) N PRIMARY 主键ID created_time datetime N 创建时间 modified_time datetime N 修改时间 version smallint(6) N 版本号 name varchar(255) N 组名 desc varchar(255) N 描述 dcc_env 名称 类型 是否为空 索引 默认值 备注 id bigint(20) N PRIMARY 主键ID created_time datetime N 创建时间 modified_time datetime N 修改时间 version smallint(6) N 版本号 name varchar(255) N env名 desc varchar(255) N 描述 dcc_config 名称 类型 是否为空 索引 默认值 备注 id bigint(20) N PRIMARY 主键ID created_time datetime N 创建时间 modified_time datetime N 修改时间 version smallint(6) N 版本号 key varchar(255) N 配置key type smallint(6) N 类型 1-String 2-Number 3-Json desc varchar(255) N 描述 group_id bigint(20) N 所属组id dcc_config_inst 名称 类型 是否为空 索引 默认值 备注 id bigint(20) N PRIMARY 主键ID created_time datetime N 创建时间 modified_time datetime N 修改时间 version smallint(6) N 版本号 config_id bigint(20) N 配置id env_id bigint(20) N 环境id value text N 配置值 Zookeeper节点数据节点：/cxis/dcc/${group_name}/key]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[DynamicConfigCenter设计的思路]]></title>
      <url>%2F2020%2F04%2F25%2FDynamicConfigCenter%E8%AE%BE%E8%AE%A1%E7%9A%84%E6%80%9D%E8%B7%AF%2F</url>
      <content type="text"><![CDATA[大概列一下动态配置中心需要实现的功能。 配置增删改查 环境隔离 客户端缓存 基于Zookeeper 集成Spring 关于具体的思路和实现可以参考下面的文章。 参考 https://juejin.im/entry/5af3a38ff265da0b9e6511c7 http://jm.taobao.org/2016/09/28/an-article-about-config-center/ https://cloud.tencent.com/developer/article/1063232 https://disconf.readthedocs.io/zh_CN/latest/design/src/分布式配置管理平台Disconf.html https://www.sfanonline.cn/Nacos配置中心设计思想/ https://www.cnblogs.com/hujunzheng/p/10932153.html https://dong4j.github.io/views/middleware/2017/03291001.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[APIGateway总结]]></title>
      <url>%2F2020%2F04%2F13%2FAPIGateway%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[用了几天时间来设计和实现一个APIGateway，这里进行一下文档和代码的汇总。 文档汇总： APIGateway设计的思路 APIGateway设计文档 APIGateway中责任链模式的使用 APIGateway中加密验签介绍 APIGateway中流控介绍 APIGatewat中使用Dubbo泛化调用 APIGateway中获取客户端IP的方法 APIGateway总结 代码： https://github.com/dachengxi/APIGateway 实现了基本功能，还有很多的细节没有实现，完整的实现还是需要根据实际的需求来，这里仅仅作为学习使用。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[APIGateway中获取客户端IP的方法]]></title>
      <url>%2F2020%2F04%2F12%2FAPIGateway%E4%B8%AD%E8%8E%B7%E5%8F%96%E5%AE%A2%E6%88%B7%E7%AB%AFIP%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
      <content type="text"><![CDATA[在使用ServletRequest获取客户端ip的时候，不仅仅只使用getRemoteHost来获取，还要使用XFF（X-Forwarded-For）。 X-Forwarded-For是HTTP扩展头部，不是HTTP/1.1协议中的定义，但是现在基本是标准了，X-Forwarded-For存储了客户端IP和请求链路上各个代理IP。 加入一个请求从IP1位置开始，经过IP2，IP3，IP4三个代理然后到达服务端，那么使用ServletRequest的getRemoteHost获取到的IP是：IP4，X-Forwarded-For中存储的是： 1X-Forwarded-For: IP1, IP2, IP3 我们可以使用X-Forwarded-For中的值来获取真是IP： 123456// ...String xff = request.getHeader(X_FORWARDED_FOR);if (StringUtils.isNotEmpty(xff)) &#123; clientIp = xff.split(",")[0];&#125;// ... 但是如果伪造请求链路，客户端请求的时候手动添加X-Forwarded-For的值，就可能不能获取到正确的IP。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[APIGateway中使用Dubbo泛化调用]]></title>
      <url>%2F2020%2F04%2F09%2FAPIGatewat%E4%B8%AD%E4%BD%BF%E7%94%A8Dubbo%E6%B3%9B%E5%8C%96%E8%B0%83%E7%94%A8%2F</url>
      <content type="text"><![CDATA[APIGateway需要调用各个业务系统的接口，但是不可能作为消费者依赖所有系统的接口jar包，可以使用Dubbo的泛化调用功能来实现。APIGateway作为消费者，连接到注册中心，拿到相应接口后可以使用泛化调用。 泛化调用比较简单，可以直接参考dubbo官方文档：Dubbo的泛化调用 示例代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class GenericInvokeDubbo &#123; public final static String PROTOCOL = "zookeeper"; public final static String REGISTRY_ADDRESS = "127.0.0.1:2181"; public final static String APP_NAME = "app-name"; private Map&lt;String, ReferenceConfig&gt; referenceConfigMap = new ConcurrentHashMap&lt;String, ReferenceConfig&gt;(); public Object invokeService(String interfaceClass, String method, String[] paramTypes, Object[] params) &#123; ReferenceConfigCache cache = null; ReferenceConfig&lt;GenericService&gt; referenceConfig = null; try &#123; referenceConfig = referenceConfigMap.get(interfaceClass); if (referenceConfig == null) &#123; referenceConfig = new ReferenceConfig&lt;&gt;(); ApplicationConfig application = new ApplicationConfig(); application.setName(APP_NAME); referenceConfig.setApplication(application); RegistryConfig registry = new RegistryConfig(); registry.setProtocol(PROTOCOL); registry.setAddress(REGISTRY_ADDRESS); referenceConfig.setRegistry(registry); ConsumerConfig consumerConfig = new ConsumerConfig(); consumerConfig.setTimeout(5000); consumerConfig.setRetries(0); referenceConfig.setConsumer(consumerConfig); referenceConfig.setGeneric(true); // referenceConfig.setVersion(); referenceConfig.setInterface(interfaceClass); referenceConfigMap.put(interfaceClass, referenceConfig); &#125; cache = ReferenceConfigCache.getCache(); GenericService genericService = cache.get(referenceConfig); return genericService.$invoke(method, paramTypes, params); &#125; catch (IllegalStateException e) &#123; referenceConfigMap.remove(interfaceClass); if (cache != null) &#123; cache.destroy(referenceConfig); &#125; e.printStackTrace(); return null; &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[APIGateway中流控介绍]]></title>
      <url>%2F2020%2F04%2F09%2FAPIGateway%E4%B8%AD%E6%B5%81%E6%8E%A7%E4%BB%8B%E7%BB%8D%2F</url>
      <content type="text"><![CDATA[流控或者叫限流，可以通过控制流量来保护我们的系统不被大流量或者异常流量冲垮，常用的限流算法有：计数器算法、令牌桶算法、漏桶算法。 计数器算法计数器算法最简单，可以实现在指定的时间段内流量不能超过多少，比如同一个ip在1秒内请求次数不能超过100次这种情形。 需要使用两个map，一个用来记录同一个ip访问的次数，一个用来记录同一个ip上次访问的时间戳。防止map无限制增长，可以单独开启一个线程，用来定时清除超过时间窗口的ip数据。 计数器算法可能会产生突刺，请求集中到达处理后，后面时间就会空闲掉。 示例代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class IPCounter &#123; /** * 保存ip访问的次数 * key：ip * value：访问次数 */ private Map&lt;String, AtomicInteger&gt; counterMap = new ConcurrentHashMap&lt;&gt;(); /** * 保存ip访问的时间 * key：ip * value：时间戳 */ private Map&lt;String, Long&gt; timeMap = new ConcurrentHashMap&lt;&gt;(); /** * 指定的次数 */ private int countRule; /** * 指定的时间，毫秒 */ private long timeRule; public IPCounter(int countRule, long timeRule) &#123; this.countRule = countRule; this.timeRule = timeRule * 1000; &#125; public boolean allow(String ip) &#123; Long time = timeMap.get(ip); Long now = System.currentTimeMillis(); // 不存在或者上一个时间窗口已经过去，重置时间和计数器 if (time == null || (now - time) &gt; timeRule) &#123; timeMap.put(ip, now); counterMap.put(ip, new AtomicInteger()); &#125; AtomicInteger count = counterMap.get(ip); int temp = 1; if (count != null) &#123; temp = count.incrementAndGet(); &#125; return temp &lt;= countRule; &#125; public static void main(String[] args) &#123; // 10秒不能超过5次 IPCounter counter = new IPCounter(5, 10); String ip = "192.168.1.1"; System.out.println(counter.allow(ip)); System.out.println(counter.allow(ip)); System.out.println(counter.allow(ip)); System.out.println(counter.allow(ip)); System.out.println(counter.allow(ip)); System.out.println(counter.allow(ip)); &#125;&#125; 漏桶算法漏桶算法，漏桶的容量是固定的，大批流量进来，超过漏桶数量的抛弃掉，进入到漏桶的请求可以匀速流出。 漏桶算法能够限制请求的速率。 令牌桶算法令牌桶算法是以固定的速度往桶里产生令牌，桶满了新的令牌被丢弃或者拒绝，请求到达的时候会先从桶里获取令牌，再继续执行。 令牌桶算法可以限制请求调用速率，也允许一定程度的突发调用。 可以使用guava包中的令牌桶算法限流器。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[APIGateway中加密验签介绍]]></title>
      <url>%2F2020%2F04%2F08%2FAPIGateway%E4%B8%AD%E5%8A%A0%E5%AF%86%E9%AA%8C%E7%AD%BE%E4%BB%8B%E7%BB%8D%2F</url>
      <content type="text"><![CDATA[需要提供给接口调用方一个用来加密的key，调用方根据key、一些其他参数以及业务参数进行加密，还需要对报文进行签名，使用加密的参数请求接口。 APIGateway接收到请求后进行验签，再进行解密，得到参数后进行处理。 处理完成需要按照跟请求接口一样的方式将结果进行加密加签，然后将结果返回给调用方，调用方按照同样的方式进行验签解密拿到结果。 方案：摘要签名、对称加密 kv参数排序，按照key自然排序，ASCII升序，并将参数值URLEncode一下。 在参数中加入两个额外参数timestamp和nonce。timestamp表示请求发送时间，APIGateway可以对比当前时间戳，来判断请求是否正常；nonce表示一个随机数，也就是常说的盐值，APIGateway可以通过一定时间段内判断nonce是否重复来判断请求是否正常。 使用给定的key，将参数进行加密，使用AES或者DES等。 再将所有参数进行签名，MD5或者SHA1等 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public class CodecClient &#123; public static final String HMAC_SHA1 = "HmacSHA1"; public static final String AES = "AES"; public static final String AES_CBC = "AES/CBC/PKCS5Padding"; public static String encrypt(String key, String content) &#123; try &#123; SecretKeySpec secretKeySpec = new SecretKeySpec(key.getBytes(StandardCharsets.UTF_8), AES); Cipher cipher = Cipher.getInstance(AES_CBC); IvParameterSpec iv = new IvParameterSpec(new byte[16]); cipher.init(Cipher.ENCRYPT_MODE, secretKeySpec, iv); return bytesToHexString(cipher.doFinal(content.getBytes(StandardCharsets.UTF_8))); &#125; catch (NoSuchPaddingException | NoSuchAlgorithmException | InvalidKeyException | BadPaddingException | IllegalBlockSizeException | InvalidAlgorithmParameterException e) &#123; throw new RuntimeException("Encrypt data error!"); &#125; &#125; public static String decrypt(String key, String content) &#123; try &#123; SecretKeySpec secretKeySpec = new SecretKeySpec(key.getBytes(StandardCharsets.UTF_8), AES); Cipher cipher = Cipher.getInstance(AES_CBC); IvParameterSpec iv = new IvParameterSpec(new byte[16]); cipher.init(Cipher.DECRYPT_MODE, secretKeySpec, iv); return new String(cipher.doFinal(hexStringToBytes(content))); &#125; catch (NoSuchAlgorithmException | InvalidKeyException | InvalidAlgorithmParameterException | NoSuchPaddingException | BadPaddingException | IllegalBlockSizeException e) &#123; e.printStackTrace(); throw new RuntimeException("Decrypt data error!"); &#125; &#125; public static String sign(String key, String data, String nonce) &#123; try &#123; SecretKeySpec secretKeySpec = new SecretKeySpec(key.getBytes(StandardCharsets.UTF_8), HMAC_SHA1); Mac mac = Mac.getInstance(HMAC_SHA1); mac.init(secretKeySpec); mac.update(data.getBytes(StandardCharsets.UTF_8)); return bytesToHexString(mac.doFinal(nonce.getBytes(StandardCharsets.UTF_8))); &#125; catch (NoSuchAlgorithmException | InvalidKeyException e) &#123; throw new RuntimeException("Sign error!"); &#125; &#125; private static String bytesToHexString(byte[] bytes) &#123; StringBuilder builder = new StringBuilder(bytes.length * 2); for (byte data : bytes) &#123; builder.append(String.format("%02x", data &amp; 0xff)); &#125; return builder.toString(); &#125; private static byte[] hexStringToBytes(String str) &#123; byte[] bytes = new byte[str.length() / 2]; for(int i = 0; i &lt; str.length() / 2; i++) &#123; String subStr = str.substring(i * 2, i * 2 + 2); bytes[i] = (byte) Integer.parseInt(subStr, 16); &#125; return bytes; &#125; public static void main(String[] args) throws UnsupportedEncodingException &#123; String key = "xxxhhhsshkjkkddd"; JSONObject jsonObject = new JSONObject(); jsonObject.put("id", 123); jsonObject.put("name", "测试姓名"); jsonObject.put("alias", "tom"); String param = URLEncoder.encode(jsonObject.toJSONString(), "utf-8"); System.out.println("param: " + param); int nonce = new SecureRandom().nextInt(); String data = String.format("apiCode=%s&amp;data=%s&amp;nonce=%d", "createUser#XDFFDDD", param, nonce); System.out.println("data: " + data); data = encrypt(key, data); System.out.println("encrypt data: " + data); String sign = sign(key, data, nonce + ""); System.out.println("sign: " + sign); System.out.println("key: " + key); String decryptData = decrypt(key, data); System.out.println("DecryptData: " + decryptData); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[APIGateway中责任链模式的使用]]></title>
      <url>%2F2020%2F04%2F08%2FAPIGateway%E4%B8%AD%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[重新看一下责任链模式，在APIGateway设计中要用到责任链模式。简单写了代码测试下Spring中使用以及Apache CommonsChain使用。 责任链模式（Chain of Responsibility Pattern），为了避免请求发送者和多个请求处理者耦合在一起，为请求创建一个请求处理者的链，多个请求处理者都在这个链中，并且每个请求处理者都记着下一个请求处理者是谁，请求发生的时候，可以沿着这个链一直向下运行。 责任链模式的角色： 抽象处理者（Handler），请求处理者的抽象，定义了处理请求的方法、 持有下一个请求处理者、设置和获取下一个请求处理者的方法。 具体处理者（ConcreteHandler），具体的请求处理者实现，可以处理请求或将请求传给下一个请求处理者。 简单代码： 12345678910111213public abstract class Handler &#123; protected Handler nextHandler; public abstract void process(); public Handler getNextHandler() &#123; return nextHandler; &#125; public void setNextHandler(Handler nextHandler) &#123; this.nextHandler = nextHandler; &#125;&#125; 1234567891011121314151617public class ConcreteHandler extends Handler&#123; @Override public void process() &#123; if (true) &#123; // 当前处理者能处理 return; &#125; // 当前处理者不能处理，交给下一个处理者 if (getNextHandler() == null) &#123; return; &#125; getNextHandler().process(); &#125;&#125; 123456789101112public class Client &#123; public static void main(String[] args) &#123; Handler handler1 = new ConcreteHandler1(); Handler handler2 = new ConcreteHandler2(); Handler handler3 = new ConcreteHandler3(); handler1.setNextHandler(handler2); handler2.setNextHandler(handler3); handler1.process(); &#125;&#125; 按照责任链模式的定义，一个请求只能被其中一个请求处理者处理，或者一个请求处理者都无法处理，但是实际应用中大多都是一个请求可以被多个请求处理者处理。 责任链模式的应用：Tomcat中的Filter、Netty中的Pipeline和ChannelHandler、SpringAOP中的Advisor执行、Dubbo的过滤器链、MyBatis中的插件机制、Zuul中的ZuulFilter。 Spring中使用责任链模式1234567891011121314public abstract class GatewayHandler &#123; protected GatewayHandler nextHandler; public abstract String process(String request); public GatewayHandler getNextHandler() &#123; return nextHandler; &#125; public void setNextHandler(GatewayHandler nextHandler) &#123; this.nextHandler = nextHandler; &#125;&#125; 12345678910111213@Order(1)@Componentpublic class FlowControlHandler extends GatewayHandler &#123; @Override public String process(String request) &#123; GatewayHandler next = getNextHandler(); if (next == null) &#123; return null; &#125; return next.process(request); &#125;&#125; 1234567891011121314151617@Order(2)@Componentpublic class BlacklistHandler extends GatewayHandler &#123; @Override public String process(String request) &#123; if (request.contains("hack")) &#123; return "ip locked"; &#125; GatewayHandler next = getNextHandler(); if (next == null) &#123; return null; &#125; return next.process(request); &#125;&#125; 1234567891011121314151617@Order(3)@Componentpublic class ParamCheckHandler extends GatewayHandler &#123; @Override public String process(String request) &#123; if (request == null || request.contains("error")) &#123; return "param error!"; &#125; GatewayHandler next = getNextHandler(); if (next == null) &#123; return null; &#125; return next.process(request); &#125;&#125; 12345678910111213141516@Order(4)@Componentpublic class InvokeServiceHandler extends GatewayHandler &#123; @Override public String process(String request) &#123; // invoke service String result = "result for request: " + request; GatewayHandler next = getNextHandler(); if (next == null) &#123; return result; &#125; return next.process(request); &#125;&#125; 1234567891011121314151617181920@Configurationpublic class ChainConfig &#123; @Resource private List&lt;GatewayHandler&gt; gatewayHandlers; @PostConstruct private void initChain() &#123; Collections.sort(gatewayHandlers, AnnotationAwareOrderComparator.INSTANCE); int size = gatewayHandlers.size(); for (int i = 0; i &lt; size; i++) &#123; if (i == size - 1) &#123; gatewayHandlers.get(i).setNextHandler(null); &#125; else &#123; gatewayHandlers.get(i).setNextHandler(gatewayHandlers.get(i + 1)); &#125; &#125; &#125;&#125; 12345678910111213@RestController@RequestMapping("/chain")public class ChainController &#123; @Resource private List&lt;GatewayHandler&gt; gatewayHandlers; @RequestMapping(value = "/test", method = RequestMethod.GET) public String test(@RequestParam String str) &#123; GatewayHandler defaultHandler = gatewayHandlers.get(0); return defaultHandler.process(str); &#125;&#125; Apache Commons Chain使用12public class CommonContext extends ContextBase &#123;&#125; 12345678910public abstract class AbstractCommand implements Command &#123; @Override public boolean execute(Context context) throws Exception &#123; CommonContext commonContext = (CommonContext) context; return execute(commonContext); &#125; public abstract boolean execute(CommonContext context);&#125; 123456789101112public class BlacklistHandler extends AbstractCommand &#123; @Override public boolean execute(CommonContext context) &#123; String request = String.valueOf(context.get("request")); if (request.contains("hack")) &#123; context.put("error", "ip locked"); return true; &#125; return false; &#125;&#125; 1234567public class FlowControlHandler extends AbstractCommand &#123; @Override public boolean execute(CommonContext context) &#123; return false; &#125;&#125; 123456789101112public class ParamCheckHandler extends AbstractCommand &#123; @Override public boolean execute(CommonContext context) &#123; String request = String.valueOf(context.get("request")); if (request.contains("error")) &#123; context.put("error", "param error!"); return true; &#125; return false; &#125;&#125; 1234567891011public class InvokeServiceHandler extends AbstractCommand &#123; @Override public boolean execute(CommonContext context) &#123; String request = String.valueOf(context.get("request")); String result = "result for request: " + request; context.put("result", result); return false; &#125;&#125; 123456789public class Chains extends ChainBase &#123; public Chains() &#123; addCommand(new BlacklistHandler()); addCommand(new FlowControlHandler()); addCommand(new ParamCheckHandler()); addCommand(new InvokeServiceHandler()); &#125;&#125; 1234567891011121314151617181920public class Client &#123; public static void main(String[] args) throws Exception &#123; Chains chains = new Chains(); CommonContext commonContext = new CommonContext(); commonContext.put("request", "this hack"); System.out.println(chains.execute(commonContext)); System.out.println(JSON.toJSONString(commonContext)); commonContext = new CommonContext(); commonContext.put("request", "this error"); System.out.println(chains.execute(commonContext)); System.out.println(JSON.toJSONString(commonContext)); commonContext = new CommonContext(); commonContext.put("request", "this is normal request"); System.out.println(chains.execute(commonContext)); System.out.println(JSON.toJSONString(commonContext)); &#125;&#125; Spring和Commons Chain12public class CommonContext extends ContextBase &#123;&#125; 12345678910public abstract class AbstractCommand implements Command &#123; @Override public boolean execute(Context context) throws Exception &#123; CommonContext commonContext = (CommonContext) context; return execute(commonContext); &#125; public abstract boolean execute(CommonContext context);&#125; 12345678910111213public class BlacklistCommand extends AbstractCommand &#123; @Override public boolean execute(CommonContext context) &#123; System.out.println("BlacklistCommand..."); String request = String.valueOf(context.get("request")); if (request.contains("hack")) &#123; context.put("error", "ip locked"); return true; &#125; return false; &#125;&#125; 12345678public class FlowControlCommand extends AbstractCommand &#123; @Override public boolean execute(CommonContext context) &#123; System.out.println("FlowControlCommand..."); return false; &#125;&#125; 12345678910111213public class ParamCheckCommand extends AbstractCommand &#123; @Override public boolean execute(CommonContext context) &#123; System.out.println("ParamCheckCommand..."); String request = String.valueOf(context.get("request")); if (request.contains("error")) &#123; context.put("error", "param error!"); return true; &#125; return false; &#125;&#125; 123456789101112public class InvokeServiceCommand extends AbstractCommand &#123; @Override public boolean execute(CommonContext context) &#123; System.out.println("InvokeServiceCommand..."); String request = String.valueOf(context.get("request")); String result = "result for request: " + request; context.put("result", result); return false; &#125;&#125; 123456789101112131415161718192021222324252627282930313233@Configurationpublic class CommonsChainConfig &#123; @Bean public Command blackListCommand() &#123; return new BlacklistCommand(); &#125; @Bean public Command flowControlCommand() &#123; return new FlowControlCommand(); &#125; @Bean public Command paramCheckCommand() &#123; return new ParamCheckCommand(); &#125; @Bean public Command invokeServiceCommand() &#123; return new InvokeServiceCommand(); &#125; @Bean public ChainBase chains() &#123; ChainBase chainBase = new ChainBase(); chainBase.addCommand(blackListCommand()); chainBase.addCommand(flowControlCommand()); chainBase.addCommand(paramCheckCommand()); chainBase.addCommand(invokeServiceCommand()); return chainBase; &#125;&#125; 123456789101112131415161718@RestController@RequestMapping("/chain")public class ChainController &#123; @Resource private ChainBase chains; @RequestMapping(value = "/commonsChainTest", method = RequestMethod.GET) public String commonsChainTest(@RequestParam String str) throws Exception &#123; CommonContext commonContext = new CommonContext(); commonContext.put("request", str); System.out.println(chains.execute(commonContext)); System.out.println(JSON.toJSONString(commonContext)); String result = commonContext.get("result") == null ? (String) commonContext.get("error") : (String) commonContext.get("result"); return result; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[APIGateway设计文档]]></title>
      <url>%2F2020%2F04%2F07%2FAPIGateway%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3%2F</url>
      <content type="text"><![CDATA[APIGateway的设计文档，包括整体架构和数据库设计。 整体架构使用draw io画的图，这里是源文件：APIGateway整体架构 调用方，手机端、接入方等等一系列调用方 LVS负载均衡 Nginx反向代理 APIGateway 流控，控制流量，针对同一个ip在指定的时间段内访问次数做限制 验签解密，校验参数、验证签名信息、将加密的信息解密 接口验证，验证接口是否存在、接口信息是否是当前调用者的接口 接口权限验证，ip黑名单校验、调用的ip是否在白名单内 业务参数验证，校验业务接口参数是否正确 调用业务接口，可以使用dubbo泛化调用 熔断降级，业务方接口不可用的时候或者业务方处理速度变慢，考虑进行熔断降级 加密返回，将调用结果封装、加密、返回 注册中心，dubbo服务注册到注册中心zookeeper 业务服务，各个业务提供的dubbo服务，服务注册到注册中心 存储 本地缓存 分布式缓存 MySQL 数据库设计 agw_api，接口信息 agw_api_param，接口对应的参数信息 agw_sys，接口所属业务系统 agw_out，外部调用方 agw_out_api，外部调用方拥有的api agw_out_ip，外部调用方的白名单配置 agw_black_ip，黑名单ip 使用draw io画的图，这里是源文件：APIGateway数据库设计 agw_api 名称 类型 是否为空 索引 默认值 备注 id bigint(20) N PRIMARY 主键ID created_time datetime N 创建时间 modified_time datetime N 修改时间 version smallint(6) N 版本号 code varchar(255) N api唯一标识 name varchar(255) N api接口名 method varchar(255) N api方法名 alias varchar() Y api方法别名 sys_id bigint(20) N 所属业务系统id timeout int(6) N 1000 超时时间，毫秒 agw_api_param 名称 类型 是否为空 索引 默认值 备注 id bigint(20) N PRIMARY 主键ID created_time datetime N 创建时间 modified_time datetime N 修改时间 version smallint(6) N 版本号 api_id varchar(255) N api id name varchar(255) N 参数名 type varchar(255) N 参数类型 sequence smallint(6) N 参数顺序 agw_sys 名称 类型 是否为空 索引 默认值 备注 id bigint(20) N PRIMARY 主键ID created_time datetime N 创建时间 modified_time datetime N 修改时间 version smallint(6) N 版本号 name varchar(255) N 业务系统名 desc varchar(255) N 业务系统描述 agw_out 名称 类型 是否为空 索引 默认值 备注 id bigint(20) N PRIMARY 主键ID created_time datetime N 创建时间 modified_time datetime N 修改时间 version smallint(6) N 版本号 name varchar(255) N 外部系统名 desc varchar(255) N 外部系统描述 code varchar(255) N 外部系统唯一标识 ip_control tinyint(4) Y 0 是否白名单控制 0-否 1-是 agw_out_api 名称 类型 是否为空 索引 默认值 备注 id bigint(20) N PRIMARY 主键ID created_time datetime N 创建时间 modified_time datetime N 修改时间 version smallint(6) N 版本号 out_id bigint(20) N 外部系统id api_id bigint(20) N api id agw_out_ip 名称 类型 是否为空 索引 默认值 备注 id bigint(20) N PRIMARY 主键ID created_time datetime N 创建时间 modified_time datetime N 修改时间 version smallint(6) N 版本号 out_id bigint(20) N 外部系统id ip varchar(255) N 外部系统白名单 agw_black_ip 名称 类型 是否为空 索引 默认值 备注 id bigint(20) N PRIMARY 主键ID created_time datetime N 创建时间 modified_time datetime N 修改时间 version smallint(6) N 版本号 out_id bigint(20) Y 外部系统id ip varchar(255) N 黑名单ip]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[APIGateway设计的思路]]></title>
      <url>%2F2020%2F04%2F06%2FAPIGateway%E8%AE%BE%E8%AE%A1%E7%9A%84%E6%80%9D%E8%B7%AF%2F</url>
      <content type="text"><![CDATA[简述一下APIGateway的设计思路，准备从头写一个网关。 API网关的职能 请求接入，承接所有外部请求。 中介策略，承担了外部请求和实际服务中间的功能，比如：鉴权、验签、路由、流控、缓存、黑白名单过滤等等。 业务聚合，所有后端业务服务都可以在这里聚合，通过某种方式将业务服务都聚集到这里。 统一管理，提供管理工具、后台服务等等，可以对服务进行注册、修改以及各种配置。 API网关需要实现的功能 流控，控制流量，针对同一个ip在指定的时间段内访问次数做限制 验签解密，校验参数、验证签名信息、将加密的信息解密 接口验证，验证接口是否存在、接口信息是否是当前调用者的接口 接口权限验证，调用的ip是否在白名单内 业务参数验证，校验业务接口参数是否正确 调用业务接口，可以使用dubbo泛化调用 熔断降级，业务方接口不可用的时候或者业务方处理速度变慢，考虑进行熔断降级 加密返回，将调用结果封装、加密、返回 管理控制台，负责接口服务注册、配置等 实现要点 实现方式使用责任链模式，链中每个模块负责一个功能 本地缓存和分布式缓存配合，需要考虑本地缓存的更新，可以使用zookeeper通知或者MQ通知 异步处理请求，使用Jetty容器部署应用 线程池隔离，请求接收、请求处理、服务调用可以使用不同线程池进行隔离 日志记录，请求以及处理等日志记录，方便问题查询 数据统计，接口的调用信息统计，方便直观查看接口调用情况 报警监控，针对异常或者其他错误选择报警 参考 https://www.infoq.cn/article/EeE1xZeic4UdpbmR*03t https://tech.youzan.com/api-gateway-in-practice/ http://www.zhikestreet.com/content/p/22.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringBoot启动流程简易图]]></title>
      <url>%2F2020%2F04%2F02%2FSpringBoot%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E7%AE%80%E6%98%93%E5%9B%BE%2F</url>
      <content type="text"><![CDATA[简单总结了下SpringBoot的启动流程，可能还有遗漏或者理解不对的地方。直接使用processon画了一张图，供后面详细阅读源码使用。 这里是源文件SpringBootStartup.pos，可以导入processon修改。 下面是导出的图片：]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring同一个类中的注解方法调用AOP失效问题总结]]></title>
      <url>%2F2020%2F03%2F23%2FSpring%E5%90%8C%E4%B8%80%E4%B8%AA%E7%B1%BB%E4%B8%AD%E7%9A%84%E6%B3%A8%E8%A7%A3%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8AOP%E5%A4%B1%E6%95%88%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[Spring中在同一个类中两个方法调用，会导致代理失效，比如同一个类中一个方法A调用另外一个带事务的方法B，会发现B方法的事务不生效；同一个类中一个方法A调用另外一个带注解的清除缓存的方法B，会发现清除缓存不成功。 Spring中仅支持方法级别的代理。 Spring中代理是动态代理，也就是在运行时生成代理，代理可以大概使用以下代码来描述下： 1234567891011121314@Servicepublic class A &#123; public void a() &#123; ...; b(); ...; &#125; @Transactional public void b() &#123; ...; &#125;&#125; 而在运行时生成的代理大概如下： 12345678910111213public class A$Proxy &#123; A serviceA = new A(); public void a() &#123; serviceA.a(); &#125; public void b() &#123; transaction start(); serviceA.b(); transaction end(); &#125;&#125; 如果我们调用A这个Bean其实调用的是A$Proxy，对于a方法的调用其实是调用的A中的a方法，而A中的a调用的是A中的b方法，并没有调用A$Proxy中的b方法来实施事务。 解决办法： 将方法写到两个类中去。 开启expose-proxy 开启expose-proxy后，我们代码需要类似如下处理： 1234567891011121314@Servicepublic class A &#123; public void a() &#123; ...; ((A)AopContext.currentProxy()).b(); ...; &#125; @Transactional public void b() &#123; ...; &#125;&#125; 这种方法在Spring中的实现大概是：Spring在代理使用的时候，会将当前代理设置到AopContext中去：AopContext.setCurrentProxy(proxy)，所以在我们上面修改后的代码里AopContext.currentProxy()就可以拿到A$Proxy，再调用b方法的时候，就是调用的A$Proxy中的增强过的b方法了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring中AOP流程的总结]]></title>
      <url>%2F2020%2F03%2F23%2FSpring%E4%B8%ADAOP%E6%B5%81%E7%A8%8B%E7%9A%84%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[总结一下Spring中AOP的流程，对于具体的源码分析以前写过文档，网上也有很多类似的文章，这里不做重复。 Spring AOP流程大致上可以分为三个阶段：标签解析和AutoProxyCreator的注册、AOP代理的创建、代理的使用。 标签解析和AutoProxyCreator的注册在Spring的扩展点中，最早期的扩展点是NamespaceHandler，这个阶段是在解析成BeanDefinition的阶段。Spring在这里完成自定义标签的解析工作，比如aop、tx等等。AOP功能在这里注册了自己的NamespaceHandler以及BeanDefinitionParser，用来将AOP标签转换成BeanDefinition交给IOC容器管理。 关于AutoProxyCreator的理解同时在这里也会注册一个AutoProxyCreator，这个组件是用来在后面Bean的初始化过程中生成代理的。这个AutoProxtCreator实现了一个接口是：SmartInstantiationAwareBeanPostProcessor，看起来很眼熟，SmartInstantiationAwareBeanPostProcessor这个接口的父接口是：InstantiationAwareBeanPostProcessor，而InstantiationAwareBeanPostProcessor的父接口是BeanPostProcessor，到这里我们可能就大概明白了。 我们知道实现了BeanPostProcessor接口的类会在Bean初始化过程中的填充属性之后这一步被调用，调用的方法是postProcessBeforeInitialization和postProcessAfterInitialization。但是Spring干嘛还要衍生出那么多子接口呢？通过接口的名字我们可以看到不同，那些接口名字都含有一个关键词：Instantiation实例化，并不是初始化Initialization，也就是说这些接口中的方法调用是要在Bean实例化的时候进行处理。在Bean的生命周期中，我们知道Bean的实例化是Bean初始化步骤中最早的一步，所以对于Instantiation等方法的处理会比Initialization要早。 试想一下，我们自己写这些逻辑的时候，会在什么时候去创建AOP代理？第一个时间点：在Bean实例化之前，我就通过创建代理的逻辑直接返回一个代理好的实例，就不用继续走Bean初始化的后面的步骤了；第二个时间点：在Bean初始化之后，也就是走完了所有的Bean初始化过程后生成了一个完整的Bean，我再进行代理的创建。Spring就是这么处理的，要么我就不用Spring创建Bean，我直接返回一个代理，要么我就等Spring创建完成一个Bean再返回一个代理。Spring还有会另外一个触发点创建代理：getEarlyBeanReference，用来在解决循环依赖时提前曝光的Bean的代理生成，暂时不做说明。 AOP代理创建明确了代理创建的时间点，就可以继续看AOP代理的创建过程了。 筛选出所有适合当前Bean的通知器，也就是所有的Advisor、Advise、Interceptor。 选择使用JDK还是CGLIB来进行创建代理。 使用具体的代理实现来创建代理。 过程简单，但是实际的细节和实现还很复杂。 代理的使用 获取当前调用方法的拦截器链，包含了所有将要执行的advice。 如果没有任何拦截器，直接执行目标方法。 如果有拦截器存在，则将拦截器和目标方法封装成一个MethodInvocation，递归调用proceed方法进行调用。 上面的处理中还有对目标对象的自我方法调用实施增强的处理，比如平时遇到的问题：在同一个类中一个方法调用另外一个带事务注解的方法，事务不会生效；在同一个类中一个方法调用另外一个带缓存注解的方法，缓存不会生效。 以上就是大概的流程，总结一下就是：AOP实现使用的是动态代理和拦截器连。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring解决循环依赖的过程总结]]></title>
      <url>%2F2020%2F03%2F22%2FSpring%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E7%9A%84%E8%BF%87%E7%A8%8B%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[简单将Spring是怎么解决循环依赖做一下总结，具体的源码实现网上有很多文章，这里不做具体分析。 Spring在初始化Bean的时候，会先初始化当前Bean所依赖的Bean，如果两个Bean互相依赖，就产生了循环依赖，Spring针对循环依赖的办法是：提前曝光加上三个缓存singletonObjects、earlySingletonObjects、singletonFactories。 假设当前Bean是A，A依赖的Bean是B，B又依赖A。 提前曝光的意思就是，当前Bean A实例化完，还没有初始化完就先把当前Bean曝光出去，在B初始化需要依赖A的时候，就先拿到提前曝光的A，这样就可以继续将B初始化完成，然后返回A继续进行初始化。 上面说的三个缓存的使用如下： 初始化Bean A，此时三个缓存中都是空，singletonObjects: [null], earlySingletonObjects: [], singletonFactories: [null] 实例化Bean A，将A放入到singletonFactories中，此时singletonObjects: [null], earlySingletonObjects: [], singletonFactories: [A]。 实例化A之后，需要注入依赖的属性，发现A依赖B，开始初始化Bean B，此时singletonObjects: [null], earlySingletonObjects: [], singletonFactories: [A] 实例化Bean B，将B放入到singletonFactories中，此时singletonObjects: [null], earlySingletonObjects: [], singletonFactories: [A, B] 实例化B之后，需要注入依赖的属性，发现B依赖A，此时需要初始化A，这时候初始化A会去singletonFactories查找一下，发现存在A，直接获取A并放入earlySingletonObjects中，然后从singletonFactories删除，此时singletonObjects: [null], earlySingletonObjects: [A], singletonFactories: [B] 此时B就拿到了上一步在singletonFactories中存在的A，B依赖注入完成，此时singletonObjects: [null], earlySingletonObjects: [A], singletonFactories: [B] B依赖注入完成后继续初始化完成，会将B从earlySingletonObjects和singletonFactories中删除，添加进singletonObjects中，此时singletonObjects: [B], earlySingletonObjects: [A], singletonFactories: [null] 接下来继续进行A的依赖注入，此时B已经初始化完成了，直接将B注入给A，然后A继续下面的初始化直到A完成，此时singletonObjects: [B], earlySingletonObjects: [A], singletonFactories: [null] A初始化完成之后，会从earlySingletonObjects和singletonFactories中删除，添加进singletonObjects中，此时singletonObjects: [A, B], earlySingletonObjects: [null], singletonFactories: [null] 这样就完成了循环依赖的解决。 循环依赖解决只针对单例Bean。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring中Bean的生命周期总结]]></title>
      <url>%2F2020%2F03%2F22%2FSpring%E4%B8%ADBean%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[总结一下Spring中Bean的生命周期，对于具体的源码分析以前写过文档，网上也有很多类似的文章，这里不做重复。 简单版的Spring中Bean的生命周期或者说任何一个物体的生命周期都可以大体分为：初始化、使用、销毁，哪怕是Spring IOC容器也可以这样总结。这里说要总结生命周期，其实就是把这三步稍微详细的再说一下。大体的过程如下： 手动或者自动的触发获取一个Bean，使用BeanFactory的时候需要我们代码自己获取Bean，ApplicationContext则是在IOC启动的时候自动初始化一个Bean。 IOC会根据BeanDefinition来实例化这个Bean，如果这个Bean还有依赖其他的Bean则会先初始化依赖的Bean，这里又涉及到了循环依赖的解决。实例化Bean的时候根据工厂方法、构造方法或者简单初始化等选择具体的实例来进行实例化，最终都是使用反射进行实例化。 Bean实例化完成，也就是一个对象实例化完成后，会继续填充这个Bean的各个属性，也是使用反射机制将属性设置到Bean中去。 填充完属性后，会调用各种Aware方法，将需要的组件设置到当前Bean中。BeanFactory这种低级容器需要我们手动注册Aware接口，而ApplicationContext这种高级容器在IOC启动的时候就自动给我们注册了Aware等接口。 接下来如果Bean实现了PostProcessor一系列的接口，会先调用其中的postProcessBeforeInitialization方法。BeanFactory这种低级容器需要我们手动注册PostProcessor接口，而ApplicationContext这种高级容器在IOC启动的时候就自动给我们注册了PostProcessor等接口。 如果Bean实现了InitializingBean接口，则会调用对应的afterPropertiesSet方法。 如果Bean设置了init-method属性，则会调用init-method指定的方法。 接下来如果Bean实现了PostProcessor一系列的接口，会先调用其中的postProcessAfterInitialization方法。BeanFactory这种低级容器需要我们手动注册PostProcessor接口，而ApplicationContext这种高级容器在IOC启动的时候就自动给我们注册了PostProcessor等接口。 到这里Bean就可以使用了。 容器关闭的时候需要销毁Bean。 如果Bean实现了DisposableBean，则调用destroy方法。 如果Bean配置了destroy-method属性，则调用指定的destroy-method方法。 在实例化完Bean和填充属性之前还会涉及到AOP的处理，在处理依赖Bean的时候还会涉及到循环依赖的处理等等细节。 复杂版的 手动或者自动的触发获取一个Bean，使用BeanFactory的时候需要我们代码自己获取Bean，ApplicationContext则是在IOC启动的时候自动初始化一个Bean。 IOC会根据BeanDefinition来实例化这个Bean，如果这个Bean还有依赖其他的Bean则会先初始化依赖的Bean，这里又涉及到了循环依赖的解决。 实例化之前先看下Bean是否实现了InstantiationAwareBeanPostProcessor接口，如果实现了该接口，则先调用其postProcessBeforeInstantiation方法，常见的实现是在AbstractAutoCreator中有该方法的实现，在这里可以根据实际情况返回一个代理，如果这里返回了一个代理Bean而不是返回null的话，下面的步骤就不会继续进行下去了。换句话说，如果这里生成了Bean就不需要下面的步骤进行Bean的实例化和初始化了。 如果上面一步返回了一个Bean，虽然不需要继续下面的实例化步骤，但是还是需要走一下postProcessBeforeInstantiation的postProcessAfterInitialization方法，就是不管怎么样生成Bean，最后都要走一下初始化的后置处理器。 如果上面没有生成一个Bean，就继续正常的实例化Bean，实例化Bean的时候根据工厂方法、构造方法或者简单初始化等选择具体的实例来进行实例化，最终都是使用反射进行实例化。 Bean实例化完成，也就是一个对象实例化完成后，如果改Bean实现了MergedBeanDefinitionPostProcessor接口，则调用这个接口的postProcessMergedBeanDefinition方法，这里我们熟悉的有：对@Autowired, @Value, @Inject等注解进行预解析；对@Resource, @PostConstruct, @PreDestroy等注解进行预解析。 经过对一些注解的预解析之后，会进行循环依赖的一些准备工作，如果需要提前曝光的话，会把还在生成的Bean放到singletonFactories中去，解决循环依赖的时候会用到。 然后会继续填充这个Bean的各个属性，在填充属性前，还需要看是否实现了InstantiationAwareBeanPostProcessor接口，如果实现了该接口，则需要调用其postProcessAfterInstantiation方法，如果有一个实现的该方法返回了false，表示不需要继续再进行下面的填充属性设置，也不需要再继续处理其他的InstantiationAwareBeanPostProcessor。 如果上一步的处理没有直接返回false，而是继续处理的话，还是会继续判断有没有实现InstantiationAwareBeanPostProcessor接口，如果实现了该接口则需要调用其postProcessPropertyValues方法，这里会有我们熟悉的动作：对@Autowired, @Value, @Inject等注解的依赖进行设值、对@Resource, @PostConstruct, @PreDestroy等注解的依赖进行设值，都是通过反射将依赖设置到目标Bean中去；还有一个对@Required所注解的必须依赖进行校验，如果没有就会抛异常。 接下来如果有depends-on属性的话，需要进行依赖检查，不满足依赖会抛异常。 这里就是真正填充属性的地方了，使用反射机制将属性设置到Bean中去。 填充完属性后，会调用各种Aware方法，将需要的组件设置到当前Bean中。BeanFactory这种低级容器需要我们手动注册Aware接口，而ApplicationContext这种高级容器在IOC启动的时候就自动给我们注册了Aware等接口。 接下来如果Bean实现了PostProcessor一系列的接口，会先调用其中的postProcessBeforeInitialization方法。BeanFactory这种低级容器需要我们手动注册PostProcessor接口，而ApplicationContext这种高级容器在IOC启动的时候就自动给我们注册了PostProcessor等接口。实现类大概如下：ApplicationContextAwareProcessor在该方法中会执行各种ApplicationContext的Aware方法，比如ApplicationContextAware、ResourceLoaderAware等；InitDestroyAnnotationBeanPostProcessor在该方法中会调用注解的init方法，也就是@PostConstruct注解的方法，比下面的InitializingBean和xml中的init-method执行要早。 如果Bean实现了InitializingBean接口，则会调用对应的afterPropertiesSet方法。 如果Bean设置了init-method属性，则会调用init-method指定的方法，使用反射调用。 接下来如果Bean实现了PostProcessor一系列的接口，会先调用其中的postProcessAfterInitialization方法。BeanFactory这种低级容器需要我们手动注册PostProcessor接口，而ApplicationContext这种高级容器在IOC启动的时候就自动给我们注册了PostProcessor等接口。实现类大概如下：AbstractAutoProxyCreator会在该方法看是否需要进行代理； 接下来继续注册DisposableBean。 到这里Bean就可以使用了。 容器关闭的时候需要销毁Bean。 如果Bean实现了DisposableBean，则调用destroy方法。 如果Bean配置了destroy-method属性，则调用指定的destroy-method方法。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring中IOC容器的初始化过程总结]]></title>
      <url>%2F2020%2F03%2F22%2FSpring%E4%B8%ADIOC%E5%AE%B9%E5%99%A8%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[总结一下Spring IOC容器的初始化过程，对于具体的源码分析以前写过文档，网上也有很多类似的文章，这里不做重复。 Spring IOC容器初始化过程总得说起来也简单，基本是整个Spring启动的过程。大体流程： Spring启动 -&gt; 加载配置文件 -&gt; 将配置文件转化成Resource -&gt; 从Resource中解析转换成BeanDefinition -&gt; 主动或则被动触发Bean的初始化过程 -&gt; 应用程序中使用Bean -&gt; 销毁Bean -&gt; 容器关闭。 其实总的流程就这么简单，但是具体实现有很多很多的细节需要处理，讲完就是一本书。这里就是简单总结，所以内容会很少很少。 Spring启动。 加载配置文件，xml、JavaConfig、注解、其他形式等等，将描述我们自己定义的和Spring内置的定义的Bean加载进来。 加载完配置文件后将配置文件转化成统一的Resource来处理。 使用Resource解析将我们定义的一些配置都转化成Spring内部的标识形式：BeanDefinition。 在低级的容器BeanFactory中，到这里就可以宣告Spring容器初始化完成了，Bean的初始化是在我们使用Bean的时候触发的；在高级的容器ApplicationContext中，会自动触发那些lazy-init=false的单例Bean，让Bean以及依赖的Bean进行初始化的流程，初始化完成Bean之后高级容器也初始化完成了。 在我们的应用中使用Bean。 Spring容器关闭，销毁各个Bean。 这中间还会有很多其他的工作，对于我们从宏观上来了解Spring的整体没有影响，不做过多阐述。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo启动以及服务调用的过程总结]]></title>
      <url>%2F2020%2F03%2F20%2FDubbo%E5%90%AF%E5%8A%A8%E4%BB%A5%E5%8F%8A%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8%E7%9A%84%E8%BF%87%E7%A8%8B%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[服务暴露过程、服务引用过程、服务调用过程、消费者调用底层通信过程、提供者接受请求底层通信过程简单总结。 服务暴露过程服务暴露、服务提供者初始化 服务转化成Invoker -&gt; Invoker转化成Exporter -&gt; Transporter使用具体的Server启动服务监听端口 -&gt; 使用具体的Registry将服务注册到注册中心。 开始暴露服务，调用ServiceConfig的export方法导出服务，ServiceConfig使用ProxyFactory将我们要暴露的服务转化成一个Invoker。服务转化成Invoker后，需要通过具体的协议（比如Dubbo）将Invoker转化成Exporter（比如DubboExporter）。Exporter中使用Transporter来初始化一个具体的Server（比如Netty），并绑定服务端口，此时服务就被暴露出去了。服务暴露之后会调用具体的Registry（比如Zookeeper）将服务注册到注册中心去。 服务暴露过程、服务引用过程、服务调用过程、消费者调用底层通信过程、提供者接受请求底层通信过程简单总结。 服务暴露过程服务暴露、服务提供者初始化 服务转化成Invoker -&gt; Invoker转化成Exporter -&gt; Transporter使用具体的Server启动服务监听端口 -&gt; 使用具体的Registry将服务注册到注册中心。 开始暴露服务，调用ServiceConfig的export方法导出服务，ServiceConfig使用ProxyFactory将我们要暴露的服务转化成一个Invoker。服务转化成Invoker后，需要通过具体的协议（比如Dubbo）将Invoker转化成Exporter（比如DubboExporter）。Exporter中使用Transporter来初始化一个具体的Server（比如Netty），并绑定服务端口，此时服务就被暴露出去了。服务暴露之后会调用具体的Registry（比如Zookeeper）将服务注册到注册中心去。 引用服务过程引用服务、消费者初始化、消费者订阅服务 服务订阅 -&gt; 服务转化成Invoker -&gt; Transporter使用具体的Client启动服务准备连接 -&gt; 使用Cluster并继续初始化Invoker -&gt; 封装成一个代理返回。 开始引用服务，调用ReferenceConfig的get方法引用服务，ReferenceConfig调用RegistryProtocol并使用具体的Registry（比如Zookeeper）来订阅服务，Registry会通知Directory开始引用服务（异步），也就是将要引用的服务转化成一个Invoker。Directory会使用具体的Protocol（如Dubbo）将引用的服务转化成一个Invoker。Invoker中使用Transporter来初始化一个具体的Client（比如Netty）用来准备和服务端提供者进行通信。RegistryProtocol调用Cluster的合并方法来初始化Invoker，然后ReferenceConfig在Invoker生成之后返回一个服务的代理。 服务调用过程服务调用过程分为两部分：服务消费者调用服务和服务提供者接受服务请求。 服务消费者调用服务获取到代理 -&gt; 调用Invoker -&gt; Exchange调用远程服务 服务开始调用，首先获取到在服务引用过程中生成的代理，获取到代理后先执行一些过滤器链，比如：缓存、mock等等。接下来会根据Cluster来选择一个具体的Invoker，比如：failover、failsave、failfast、failback、forking、broadcast等，同时使用Directory从Registry中获取所有的invokers，然后使用LoadBalance（random、roundRobin、leastActive、consistentHash）选中具体调用的服务。选中服务之后会先执行过滤器链，再使用具体的Protocol（比如DubboProtocol）调用Transporter并使用具体的Client（比如Netty）来进行服务的调用。发送的请求会进行Codec编码和Serialzation序列化。 服务提供者接受服务请求服务提供者接收到请求后，会进行反序列化和Decodec解码，然后从线程池中获取一个线程交给具体的Server（比如Netty)进行处理，然后会交给具体的Protocol（比如Dubbo）来根据参数获取具体的Exporter，继续执行一系列的过滤器链，然后使用ProxyFactory来获取具体的Invoker（比如Dubbo），Invoker就会调用真正的服务实现类，然后将结果返回。 processon源文件：dubbo-invoke.pos 底层通信过程服务消费者发送请求底层通信过程和服务提供者接受服务请求底层通信过程 稍后添加 引用服务过程引用服务、消费者初始化、消费者订阅服务 服务订阅 -&gt; 服务转化成Invoker -&gt; Transporter使用具体的Client启动服务准备连接 -&gt; 使用Cluster并继续初始化Invoker -&gt; 封装成一个代理返回。 开始引用服务，调用ReferenceConfig的get方法引用服务，ReferenceConfig调用RegistryProtocol并使用具体的Registry（比如Zookeeper）来订阅服务，Registry会通知Directory开始引用服务（异步），也就是将要引用的服务转化成一个Invoker。Directory会使用具体的Protocol（如Dubbo）将引用的服务转化成一个Invoker。Invoker中使用Transporter来初始化一个具体的Client（比如Netty）用来准备和服务端提供者进行通信。RegistryProtocol调用Cluster的合并方法来初始化Invoker，然后ReferenceConfig在Invoker生成之后返回一个服务的代理。 服务暴露过程、服务引用过程、服务调用过程、消费者调用底层通信过程、提供者接受请求底层通信过程简单总结。 服务暴露过程服务暴露、服务提供者初始化 服务转化成Invoker -&gt; Invoker转化成Exporter -&gt; Transporter使用具体的Server启动服务监听端口 -&gt; 使用具体的Registry将服务注册到注册中心。 开始暴露服务，调用ServiceConfig的export方法导出服务，ServiceConfig使用ProxyFactory将我们要暴露的服务转化成一个Invoker。服务转化成Invoker后，需要通过具体的协议（比如Dubbo）将Invoker转化成Exporter（比如DubboExporter）。Exporter中使用Transporter来初始化一个具体的Server（比如Netty），并绑定服务端口，此时服务就被暴露出去了。服务暴露之后会调用具体的Registry（比如Zookeeper）将服务注册到注册中心去。 引用服务过程引用服务、消费者初始化、消费者订阅服务 服务订阅 -&gt; 服务转化成Invoker -&gt; Transporter使用具体的Client启动服务准备连接 -&gt; 使用Cluster并继续初始化Invoker -&gt; 封装成一个代理返回。 开始引用服务，调用ReferenceConfig的get方法引用服务，ReferenceConfig调用RegistryProtocol并使用具体的Registry（比如Zookeeper）来订阅服务，Registry会通知Directory开始引用服务（异步），也就是将要引用的服务转化成一个Invoker。Directory会使用具体的Protocol（如Dubbo）将引用的服务转化成一个Invoker。Invoker中使用Transporter来初始化一个具体的Client（比如Netty）用来准备和服务端提供者进行通信。RegistryProtocol调用Cluster的合并方法来初始化Invoker，然后ReferenceConfig在Invoker生成之后返回一个服务的代理。 服务调用过程服务调用过程分为两部分：服务消费者调用服务和服务提供者接受服务请求。 服务消费者调用服务获取到代理 -&gt; 调用Invoker -&gt; Exchange调用远程服务 服务开始调用，首先获取到在服务引用过程中生成的代理，获取到代理后先执行一些过滤器链，比如：缓存、mock等等。接下来会根据Cluster来选择一个具体的Invoker，比如：failover、failsave、failfast、failback、forking、broadcast等，同时使用Directory从Registry中获取所有的invokers，然后使用LoadBalance（random、roundRobin、leastActive、consistentHash）选中具体调用的服务。选中服务之后会先执行过滤器链，再使用具体的Protocol（比如DubboProtocol）调用Transporter并使用具体的Client（比如Netty）来进行服务的调用。发送的请求会进行Codec编码和Serialzation序列化。 服务提供者接受服务请求服务提供者接收到请求后，会进行反序列化和Decodec解码，然后从线程池中获取一个线程交给具体的Server（比如Netty)进行处理，然后会交给具体的Protocol（比如Dubbo）来根据参数获取具体的Exporter，继续执行一系列的过滤器链，然后使用ProxyFactory来获取具体的Invoker（比如Dubbo），Invoker就会调用真正的服务实现类，然后将结果返回。 processon源文件：dubbo-invoke.pos 底层通信过程服务消费者发送请求底层通信过程和服务提供者接受服务请求底层通信过程 稍后添加 服务调用过程服务调用过程分为两部分：服务消费者调用服务和服务提供者接受服务请求。 服务消费者调用服务获取到代理 -&gt; 调用Invoker -&gt; Exchange调用远程服务 服务开始调用，首先获取到在服务引用过程中生成的代理，获取到代理后先执行一些过滤器链，比如：缓存、mock等等。接下来会根据Cluster来选择一个具体的Invoker，比如：failover、failsave、failfast、failback、forking、broadcast等，同时使用Directory从Registry中获取所有的invokers，然后使用LoadBalance（random、roundRobin、leastActive、consistentHash）选中具体调用的服务。选中服务之后会先执行过滤器链，再使用具体的Protocol（比如DubboProtocol）调用Transporter并使用具体的Client（比如Netty）来进行服务的调用。发送的请求会进行Codec编码和Serialzation序列化。 服务提供者接受服务请求服务提供者接收到请求后，会进行反序列化和Decodec解码，然后从线程池中获取一个线程交给具体的Server（比如Netty)进行处理，然后会交给具体的Protocol（比如Dubbo）来根据参数获取具体的Exporter，继续执行一系列的过滤器链，然后使用ProxyFactory来获取具体的Invoker（比如Dubbo），Invoker就会调用真正的服务实现类，然后将结果返回。 processon源文件：dubbo-invoke.pos 底层通信过程服务消费者发送请求底层通信过程和服务提供者接受服务请求底层通信过程 稍后添加]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo架构简单理解]]></title>
      <url>%2F2020%2F03%2F19%2FDubbo%E6%9E%B6%E6%9E%84%E7%AE%80%E5%8D%95%E7%90%86%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[分析总结一下Dubbo的架构，通过对Dubbo、RocketMQ、Tair等架构的类比，从整体上来理解一般分布式框架、应用的组成。 Dubbo架构Dubbo在日常开发中我们应该是接触的最多的一个框架，它的组成我们最熟悉的应该就是三部分：Provider、Consumer、Registry。以下是官方的架构图： 使用的时候，第一步我们要启动注册中心。注册中心用来注册服务、发现服务，充当着整个系统的中心点，提供指挥或者导航的作用。 第二步，启动服务提供者，服务提供者启动后会把自己注册到注册中心，告诉注册中心我可以使用了。这里服务提供者是把自己告诉给注册中心，而不是服务使用者，服务提供者不知道服务使用者是谁，也不知道服务使用者在哪里，也不知道有多少服务使用者，但是我就把自己告诉注册中心，剩下的你们自己决定怎么使用。 试想一下如果服务提供者要把自己亲自告诉服务使用者，那会是怎样的场景。 第三步，启动服务消费者，服务消费者启动后会向注册中心订阅服务，也就是向注册中心要自己需要的服务，找到需要的服务后，就可以调用服务了。 这根我们现实生活中的很多场景都类似，我们需要一个中心点，比如交通指挥中心、电力指挥中心，甚至于社区中心都可以类比。这种中心实际上还是以前的中心化管理方式，只不过我们可以让中心复制出来几个，让一个或者几个中心对外服务，其他的作为备份，用来做高可用方案，保证任一时刻中心都能对外服务。 Tair架构我们再看下Tair的架构，最重要的也是三个：ConfigServer、DataServer、Client。下面是架构图： 其中ConfigServer就是类似传统应用系统的中心节点，DataServer会保持和ConfigServer的心跳，ConfigServer知道DataServer的信息。Client会到ConfigServer中获取DataServer信息，然后才能知道要去哪里找数据。 同样ConfigServer也是采用主备方案来保证高可用，如果从宏观上看其实它还是一个中心节点，没有变。 RocketMQ架构接下来看看RocketMQ的架构设计，它由四部分组成：NameServer、Broker、Producer、Consumer，以下是架构图： 这里NameServer用来管理Broker，Producer和Consumer从NameServer中获取Broker的信息，整体的逻辑和上面Dubbo以及Tair类似。NameServer这次不是采用主备这种带有等级意义的关系，而是采用平等关系，Broker向所有的NameServer注册，而Producer和Consumer则选择其中一台NameServer进行通信，因为NameServer上存储的信息都一样。 这样宏观看下来其实NameServer还是中心，只不过它也是通过同时部署多台服务器来保证高可用。 Zookeeper另外像zookeeper我们也可以理解成类似的，只不过zookeeper的中心可认为是动态中心，它的Leader角色可以进行选举更换。 小结这样总结一下，我们使用的其实还是以前的中心化管理方式，并没有变化，变化的是我们让中心保持高可用，不再是传统意义上的单点中心。更一般的场景：中心、用户、服务商。成千上万的服务商不可能直接和上亿的用户直接打交道，否则一团乱麻，但是中间可以通过一个中心来打交道，这样就会更加有秩序了。 以上仅仅是个人的理解和观点，不对或者不恰当的地方还请指出。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MyBatis的MappedStatement介绍]]></title>
      <url>%2F2019%2F07%2F20%2FMyBatis%E7%9A%84MappedStatement%E4%BB%8B%E7%BB%8D%2F</url>
      <content type="text"><![CDATA[MyBatis中的SqlSession在使用Executor进行具体的操作之前，会先到Configuration中获取一个MappedStatement，MappedStatement是对mapper文件中的select、update、delete、insert等结点的封装。 所有的MappedStatement都保存在Configuration的一个map中：mappedStatements，key是namespace+id，value是MappedStatement对象。SqlSession获取到具体的MappedStatement之后，才可以使用Executor执行具体的操作。 MappedStatement对象中的属性基本上都能和mapper.xml中节点和属性对应起来： ParmeterMap，查询参数 ResultMap，结果集映射 MappedStatement有个重要的SqlSource，是用来执行动态sql的，就是用来处理像&lt;if&gt;之类的标签，处理完后会将信息封装到BoundSql中，这里会带有具体的sql语句和对应的参数信息等。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MyBatis中的策略模式]]></title>
      <url>%2F2019%2F07%2F08%2FMyBatis%E4%B8%AD%E7%9A%84%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[MyBatis的DefaultSqlSession使用具体Executor的时候，用的是策略模式。 策略模式是定义一系列算法，并将算法封装起来，使用的时候算法可以互相替换。策略模式的角色： 抽象策略（Strategy），一般是接口或者抽象类，定义算法。 具体策略（ConcreteStrategy），具体的抽象策略实现类。 上下文（Context），持有策略Strategy对象，并且有一个能改变具体策略实现类的方法，来动态改变所向持有的策略。 MyBatis中的DefaultSqlSessionFactory在创建SqlSession的时候，会根据不同的ExecutorType来创建不同的Executor对象，并将这些对象给具体的SqlSession使用。MyBatis中策略模式的角色： 抽象策略：Executor 具体策略：SimpleExecutor、ReuseExecutor、BatchExecutor、CachingExecutor 上下文：DefaultSqlSession 简要代码： 123public interface Executor &#123; // ...&#125; 123public class SimpleExecutor extends BaseExecutor &#123; // ...&#125; 123456789public class DefaultSqlSession implements SqlSession &#123; private final Executor executor; public DefaultSqlSession(Configuration configuration, Executor executor, boolean autoCommit) &#123; this.executor = executor; &#125; // ...&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MyBatis中的装饰器模式]]></title>
      <url>%2F2019%2F07%2F07%2FMyBatis%E4%B8%AD%E7%9A%84%E8%A3%85%E9%A5%B0%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[在MyBatis的Executor和缓存的学习的时候，提到了CachingExecutor使用了装饰器模式来增加二级缓存，这里对MyBatis中的装饰器模式进行简单学习。 装饰器模式（Decorator Pattern）可以向一个现有的对象增加一些额外的功能，而又不改变其结构。MyBatis中CachingExecutor就是使用了装饰器模式来给普通的Executor增加了缓存功能，也就是二级缓存。 装饰器模式中的角色： 抽象组件（Component），一般就是一个接口，定义了一些规范。 具体组件实现（ConcreteComponent），接口具体的实现类。 装饰器（Decorator），实现抽象组件接口，并且内部持有一个Component实现。 具体装饰器（ConcreteDecorator），向组件添加新的功能 CachingExecutorMyBatis中CachingExecutor的实现与标准的装饰器模式有一点点的不同： 抽象组件：Executor 具体组件实现：SimpleExecutor、ReuseExecutor、BatchExecutor 装饰器：CachingExecutor 具体装饰器：CachingExecutor 简要代码如下： 123public interface Executor &#123; // ...&#125; 123public class SimpleExecutor extends BaseExecutor &#123; // ...&#125; 12345678910111213141516171819public class CachingExecutor implements Executor &#123; private Executor delegate; // ... public CachingExecutor(Executor delegate) &#123; this.delegate = delegate; // ... &#125; public &lt;E&gt; List&lt;E&gt; query(/*.....*/) throws SQLException &#123; // ... 查询缓存 delegate.query(); // ... 写缓存 &#125; // ... &#125; CacheMyBatis中的一级缓存也是使用了装饰器模式： 抽象组件：Cache 具体组件实现：PerpetualCache 装饰器：FifoCache、LruCache、WeakCache、BlockingCache等等 具体装饰器：FifoCache、LruCache、WeakCache、BlockingCache等等 简要代码如下： 123public interface Cache &#123; // ...&#125; 123public class PerpetualCache implements Cache &#123; // ...&#125; 12345678910111213141516public class LruCache implements Cache &#123; private final Cache delegate; public LruCache(Cache delegate) &#123; this.delegate = delegate; &#125; // ... @Override public void putObject(Object key, Object value) &#123; delegate.putObject(key, value); // 基于LinkedHashMap实现了LRU cycleKeyList(key); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MyBatis缓存机制介绍]]></title>
      <url>%2F2019%2F07%2F06%2FMyBatis%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6%E4%BB%8B%E7%BB%8D%2F</url>
      <content type="text"><![CDATA[MyBatis提供一级缓存和二级缓存，默认一级缓存是开启的，二级缓存是需要手动开启的。MyBatis的一级缓存是SqlSession级别的，二级缓存是mapper级别的，多个SqlSession可共享同一个二级缓存。如果开始了二级缓存，查询数据会先查询二级缓存，在查询一级缓存，最后才是查库。 一级缓存一级缓存是SqlSession级别的，SqlSession会持有Executor，使用Executor来进行真正的操作，在BaseExecutor中有个localCache对象，就是实现一级缓存的。 一级缓存有两种：Session级别的和Statement级别的，默认就是Session级别，Statement级别的缓存只针对一次Statement有效。 多个SqlSession并发的情况下，写数据库可能会引起脏数据。 SqlSession执行了插入、更新、删除操作，就会清空一级缓存。 二级缓存二级缓存是多个SqlSession共享的，mapper级别的缓存，默认没有开启，需要手动开启。开启后，SqlSession会持有一个CachingExecutor，这个Executor使用装饰器模式，增加了二级缓存功能。 二级缓存在分布式环境下是很不安全的，因为它是单机的缓存，分布式环境会导致读取到脏数据。 MyBatis整合Spring后的一级缓存Spring整合MyBatis后，MyBatis将SqlSession交给了Spring管理，如果说不是同一个事务每次操作都是新的SqlSession，不会命中一级缓存；如果是同一个事务，可以使用同一个SqlSession。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MyBatis中Executor介绍]]></title>
      <url>%2F2019%2F06%2F23%2FMyBatis%E4%B8%ADExecutor%E4%BB%8B%E7%BB%8D%2F</url>
      <content type="text"><![CDATA[在MyBatis的执行流程中，SqlSession会使用Executor来执行实际的操作，Executor中定义了操作数据库的基本方法。Executor的具体实现再使用StatementHandler来执行更底层操作。Executor是核心组件之一。 Executor共有四种： SimpleExecutor，是默认的执行器，它每次执行完一个操作，就会把使用的Statement关闭。 ReuseExecutor，可重用执行器，同一个SqlSession每次执行完一个操作，会把使用到的Statement缓存起来，可以重用Statement。ReuseExecutor维护着一个statementMap，key是执行的sql，value是对应的Statement对象，相同的sql就可以重用Statement对象。 BatchExecutor，可以批量的执行修改，每次的修改操作记录到内存中，等待事务提交的时候或者触发下一次查询的时候，批量提交修改操作。 CachingExecutor，缓存执行器，查询的时候会先从缓存中查询。如果MyBatis开启了二级缓存，才会使用CachingExecutor，使用装饰器模式，内部持有的还是上面三种Executor实现。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MyBatis执行流程图解]]></title>
      <url>%2F2019%2F06%2F15%2FMyBatis%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E5%9B%BE%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[记录一下MyBatis执行流程，使用图解方便看源码。 以下是画的思维导图，这里是processon的源文件：MyBatis执行流程.pos，可以自行导入。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MyBatis的mapper文件标签和类对应关系]]></title>
      <url>%2F2019%2F06%2F09%2FMyBatis%E7%9A%84mapper%E6%96%87%E4%BB%B6%E6%A0%87%E7%AD%BE%E5%92%8C%E7%B1%BB%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB%2F</url>
      <content type="text"><![CDATA[列举了一下MyBatis的mapper.xml文件中标签和类的对应关系。 以下是画的思维导图，这里是processon的源文件：MyBatisMapperClass.pos，可以自行导入。 列举了一下MyBatis的mapper.xml文件中标签和类的对应关系。 以下是画的思维导图，这里是processon的源文件：MyBatisMapperClass.pos，可以自行导入。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MyBatis的Configuration图解]]></title>
      <url>%2F2019%2F06%2F07%2FMyBatis%E7%9A%84Configuration%E5%9B%BE%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[MyBatis的配置文件mybatis-config.xml、映射配置文件mapper.xml以及Mapper接口中的注解信息等等，都会在解析后保存在Configuration对象中。Configuration对象是核心内容。 以下是画的思维导图，这里是processon的源文件：MyBatisConfiguration.pos，可以自行导入。 MyBatis的配置文件mybatis-config.xml、映射配置文件mapper.xml以及Mapper接口中的注解信息等等，都会在解析后保存在Configuration对象中。Configuration对象是核心内容。 以下是画的思维导图，这里是processon的源文件：MyBatisConfiguration.pos，可以自行导入。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MyBatis整体架构设计]]></title>
      <url>%2F2019%2F06%2F01%2FMyBatis%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%2F</url>
      <content type="text"><![CDATA[学习一下MyBatis整体架构设计，以及主要模块的功能说明。 MyBatis整体上分为三层：接口层、核心处理层、基础支持层： 图片源自《MyBatis技术内幕》 接口层接口层是提供给应用程序使用的，也就是使用SqlSession来执行sql语句。 核心处理层 配置解析 参数映射 SQL解析 SQL执行 结果集映射 插件 配置解析配置解析发生在MyBatis启动阶段，加载mybatis-config.xml配置文件以及我们自定义的mapper.xml文件或者是注解定义的Mapper接口文件，MyBatis解析这些文件后会生成对应的对象，保存在Configuration对象中。 参数映射Java类型和JDBC类型之间的转换。 SQL解析MyBatis提供动态SQL功能，MyBatis会根据传入的实参，解析映射文件中定义的动态SQL节点并生成可执行的SQL，然后处理SQL中占位符绑定传入的实参。 SQL执行SQL执行涉及多个组件： Executor维护一级和二级缓存，提供事务管理相关操作，将数据库相关操作委托给StatementHandler完成。 StatementHandler调用ParmeterHandler完成SQL实参绑定，然后通过Statement执行SQL得到结果。 ResultSetHandler进行结果集映射，得到结果对象返回。 结果集映射ResultSetHandler进行结果集映射，将从数据库中查询的结果映射成我们需要的Java对象。 插件MyBatis提供插件接口，可以进行扩展，比如可以拦截SQL进行重写。 基础支持层 数据源模块 事务管理模块 缓存模块，提供了一级缓存和二级缓存 Binding模块，将用户自定义的Mapper接口和映射配置文件关联起来 反射模块，对Java原生反射进行封装，优化，加缓存提高性能 类型转换，JDBC和Java类型之间的转换，SQL绑定实参和映射结果集都会使用 日志模块 资源加载，对类加载器进行封装 解析器模块，解析mybatis-config-xml配置文件以及映射文件，为处理动态SQL语句中占位符提供支持 参考 《MyBatis技术内幕》]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringBoot自动配置的原理]]></title>
      <url>%2F2019%2F05%2F25%2FSpringBoot%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE%E7%9A%84%E5%8E%9F%E7%90%86%2F</url>
      <content type="text"><![CDATA[需要先了解一下Spring的@Import注解和@Enable注解的实现原理，以及SpringFactoriesLoader的实现，再来看SpringBoot的自动配置原理就基本上会明白了。 SpringBoot应用一般都会在主类上注解@SpringBootApplication，这个注解上有@EnableAutoConfiguration注解，一般@Enable注解上都会有@Import注解，这里也不例外，有个@Import(EnableAutoConfigurationImportSelector.class)。 EnableAutoConfigurationImportSelector是一个ImportSelector，Spring在初始化的时候会调用invokeBeanFactoryPostProcessor，这里会调用实现了接口BeanDefinitionRegistryPostProcessor的postProcessBeanDefinitionRegistry方法，ConfigurationClassPostProcessor也实现了此接口，在该方法postProcessBeanDefinitionRegistry中会处理@Configuration相关注解，这里就进行了@Import注解的处理。对于ImportSelector，会调用它的selectImports方法进行处理。 EnableAutoConfigurationImportSelector的selectImports方法中会先使用SpringFactoriesLoader在classpath下的spring.factories文件中来加载@EnableAutoConfiguration类型的各种实现类，也包括各种starter中和我们自定义的starter中的对应实现类。SpringBoot中预先配置的EnableAutoConfiguration可以在spring-boot-project/spring-boot-autoconfigure/src/main/resources/META-INF/spring.factories中查询，配置了很多很多个自动配置类。 加载完这些配置类的名字后，经过一系列的校验等操作，就会把所有的EnableAutoConfiguration实现类的名字都返回给Spring，Spring会继续的处理这些配置类，也就是处理这些配置类中的@Configuration、@Import这些注解，继续递归处理这些注解，最后把相关的Bean都注册到容器中。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring的@Enable注解的实现机制]]></title>
      <url>%2F2019%2F05%2F18%2FSpring%E7%9A%84%40Enable%E6%B3%A8%E8%A7%A3%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6%2F</url>
      <content type="text"><![CDATA[如果要了解Spring中@Enable的实现机制，需要提前了解下@Import的用途和实现方式，每个@Enable注解上都会有@Import注解，@Import中导入自定的ImportSelector或者ImportBeanDefinitionRegistrar或者配置，这里面会实现相关功能会引入相关功能。 举个例子：@EnableCaching： 12345678910111213@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(CachingConfigurationSelector.class)public @interface EnableCaching &#123; boolean proxyTargetClass() default false; AdviceMode mode() default AdviceMode.PROXY; int order() default Ordered.LOWEST_PRECEDENCE;&#125; @EnableCaching注解上有注解@Import({CachingConfigurationSelector.class})，在处理@Import的时候，会调用CachingConfigurationSelector的selectImports方法来加入缓存相关功能和配置。 可以认为@Enable就是帮我们使用@Import导入一些配置和实现等，我们也可以自己直接使用@Import，不使用@Enable。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring的@Import是怎样工作的]]></title>
      <url>%2F2019%2F05%2F15%2FSpring%E7%9A%84%40Import%E6%98%AF%E6%80%8E%E6%A0%B7%E5%B7%A5%E4%BD%9C%E7%9A%84%2F</url>
      <content type="text"><![CDATA[Spring提供了JavaConfig配置的方式，可以将原来的xml配置文件使用JavaConfig配置的方式来替换。xml配置文件可以类比@Configuration注解的文件，@Import注解可以类比xml配置文件中的&lt;import&gt;标签，@Bean注解可以类比xml配置文件的&lt;bean&gt;标签。&lt;import&gt;标签用来将多个分散的xml配置文件整合起来，@Import注解可以将多个分散的@Configuration整合起来。 另外@Import也可以导入一个普通的类。@Import只允许放到类上，不能放在方法上。 @Import注解有四种使用方法： @Import导入普通类（Spring4.2之后支持） @Import导入@Configuration注解的类 @Import导入ImportBeanDefinitionRegistrar的实现类 @Import导入ImportSelector的实现类 导入普通类导入普通类的意思就是，我们可以写一个类，不需要任何注解，比如@Service之类的。我们可以在我们的配置类里把我们的这个普通类导入进来@Import({Xxxxx.class})，这样就可以在配置类处理的时候把我们的普通类注册成一个Bean。 导入@Configuration注解的类假设一个类中使用@Configuration注解，这个类中有很多的@Bean注解方法，我们可以在我们的配置类中使用@Import将这个类导入。 导入ImportBeanDefinitionRegistrar实现类我们可以定义一个普通类，实现接口ImportBeanDefinitionRegistrar，并实现其方法registerBeanDefinitions，之后就可以在我们的配置类中中使用@Import({Xxxxx.class})将我们的自定义类导入，这样我们会把registerBeanDefinitions方法中指定的类注册到容器中，但是这个自定义类本身不会被加载进去。 导入ImportSelector实现类们可以定义一个普通类，实现接口ImportSelector，并实现其方法selectImports，之后我们就可以在配置类中使用@Import({Xxxx.class})将自定义类导入，这样我们会把selectImports方法中返回的所有的类注册到容器中。 @Import的实现Spring容器初始化的时候有一步invokeBeanFactoryPostProcessor，这里会调用实现了接口BeanDefinitionRegistryPostProcessor的postProcessBeanDefinitionRegistry方法，ConfigurationClassPostProcessor也实现了此接口，在该方法postProcessBeanDefinitionRegistry中会处理@Configuration相关注解，这里就进行了@Import注解的处理。 ConfigurationClassParser的processImport方法： 12345678910111213141516171819202122232425262728293031... // ImportSelector的处理，会实例化我们自定义的实现类ImportSelector接口的类 ，然后调用ImportSelector的selectImports方法获取我们要处理Beanif (checkAssignability(ImportSelector.class, candidateToCheck)) &#123; // Candidate class is an ImportSelector -&gt; delegate to it to determine imports Class&lt;?&gt; candidateClass = (candidate instanceof Class ? (Class) candidate : this.resourceLoader.getClassLoader().loadClass((String) candidate)); ImportSelector selector = BeanUtils.instantiateClass(candidateClass, ImportSelector.class); processImport(configClass, metadata, Arrays.asList(selector.selectImports(metadata)), false);&#125;// ImportBeanDefinitionRegistrar的处理，实例化我们自定义的实现了ImportBeanDefinitionRegistrar接口的类，然后调用registerBeanDefinitions方法将我们的Bean注册到容器中else if (checkAssignability(ImportBeanDefinitionRegistrar.class, candidateToCheck)) &#123; // Candidate class is an ImportBeanDefinitionRegistrar -&gt; // delegate to it to register additional bean definitions Class&lt;?&gt; candidateClass = (candidate instanceof Class ? (Class) candidate : this.resourceLoader.getClassLoader().loadClass((String) candidate)); ImportBeanDefinitionRegistrar registrar = BeanUtils.instantiateClass(candidateClass, ImportBeanDefinitionRegistrar.class); invokeAwareMethods(registrar); registrar.registerBeanDefinitions(metadata, this.registry);&#125;else &#123; // 除了上面两种情形之外的@Import注解，当做 // Candidate class not an ImportSelector or ImportBeanDefinitionRegistrar -&gt; // process it as a @Configuration class this.importStack.registerImport(metadata, (candidate instanceof Class ? ((Class) candidate).getName() : (String) candidate)); processConfigurationClass(candidateToCheck instanceof Class ? new ConfigurationClass((Class) candidateToCheck, true) : new ConfigurationClass((MetadataReader) candidateToCheck, true));&#125;...]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring的工厂加载机制SpringFactoriesLoader介绍]]></title>
      <url>%2F2019%2F05%2F12%2FSpring%E7%9A%84%E5%B7%A5%E5%8E%82%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6SpringFactoriesLoader%E4%BB%8B%E7%BB%8D%2F</url>
      <content type="text"><![CDATA[SpringFactoriesLoader和Java的SPI机制一样，SpringFactoriesLoader是Spring框架内部使用的，用来加载Spring一些工厂类的工具。 加载的原理也很简单： 使用的时候指定要加载的工厂类型factoryType以及类加载器。 SpringFactoriesLoader会先根据传入的类加载器到缓存中查一下，如果有就直接返回。 缓存中没有就从指定位置META-INF/spring.factories加载所有指定的类型的实现类的类名。 使用反射实例化所有的实现类，然后返回。 SpringFactoriesLoader在SpringBoot中使用比较多。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring中扩展点汇总]]></title>
      <url>%2F2019%2F05%2F11%2FSpring%E4%B8%AD%E6%89%A9%E5%B1%95%E7%82%B9%E6%B1%87%E6%80%BB%2F</url>
      <content type="text"><![CDATA[通过阅读Spring的源码，按照自己的理解，汇总了一下Spring中常用的扩展点，可能还有遗漏或者理解不对的地方。直接使用processon画了一张图，按照容器的初始化以及bean的实例化和初始化等过程来描述。 这里是源文件SpringExtension.pos，可以导入processon修改。 下面是导出的图片：]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis内存模型]]></title>
      <url>%2F2019%2F05%2F04%2FRedis%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
      <content type="text"><![CDATA[Redis内存主要可以分为：数据部分、Redis进程本身、缓冲区内存、内存碎片这四个部分。Redis默认通过jemalloc来分配内存。 jemallocRedis默认使用jemalloc来分配内存，jemalloc在减小内存碎片做的比较好，在64位系统中将内存划分为small、large、huge三个范围，每个范围内又划分了很多小的内存块，存储数据时就可以选择合适内存块进行存储。新版本中huge没有了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051+---------+---------+--------------------------------------+|Category | Spacing | Size |+---------+---------+--------------------------------------+| | lg | [8] || +---------+--------------------------------------+| | 16 | [16, 32, 48, 64, 80, 96, 112, 128] || +---------+--------------------------------------+| | 32 | [160, 192, 224, 256] || +---------+--------------------------------------+| | 64 | [320, 384, 448, 512] || +---------+--------------------------------------+|Small | 128 | [640, 768, 896, 1024] || +---------+--------------------------------------+| | 256 | [1280, 1536, 1792, 2048] || +---------+--------------------------------------+| | 512 | [2560, 3072, 3584, 4096] || +---------+--------------------------------------+| | 1 KiB | [5 KiB, 6 KiB, 7 KiB, 8 KiB] || +---------+--------------------------------------+| | 2 KiB | [10 KiB, 12 KiB, 14 KiB] |+---------+---------+--------------------------------------+| | 2 KiB | [16 KiB] || +---------+--------------------------------------+| | 4 KiB | [20 KiB, 24 KiB, 28 KiB, 32 KiB] || +---------+--------------------------------------+| | 8 KiB | [40 KiB, 48 KiB, 54 KiB, 64 KiB] || +---------+--------------------------------------+| | 16 KiB | [80 KiB, 96 KiB, 112 KiB, 128 KiB] ||Large +---------+--------------------------------------+| | 32 KiB | [160 KiB, 192 KiB, 224 KiB, 256 KiB] || +---------+--------------------------------------+| | 64 KiB | [320 KiB, 384 KiB, 448 KiB, 512 KiB] || +---------+--------------------------------------+| | 128 KiB | [640 KiB, 768 KiB, 896 KiB, 1 MiB] || +---------+--------------------------------------+| | 256 KiB | [1280 KiB, 1536 KiB, 1792 KiB] |+---------+---------+--------------------------------------+| | 256 KiB | [2 MiB] || +---------+--------------------------------------+| | 512 KiB | [2560 KiB, 3 MiB, 3584 KiB, 4 MiB] || +---------+--------------------------------------+| | 1 MiB | [5 MiB, 6 MiB, 7 MiB, 8 MiB] || +---------+--------------------------------------+|Huge | 2 MiB | [10 MiB, 12 MiB, 14 MiB, 16 MiB] || +---------+--------------------------------------+| | 4 MiB | [20 MiB, 24 MiB, 28 MiB, 32 MiB] || +---------+--------------------------------------+| | 8 MiB | [40 MiB, 48 MiB, 56 MiB, 64 MiB] || +---------+--------------------------------------+| | ... | ... |+---------+---------+--------------------------------------+ 内存划分数据内存数据内存用来存储Redis的键值对、慢查询日志等，是主要占用内存的部分，这部分内存会统计在used_memory中 Redis进程内存Redis进程本身也会占用一部分内存，这不二分内存不是jemalloc分配，不会统计在used_memory中。执行RDB和AOF时创建的子进程也会占用内存，但也不会统计在used_memory中。 缓冲内存缓冲内存包括： 客户端缓冲区：存储客户端连接的输入和输出缓冲 复制积压缓冲区：用于PSYNC的部分复制功能 AOF缓冲区：AOF操作时，保存最近写入的命令。 这部分内存由jemalloc分配，会被统计在used_memory中 内存碎片Redis在分配和回收物理内存的过程中会产生内存碎片，这部分不会统计在used_memory中。内存碎片太多的话可以通过安全重启方式减少内存碎片，重启之后Redis会使用RDB或者AOF恢复数据，内存会被重排。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis分布式锁及其他分布式锁实现方式]]></title>
      <url>%2F2019%2F04%2F20%2FRedis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%8F%8A%E5%85%B6%E4%BB%96%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%2F</url>
      <content type="text"><![CDATA[Redis实现分布式锁大概有几种方案：使用set命令同时指定过期时间和NX、使用lua脚本和setnx加过期时间配合、基于Redlock算法的Redisson实现。分布式锁除了可以使用Redis实现外，还可以使用其他的实现，比如：mysql数据库方式、Tair实现、Zookeeper等等。 set命令加过期时间加nxRedis的set命令有一系列的选项： 1set key value [EX seconds][PX milliseconds][NX|XX] EX 设置过期时间，单位秒 PX 设置过期时间，单位毫秒 NX 仅当key不存在时设置值 XX 仅当key存在时设置值 lua脚本加setnx加过期时间Redis中可以执行lua脚本，脚本执行是原子性的，可以使用lua脚本中执行多个命令： 1if redis.call('setnx',KEYS[1],ARGV[1]) == 1 then redis.call('expire',KEYS[1],ARGV[2]) return 1 else return 0 end 锁的释放分布式锁的value需要每个获取锁的线程都设置对应唯一的值，防止不同线程误删锁，设置唯一的值后就可以在删除的时候验证下锁是不是属于当前线程。不能使用del命令直接删除，否则所有的线程都可以进行删除。 锁释放可以使用lua脚本保证原子性，先判断value是否是当前线程设置的，如果是就删除： 1if redis.call('get',KEYS[1]) == ARGV[1] then return redis.call('del',KEYS[1]) else return 0 end 单点Redis分布式锁的问题 必须设置一个过期时间，过期时间长短需要根据业务判断。 如果发生了故障转移，一个线程在master节点获取到了锁，但是没有同步到slave节点，master宕机，slave升级为master，其他线程获取分布式锁成功，就导致了有多个线程获取到了同一个锁。 Redlock和RedissonRedlock算法基于N个完全独立的Redis节点来实现，获取锁的操作步骤： 获取当前时间毫秒数 按顺序依次向N个Redis节点执行获取锁操作，使用相同的key和具有唯一性的value，也包含过期时间。获取锁的操作还需要有个超时时间，需要远小于key的过期时间。获取失败后应该立即尝试下一个Redis节点。 客户端使用当前时间减去开始获取锁的时间，得到了获取到锁使用的时间，如果客户端从大多数节点（N/2+1）成功获取到锁，并且总的获取锁的时间没有超过锁的有效期，才可以任务获取锁成功。 获取锁成功之后，锁的有效期等于最初的有效期减去上一步获取锁消耗的时间。 如果最终获取锁失败，客户端立刻向所有Redis节点发起释放锁的操作。 zookeeper实现分布式锁 先建立一个持久（PERSISTENT）节点，比如名字是：lock 需要获取锁的时候，线程在lock节点下创建对应的临时顺序（EPHEMERAL_SEQUENTIAL）节点 获取lock下所有的子节点，判断自己的节点是否是最小的节点，如果是最小的节点则获取锁成功 如果当前不是最小节点，说明有其他线程获取到了锁，当前线程需要获取到前一个节点，并注册监听事件监听前一个节点 当上一个节点完成后，释放锁，也就是删除了临时节点后，当前等待的节点会收到zk的通知事件，就可以获取到锁。 Tair实现分布式锁使用Tair的put方法来实现分布式锁，跟Redis的set类似，Tair可以传入版本号，cas保证只有一个能成功，同样还是使用key value加上过期时间来实现。 其他方式实现mysql、文件实现分布式锁，mysql可以创建一个锁的表，mysql和文件的方式性能对比缓存来说不是很好。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis跳表]]></title>
      <url>%2F2019%2F04%2F19%2FRedis%E8%B7%B3%E8%A1%A8%2F</url>
      <content type="text"><![CDATA[跳表skiplist是一种有序数据结构，在每个节点维持指向其他节点的指针，可以达到快速访问节点的目的。可以认为跳表在原有的有序链表上增加了多级索引，通过索引就可以快速查找。跳表的查找、插入、删除事件复杂度都是O(log n)，还可以实现区间查找。 Redis的有序集合的底层实现使用了跳表。 Redis为什么使用跳表而不使用红黑树 在查找、插入、删除、有序输出元素，跳表和红黑树都可以完成，并且时间复杂度都是O(long n)。 查找区间内的元素红黑树效率没有跳表高。跳表只需要定位两个端点在最低层级的位置，然后遍历元素；红黑树定位到端点后，需要每次从首位置开始查找元素。 红黑树实现也很复杂，跳表实现简单。 跳表的实现Redis跳表由两个结构组成：zskiplistNode表示跳表节点、zskiplist保存跳表节点相关信息： 12345678910111213141516171819202122232425262728293031struct zskiplist &#123; // 表头节点和表尾节点 struct zskiplistNode *header， *tail; // 表中节点的数量 unsigned long length; // 表中层数最大的节点的层数 int level;&#125;struct zskiplistNode &#123; // level数组，层 struct zskiplistLevel &#123; // 前进指针 struct zskiplistNode *forward; // 跨度 unsigned int span; &#125; level[]; // 后退指针 struct zskiplistNode *backward; // 分值 double score; // 成员对象 robj *obj; &#125; zskiplist： header指向跳表头节点 tail指向跳表尾节点 level表示跳表内层数最大的节点层数，表头节点层数不计算在内 length表示跳表长度、包含节点的数量，不包含表头节点 zskiplistNode： level，层，每个层有两个属性：前进指针和跨度，前进指针指向表尾方向的其他的节点；跨度记录了前进至真所指向节点和当前结点的距离 backward，指向当前节点的前一个节点，用于从表尾向表头遍历时使用 score，分值，各个结点的分值从小到大排列 obj，成员对象。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis对象的9种类型]]></title>
      <url>%2F2019%2F04%2F14%2FRedis%E5%AF%B9%E8%B1%A1%E7%9A%849%E7%A7%8D%E7%B1%BB%E5%9E%8B%2F</url>
      <content type="text"><![CDATA[Redis中基本数据结构有：简单动态字符串SDS、双端链表、跳表、字典、整数集合、压缩列表。但是Redis并没有直接使用这些数据结构来存放键值对，而是在这些基本数据结构之上构建了Redis的对象来表示。Redis对象系统包含：字符串对象String、列表对象List、哈希对象Hash、集合对象Set、有序集合对象ZSet、bitmaps、HyperLogLogs、Streams、GeoHash。 使用对象而不使用基本的数据结构来直接表示的好处是： Redis可以为不同场景下使用的对象来设置不同的数据结构。 Redis可以根据对象的类型来判断一个对象是否可以执行指定的命令。 Redis对象系统实现了基于引用计数的内存回收机制。 Redis对象中还记录了关于键的其他信息，比如访问时间，用来实现键过期策略以及内存淘汰机制。 Redis对象的的结构： 123456789101112131415161718redisObject &#123; // 类型 unsigned type:4; // 编码 unsigned encoding:4; // 指向底层实现数据结构的指针 void * ptr; // lru，记录对象最后一次被访问的时间 unsigned lru:22; // 引用计数 int refcount; // ...&#125; Redis中基本数据结构有：简单动态字符串SDS、双端链表、跳表、字典、整数集合、压缩列表。但是Redis并没有直接使用这些数据结构来存放键值对，而是在这些基本数据结构之上构建了Redis的对象来表示。Redis对象系统包含：字符串对象String、列表对象List、哈希对象Hash、集合对象Set、有序集合对象ZSet、bitmaps、HyperLogLogs、Streams、GeoHash。 使用对象而不使用基本的数据结构来直接表示的好处是： Redis可以为不同场景下使用的对象来设置不同的数据结构。 Redis可以根据对象的类型来判断一个对象是否可以执行指定的命令。 Redis对象系统实现了基于引用计数的内存回收机制。 Redis对象中还记录了关于键的其他信息，比如访问时间，用来实现键过期策略以及内存淘汰机制。 Redis对象的的结构： 123456789101112131415161718redisObject &#123; // 类型 unsigned type:4; // 编码 unsigned encoding:4; // 指向底层实现数据结构的指针 void * ptr; // lru，记录对象最后一次被访问的时间 unsigned lru:22; // 引用计数 int refcount; // ...&#125; 字符串对象字符串对象的编码可以是：int、raw、embstr： 如果一个字符串对象保存的是整数值，并且整数值可以用long来表示，这个字符串编码是int。 如果一个字符串对象保存的是字符串值，并且字符串长度大于32字节，将使用SDS简单动态字符串来表示，对象编码是raw。 如果一个字符串对象保存的是字符串值，并且字符串长度小于32字节，将使用embstr编码的方式来保存这个字符串。 long double类型表示的浮点数在Redis中也是作为字符串来保存的。 embstrembstr是用来保存短字符串的一种优化编码方式，和raw编码一样使用redisObject结构和sdshdr结构来表示字符串对象，但raw编码会调用两次内存分配来分别创建redisObject和sdshdr，而embstr会一次内存分配来分配一块连续空间，依次包含redisObject和sdshdr。 编码的转换int编码和embstr编码的字符串在一定条件下会转换为raw编码的字符串对象： int编码的字符串值修改为不是整数的字符串值，就变成了raw编码的字符串对象。 embstr编码的字符串对象实际上是只读的，如果修改embstr字符串的值，会成一个raw编码的字符串对象，然后再修改，最后就变成了一个raw编码的字符串对象。 列表对象列表对象的编码可以是：ziplist、linkedlist： ziplist编码的列表对象使用压缩列表作为底层实现，每个压缩列表节点保存一个列表元素。 linkedlist编码的列表对象使用双端链表作为底层实现，每个双端链表节点都保存了一个字符串对象，每个字符串对象都保存了一个列表元素。 编码的转换当列表对象保存的所有的字符串元素长度都小于64字节并且列表保存的元素数量小于512个，列表对象使用ziplist编码，否则使用linkedlist编码。 哈希对象哈希对象的编码可以是：ziplist、hashtable： ziplist编码的哈希对象使用压缩列表作为底层实现。当要加入哈希对象时，会先将保存了键的压缩列表节点推入压缩列表表尾，然后再将保存了值的压缩列表节点推入压缩列表表尾。保存了同一键值对的两个节点总是挨在一起。 hashtable编码的哈希对象使用字典作为底层实现，哈希对象中的每个键都是一个字符串对象，对象中保存了键；哈希对象中每个值都是一个字符串对象，对象中保存了值。 编码的转换当哈希对象保存的所有键值对的键值的字符串长度都小于64字节，并且键值对数量小于512个，就使用ziplist编码，否则使用hashtable编码。 集合对象集合对象编码可以是：intset、hashtable： intset编码的集合对象使用整数集合作为底层实现，集合对象包含的所有元素都保存在整数集合里。 hashtable编码的集合对象使用字典作为底层实现，字典的每个键都是一个字符串对象，每个字符串对象都包含了一个集合元素，字典的值全部设置为NULL。 编码的转换集合对象保存的都是整数值并且元素数量不超过512个，则使用intset编码，否则使用hashtable编码。 有序集合对象有序集合对象的编码可以是：ziplist、skiplist： ziplist编码的有序集合对象使用压缩列表作为底层实现，每个集合元素使用两个紧挨在一起的压缩列表节点表示，第一个节点保存元素的成员member，第二个节点保存元素的分值score。压缩列表内容按分值从小到大排序。 skiplist编码的有序集合对象使用zset结构作为底层实现，一个zset同时包含一个字典和一个跳表，跳表按照分值从小到大保存了所有集合元素，每个跳表节点的object属性保存了元素成员，跳表的score属性保存了元素的分值，通过跳表可对有序集合进行范围操作。zset的字典为有序集合创建了一个从成员到分值的映射，字典中每个键值对都保存了一个集合元素，键保存了元素的成员，值保存了元素的分值，通过字典可以使用O(1)复杂度查找成员的分值。 有序集合的每个元素的成员都是一个字符串对象，每个元素分值都是一个double类型的浮点数。 编码的转换当有序集合对象保存的元素数量小于128并且所有元素成员的长度都小于64字节，则使用ziplist编码，否则使用skiplist编码。 bitmapbitmap不是一种真实的数据结构，本质上是String数据结构。 GeoHashGeoHash本身也不是一种数据结构，而是借助ZSet实现的，将将维度使用52位整数进行编码，放进zset中，score是GeoHash的52位整数值。 Geo查询内部使用zset查询，通过score排序就可得到附近的坐标，将score还原成经纬度就可以得到结果。 处理的过程： 将二维坐标转换为一维整数编码值 使用zset存储，score就是整数编码值 使用zrangbyrank获取score相近的元素zrangebyscore 通过score还原成坐标 HyperLogLogRedis高级数据结构，用来统计基数。 SteamsRedis5.0引入的全新数据结构，是一个内存版的kafka，有Consumer Groups的概念，Streams底层数据结构是radix tree。 字符串对象字符串对象的编码可以是：int、raw、embstr： 如果一个字符串对象保存的是整数值，并且整数值可以用long来表示，这个字符串编码是int。 如果一个字符串对象保存的是字符串值，并且字符串长度大于32字节，将使用SDS简单动态字符串来表示，对象编码是raw。 如果一个字符串对象保存的是字符串值，并且字符串长度小于32字节，将使用embstr编码的方式来保存这个字符串。 long double类型表示的浮点数在Redis中也是作为字符串来保存的。 embstrembstr是用来保存短字符串的一种优化编码方式，和raw编码一样使用redisObject结构和sdshdr结构来表示字符串对象，但raw编码会调用两次内存分配来分别创建redisObject和sdshdr，而embstr会一次内存分配来分配一块连续空间，依次包含redisObject和sdshdr。 编码的转换int编码和embstr编码的字符串在一定条件下会转换为raw编码的字符串对象： int编码的字符串值修改为不是整数的字符串值，就变成了raw编码的字符串对象。 embstr编码的字符串对象实际上是只读的，如果修改embstr字符串的值，会成一个raw编码的字符串对象，然后再修改，最后就变成了一个raw编码的字符串对象。 列表对象列表对象的编码可以是：ziplist、linkedlist： ziplist编码的列表对象使用压缩列表作为底层实现，每个压缩列表节点保存一个列表元素。 linkedlist编码的列表对象使用双端链表作为底层实现，每个双端链表节点都保存了一个字符串对象，每个字符串对象都保存了一个列表元素。 编码的转换当列表对象保存的所有的字符串元素长度都小于64字节并且列表保存的元素数量小于512个，列表对象使用ziplist编码，否则使用linkedlist编码。 哈希对象哈希对象的编码可以是：ziplist、hashtable： ziplist编码的哈希对象使用压缩列表作为底层实现。当要加入哈希对象时，会先将保存了键的压缩列表节点推入压缩列表表尾，然后再将保存了值的压缩列表节点推入压缩列表表尾。保存了同一键值对的两个节点总是挨在一起。 hashtable编码的哈希对象使用字典作为底层实现，哈希对象中的每个键都是一个字符串对象，对象中保存了键；哈希对象中每个值都是一个字符串对象，对象中保存了值。 编码的转换当哈希对象保存的所有键值对的键值的字符串长度都小于64字节，并且键值对数量小于512个，就使用ziplist编码，否则使用hashtable编码。 集合对象集合对象编码可以是：intset、hashtable： intset编码的集合对象使用整数集合作为底层实现，集合对象包含的所有元素都保存在整数集合里。 hashtable编码的集合对象使用字典作为底层实现，字典的每个键都是一个字符串对象，每个字符串对象都包含了一个集合元素，字典的值全部设置为NULL。 编码的转换集合对象保存的都是整数值并且元素数量不超过512个，则使用intset编码，否则使用hashtable编码。 有序集合对象有序集合对象的编码可以是：ziplist、skiplist： ziplist编码的有序集合对象使用压缩列表作为底层实现，每个集合元素使用两个紧挨在一起的压缩列表节点表示，第一个节点保存元素的成员member，第二个节点保存元素的分值score。压缩列表内容按分值从小到大排序。 skiplist编码的有序集合对象使用zset结构作为底层实现，一个zset同时包含一个字典和一个跳表，跳表按照分值从小到大保存了所有集合元素，每个跳表节点的object属性保存了元素成员，跳表的score属性保存了元素的分值，通过跳表可对有序集合进行范围操作。zset的字典为有序集合创建了一个从成员到分值的映射，字典中每个键值对都保存了一个集合元素，键保存了元素的成员，值保存了元素的分值，通过字典可以使用O(1)复杂度查找成员的分值。 有序集合的每个元素的成员都是一个字符串对象，每个元素分值都是一个double类型的浮点数。 编码的转换当有序集合对象保存的元素数量小于128并且所有元素成员的长度都小于64字节，则使用ziplist编码，否则使用skiplist编码。 bitmapbitmap不是一种真实的数据结构，本质上是String数据结构。 GeoHashGeoHash本身也不是一种数据结构，而是借助ZSet实现的，将将维度使用52位整数进行编码，放进zset中，score是GeoHash的52位整数值。 Geo查询内部使用zset查询，通过score排序就可得到附近的坐标，将score还原成经纬度就可以得到结果。 处理的过程： 将二维坐标转换为一维整数编码值 使用zset存储，score就是整数编码值 使用zrangbyrank获取score相近的元素zrangebyscore 通过score还原成坐标 HyperLogLogRedis高级数据结构，用来统计基数。 SteamsRedis5.0引入的全新数据结构，是一个内存版的kafka，有Consumer Groups的概念，Streams底层数据结构是radix tree。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis内存淘汰机制]]></title>
      <url>%2F2019%2F04%2F14%2FRedis%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6%2F</url>
      <content type="text"><![CDATA[Redis可以设置key的过期时间，key过期了之后会根据key过期策略将key进行淘汰，但是如果Redis的内存到达了一定的阈值，即使key没有过期，也会根据一定的策略对数据进行淘汰。 Redis可以配置maxmemory来开启内存淘汰机制，当内存达到了配置的值，就会开始淘汰内存中的数据。maxmemory为0的时候表示对内存的使用没有限制。 Redis内存淘汰策略有以下几种： volatile-lru，从已设置过期时间的数据集中挑选最近最少使用的数据淘汰，设置过期时间的数据在expires字典中，Redis并不是将所有的最近最少使用的数据全部淘汰，而是随机挑选几个进行淘汰。 volatile-ttl，从已设置过期时间的数据集中挑选将要过期的数据进行淘汰，设置过期时间的数据在expires字典中，Redis并不是将所有的将要过期的数据全部淘汰，而是随机挑选几个进行淘汰。 volatile-random，从已设置过期时间的数据集中随机选择数据进行淘汰。 allkeys-lru，从所有数据集中挑选最近最少使用的数据淘汰，数据集在服务器的dict字典中。 allkeys-random，从所有数据集中随机选择数据进行淘汰，数据集在服务器的dict字典中。 no-enviction，禁止淘汰数据，新写入会报错。 Redis4.0之后增加了两个LFU（Least Frequently Used）使用频率最少的： volatile-lfu，从已设置过期时间的数据集中选择使用频率最少的数据进行淘汰。 allkeys-lfu，从所有数据集中选择使用频率最少的数据进行淘汰。 一般会选择allkeys-lru淘汰策略，原因是如果我们的应用对缓存的访问符合幂律分布，存在相对热点数据，或者不太清楚应用的缓存访问分布状况，则可以选allkeys-lru策略。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis事务]]></title>
      <url>%2F2019%2F04%2F14%2FRedis%E4%BA%8B%E5%8A%A1%2F</url>
      <content type="text"><![CDATA[Redis事务会将多个命令请求打包，一次性的按照顺序执行多个命令，在事务执行期间，服务器不会中断事务去执行其他客户端的请求命令，会一直执行完。涉及到的命令：MULTI、EXEC、WATCH。 MULTI命令的执行标志着事务的开始 事务开始后的普通命令会被放入一个事务队列，返回给客户端QUEUED回复 EXEC命令的执行表示提交事务，会遍历事务队列执行所有的命令，然后将所有的结果返回给客户端 WATCH命令是一个乐观缩，在EXEC命令执行前监视任意数量的数据库键，在EXEC执行时会检查键是否被修改，如果被修改了服务器拒绝执行事务，向客户端返回空回复表示事务执行失败。 参考 《redis设计与实现》（第二版）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis发布与订阅]]></title>
      <url>%2F2019%2F04%2F14%2FRedis%E5%8F%91%E5%B8%83%E4%B8%8E%E8%AE%A2%E9%98%85%2F</url>
      <content type="text"><![CDATA[Redis支持发布订阅功能，SUBSCRIBE命令可以让客户端订阅一个或者多个频道，PSUBSCRIBE可以让客户端订阅一个或多个模式的，PUBLISH用来发布消息。 频道的订阅和退订客户端执行SUBSCRIBE可以订阅频道，订阅关系保存在服务器状态的pubsub_channels字典里： 键时某个被订阅的频道 值是一个链表，记录了所有订阅这个频道的客户端 退订频道的时候使用UNSUBSCRIBE命令，服务器会把客户端从pubsub_channels字典中删除。 发送消息客户端使用PUBLISH &lt;channel&gt; &lt;message&gt;来发送消息给频道channel，服务器会执行： 将消息发送给所有订阅了这个channel的订阅者 如果有模式频道匹配到，则将消息发送给订阅了这个模式的订阅者 参考 《redis设计与实现》（第二版）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis集群Cluster]]></title>
      <url>%2F2019%2F04%2F13%2FRedis%E9%9B%86%E7%BE%A4Cluster%2F</url>
      <content type="text"><![CDATA[Redis提供的分布式解决方案：Redis Cluster集群，使用分片sharding来进行数据共享，还提供了复制和故障转移功能。 Redis集群通常由多个节点node组成，节点通过CLUSTER MEET命令连接起来组成集群。 Redis集群通过分片方式保存数据库中的键值对，集群的整个数据库分为16384个槽slot，数据库中的每个键都属于这16384个槽的其中一个，集群中每个节点可以处理0到最多16384个槽。 一个节点出了会记录自己负责的槽外，还会把自己负责的slots数组通过消息发送给集群其他的节点，告知其他节点自己负责的槽有哪些。 在集群中执行命令客户端向节点发送命令时，接收命令的节点会计算出键对应属于哪个槽： 如果键对应的槽属于自己，直接执行命令。 如果键对应的槽属于其他节点，会向客户端返回MOVED错误，指引客户端转向redirect到正确的节点，并再次发送要执行的命令。 重新分片Redis集群可以通过重新分片将某节点的槽指派给另外一个节点，所有的对应的键值对也会被迁移到新的目标节点。 redis-trib向目标节点发送：CLUSTER SETSLOT &lt;slot&gt; IMPORTING &lt;source_id&gt;，让目标节点准备好从源节点导入键值对 redis-trib向源节点发送：CLUSTER SETSLOT &lt;slot&gt; MIGRATING &lt;target_id&gt;，让源标节点准备好从源节点迁移键值对到目标节点 redis-trib向源节点发送：CLUSTER GETKEYSINSLOT &lt;slot&gt; &lt;count&gt;，获得最多count个键值对的键 针对每个键，redis-trib向源节点发送：MIGRATE &lt;target_ip&gt; &lt;target_port&gt; &lt;key_name&gt; 0 &lt;timeout，将被选中的键原子的从源节点迁移到目标节点 重复迁移步骤直到完成 redis-trib向集群中任一节点发送CLUSTER SETSLOT &lt;slot&gt; NODE &lt;target_id&gt;，将槽指派配目标节点，这会通知整个集群。 复制和故障转移Redis集群中的节点分为主节点和从节点，从节点会复制主节点，主节点下线时从节点代替主节点处理命令请求。 集群中每个节点定期向集群中其他节点发送PING消息，用来检测对方是否在线，如果不在线就会将其标记疑似下线，并且各个节点会通过相互发消息交换集群中各个节点状态信息，如果一个集群中半数以上的节点都将某一个节点报告为疑似下线，那么这个节点会被标记为已下线，并广播给集群其他的节点，该节点已下线。 当从节点发现主节点已下线，就开始故障转移： 有一个从节点会被选中，执行SLAVEOF no one，变成新的主节点 新的主节点会撤销所有对已下线主节点的槽指派，并把这些槽指派给自己 新的主节点向集群发送PONG消息，让其他的节点知道自己变成了主节点 新的主节点开始对外服务 参考 《redis设计与实现》（第二版）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis哨兵Sentinel]]></title>
      <url>%2F2019%2F04%2F10%2FRedis%E5%93%A8%E5%85%B5Sentinel%2F</url>
      <content type="text"><![CDATA[Sentinel哨兵，是Redis的高可用解决方案，由一个或多个Sentinel实例组成Sentinel系统，监控任意多个主服务器和从服务器，主服务器下线时自动将其下的从服务器升级成新的主服务器。 Sentinel介绍 Sentinel是一个运行在特殊模式下的Redis服务器，只是它不使用数据库，不会启动时载入RDB或者AOF文件，它有自己的命令。 Sentinel状态的masters字典中记录了所有被Sentinel监控的主服务器信息，字典中的每一项就是一个被监视的Redis服务器实例。 Sentinel初始化的时候会向被监视的主服务器创建两个连接： 命令连接，专门用于向主服务器发送命令，并接受命令回复。 订阅连接，专门订阅主服务器的__sentinel__:hello频道。 获取主服务器信息Sentinel默认10秒一次，通过命令向被监视的主服务器发送INFO命令，通过回复获取主服务器信息，这些信息也包括了从服务器相关信息。Sentinel会将这些信息缓存起来。 获取从服务器信息Sentinel发现主服务器有新的从服务器出现，会创建新的实例结构在缓存中，还会创建到这个从服务器的命令连接和订阅连接。 Sentinel默认10秒一次，向从服务器发送INFO命令获取从服务器信息，并更新缓存的实例信息。 向主从服务器发送信息Sentinel默认2秒会通过命令连接想所有被监视的主服务器和从服务器发送命令： 1PUBLISH __sentinel__:hello "&lt;s_ip&gt;,&lt;s_port&gt;,&lt;s_runid&gt;,&lt;s_epoch&gt;,&lt;m_name&gt;,&lt;m_ip&gt;,&lt;m_port&gt;,&lt;m_epoch&gt;" s开头的是Sentinel本身信息 m开头的是主服务器信息，如果Sentinel监控的是主服务器，这些就是主服务器信息；如果监控的是从服务器，这些就是从服务器对应的主服务器的信息 接收来主从服务器的频道信息Sentinel与主从服务器建立订阅连接后，会订阅频道： 1SUBSCRIBE __sentinel__:hello Sentinel会向服务器的__sentinel__:hello频道发消息，也会订阅服务器的__sentinel__:hello频道接收消息。 Sentinel之间通过这些信息相互感知。 Sentinel的sentinels字典除了保存自己本身之外，还保存同样监视这个主服务器的其他的Sentinel信息。Sentinel通过频道信息发现了新的Sentinel时，会更新sentinels字典，还会创建一个命令连接到新的Sentinel。 Sentinel之间也是相互连接的。 检测主观下线状态Sentinel每一秒都会想所有与他建立了命令连接的实例：主服务器、从服务器、其他Sentinel发送PING命令，并通过返回的信息判断实例是否在线。 检测客观下线状态当Sentinel将一个主服务器判断为主观下线后，为了确认是否是真的下线，它会向其他也监视这个主服务器的Sentinel询问，其他的Sentinel如果有足够多的数量说已经下线，则就会判定该服务器为客观下线，并对主服务器执行故障转移操作。 选举Sentinel Leader当一个主服务器被判断为客观下线，监视这个主服务器的所有Sentinel会进行协商，选出一个Sentinel Leader，这个Leader会对下线的主服务器进行故障转移。 选举算法是Raft。 故障转移选出Sentinel Leader后，该Leader会对已下线的主服务器进行故障转移操作： 会在已下线的主服务器的从服务器中选一个作为主服务器，向被选中的从服务器发送：SLAVEOF no one 让其他的从服务器成为新的主服务器的从服务器，通过发送命令SLAVEOF来实现 让已下线的主服务器变成新的主服务器的从服务器，等待重新上线后使用。 参考 《redis设计与实现》（第二版）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis主从复制]]></title>
      <url>%2F2019%2F04%2F05%2FRedis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
      <content type="text"><![CDATA[主从复制，用户可以执行SLAVEOF命令或者设置slaveof选项，让一个服务器（从服务器slave）去复制replicate另外一个服务器（主服务器master）。 Redis复制功能分为同步sync和命令传播command propagate： 同步用于将服务器数据库状态更新到主服务器所处的数据库状态。 命令传播用于主服务器数据库状态被修改后，让从服务器数据库重新回到一致状态。 旧版复制功能实现同步 从服务器向主服务器发送SYNC命令 主服务器收到SYNC命令后执行BGSAVE命令，生成一个RDB文件，并使用一个缓冲区记录从现在开始执行的所有写命令。 主服务器BGSAVE执行完成后，将RDB文件发送给从服务器，从服务器接受并载入RDB文件恢复。 主服务器将记录在缓冲区的所有写命令发个从服务器，从服务器执行这些命令。 命令传播同步操作完成之后，主从一致，后面每当主服务器有写命令执行，主服务器会执行命令传播操作，将写命令发送个从服务器。 旧版复制功能缺陷Redis中复制分为：初次复制和断线后复制。旧版复制功能在断线后复制会重新发送SYNC命令执行一次完整的复制，效率十分低下。 新版复制功能实现新版使用PSYNC命令代替SYNC来执行复制同步操作。PSYNC具有完整重同步和部分重同步两种功能： 完整重同步，和SYNC基本一样，让主服务器创建并发送RDB文件，以及向从服务器发送保存在缓冲区的写命令进行同步。 部分重同步，用来处理断线后的复制，不会完整的执行一遍复制，而是尽可能的从断开的位置继续复制。 部分重同步的实现 主从服务器分别维护一个复制偏移量 主服务器进行命令传播时，不仅会将命令发送给所有从服务器，还会将命令写入到复制积压缓冲区中，从服务器断线重连后将自己的偏移量通过PSYNC发给主服务器，从而根据这个偏移量和积压缓冲区中偏移量进行对比，决定是执行部分重同步还是完整重同步操作 服务器运行ID，主从服务器都会有自己的运行ID PSYNC命令的实现 参考 《redis设计与实现》（第二版）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis线程模型及事件]]></title>
      <url>%2F2019%2F04%2F03%2FRedis%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%E5%8F%8A%E4%BA%8B%E4%BB%B6%2F</url>
      <content type="text"><![CDATA[Redis使用事件驱动模型，主要处理：文件事件，也就是和客户端的网络通信等等；以及时间事件，也就是一些定时任务之类的抽象。 文件事件Redis基于Reactor模式，采用I/O多路复用来处理请求，以单线程来运行，可以实现高性能网络通信模型。 文件事件处理器组成：套接字、I/O多路复用程序、文件事件分派器、事件处理器。 I/O多路复用监听多个套接字，向文件事件派发器传送产生了事件的套接字，如果存在并发，I/O多路复用程序会将所有产生事件的套接字放到一个队列里，按顺序向事件派发器传送。派发器根据套接字产生的事件调用响应的事件处理器。 事件类型 AE_READABLE事件 AE_WRITABLE事件 服务器监听套接字的AE_READABLE事件，Redis客户端发起连接，会触发连接应答处理器执行，处理器会对客户端连接请求应答，然后创建客户端套接字，以及客户端状态，并将客户端套接字的AE_READABLE事件与命令请求关联，使得客户端可以向主服务器发送命令请求。 客户端向服务器发送一个命令请求，客户端套接字会产生一个AE_READABLE事件，引发命令请求处理器执行，处理器读取客户端命令，然后传给相应程序去执行。 执行命令后产生相应的回复，需要传回给客户端，服务器会将客户端套接字的AE_WRITABLE事件与命令处理回复处理器进行关联。 客户端尝试读取命令回复的时候，客户端套接字产生AE_WRITABLE事件，触发命令回复处理器执行，当命令回复处理器将命令全部写回套接字后，服务器就会解除客户端套接字的AE_WRITABLE事件与命令回复处理器间的关联。 时间事件Redis使用周期性事件。 服务器将所有时间事件放到一个无序链表，每当时间事件执行器运行，会遍历链表，查找已到达的时间事件，并调用相关事件处理器。 参考 《redis设计与实现》（第二版）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis持久化]]></title>
      <url>%2F2019%2F04%2F02%2FRedis%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
      <content type="text"><![CDATA[Redis可以将内存中的数据库状态持久化到磁盘中去，提供了两种持久化方法：RDB持久化和AOF持久化。 RDB持久化RDB创建和加载RDB文件创建有两个命令：SAVE和BGSAVE SAVE，会阻塞Redis服务进程，直到RDB文件创建完毕，此期间服务器不能处理任何命令请求。 BGSAVE，会派生一个子进程去创建RDB文件，服务器进程继续处理命令请求。 RDB文件恢复是在服务器启动的时候自动执行的，只要Redis服务器启动时检测到RDB文件存在，就自动载入RDB文件，RDB载入期间，服务器会一直处于阻塞，直到载入完成才能提供服务。 由于AOF文件更新频率会比RDB文件更新频率高，所以： 如果开启了AOF，则优先使用AOF来还原数据库状态。 如果AOF未开启，则使用RDB来还原数据库状态。 另外，SAVE、BGSAVE、BGREWRITEAOF三个命令之间也会有一些互斥的关系： SAVE命令执行期间，Redis服务器会被阻塞，所有客户端的请求都会被拒绝。 BGSAVE是子进程，在执行期间，SAVE命令会被拒绝，新的BGSAVE命令也会被拒绝。 BGSAVE运行期间，BGREWRITEAOF命令会被延迟到BGSAVE命令执行完毕。 BGREWRITEAOF执行期间，BGSAVE命令会被拒绝。 dirty计数器和lastsave属性Redis服务器维持着一个dirty计数器和leastsave属性： 12345678redisServer &#123; // 计数器，记录距离上一次成功执行SAVE或者BGSAVE命令后，服务器 // 对数据库进行了多少次修改 long long dirty; // 上一次执行SAVE命令或者BGSAVE命令的时间 time_t lastsave;&#125; Redis服务器会周期性的每隔100ms检查，如果条件满足了，就会执行BGSAVE命令。 RDB文件结构 REDIS，用来快速检查载入的文件是否是RDB文件 db_verson，记录了RDB文件版本号。 SELECTDB，程序读入这个值的时候表示接下来要读取的是数据库号码。 db_number，图中的0和3表示0号数据库和3号数据库，空的数据库不会有。 pairs，key_value_pairs保存了数据库中所有键值对数据，如果带有过期时间也会和键值对保存在一起。 EOF，表示RDB文件正文结束。 check_sum，通过对前面部分计算得出的一个校验和，用来检查RDB是否出错或损坏。 不带过期时间的键值对key_value_pairs： Redis可以将内存中的数据库状态持久化到磁盘中去，提供了两种持久化方法：RDB持久化和AOF持久化。 RDB持久化RDB创建和加载RDB文件创建有两个命令：SAVE和BGSAVE SAVE，会阻塞Redis服务进程，直到RDB文件创建完毕，此期间服务器不能处理任何命令请求。 BGSAVE，会派生一个子进程去创建RDB文件，服务器进程继续处理命令请求。 RDB文件恢复是在服务器启动的时候自动执行的，只要Redis服务器启动时检测到RDB文件存在，就自动载入RDB文件，RDB载入期间，服务器会一直处于阻塞，直到载入完成才能提供服务。 由于AOF文件更新频率会比RDB文件更新频率高，所以： 如果开启了AOF，则优先使用AOF来还原数据库状态。 如果AOF未开启，则使用RDB来还原数据库状态。 另外，SAVE、BGSAVE、BGREWRITEAOF三个命令之间也会有一些互斥的关系： SAVE命令执行期间，Redis服务器会被阻塞，所有客户端的请求都会被拒绝。 BGSAVE是子进程，在执行期间，SAVE命令会被拒绝，新的BGSAVE命令也会被拒绝。 BGSAVE运行期间，BGREWRITEAOF命令会被延迟到BGSAVE命令执行完毕。 BGREWRITEAOF执行期间，BGSAVE命令会被拒绝。 dirty计数器和lastsave属性Redis服务器维持着一个dirty计数器和leastsave属性： 12345678redisServer &#123; // 计数器，记录距离上一次成功执行SAVE或者BGSAVE命令后，服务器 // 对数据库进行了多少次修改 long long dirty; // 上一次执行SAVE命令或者BGSAVE命令的时间 time_t lastsave;&#125; Redis服务器会周期性的每隔100ms检查，如果条件满足了，就会执行BGSAVE命令。 RDB文件结构 REDIS，用来快速检查载入的文件是否是RDB文件 db_verson，记录了RDB文件版本号。 SELECTDB，程序读入这个值的时候表示接下来要读取的是数据库号码。 db_number，图中的0和3表示0号数据库和3号数据库，空的数据库不会有。 pairs，key_value_pairs保存了数据库中所有键值对数据，如果带有过期时间也会和键值对保存在一起。 EOF，表示RDB文件正文结束。 check_sum，通过对前面部分计算得出的一个校验和，用来检查RDB是否出错或损坏。 不带过期时间的键值对key_value_pairs： 带过期时间的键值对key_value_pairs： TYPE记录了value的类型。 EXPIRETIME_MS，表示接下来读入的是一个毫秒为单位的过期时间。 ms，毫秒为单位的UNIX时间戳，表示键值对的过期时间。 AOF持久化AOF（Append Only File），通过保存Redis服务器所执行的写命令来记录数据库状态，而RDB是保存数据库中的键值对数据来记录数据库状态。 AOF持久化实现AOF持久化功能实现分为： 命令追加append，执行完一个写命令后，会以协议格式将写命令追加到服务器的aof_buff缓冲区末尾。 文件写入 文件同步sync 文件写入和同步有三个选项appendfsync： always，每个事件都要将aof_buf缓冲区中所有内容写入到AOF文件中，并且同步AOF文件，效率最慢，但是最安全，出现故障只会丢失一个事件循环中的命令数据。 everysec，每个事件循环都要将aof_buf缓冲区所有内容写到AOF文件，并且每隔一秒就要在子线程中对AOF进行同步一次，效率足够快，出现故障会丢失1秒的数据。默认选项是这个。 no，每个事件循环都要将aof_buf缓冲区内容写到AOF文件中，但AOF文件同步则由操作系统决定，由于不进行同步操作，效率最好，但是出现故障丢失的数据是积累一段时间的数据。 AOF文件载入和数据还原服务器读取并重新执行一遍AOF文件中保存的写命令： 创建一个不带网络连接的伪客户端 从AOF文件中分析读取一条写命令 使用伪客户端执行被读出的写命令 AOF重写AOF持久化记录了被执行的写命令，AOF文件会越来越大，会对服务器造成影响，恢复时间也会很长，AOF采用重写rewrite来解决文件膨胀问题，创建一个新的AOF文件代替现有的AOF文件，新旧文件保存的数据库状态相同，但是新文件不会包含冗余的命令，体积会比旧文件小很多。 简单说就是根据数据库现有状态，将现有一个键值对的数据汇总成一条写命令，而不是原来的若干条命令。这样就减少了AOF文件的大小。 AOF后台重写由于AOF重写会阻塞服务，所以需要采用后台重写，后台重写使用子进程来处理。子进程开始重写文件后，主进程还在继续提供服务，会有新的命令进来，会造成重写后的AOF文件和数据库状态不一致，Redis使用AOF重写缓冲区来解决，Redis服务器执行一个写命令后，会同时将这个命令发送给AOF缓冲区和AOF重写缓冲区。 子进程完成AOF重写工作后，会向父进程发一个信号，父进程会调用处理函数： 将AOF重写缓冲区所有内容写到新的AOF文件中，新的AOF文件和服务器当前数据库状态就保持一致了。 对新AOF文件改名，并原子的覆盖现有AOF文件，完成新旧文件的替换。 参考 《redis设计与实现》（第二版） 带过期时间的键值对key_value_pairs： Redis可以将内存中的数据库状态持久化到磁盘中去，提供了两种持久化方法：RDB持久化和AOF持久化。 RDB持久化RDB创建和加载RDB文件创建有两个命令：SAVE和BGSAVE SAVE，会阻塞Redis服务进程，直到RDB文件创建完毕，此期间服务器不能处理任何命令请求。 BGSAVE，会派生一个子进程去创建RDB文件，服务器进程继续处理命令请求。 RDB文件恢复是在服务器启动的时候自动执行的，只要Redis服务器启动时检测到RDB文件存在，就自动载入RDB文件，RDB载入期间，服务器会一直处于阻塞，直到载入完成才能提供服务。 由于AOF文件更新频率会比RDB文件更新频率高，所以： 如果开启了AOF，则优先使用AOF来还原数据库状态。 如果AOF未开启，则使用RDB来还原数据库状态。 另外，SAVE、BGSAVE、BGREWRITEAOF三个命令之间也会有一些互斥的关系： SAVE命令执行期间，Redis服务器会被阻塞，所有客户端的请求都会被拒绝。 BGSAVE是子进程，在执行期间，SAVE命令会被拒绝，新的BGSAVE命令也会被拒绝。 BGSAVE运行期间，BGREWRITEAOF命令会被延迟到BGSAVE命令执行完毕。 BGREWRITEAOF执行期间，BGSAVE命令会被拒绝。 dirty计数器和lastsave属性Redis服务器维持着一个dirty计数器和leastsave属性： 12345678redisServer &#123; // 计数器，记录距离上一次成功执行SAVE或者BGSAVE命令后，服务器 // 对数据库进行了多少次修改 long long dirty; // 上一次执行SAVE命令或者BGSAVE命令的时间 time_t lastsave;&#125; Redis服务器会周期性的每隔100ms检查，如果条件满足了，就会执行BGSAVE命令。 RDB文件结构 REDIS，用来快速检查载入的文件是否是RDB文件 db_verson，记录了RDB文件版本号。 SELECTDB，程序读入这个值的时候表示接下来要读取的是数据库号码。 db_number，图中的0和3表示0号数据库和3号数据库，空的数据库不会有。 pairs，key_value_pairs保存了数据库中所有键值对数据，如果带有过期时间也会和键值对保存在一起。 EOF，表示RDB文件正文结束。 check_sum，通过对前面部分计算得出的一个校验和，用来检查RDB是否出错或损坏。 不带过期时间的键值对key_value_pairs： 带过期时间的键值对key_value_pairs： TYPE记录了value的类型。 EXPIRETIME_MS，表示接下来读入的是一个毫秒为单位的过期时间。 ms，毫秒为单位的UNIX时间戳，表示键值对的过期时间。 AOF持久化AOF（Append Only File），通过保存Redis服务器所执行的写命令来记录数据库状态，而RDB是保存数据库中的键值对数据来记录数据库状态。 AOF持久化实现AOF持久化功能实现分为： 命令追加append，执行完一个写命令后，会以协议格式将写命令追加到服务器的aof_buff缓冲区末尾。 文件写入 文件同步sync 文件写入和同步有三个选项appendfsync： always，每个事件都要将aof_buf缓冲区中所有内容写入到AOF文件中，并且同步AOF文件，效率最慢，但是最安全，出现故障只会丢失一个事件循环中的命令数据。 everysec，每个事件循环都要将aof_buf缓冲区所有内容写到AOF文件，并且每隔一秒就要在子线程中对AOF进行同步一次，效率足够快，出现故障会丢失1秒的数据。默认选项是这个。 no，每个事件循环都要将aof_buf缓冲区内容写到AOF文件中，但AOF文件同步则由操作系统决定，由于不进行同步操作，效率最好，但是出现故障丢失的数据是积累一段时间的数据。 AOF文件载入和数据还原服务器读取并重新执行一遍AOF文件中保存的写命令： 创建一个不带网络连接的伪客户端 从AOF文件中分析读取一条写命令 使用伪客户端执行被读出的写命令 AOF重写AOF持久化记录了被执行的写命令，AOF文件会越来越大，会对服务器造成影响，恢复时间也会很长，AOF采用重写rewrite来解决文件膨胀问题，创建一个新的AOF文件代替现有的AOF文件，新旧文件保存的数据库状态相同，但是新文件不会包含冗余的命令，体积会比旧文件小很多。 简单说就是根据数据库现有状态，将现有一个键值对的数据汇总成一条写命令，而不是原来的若干条命令。这样就减少了AOF文件的大小。 AOF后台重写由于AOF重写会阻塞服务，所以需要采用后台重写，后台重写使用子进程来处理。子进程开始重写文件后，主进程还在继续提供服务，会有新的命令进来，会造成重写后的AOF文件和数据库状态不一致，Redis使用AOF重写缓冲区来解决，Redis服务器执行一个写命令后，会同时将这个命令发送给AOF缓冲区和AOF重写缓冲区。 子进程完成AOF重写工作后，会向父进程发一个信号，父进程会调用处理函数： 将AOF重写缓冲区所有内容写到新的AOF文件中，新的AOF文件和服务器当前数据库状态就保持一致了。 对新AOF文件改名，并原子的覆盖现有AOF文件，完成新旧文件的替换。 参考 《redis设计与实现》（第二版） TYPE记录了value的类型。 EXPIRETIME_MS，表示接下来读入的是一个毫秒为单位的过期时间。 ms，毫秒为单位的UNIX时间戳，表示键值对的过期时间。 AOF持久化AOF（Append Only File），通过保存Redis服务器所执行的写命令来记录数据库状态，而RDB是保存数据库中的键值对数据来记录数据库状态。 AOF持久化实现AOF持久化功能实现分为： 命令追加append，执行完一个写命令后，会以协议格式将写命令追加到服务器的aof_buff缓冲区末尾。 文件写入 文件同步sync 文件写入和同步有三个选项appendfsync： always，每个事件都要将aof_buf缓冲区中所有内容写入到AOF文件中，并且同步AOF文件，效率最慢，但是最安全，出现故障只会丢失一个事件循环中的命令数据。 everysec，每个事件循环都要将aof_buf缓冲区所有内容写到AOF文件，并且每隔一秒就要在子线程中对AOF进行同步一次，效率足够快，出现故障会丢失1秒的数据。默认选项是这个。 no，每个事件循环都要将aof_buf缓冲区内容写到AOF文件中，但AOF文件同步则由操作系统决定，由于不进行同步操作，效率最好，但是出现故障丢失的数据是积累一段时间的数据。 AOF文件载入和数据还原服务器读取并重新执行一遍AOF文件中保存的写命令： 创建一个不带网络连接的伪客户端 从AOF文件中分析读取一条写命令 使用伪客户端执行被读出的写命令 AOF重写AOF持久化记录了被执行的写命令，AOF文件会越来越大，会对服务器造成影响，恢复时间也会很长，AOF采用重写rewrite来解决文件膨胀问题，创建一个新的AOF文件代替现有的AOF文件，新旧文件保存的数据库状态相同，但是新文件不会包含冗余的命令，体积会比旧文件小很多。 简单说就是根据数据库现有状态，将现有一个键值对的数据汇总成一条写命令，而不是原来的若干条命令。这样就减少了AOF文件的大小。 AOF后台重写由于AOF重写会阻塞服务，所以需要采用后台重写，后台重写使用子进程来处理。子进程开始重写文件后，主进程还在继续提供服务，会有新的命令进来，会造成重写后的AOF文件和数据库状态不一致，Redis使用AOF重写缓冲区来解决，Redis服务器执行一个写命令后，会同时将这个命令发送给AOF缓冲区和AOF重写缓冲区。 子进程完成AOF重写工作后，会向父进程发一个信号，父进程会调用处理函数： 将AOF重写缓冲区所有内容写到新的AOF文件中，新的AOF文件和服务器当前数据库状态就保持一致了。 对新AOF文件改名，并原子的覆盖现有AOF文件，完成新旧文件的替换。 参考 《redis设计与实现》（第二版）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis过期键的删除策略]]></title>
      <url>%2F2019%2F03%2F26%2FRedis%E8%BF%87%E6%9C%9F%E9%94%AE%E7%9A%84%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5%2F</url>
      <content type="text"><![CDATA[Redis过期时间保存在过期字典中，键的过期策略有三种：定时删除、惰性删除、定期删除。Redis采用了惰性删除和定期删除两种策略配合。 过期键删除策略 定时删除，设置过期键同时设置一个定时器，可保证过期键尽快删除，内存友好，CPU不友好，占用CPU。主动删除策略。 惰性删除，每次从键空间获取键时，如果过期就删除，没过期就返回该键，CPU友好，内存不友好，不能及时删除过期键。被动删除策略。 定期删除，每隔一段时间检查一次，删除过期键。主动删除策略。 Redis过期键删除策略Redis使用惰性删除和定期删除配合，在CPU时间和内存之间取得平衡。 在访问key的时候判断key是否过期。 在定期的serverCorn任务中，逐出部分过期key。默认在CPU空闲时每秒执行10次。 RDB功能对过期键的处理 生成RDB文件，使用SAVE或者BGSAVE新建RDB文件时，会对键检查，过期的键不会保存到RDB中。 载入RDB文件，主服务器载入RDB文件，过期键会被忽略。 载入RDB文件，从服务载入RDB文件，不会检查过期键，全部载入数据库中。主从服务器同步的时候，从服务器数据库会被清空。 AOF功能对过期键的处理 服务器AOF持久化模式运行时，如果键过期，还没被惰性删除或定期删除，AOF文件不会做处理。 当键被惰性删除或定期删除，程序会向AOF文件追加一条DEL命令，显式记录删除该键。 AOF重写时，会对键校验，已过期的键不会保存到重写后的AOF文件中。 复制功能对过期键的处理 从服务器的过期键删除动作由主服务器控制。 主服务器删除一个过期键后，会显式向所有从服务器发送一个DEL命令，告知删除过期键。 从服务器执行客户端发送的读命令时，碰到过期键也不会删除。 从服务器只有在接收到主服务器发来的DEL命令才会删除过期键。 参考 《redis设计与实现》（第二版）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis数据库实现以及各种操作实现]]></title>
      <url>%2F2019%2F03%2F25%2FRedis%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E5%90%84%E7%A7%8D%E6%93%8D%E4%BD%9C%E5%AE%9E%E7%8E%B0%2F</url>
      <content type="text"><![CDATA[Redis数据库实现，保存键值对的方法，针对数据库添加、删除、更新、查询等方法的实现，设置生存时间和过期时间操作。 数据库实现Redis服务器的所有数据库存在redisServer的db数组中： 1234567redisServer &#123; // db数组，保存服务器中所有数据库 redisDb *db; // 服务器的数据库数量 int dbnum;&#125; 服务器初始化时，程序会根据dbnum属性来决定创建多少个数据库，默认16个。 服务器数据库示例： 数据库键空间Redis数据库由redisDb结构表示，所有键值对保存在redisDb的dict字典中，这个字典称为键空间key space： 1234567redisDb &#123; // 键空间，保存数据库中所有键值对 dict *dict; // 过期字典，保存着键的过期时间 dict *expires&#125; 键空间的键，就是数据库的键，是字符串对象 键空间的值，就是数据库的值，可以是：字符串对象、列表对象、哈希表对象、集合对象、有序集合对象 键空间示例： 添加新键：将新键值添加到键空间字典里面。 删除键：在键空间里面删除键所对应的键值对对象。 更新键：对键空间里键对应的值对象进行更新。 对键取值：在键空间字典里取出键对应的值对象。 读写键空间时的附加操作 对键的读写操作，会根据键是否存在来更新服务器键空间命中hit次数和不命中miss次数。 读取键后，服务器会更新键的LRU时间。 读取一个键时发现键过期，服务器会先删除这个键。 客户端如果使用WATCH监听了键，服务器对键的修改，会把这个键标记为dirty，让事务程序注意到这个键被修改。 服务器每修改一次键，会对dirty计数器加1，计数器会触发服务器的持久化以及复制操作。 如果服务器开启了数据库通知功能，对键修改后，服务器会按照配置发送通知。 设置键的生存时间或过期时间 EXPIRE，设置键的生存时间TTL，单位：秒 PEXPIRE，设置键的生存时间TTL，单位：毫秒 EXPIREAT，设置键的过期时间，单位：秒 PEXPIREAT，设置键的过期时间，单位：毫秒 EXPIRE、PEXPIRE、EXPIREAT三个命令都是使用PEXPIZREAT命令来实现的。 保存过期时间redisDb使用expires字典来保存数据库中所有键的过期时间，叫做过期字典： 1234567redisDb &#123; // 键空间，保存数据库中所有键值对 dict *dict; // 过期字典，保存着键的过期时间 dict *expires&#125; 过期字典的键是个指针，指向某个键对象。 过期字典的值是一个long long类型整数，保存了键指向的键对象过期时间，毫秒经度的unix时间戳。 参考 《redis设计与实现》（第二版）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis对象]]></title>
      <url>%2F2019%2F03%2F20%2FRedis%E5%AF%B9%E8%B1%A1%2F</url>
      <content type="text"><![CDATA[Redis对象系统包含：字符串对象String、列表对象List、哈希对象Hash、集合对象Set、有序集合对象ZSet。 Redis执行命令前可以根据对象类型判断一个对象是否可以执行给定的命令。 可以针对不同使用场景为对象设置不同的数据结构实现，优化对象在不同场景下的使用效率。 Redis对象系统实现了基于引用计数计数的内存回收机制。 还通过引用计数计数实现了对象共享机制，让多个数据库键共享同一个对象来节约内存。 对象还带有访问时间记录信息，可以在启用了maxmemory功能时，优先删除一些键。 对象的类型和编码Redis中的键和值都是对象，对象结构如下： 123456789101112131415161718redisObject &#123; // 类型 unsigned type:4; // 编码 unsigned encoding:4; // 指向底层实现数据结构的指针 void * ptr; // lru，记录对象最后一次被访问的时间 unsigned lru:22; // 引用计数 int refcount; // ...&#125; 类型 对于键，总是一个字符串对象 对于值，类型可以是：字符串、列表、哈希、集合、有序集合对象。 对象的类型： 类型常量 对象名称 REDIS_STRING 字符串对象 REDIS_LIST 列表对象 REDIS_HASH 哈希对象 REDIS_SET 集合对象 REDIS_ZSET 有序集合对象 编码和底层实现对象的ptr指针指向对象的具体底层实现数据结构，数据结构由对象的encoding属性决定。 对象的编码： 编码常量 编码对应的底层数据结构 REDIS_ENCODING_INT long类型的整数 REDIS_ENCODING_EMBSTR embstr编码的简单动态字符串 REDIS_ENCODING_RAW 简单动态字符串 REDIS_ENCODING_HT 字典 REDIS_ENCODING_LINKEDLIST 双端链表 REDIS_ENCODING_ZIPLIST 压缩列表 REDIS_ENCODING_INTSET 整数集合 REDIS_ENCODING_SKIPSET 跳表和字典 字符串对象字符串的对象编码可以是： int，整数值 raw，字符串，长度大于32字节，使用SDS保存，编码设置为raw embstr，字符串，长度小于32字节，使用embstr编码方式来保存字符串 embstr是专门用于保存短字符串的一种优化编码方式，embstr会一次内存分配来创建redisObject和sdshdr接口，而raw编码方式会调用两次分别创建。 编码转换int编码的字符串和embstr编码的字符串可以抓换为raw编码的字符串对象。 列表对象列表对象编码可以是： ziplist，压缩列表，每个压缩列表节点entry保存一个列表元素。 linkedlist，双端链表，每个双端列表节点node保存了一个字符串对象，每个字符串对象都保存了一个列表元素。 编码转换 列表对象保存的所有字符串元素长度都小于64字节，并且列表对象保存的对象元素数量小于512个，使用ziplist编码。 其他的都是用linkedlist编码。 哈希对象哈希对象的编码可以是： ziplist，压缩列表，有新键值对加入到哈希对象，先将键的压缩列表节点推入压缩列表尾部，然后再将值的压缩列表节点推入压缩列表尾部。 hashtable，字典，哈希对象中每个键值对都是用一个字典键值对来保存。 编码转换 哈希对象所有的键值对的键和值的字符串长度都小于64字节，并且哈希对象保存的键值对数量小于512个，使用ziplist编码 其他的使用hashtable编码 集合对象集合对象的编码可以是： intset，整数集合 hashtable，字典，每个键都是一个字符串对象，每个字符串对象保存了一个集合元素，字典的值全部都是NULL 编码转换 所有元素都是整数值，并且保存的元素数量不超过512个，使用intset编码 其他的使用hashtable编码 有序集合对象有序集合对象编码可以是： ziplist，压缩列表，每个元素使用两个紧挨在一起的压缩列表节点来保存 skiplist，跳表，skiplist编码的有序集合对象使用zset结构作为底层实现，一个zset结构同时包含一个字典和一个跳表。字典查询快，跳表范围查找快。 编码转换 有序集合保存数量小于128个并且所有元素长度都小于64字节，使用ziplist编码 其他的使用skiplist编码 内存回收使用引用计数技术实现内存回收机制，redisObject结构中有个refCount属性，用来记录对象的引用计数信息。 对象共享引用计数属性还带有对象共享的作用。 Redis在初始化服务器时，创建一万个字符串对象，包含了0-9999所有整数值，服务器会使用这些共享对象。 对象的空转时长redisObject结构中还包含一个lru属性，记录了对象最后一次被命令程序访问的时间。 如果服务器开了maxmemory选项，并且回收内存的算法为volatile-lru或者allkeys-lru，当服务器占用内存数超过了maxmemory值，空转时长较高的那部分键会被优先释放掉，从而回收内存。 参考 《redis设计与实现》（第二版）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis压缩列表]]></title>
      <url>%2F2019%2F03%2F19%2FRedis%E5%8E%8B%E7%BC%A9%E5%88%97%E8%A1%A8%2F</url>
      <content type="text"></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis整数集合]]></title>
      <url>%2F2019%2F03%2F19%2FRedis%E6%95%B4%E6%95%B0%E9%9B%86%E5%90%88%2F</url>
      <content type="text"><![CDATA[当一个集合只包含整数值元素，并且集合的元素数不多时，Redis使用整数集合intset作为集合键的底层实现。 Intset实现：12345678910intset &#123; // 编码方式 uint32_t encoding; // 集合包含的元素数量 uint32_t length; // 保存元素的数组 int8_t contents[];&#125; encoding，决定contents数组的真正类型，取值：int16_t, int32_t, int64_t length，记录整数集合包含的元素数量，也就是contents数组长度 contents，数组，每项都按从小到大有序排列，不包含重复项 升级当要添加到集合中的新元素类型比现有元素类型长，需要对集合进行升级upgrade，才能将新元素添加到集合中： 根据新元素类型，扩展底层数组空间大小，为新元素分配空间。 将现有元素转化成和新元素相同类型，并放到正确位置上，保持有序不变 将新元素添加到数组里 升级的好处 提升整数集合的灵活性，可以将不同类型的整数添加到集合中，不需担心出现类型错误。 尽可能节约内存，可以确保升级操作只在有需要的时候才进行。 降级整数集合不支持降级操作，一旦对数组进行了升级，编码就会一直保持升级后的状态。 参考 《redis设计与实现》（第二版）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis字典]]></title>
      <url>%2F2019%2F03%2F15%2FRedis%E5%AD%97%E5%85%B8%2F</url>
      <content type="text"><![CDATA[Redis字典使用哈希表作为底层实现，一个哈希表可以有多个哈希节点，每个哈希表节点就保存了字典中的一个键值对。 哈希表Redis字典使用哈希表作为底层实现，一个哈希表可以有多个哈希节点，每个哈希表节点就保存了字典中的一个键值对。 哈希表： 哈希表就类似Java中的Map实现。 table，哈希表数组 size，哈希表大小 sizemask，哈希表大小掩码，用于计算索引，等于size-1 used，哈希表已有节点数量 哈希表节点 key，键 v，保存着键值对中的值，可以是一个指针，也可是一个uint64_t整数，也可以是int64_t整数 next指向另外一个哈希表节点的指针，处理冲突。 字典字典： type，指向一个dictType结构指针，为不同字典设置不同类型特定函数。 privdata，保存了需要传给那些类型特定函数的可选参数 ht，包含两个dictht哈希表的数组，ht[0]是哈希表，ht[1]只会在堆ht[0]哈希表进行rehash时使用。 rehashidx，记录了rehash目前的进度，没有rehash时为-1 哈希算法根据键值对的键计算出哈希值和索引值，根据索引值将键值对哈希节点放到哈希表数组的指定索引上面。类似Java中HashMap的算法。 解决键冲突采用链地址法解决冲突，多个哈希表节点用next指针形成一个单向链表，新节点添加到链表表头。跟Java的HashMap一样。 rehash对字典的哈希表进行扩展和收缩通过rehash实现： 扩容： 为字典ht[1]分配空间，ht[1]大小为ht[0].used * 2，但是要保持大小为2的n次方 把ht[0]中所有键值对rehash到ht[1]上 完成后将ht[0]释放，将ht[1]设置为ht[0]，并在ht[1]新建一个空白哈希表，为下次rehash做准备 收缩： 为字典ht[1]分配空间，ht[1]大小为2的n次方，其中n=ht[0].used 把ht[0]中所有键值对rehash到ht[1]上 完成后将ht[0]释放，将ht[1]设置为ht[0]，并在ht[1]新建一个空白哈希表，为下次rehash做准备 哈希表的扩展和收缩负载因子 = 已保存节点数量 / 哈希表大小 服务器没有执行BGSAVE和BGREWRITEAOF命令，且哈希表负载因子大于等于1时，会自动对哈希表进行扩展操作。 服务器正在执行BGSAVE和BGREWRITEAOF命令，且哈希表负载因子大于等于5,时，会自动对哈希表进行扩展操作。 BGSAVE或BGREWRITEAOF命令执行过程中，Redis需要创建当前进程的子进程，操作系统一采用copy-on-write技术来优化使用效率，在子进程存在期间，需要尽可能避免进行哈希表扩展操作，所以会使用一个高的负载因子，最大限度的节约内存。 负载因子小于0.1时，程序会自动对哈希表执行收缩操作。 渐进式rehashrehash的时候会将ht[0]的所有键值对rehash到ht[1]里，如果说数据量非常大，一次性全部rehash会导致服务器暂停服务，所以Redis采用分多次、渐进式的将ht[0]里的键值对慢慢rehash到ht[1]中： 位ht[1]分配空间，字典同时持有ht[0]和ht[1] 字典中维持一个索引计数器rehashidx，并设为0，表示开始工作，从第0个索引位置开始 rehash期间对字典执行的增、删、查、改，都会顺带将ht[0]上对应rehashidx索引的键值对rehash到ht[1]，完成后rehashidx增1 等所有键值对都被rehash到ht[1]后，将rehashidx设置-1，表示已完成 在渐进式rehash期间，删除、查找、更新会在两个哈希表上都进行，而新增则只在ht[1]上进行。 参考 《redis设计与实现》（第二版）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis简单动态字符串SDS]]></title>
      <url>%2F2019%2F03%2F13%2FRedis%E7%AE%80%E5%8D%95%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2SDS%2F</url>
      <content type="text"><![CDATA[Redis中的字符串使用的是Redis自定义的抽象类型，而不是直接使用C语言的字符串表示。Redis的字符串叫做：简单动态字符串Simple Dynamic String，简称SDS。 SDS除了能保存字符串值，还能作为缓冲区buffer：AOF模块中的AOF缓冲区、客户端状态中的输入缓冲区。 SDS定义 12345678910struct sdshdr&#123; // 字符数组，用于保存字符串 char buf[]; // buf数组中已使用字节的数量，等于SDS所保存字符串的长度 int len; // buf数组中未使用字节的数量 int free;&#125; Redis中的字符串使用的是Redis自定义的抽象类型，而不是直接使用C语言的字符串表示。Redis的字符串叫做：简单动态字符串Simple Dynamic String，简称SDS。 SDS除了能保存字符串值，还能作为缓冲区buffer：AOF模块中的AOF缓冲区、客户端状态中的输入缓冲区。 SDS定义 12345678910struct sdshdr&#123; // 字符数组，用于保存字符串 char buf[]; // buf数组中已使用字节的数量，等于SDS所保存字符串的长度 int len; // buf数组中未使用字节的数量 int free;&#125; free=0，表示SDS没有分配未使用空间 len=5，表示SDS保存了一个5字节长的字符串 buf是一个char类型数组，前面5个保存了实际的字符，最后一个字节保存了空字符\0 free=5，表示为buf数组分配了5字节未使用空间 SDS与C字符串的区别常数复杂度获取字符串长度C字符串不记录自身长度，需要遍历字符串，直到遇到结尾空字符串，时间复杂度为O(N)。SDS记录了自身长度，获取长度的时间复杂度为O(1)。 杜绝缓冲区溢出C字符串不记录自身长度，修改字符串容易产生缓冲区溢出问题。SDS修改字符串时会先检查空间是否满足要求，不满足的话会自动将SDS空间扩充到所需大小，再执行修改，也就不会产生缓冲区溢出问题。 减少修改字符串时带来的内存重分配次数C字符串每次增长或缩短，程序都需要对这个C字符数组进行内存充分配操作： 增长C字符串时，程序先通过内存重分配来扩展底层数组空间大小，否则会产生缓冲区溢出。 缩短C字符串时，程序先通过内存充分配来释放不再使用的空间，否则会产生内存泄露。 C字符串的这种方式会对Redis产生性能影响，SDS通过未使用空间实现了空间预分配和惰性空间释放两种优化策略。 空间预分配SDS需要进行空间扩展的时候，先会分配必须要的空间，还会分配额外未使用空间，通过空间预分配可以减少连续执行字符串增长操作所需的内存重分配次数： SDS修改后，长度len小于1MB时，会分配一个长度也为len的未使用空间。比如修改后SDS长度len=13，则分配free=13，SDS长度实际为：len + free + 1 = 13 + 13 + 1 SDS修改后，长度len大于等于1MB时，会分配一个长度为1MB的未使用空间。比如修改后SDS长度len=2MB，则分配free=1MB，SDS长度实际为：len + free + 1 = 2MB + 1MB + 1byte 惰性空间释放SDS需要进行字符串缩短操作时，不会立即回收缩短后空闲出来的空间，而是分配给free，等待将来使用。 二进制安全C字符串中的字符必须符合某种编码，除了末尾字符，其他字符不能是空字符。C字符串只能保存文本数据，不能保存图像、音频、视频、压缩文件等二进制数据。 SDS是二进制安全的，buf数组里的数据没有任何限制，buf数组里不保存字符，而保存二进制数据。 兼容部分C字符串函数SDS可使用部分的C字符串函数 总结 C字符串 SDS 获取长度时间复杂度O(N) 获取长度时间复杂度O(1) API不安全，可能造成缓冲区溢出 API安全，不会造成缓冲区溢出 修改长度N次，需要N次内存重分配 修改长度N次，最多需要N次内存重分配 只能保存文本数据 可以保存文本和二进制数据 可使用C的所有字符串函数 可使用部分C的字符串函数 参考 《redis设计与实现》（第二版） free=0，表示SDS没有分配未使用空间 len=5，表示SDS保存了一个5字节长的字符串 buf是一个char类型数组，前面5个保存了实际的字符，最后一个字节保存了空字符\0 free=5，表示为buf数组分配了5字节未使用空间 SDS与C字符串的区别常数复杂度获取字符串长度C字符串不记录自身长度，需要遍历字符串，直到遇到结尾空字符串，时间复杂度为O(N)。SDS记录了自身长度，获取长度的时间复杂度为O(1)。 杜绝缓冲区溢出C字符串不记录自身长度，修改字符串容易产生缓冲区溢出问题。SDS修改字符串时会先检查空间是否满足要求，不满足的话会自动将SDS空间扩充到所需大小，再执行修改，也就不会产生缓冲区溢出问题。 减少修改字符串时带来的内存重分配次数C字符串每次增长或缩短，程序都需要对这个C字符数组进行内存充分配操作： 增长C字符串时，程序先通过内存重分配来扩展底层数组空间大小，否则会产生缓冲区溢出。 缩短C字符串时，程序先通过内存充分配来释放不再使用的空间，否则会产生内存泄露。 C字符串的这种方式会对Redis产生性能影响，SDS通过未使用空间实现了空间预分配和惰性空间释放两种优化策略。 空间预分配SDS需要进行空间扩展的时候，先会分配必须要的空间，还会分配额外未使用空间，通过空间预分配可以减少连续执行字符串增长操作所需的内存重分配次数： SDS修改后，长度len小于1MB时，会分配一个长度也为len的未使用空间。比如修改后SDS长度len=13，则分配free=13，SDS长度实际为：len + free + 1 = 13 + 13 + 1 SDS修改后，长度len大于等于1MB时，会分配一个长度为1MB的未使用空间。比如修改后SDS长度len=2MB，则分配free=1MB，SDS长度实际为：len + free + 1 = 2MB + 1MB + 1byte 惰性空间释放SDS需要进行字符串缩短操作时，不会立即回收缩短后空闲出来的空间，而是分配给free，等待将来使用。 二进制安全C字符串中的字符必须符合某种编码，除了末尾字符，其他字符不能是空字符。C字符串只能保存文本数据，不能保存图像、音频、视频、压缩文件等二进制数据。 SDS是二进制安全的，buf数组里的数据没有任何限制，buf数组里不保存字符，而保存二进制数据。 兼容部分C字符串函数SDS可使用部分的C字符串函数 总结 C字符串 SDS 获取长度时间复杂度O(N) 获取长度时间复杂度O(1) API不安全，可能造成缓冲区溢出 API安全，不会造成缓冲区溢出 修改长度N次，需要N次内存重分配 修改长度N次，最多需要N次内存重分配 只能保存文本数据 可以保存文本和二进制数据 可使用C的所有字符串函数 可使用部分C的字符串函数 参考 《redis设计与实现》（第二版）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo中SPI源码解析]]></title>
      <url>%2F2019%2F02%2F20%2FDubbo%E4%B8%ADSPI%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[从两个示例代码，介绍dubbo的SPI的使用以及相关源码分析，分析了获取扩展实现和获取自适应扩展点实现的源码，最后简单说了下ExtensionFactory的流程，看完就可以理解为什么dubbo是自包含的了。从上往下看，再回头看，应该能看明白，文章比较长，希望能耐心读下去。如果有错误的地方希望能指出来，我也理解不是太完整或者表述不是太明白。 ExtensionLoader使用以及简单流程分析假设有这样一段示例代码： 123456public static void main(String[] args) &#123; ExtensionLoader&lt;Protocol&gt; extensionLoader = ExtensionLoader.getExtensionLoader(Protocol.class); Protocol dubboProtocol = extensionLoader.getExtension("dubbo"); System.out.println(dubboProtocol.getDefaultPort()); &#125; 我们先通过ExtensionLoader.getExtensionLoader(Protocol.class)获取ExtensionLoader实例，然后通过getExtension(&quot;dubbo&quot;)获取到具体的Protocol实现DubboProtocol。 首先看下获取ExtensionLoader实例的过程： 各种校验。 从缓存中获取指定类型的ExtensionLoader实例。 如果缓存中不存在的话，就新建一个ExtensionLoader实例，并放入缓存。 返回ExtensionLoader实例。 这部分源码如下： 1234567891011121314151617181920212223242526public static &lt;T&gt; ExtensionLoader&lt;T&gt; getExtensionLoader(Class&lt;T&gt; type) &#123; // 扩展点类型不能为空 if (type == null) throw new IllegalArgumentException("Extension type == null"); // 扩展点类型只能是接口类型的 if(!type.isInterface()) &#123; throw new IllegalArgumentException("Extension type(" + type + ") is not interface!"); &#125; // 没有添加@SPI注解 if(!withExtensionAnnotation(type)) &#123; throw new IllegalArgumentException("Extension type(" + type + ") is not extension, because WITHOUT @" + SPI.class.getSimpleName() + " Annotation!"); &#125; // 先从缓存中获取指定类型的ExtensionLoader ExtensionLoader&lt;T&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); // 缓存中不存在 if (loader == null) &#123; /** * 创建一个新的ExtensionLoader实例，放到缓存中去 * 对于每一个扩展，dubbo中只有个对应的ExtensionLoader实例 */ EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader&lt;T&gt;(type)); loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); &#125; return loader;&#125; ExtensionLoader缓存前面的校验可以参考注释，这里先说下缓存EXTENSION_LOADERS： 1private static final ConcurrentMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt; EXTENSION_LOADERS = new ConcurrentHashMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt;(); 可以看到每个SPI扩展的ExtensionLoader的实例只有一个，缓存的key就是具体SPI接口类型，比如com.alibaba.dubbo.rpc.Protocol作为key。 ExtensionLoader实例化new ExtensionLoader&lt;T&gt;(type)这里做了什么？ 12345678private ExtensionLoader(Class&lt;?&gt; type) &#123; this.type = type; objectFactory = ( type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension() );&#125; 上面示例代码执行后，第一次到这里，type是com.alibaba.dubbo.rpc.Protocol，所以这里会先执行ExtensionLoader.getExtensionLoader(ExtensionFactory.class)，然后执行getAdaptiveExtension()。 也就是说如果是第一次执行获取Protocol类型的ExtensionLoader的实例的话，会先获取ExtensionFactory类型的ExtensionLoader实例。为什么要先获取ExtensionFactory类型的ExtensionLoader的实例呢？因为ExtensionFactory是用来生成扩展点具体实现的工厂，这里暂时先到这里，后面会再说ExtensionFactory相关的东西。 获取完了ExtensionFactory类型的ExtensionLoader后，紧接着调用getAdaptiveExtension()方法来获取一个自适应的ExtensionFactory实例，获取自适应AdaptiveExtensionFactory实例的原因是ExtensionFactory会有多个实现，这样可以在运行时来决定调用哪个具体实现，而不是直接写死使用哪个具体实现。 ExtensionFactory的具体实现有三个： AdaptiveExtensionFactory SpiExtensionFactory SpringExtensionFactory 其中AdaptiveExtensionFactory注解了@Adaptive注解，是ExtensionFactory这个SPI接口的自适应实现，如果在运行时需要获取一个ExtensionFactory的实现时，会调用AdaptiveExtensionFactory来进行动态获取。 说明一下，一个扩展点最多只能有一个自适应实现，也就是一个扩展点的具体实现类最多只能有一个可以在类级别上注解@Adaptive。如果一个扩展点没有任何一个实现在类级别上注解@Adaptive，那么dubbo会在运行时动态生成一个自适应实现类，比如Protocol的具体实现类就没有任何一个有在类级别上注解了@Adaptive，dubbo会自动生成一个名字是Protocol$Adpative的自适应实现类。 使用ExtensionLoader获取扩展点实现上面的步骤完成了获取Protocol类型的ExtensionLoader的实例，同时也完成了ExtensionFactory类型的ExtensionLoader实例的加载，同时也生成了ExtensionFactory的自适应实现，接下来继续往下走： 1Protocol dubboProtocol = extensionLoader.getExtension("dubbo"); 获取了Protocol类型的ExtensionLoader实例后，就可以根据名字来加载具体的实现类了，Protocol的具体实现类有： DubboProtocol HessianProtocol HttpProtocol ThriftProtocol InjvmProtocol RmiProtocol WebServiceProtocol RegistryProtocol RedisProtocol MemcachedProtocol 一些Wrapper类 可以看到Protocol有很多具体的实现，根据使用协议的不同，可以动态选择具体使用哪一个Protocol实现。 继续看getExtension()方法： 123456789101112131415161718192021222324252627public T getExtension(String name) &#123; if (name == null || name.length() == 0) throw new IllegalArgumentException("Extension name == null"); // 获取默认实现 if ("true".equals(name)) &#123; return getDefaultExtension(); &#125; // 从缓存获取 Holder&lt;Object&gt; holder = cachedInstances.get(name); if (holder == null) &#123; cachedInstances.putIfAbsent(name, new Holder&lt;Object&gt;()); holder = cachedInstances.get(name); &#125; Object instance = holder.get(); if (instance == null) &#123; synchronized (holder) &#123; instance = holder.get(); if (instance == null) &#123; // 缓存不存在，创建实例 instance = createExtension(name); // 加入缓存 holder.set(instance); &#125; &#125; &#125; return (T) instance;&#125; 该方法是根据指定的名字来获取具体的扩展点的实现的实例，比如我们这里传的name是dubbo，就会获取DubboProtocol的实例，具体步骤如下： 校验 如果name是true，就获取默认扩展点的实现实例 从缓存中获取扩展点实现实例 如果缓存中不存在，就根据name创建具体的扩展点实现实例 返回name对应的具体扩展点实现的实例 扩展点实现的实例缓存获取默认扩展点实现实例暂时不说，先看下cachedInstances缓存： 1private final ConcurrentMap&lt;String, Holder&lt;Object&gt;&gt; cachedInstances = new ConcurrentHashMap&lt;String, Holder&lt;Object&gt;&gt;(); 这里缓存了扩展点具体实现的实例，key是扩展点的名字，比如DubboProtocol的实例，key就是dubbo，value是DubboProtocol的实例，Holder中持有DubboProtocol的实例。 创建扩展点实现实例接下来看根据name创建具体扩展点实现实例的方法createExtension(name)方法，该方法的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647private T createExtension(String name) &#123; &#x2F;** * getExtensionClasses加载当前扩展点的所有实现 * 比如： * 我们在使用ExtensionLoader.getExtensionLoader(Protocol.class) * 获取Protocol的ExtensionLoader的时候，就已经设置了当前ExtensionLoader * 的类型是Protocol的，所以这里获取的时候就是Protocol的所有实现。 * * 获取到所有的实现之后，getExtensionClasses()返回的是Map&lt;String, Class&lt;?&gt;&gt; *&#x2F; Class&lt;?&gt; clazz &#x3D; getExtensionClasses().get(name); if (clazz &#x3D;&#x3D; null) &#123; throw findException(name); &#125; try &#123; &#x2F;** * 从缓存中获取已经创建的扩展点的实现的实例 * 如果还没有，就根据Class通过反射来创建具体的实例， * 并放到缓存中去 *&#x2F; T instance &#x3D; (T) EXTENSION_INSTANCES.get(clazz); if (instance &#x3D;&#x3D; null) &#123; EXTENSION_INSTANCES.putIfAbsent(clazz, (T) clazz.newInstance()); instance &#x3D; (T) EXTENSION_INSTANCES.get(clazz); &#125; &#x2F;** * 向实例中注入依赖的扩展 * 如果一个扩展点A依赖了其他的扩展点B，并且有setter方法 * 就会执行将扩展点B注入扩展点A的操作 *&#x2F; injectExtension(instance); &#x2F;** * 如果扩展点有包装类，将扩展点进行包装 * 包装后如果也依赖了其他扩展点，也需要注入其他扩展点 *&#x2F; Set&lt;Class&lt;?&gt;&gt; wrapperClasses &#x3D; cachedWrapperClasses; if (wrapperClasses !&#x3D; null &amp;&amp; wrapperClasses.size() &gt; 0) &#123; for (Class&lt;?&gt; wrapperClass : wrapperClasses) &#123; instance &#x3D; injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); &#125; &#125; return instance; &#125; catch (Throwable t) &#123; throw new IllegalStateException(&quot;Extension instance(name: &quot; + name + &quot;, class: &quot; + type + &quot;) could not be instantiated: &quot; + t.getMessage(), t); &#125;&#125; 该方法根据扩展点的名字来创建具体扩展点实现的实例，具体步骤如下： 通过getExtensionClasses()方法将当前扩展点的所有的实现类进行加载，如果是@Adaptive注解的自适应实现类，则放到cachedAdaptiveClass缓存中；如果是包装类，则放到cachedWrapperCalsses缓存中。经过这一步，扩展点的所有实现都已经解析加载。 根据名字获取到具体的某一个扩展点实现类，并去EXTENSION_INSTANCES缓存中查询是不是有实例，如果没有的话，就使用反射创建一个实例。 如果该实例中依赖了其他的扩展点（需要有setter方法），需要将依赖的扩展点进行注入。 如果扩展点有包装类，则将扩展点进行包装，如果包装后，也依赖了其他的扩展点（需要有setter方法），需要将依赖的扩展点进行注入。 返回注入和包装后的扩展点实现的实例，在我们的这个例子中返回的不是DubboProtocol实例了，而是经过了ProtocolFilterWrapper和ProtocolListenerWrapper包装后的实例。 总体的流程就算说完了，已经获取到了名字为dubbo的Protocol的实现的实例，接下来的执行最后一行代码，得到结果： 1System.out.println(dubboProtocol.getDefaultPort()); 加载扩展点实现类的Class接下来我们看看getExtensionClasses()方法具体做了什么，该方法是用来加载当前扩展点的所有实现的class的，具体代码如下： 123456789101112131415161718192021222324private Map&lt;String, Class&lt;?&gt;&gt; getExtensionClasses() &#123; /** * 先从缓存中获取，不存在的话就调用loadExtensionClasses进行加载 * cachedClasses缓存中存储了当前扩展点所有的实现类 */ Map&lt;String, Class&lt;?&gt;&gt; classes = cachedClasses.get(); if (classes == null) &#123; synchronized (cachedClasses) &#123; classes = cachedClasses.get(); if (classes == null) &#123; /** * 如果没有加载Extension的实现，进行扫描加载，完成后缓存起来 * 每个扩展点，其实现的加载只会执行一次 * 例如，如果Protocol的某个具体实现加载出错了，没有放到缓存中去 * 后面再使用，也不会再进行加载了。 */ classes = loadExtensionClasses(); // 缓存起来 cachedClasses.set(classes); &#125; &#125; &#125; return classes;&#125; 这里也只是尝试从缓存中获取，如果缓存中不存在的话，就进行具体的加载逻辑。但是这里有个点要注意，一个扩展点的的实现类加载只会执行一次。 继续往下走就是真正的加载扩展点的实现逻辑了，代码如下： 12345678910111213141516171819202122232425private Map&lt;String, Class&lt;?&gt;&gt; loadExtensionClasses() &#123; final SPI defaultAnnotation = type.getAnnotation(SPI.class); if(defaultAnnotation != null) &#123; // 当前扩展点的默认实现名字，如果有的话进行缓存 String value = defaultAnnotation.value(); if(value != null &amp;&amp; (value = value.trim()).length() &gt; 0) &#123; String[] names = NAME_SEPARATOR.split(value); if(names.length &gt; 1) &#123; throw new IllegalStateException("more than 1 default extension name on extension " + type.getName() + ": " + Arrays.toString(names)); &#125; if(names.length == 1) cachedDefaultName = names[0]; &#125; &#125; // 从配置文件中加载扩展实现类 Map&lt;String, Class&lt;?&gt;&gt; extensionClasses = new HashMap&lt;String, Class&lt;?&gt;&gt;(); // 从META-INF/dubbo/internal目录下加载 loadFile(extensionClasses, DUBBO_INTERNAL_DIRECTORY); // 从META-INF/dubbo/目录下加载 loadFile(extensionClasses, DUBBO_DIRECTORY); // 从META-INF/services/下加载 loadFile(extensionClasses, SERVICES_DIRECTORY); return extensionClasses;&#125; 这里面逻辑也挺简单的，先获取扩展点的默认名字，如果有的话进行缓存；然后就从配置文件中加载具体的实现类了，加载的位置有三个，请参照代码里的注释。 具体的从配置文件中加载的代码，就不在贴出来了，太长了。说下大概的逻辑： 组装配置文件名字，加载配置文件，遍历文件中每一行进行处理。 加载配置文件中配置的实现类。 如果是注解了@Adaptive注解的实现类，加入到cachedAdaptiveClass缓存中。 如果是包装类型的实现类，加入到cachedWrapperClasses缓存中。 如果是除了上面两种的类，放到extensionClasses这个map中，用于在上层返回。 扩展点依赖注入我们在返回上面，还又一点没说，就是依赖注入的功能injectExtension的代码： 12345678910111213141516171819202122232425262728293031323334353637private T injectExtension(T instance) &#123; try &#123; // 在获取第一个扩展点的ExtensionLoader的实例的时候，objectFactory就被实例化了，是AdaptiveExtensionFactory if (objectFactory != null) &#123; // 遍历要注入的实例的方法 for (Method method : instance.getClass().getMethods()) &#123; // 只处理set方法，比如setA，就是要把A注入到instance中 if (method.getName().startsWith("set") &amp;&amp; method.getParameterTypes().length == 1 &amp;&amp; Modifier.isPublic(method.getModifiers())) &#123; // set方法参数类型 Class&lt;?&gt; pt = method.getParameterTypes()[0]; try &#123; // setter方法对应的属性名，也就是扩展点接口名称 String property = method.getName().length() &gt; 3 ? method.getName().substring(3, 4).toLowerCase() + method.getName().substring(4) : ""; /** * objectFactory是AdaptiveExtensionFactory实例 * 比如这里的pt是com.alibaba.dubbo.rpc.Protocol，property是protocol * objectFactory就会根据这两个参数去获取Protocol对应的扩展实现的实例 */ Object object = objectFactory.getExtension(pt, property); // 获取到了setter方法的参数的实现，可以进行注入 if (object != null) &#123; method.invoke(instance, object); &#125; &#125; catch (Exception e) &#123; logger.error("fail to inject via method " + method.getName() + " of interface " + type.getName() + ": " + e.getMessage(), e); &#125; &#125; &#125; &#125; &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; return instance;&#125; 依赖注入的代码也很简单，就是实例化要注入的类，然后反射调用set方法注入实例中去。 自适应扩展点使用到这里，使用指定名称加载扩展点实现的流程就分析完了，但是这种直接指定扩展点名字的方式却不是我们主要使用的方式。可以想象一下，dubbo是可以配置多协议的，也就是可以同时配置比如dubbo、rmi等协议。如果我们使用了多协议的话，那dubbo是怎么做的呢？我们可以想到最简单的方法就是有一个转发器，用来根据实际请求中配置的协议来使用不同的实现来处理，下面可以写个伪代码： 12345678910public class ProtocolDispatcher implements Protocol &#123; public void refer(String name) &#123; if (name.equals("dubbo")) &#123; Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getExtension("dubbo"); &#125; else if(name.equals("rmi")) &#123; Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getExtension("rmi"); &#125; &#125;&#125; 实际上dubbo中没有这样的代码，但实际上也差不多类似这样的方式来处理的，我们看下实际在dubbo中的使用方式： 1private static final Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); 可以看到第一步还是先获取Protocol类型的ExtensionLoader的实例，这个过程跟最上面的获取ExtensionLoader实例的过程是一样的，接下来这一步getAdaptiveExtension()就跟我们之前的示例不一样了，这是获取自适应扩展的方法。 自适应扩展是不是很熟悉，上面我们也说过自适应，可以回头先去看下大概情况。首先说下获取自适应扩展是干嘛的？其实就是做到上面那个伪代码的转发器功能。 自适应扩展点动态生成的代码当调用了上面getAdaptiveExtension()方法后，dubbo会动态生成如下代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.alibaba.dubbo.rpc;import com.alibaba.dubbo.common.extension.ExtensionLoader;public class Protocol$Adpative implements com.alibaba.dubbo.rpc.Protocol &#123; public void destroy() &#123; throw new UnsupportedOperationException( "method public abstract void com.alibaba.dubbo.rpc.Protocol.destroy() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!" ); &#125; public int getDefaultPort() &#123; throw new UnsupportedOperationException( "method public abstract int com.alibaba.dubbo.rpc.Protocol.getDefaultPort() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!" ); &#125; public com.alibaba.dubbo.rpc.Exporter export(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker &#123; if (arg0 == null) throw new IllegalArgumentException("com.alibaba.dubbo.rpc.Invoker argument == null"); if (arg0.getUrl() == null) throw new IllegalArgumentException("com.alibaba.dubbo.rpc.Invoker argument getUrl() == null"); com.alibaba.dubbo.common.URL url = arg0.getUrl(); String extName = (url.getProtocol() == null ? "dubbo" : url.getProtocol()); if (extName == null) throw new IllegalStateException( "Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(" + url.toString() + ") use keys([protocol])" ); com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol) ExtensionLoader .getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class) .getExtension(extName); return extension.export(arg0); &#125; public com.alibaba.dubbo.rpc.Invoker refer(java.lang.Class arg0, com.alibaba.dubbo.common.URL arg1) throws java.lang.Class &#123; if (arg1 == null) throw new IllegalArgumentException("url == null"); com.alibaba.dubbo.common.URL url = arg1; String extName = (url.getProtocol() == null ? "dubbo" : url.getProtocol()); if (extName == null) throw new IllegalStateException( "Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(" + url.toString() + ") use keys([protocol])" ); com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol) ExtensionLoader .getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class) .getExtension(extName); return extension.refer(arg0, arg1); &#125;&#125; 当我们调用protocol.xxxx()方法的时候，其实就是调用动态生成的Protocol$Adaptive这个类的方法，这里面的逻辑其还是就跟我们的伪代码差不多了，根据url中传入的Protocol名字，通过getExtension(extName)方法获取实际的扩展点实现实例。 自适应扩展点的获取接下来就看下获取自适应扩展的源码： 1234567891011121314151617181920212223242526272829public T getAdaptiveExtension() &#123; // 先从自适应实例缓存中查找实例对象 Object instance = cachedAdaptiveInstance.get(); // 缓存中不存在 if (instance == null) &#123; if(createAdaptiveInstanceError == null) &#123; synchronized (cachedAdaptiveInstance) &#123; // 获取锁之后再检查一次缓存中是不是已经存在 instance = cachedAdaptiveInstance.get(); if (instance == null) &#123; try &#123; // 缓存中没有，就创建新的AdaptiveExtension实例 instance = createAdaptiveExtension(); // 新实例加入缓存 cachedAdaptiveInstance.set(instance); &#125; catch (Throwable t) &#123; createAdaptiveInstanceError = t; throw new IllegalStateException("fail to create adaptive instance: " + t.toString(), t); &#125; &#125; &#125; &#125; else &#123; throw new IllegalStateException("fail to create adaptive instance: " + createAdaptiveInstanceError.toString(), createAdaptiveInstanceError); &#125; &#125; return (T) instance;&#125; 这边还是老套路，先从缓存中获取，如果缓存中不存在，就创建自适应扩展实例，继续看createAdaptiveExtension()方法： 123456789101112private T createAdaptiveExtension() &#123; try &#123; /** * 先通过getAdaptiveExtensionClass获取自适应扩展类的Class * 然后通过反射获取实例 * 最后如果自适应扩展依赖了其他的扩展点，就进行扩展点注入 */ return injectExtension((T) getAdaptiveExtensionClass().newInstance()); &#125; catch (Exception e) &#123; throw new IllegalStateException("Can not create adaptive extenstion " + type + ", cause: " + e.getMessage(), e); &#125;&#125; 这里的逻辑跟createExtension()差不多，大概步骤： 先通过getAdaptiveExtensionClass()方法获取自适应扩展类的Class 然后通过反射获取实例 最后如果自适应扩展类实例依赖了其他的扩展点，就进行扩展点的注入 获取自适应扩展点类的Class首先看下获取自适应扩展类的Class方法： 12345678910111213141516171819202122232425262728293031323334private Class&lt;?&gt; getAdaptiveExtensionClass() &#123; /** * getExtensionClasses加载当前扩展点的所有实现 * 比如： * 我们在使用ExtensionLoader.getExtensionLoader(Protocol.class) * 获取Protocol的ExtensionLoader的时候，就已经设置了当前ExtensionLoader * 的类型是Protocol的，所以这里获取的时候就是Protocol的所有实现。 * * 获取到所有的实现之后，getExtensionClasses()返回的是Map&lt;String, Class&lt;?&gt;&gt; * * 另外需要说的是，如果扩展点的实现注解了类级别的@Adaptive注解， * 这些实现的Class加载完后会赋值给cachedAdaptiveClass缓存。如果扩展点的实现 * 是包装类，这些实现的Class加载完后会放到cachedWrapperClasses缓存中。 * 其他的正常的扩展点的实现都会放到Map&lt;String, Class&lt;?&gt;&gt;中返回。 * * 目前只有AdaptiveExtensionFactory和AdaptiveCompiler两个实现类是被注解了@Adaptive * 也就是说这两个就是自适应扩展，如果要加载ExtensionFactory和Compiler的自适应扩展 * 不需要使用自动生成代码，而是直接使用两个实现类就可以了。 * 其他的扩展点如果想要获取自适应扩展实现，就需要继续往下走，使用生成的Xxx$Adaptive代码。 * * 一个扩展点有且只有一个自适应扩展点，要么是内置的两个AdaptiveExtensionFactory和AdaptiveCompiler， * 要么是生成的Xxx$Adaptive */ getExtensionClasses(); /** * 自适应扩展实现，在上面一步加载的时候，就会被加载缓存起来 * 只会执行一次，后面再获取的时候，就是获取缓存起来的这个。 */ if (cachedAdaptiveClass != null) &#123; return cachedAdaptiveClass; &#125; // 没有缓存自适应扩展实现，就动态创建一个 return cachedAdaptiveClass = createAdaptiveExtensionClass();&#125; 获取自适应扩展类的过程参考上面代码的注释即可，继续往下说创建自适应扩展类的方法createAdaptiveExtensionClass()： 12345678910111213private Class&lt;?&gt; createAdaptiveExtensionClass() &#123; /** * 根据具体的接口来生成自适应扩展类的代码 * 比如Protocol就会生成Protocol$Adaptive为名字的类的代码 */ String code = createAdaptiveExtensionClassCode(); // 获取类加载器 ClassLoader classLoader = findClassLoader(); // 获取Compiler的自适应扩展，获取到的是AdaptiveCompiler实例 com.alibaba.dubbo.common.compiler.Compiler compiler = ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.common.compiler.Compiler.class).getAdaptiveExtension(); // 如果我们没有指定名字，默认使用javassist return compiler.compile(code, classLoader);&#125; 这里大概的步骤是： 生成自适应扩展类的代码。 获取类加载器。 获取自适应的Compiler的扩展实现，获取到的AdaptiveCompiler实例，这个在上面已经说过了。 最后使用具体的Compiler进行生成代码的编译。 这里只看第一步，生成自适应扩展类的代码这步，这里代码有点长，不在此贴出来了，参考我的github上ExtensionLoader的源码注释ExtensionLoader.java。 @Adaptive注解这里说下@Adaptive注解，有两种地方使用这个注解： 使用在实现类上 使用在接口的方法上 这两种不能重复使用。如果用在实现类上，一个扩展点的实现类有且只能有一个类使用此注解，比如ExtensionFactory的实现类AdaptiveExtensionFactory使用了此注解，这个类本身就是一个自适应扩展类了；如果用在接口的方法上，表示dubbo框架会在生成该接口的自适应扩展类的时候，生成该方法的代码，如果方法没有添加此注解，则生成抛出不支持异常的代码。 ExtensionFactory到这里获取扩展和获取自适应扩展就已经说完了，接下来可以把最上面留下的ExtensionFactory相关的加载流程说下了，每个ExtensionLoader实例中都会有一个objectFactory实例，而objectFactory实例的赋值都是在ExtensionLoader的构造方法中： 123456789101112131415private ExtensionLoader(Class&lt;?&gt; type) &#123; this.type = type; /** * 对于扩展类型是ExtensionFactory的，设置为null * getAdaptiveExtension方法获取一个运行时自适应的扩展类型 * 每个Extension只能有一个@Adaptive类型的实现，如果么有，dubbo会自动生成一个类 * objectFactory是一个ExtensionFactory类型的属性，主要用于加载扩展的实现 */ objectFactory = ( type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension() );&#125; 可以看到ExtensionFactory的实例获取也是通过扩展点自适应来获取到的，获取到的实例是AdaptiveExtensionFactory。而在AdaptiveExtensionFactory实例化的时候，会通过SPI机制加载所有的ExtensionFactory的实现： 123456789public AdaptiveExtensionFactory() &#123; ExtensionLoader&lt;ExtensionFactory&gt; loader = ExtensionLoader.getExtensionLoader(ExtensionFactory.class); List&lt;ExtensionFactory&gt; list = new ArrayList&lt;ExtensionFactory&gt;(); for (String name : loader.getSupportedExtensions()) &#123; // 保存所有ExtensionFactor y的实现 list.add(loader.getExtension(name)); &#125; factories = Collections.unmodifiableList(list);&#125; 使用objectFactory获取扩展的时候，是调用AdaptiveExtensionFactory的getExtension方法，该方法会遍历所有的ExtensionFactory的实现的getExtension方法： 1234567891011public &lt;T&gt; T getExtension(Class&lt;T&gt; type, String name) &#123; // 依次遍历各个ExtensionFactory实现的getExtension方法 // 找到Extension后立即返回，没找到返回null for (ExtensionFactory factory : factories) &#123; T extension = factory.getExtension(type, name); if (extension != null) &#123; return extension; &#125; &#125; return null;&#125; 共两种实现SpiExtensionFactory和SpringExtensionFactory，如果在任何一个实现中找到了扩展点实现，就返回结束了。 dubbo是自包含的，这个概念通过上面的解析也应该不难理解了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ArrayList的初始容量现在为0，不再是10了]]></title>
      <url>%2F2018%2F10%2F19%2FArrayList%E7%9A%84%E5%88%9D%E5%A7%8B%E5%AE%B9%E9%87%8F%E7%8E%B0%E5%9C%A8%E4%B8%BA0%EF%BC%8C%E4%B8%8D%E5%86%8D%E6%98%AF10%E4%BA%86%2F</url>
      <content type="text"><![CDATA[前言一直记得ArrayList的初始容量大小是10，今天再次看ArrayList的源码（版本：Jdk 7u80）时发现在构造函数的注释上写着初始化容量是10，但是构造函数中却没有指定初始容量，仅仅初始化了一个空的数组。应该是不知道在哪个版本中已经修改了，我却还记着之前从别人口里得来的一句话：初始容量是10。实际上初始容量已经是0了，写出来分享下，有错的地方烦请指出来，说的不一定对。 测试写了下代码来测试下，ArrayList中没有直接获取capacity的方法，只能通过反射获取elementData数组的size来间接获取到capacity。代码如下： 123456789101112131415161718192021222324public class ArrayListCapacityTest &#123; public static void main(String[] args) &#123; ArrayList arrayList = new ArrayList(); System.out.println("capacity: " + getCapacity(arrayList) + " size: " + arrayList.size()); arrayList.add("test"); System.out.println("capacity: " + getCapacity(arrayList) + " size: " + arrayList.size()); arrayList = new ArrayList(11); System.out.println("capacity: " + getCapacity(arrayList) + " size: " + arrayList.size()); &#125; public static int getCapacity(ArrayList arrayList) &#123; try &#123; Field elementDataField = ArrayList.class.getDeclaredField("elementData"); elementDataField.setAccessible(true); return ((Object[]) elementDataField.get(arrayList)).length; &#125; catch (NoSuchFieldException | IllegalAccessException e) &#123; e.printStackTrace(); return -1; &#125; &#125;&#125; 结果如下： 123capacity: 0 size: 0capacity: 10 size: 1capacity: 11 size: 0 分析上面结果也可以看出来，确实是初始容量为0了。接着看下ArrayList的源码（下面所有源码版本为Jdk 7u80）： 1234567 /** * Constructs an empty list with an initial capacity of ten. */public ArrayList() &#123; super(); this.elementData = EMPTY_ELEMENTDATA;&#125; 源码中这注释确实很误导人，构造函数中没有初始化大小。但是现在这样有个问题，数组大小为0， 我怎么添加元素进去？应该就是在add的时候初始化，继续跟进add方法的源码： 123456public boolean add(E e) &#123; // 如果刚初始化ArrayList，size肯定是0 ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125; add方法中第一步先确保容量够用，这里面有可能就是初始化容量的方法，继续跟进ensureCapacityInternal的源码： 123456789private void ensureCapacityInternal(int minCapacity) &#123; // 由上一步知道minCapacity为1 // 这里if的条件也一定为true if (elementData == EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; // 经过上一步之后，minCapacity就等于DEFAULT_CAPACITY，即10。 ensureExplicitCapacity(minCapacity);&#125; 继续跟进ensureExplicitCapacity源码： 12345678private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code // minCapacity此时为10，if条件成立 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125; 继续跟进grow源码： 123456789101112131415private void grow(int minCapacity) &#123; // overflow-conscious code // oldCapacity = 0 int oldCapacity = elementData.length; // newCapacity = 0 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) // newCapacity由上层传来为10 newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: // 这里就是数组初始化为10的地方了 elementData = Arrays.copyOf(elementData, newCapacity);&#125; 源码跟到这里就算完了，确实是在add的时候初始化容量为10。 结论ArrayList的初始化容量已经变了，不再是以前的10了，而是初始化为0，等到第一次add的时候再初始化为10。 做这样的改动，就是延迟初始化ArrayList的实际容量，应该是考虑到空间的问题，如果一开始就初始化为10，这个大小为10的数组中就全部是存的null，如果数量多了，这个也是很大的空间。应该是这样的原因吧。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Lucene中的索引结构]]></title>
      <url>%2F2018%2F06%2F18%2FLucene%E4%B8%AD%E7%9A%84%E7%B4%A2%E5%BC%95%E7%BB%93%E6%9E%84%2F</url>
      <content type="text"><![CDATA[Lucene中的索引结构学习。 Lucene支持两种索引结构：多文件索引结构和复合索引结构。多文件索引结构使用多个文件来表示索引，复合索引结构使用一个特殊的文件来表示。 默认是用的是复合索引结构，可通过设置useCompoundFile=false来启用多文件索引结构。 多文件索引结构通过设置useCompoundFile=false来启用多文件索引结构 1234567891011121314151617_0.dii_0.dim_0.fdt_0.fdx_0.fnm_0.nvd_0.nvm_0.si_0.tvd_0.tvx_0_Lucene50_0.doc_0_Lucene50_0.pay_0_Lucene50_0.pos_0_Lucene50_0.tim_0_Lucene50_0.tipsegments_1write.lock segments_1，段文件，保存了现有索引段的名称以及相关信息，每当IndexWriter向索引提交修改之前，段文件的值会增加1。在访问索引目录中任何文件前，Lucene都会查找该段文件，以确认要打开和读入的索引文件 write.lock，锁文件，可防止多个IndexWriter同时操作同一个索引文件 .si，Segment Info，保存Segment的元数据信息 .fnm，Fields，保存fields的相关信息，包括：是否已被索引、是否允许使用项向量、是否存储norms、是否包含有效负载 .fdx，Field Index，保存指向Field Data的指针 .fdt，Field Data，文档中存储的Field的值 .tim，Term Directory，存储Term信息 .tip，Term Index，到Term Directory的索引 .doc，Frequencies，由包含每个Term以及频率的docs列表组成 .pos，Positions，存储出现在索引中的Term位置信息 .pay，Payloads，存储额外的per-position元数据信息，例如字符偏移和用户payloads .nvd，Norms，保存索引字段加权数据 .nvm，Norms，保存索引字段加权因子的元数据 .tvx，Term Vector Index，将偏移存储到文档数据文件中 .tvd，Term Vector Documents，包含有Term Vectors的每个文档信息 .dii，.dm，Point Values，保留索引点 索引段Lucene索引由一个或多个Segment组成，每个Segment由多个索引文件组成，属于同一个Segment的索引文件具有相同的前缀名 新添加的文档会添加到新创建的索引Segment中，多个Segment周期性的进行合并，该过程提高了效率，最大限度的减少了对物理索引文件的修改。 .fdx和.fdt一个文档中所有Field数据都存在.fdt中，可设置Field.Store.NO不存储这个Field的原始数据。 复合索引结构通过设置useCompoundFile=true来启用多文件索引结构，默认启用，不需要设置。 12345_0.cfe_0.cfs_0.sisegments_1write.lock .cfs、.cfe，Compound File，复合索引文件，所有的索引信息都存在这些文件中 复合索引减少了索引文件数量，把各个独立的索引文件封装在了cfg文件中 其他的文件： .dvd，Per-Document Values，保存索引文档评分数据 .dvm，Per-Document Values，保存索引文档评分因子数据 .tvf，Term Vector Fields，字段级别有关Term Vectors的信息 .liv，Live Documents，哪些文件是有效的文件 参考 Lucene实战]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Lucene中的Query]]></title>
      <url>%2F2018%2F06%2F18%2FLucene%E4%B8%AD%E7%9A%84Query%2F</url>
      <content type="text"><![CDATA[Lucene中的各种Query学习。 Lucene的Query包含：TermQuery、TermRangeQuery、NumbericRangeQuery、PrefixQuery、BooleanQuery、PhraseQuery、WildcardQuery、FuzzyQuery、MatchAllDocsQuery TermQuery通过项进行搜索，对索引中特定项进行搜索，Term是最小的索引片段，Term包含了一个Field Name和一个Field Value。 TermRangeQuery在指定的项范围内搜索，索引中各个Term对象会按照字典编排顺序进行排序。适用于文本范围查询。 NumbericRangeQuery在指定的数字范围内搜索，如果使用NumbericField来索引Field，就可使用NumbericRangeQuery在某个特定范围内搜索该Field。 PrefixQuery通过字符串前缀搜索 BooleanQuery组合查询，可将各种查询组合成复杂的查询方式，可进行逻辑AND、OR、NOT组合。 BooleanClause.Occur.MUST，必须匹配该查询子句 BooleanClause.Occur.SHOULD，该查询自己是可选的 BooleanClause.Occur.MUST_NOT，不包含匹配该查询子句的文档 PhraseQuery通过短语搜索，会根据各个词项的位置信息定位某个距离范围内的词项对应的文档 WildcardQuery通配符查询： *代表0个或多个字母 ?代表0个或1个字母 FuzzyQuery搜索类似项，模糊查询，用于匹配与指定项相似的项。 MatchAllDoscQuery匹配所有文档 参考 Lucene实战]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Lucene中的Segment合并]]></title>
      <url>%2F2018%2F06%2F18%2FLucene%E4%B8%AD%E7%9A%84Segment%E5%90%88%E5%B9%B6%2F</url>
      <content type="text"><![CDATA[Lucene中的Segment合并学习。 如果索引包含Segment太多，IndexWriter会选择其中的一些，将它们合并成一个Segment： 合并后会减少索引中Segment的数量，完成合并后，旧的Segment会被删除。搜索的Segment减少，能加快搜索速度；避免达到操作系统的文件描述打开过多的限制 合并还会减小索引尺寸，如果被合并的Segment中包含挂起的删除操作，合并会释放删除数据占用的空间 Segment合并策略MergePolicy，合并策略的抽象。IndexWriter依赖MergePolicy具体的子类实现来完成合并： LogByteSizeMergePolicy，默认策略，会测量Segment的尺寸，就是Segment包含的所有文件总字节数 LogDocMergePolicy，测量是通过Segment中文档数量来表示 一旦索引级别数达到或超过mergeFactor设定的尺寸，Segment将被合并。 MergeScheduler选取好了需要合并的Segment后，接下来就是真正的合并操作，IndexWriter使用MergeScheduler的子类实现来完成。默认使用ConcurrentMergeScheduler进行，利用后台线程完成合并。SerialMergeScheduler由调用它的线程来完成合并。 参考 Lucene实战]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Lucene中的文档删除]]></title>
      <url>%2F2018%2F06%2F17%2FLucene%E4%B8%AD%E7%9A%84%E6%96%87%E6%A1%A3%E5%88%A0%E9%99%A4%2F</url>
      <content type="text"><![CDATA[Lucene中文档删除的更深入学习。 IndexReader删除文档IndexReader和IndexWriter都可以删除文档： IndexReader能够根据文档号删除文档 IndexReader可通过Term对象删除文档，IndexReader会返回被删除的文档号，IndexReader可以立即决定删除哪个文档；IndexWriter不会返回删除的文档号，因为它仅仅是将被删除的Term进行缓存，后续在进行实际的删除操作 IndexReader删除操作会立即生效，IndexWriter的删除操作必须等到程序打开一个新的Reader时才能被感知 IndexWriter可通过Query删除，IndexReader不行 IndexReader的undeleteAll方法可以反向操作索引中所有被挂起的删除。只能对未进行段合并的文档进行反删除操作。之所以能这样，是因为IndexWriter只是将被删除文档标记为已删除状态，但并未真正移除这些文档，最终的删除操作是在该文档所对应段进行合并时才执行 回收被删除文档所使用的磁盘空间Lucene使用bit数组的形式来标识文档被删除，操作很快，但是对应的磁盘空间仍占用。对于一个倒排索引，给定的文档项可能是分散在各处的，在删除文档时试图回收占用磁盘空间是不实际的，只有在发生段合并操作时，这些磁盘才能被回收。 也可以显式调用expungeDeletes方法来回收被删除文档占用的磁盘空间，该调用会对被挂起的删除操作相关的所有段进行合并 参考 Lucene实战]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Lucene中的索引缓冲、刷新和提交]]></title>
      <url>%2F2018%2F06%2F17%2FLucene%E4%B8%AD%E7%9A%84%E7%B4%A2%E5%BC%95%E7%BC%93%E5%86%B2%E3%80%81%E5%88%B7%E6%96%B0%E5%92%8C%E6%8F%90%E4%BA%A4%2F</url>
      <content type="text"><![CDATA[Lucene中的索引缓冲、刷新和提交学习。 缓冲和刷新创建和删除文档操作时，会先被缓存之内存，而不是立即写盘，这些操作会以 衅端的形式周期性的写入索引的Directory，IndexWriter刷盘操作时机如下： 当缓存占用空间超过设置的阈值，setRAMBufferSizeMB来设置 在指定文档号对应的文档被添加进索引之后，通过调用setMaxBufferedDocs来完成刷新操作 在删除和查询语句等操作占用内存总量超过预设值时，可通过调用setMaxBufferedDeleteTerm方法来触发刷新操作 默认情况下IndexWriter在RAM用量为16M的时候启动刷新操作。 发生刷新操作时，Writer会在Directory目录创建新的段和被删除文件，这些文件对于新打开的IndexReader不可见也不可用，直到Writer提交更改以及重新打开Reader后。 刷新操作是用来释放缓存的更改 提交操作是用来让所有更改在索引中保持可见。 IndexReader所看到的一直是索引的起始状态，也就是IndexWriter被打开时的状态，直到IndexWriter提交更改为止。 索引提交IndexWriter的commit方法调用，都会创建一个新的索引提交，新打开或重启的IndexReader和IndexSearcher只能看到上次提交后的索引状态，IndexWriter在两次提交之间完成的更改对Reader来说不可见。而近实时搜索功能能够在不用首次向磁盘提交更改的情况下对IndexWriter所做的更改进行搜索。 如果需要取消所有更改，可在上一次索引提交更改后，调用rollback方法删除当前IndexWriter包含的所有更改。 IndexWriter的提交步骤： 刷新所有缓存的文档和文档删除操作 对所有新创建的文件进行同步，包括刷新的文件，还包括上一次调用commit方法或从打开IndexWriter后已完成的段合并操作所生成的所有文件。IndexWriter调用Directory.sync方法实现，该方法会在所有挂起的写操作都写到磁盘后才返回 写入和同步下一个segment_X文件，一旦完成，IndexReader会立即看到上一次提交后发生的所有变化。 通过调用IndexDeletionPolicy删除旧的提交。 两阶段提交对于需要提交包括Lucene索引和其他外部资源等事务的应用程序，Lucene提供了prepareCommit方法，该方法完成了上面步骤的前两步或前三部，但不能使新的segment_X文件对Reader可见，调用prepareCommit后还需要调用rollback或commit方法。 索引删除策略IndexDeletionPolicy负责通知IndexWriter何时能够安全删除旧的提交，默认策略KeepOnlyLastCommitDeletionPolicy，会在每次创建完新的提交后删除先前的提交。 参考 Lucene实战]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Lucene中的Directory]]></title>
      <url>%2F2018%2F06%2F17%2FLucene%E4%B8%AD%E7%9A%84Directory%2F</url>
      <content type="text"><![CDATA[Lucene的Directory学习。 Directory提供一个简单的文件类存储API，子类实现如下： SimpleFSDirectory，使用java.io.*API将文件存入文件系统，不能很好的支持多线程操作，如果要支持多线程，需要在内部加锁；不支持按位置读取 NIOFSDirectory，使用nio API将文件保存至文件系统，能支持多线程操作 MMapDirectory，使用内存映射进行文件访问，Java没有提供方法来取消文件在内存中的映射关系，只有在JVM进行垃圾回收时才会关闭文件和释放内存 RAMDirectory，所有文件存入RAM FileSwitchDirectory，使用两个文件目录，根据文件扩展名在两个目录间切换使用 TODO 参考 Lucene实战]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Lucene中的并发、线程安全及锁机制]]></title>
      <url>%2F2018%2F06%2F17%2FLucene%E4%B8%AD%E7%9A%84%E5%B9%B6%E5%8F%91%E3%80%81%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E5%8F%8A%E9%94%81%E6%9C%BA%E5%88%B6%2F</url>
      <content type="text"><![CDATA[Lucene中的并发、线程安全及锁机制学习。 线程安全和多虚拟机安全 任意数量的只读的IndexReader都可以同时打开一个索引同一个索引 对于一个索引，一次只能有一个Writer打开它。Lucene采用文件锁来保障，一旦建立起IndexWriter对象，系统会分配一个锁给它 IndexReader对象可以在IndexWriter对象正在修改索引时打开索引 任意多个线程可以共享同一个IndexReader或IndexWriter 锁机制Lucene采用基于文件的锁。 NativeFSLockFactory，FSDirectory的默认锁，使用nio本地操作系统锁。 SimpleFSLockFactory，使用Java的File.createNewFile API SingleInstanceLockFactory，在内存中创建一个完全的锁，是RAMDirectory默认的锁实现 NoLockFactory，关闭锁机制 这些锁的实现都是不公平的。 参考 Lucene实战]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Lucene中的Field]]></title>
      <url>%2F2018%2F06%2F17%2FLucene%E4%B8%AD%E7%9A%84Field%2F</url>
      <content type="text"><![CDATA[Lucene的Field学习。 Field.Store枚举用来确定一个Field是否需要存储原始值，以便后续搜索时能恢复这个原始数据。 YES，存储原始值，原始的字符串全部被保存在索引中，并且IndexReader可以恢复它。对于需要展示搜索结果的Field很有用，尽量不要存储Field太大的原始数据 NO，不存储原始值，比如说一些正文信息等。 TODO 参考 Lucene实战]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Lucene中的索引过程和基本操作]]></title>
      <url>%2F2018%2F06%2F17%2FLucene%E4%B8%AD%E7%9A%84%E7%B4%A2%E5%BC%95%E8%BF%87%E7%A8%8B%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
      <content type="text"><![CDATA[Lucene索引过程学习。 索引过程1提取数据 -&gt; 分析文本 -&gt; 添加文档到索引 提取文本建立索引数据时，需要先从数据中提取纯文本格式信息。 提取完文档后还需要建立Document文档。 分析文档建立Document和Field后，会对文本进行分析，将文本分割成词项，这一步就是进行分词等操作。比如需要将词项转换为小写，去掉一些stop words等等。 向索引添加文档分析完数据后，就可以将分析结果写入索引文件。存储的时候是使用倒排索引的数据结构进行存储。进行关键字快速查找时，这种数据结构能有效利用磁盘空间。 Lucene索引都包含一个或多个段segment，每个段都是一个独立索引，包含整个文档索引的一个子集。 每个段都包含多个文件，各个独立的文件共同组成了索引的不同组成部分（Term向量、存储的Field、倒排索引等等）。 如果使用了混合文件格式，上面说的索引文件都会被压缩成一个单一的文件，这种方式能够在搜索期间减少打开文件数量。 还有个特殊文件叫段文件，segments_x x=1,2,3...，该文件指向所有激活的segment，Lucene会首先打开该文件，然后打开它所指向的其他文件，其中的x（x=1,2,3…)被称为the generation，是一个整数，Lucene每次向索引提交更改的时候，都会将这个数字加1 IndexWriter会周期性的选择一些segment，将它们合并到一个新segment中，然后删除老的segment 索引基本操作向索引添加文档 addDocument(Document)，添加文档，其中使用的Analyzer在创建IndexWriter时，由IndexWriterConfig中指定。 删除索引中的文档 deleteDocuments(Term...)，删除包含指定词项的文档 deleteDocuments(Query...)，删除匹配查询语句的文档 更新索引中的文档Lucene只能删除整个旧文档，然后向索引中添加新文档。这就要求新文档必须包含旧文档中所有Field，包括未发生变化的Field。 updateDocument(Term, Document)，首先删除包含Term的文档，然后添加新文档 参考 Lucene实战]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Lucene中的基础核心类]]></title>
      <url>%2F2018%2F06%2F17%2FLucene%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A0%B8%E5%BF%83%E7%B1%BB%2F</url>
      <content type="text"><![CDATA[Lucene索引创建和搜索索引的核心类学习。 索引过程中的核心类IndexWriterIndexWriter负责创建新索引或者打开已有索引，向索引中添加、删除、更新被索引文档的信息。IndexWriter需要开辟一定空间来存储索引，由Directory完成。 DirectoryDirectory描述了索引的存放位置，子类负责具体指定索引的存储路径。 AnalyzerAnalyzer负责从被索引文本中提取词汇单元，也就是分词。 DocumentDocument文档，代表一些域Field的集合。包含多个Field对象的容器。 Field索引中的每个文档都包含一个或者多个不同命名的域，这些域包含在Field中，每个域都有域名和对应值 搜索过程中的核心类IndexSearcherIndexSearcher用来搜索由IndexWriter创建的索引。IndexSearcher可看做一个以只读方式打开索引的类，需要利用Directory来找到索引位置。 TermTerm对象是搜索功能的基本单元，包含域名和值 QueryQuery查询，有很多子类：TermQuery、BooleanQuery、PhraseQuery、PrefixQuery、PhrasePrefixQuery、TermRangeQuery、NumbericRangeQuery、FilteredQuery、SpanQuery TermQuery词项查询，用来匹配指定域中包含特定项的文档。 TopDocs是一个简单的指针容器，指针一般指向前N个排名的搜索结果。 ScoreDoc提供对TopDocs中每条搜索结果的访问接口 QueryParser将用户输入的查询表达式处理成具体的Query对象 参考 Lucene实战]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Elasticsearch的基础概念]]></title>
      <url>%2F2018%2F06%2F16%2FElasticsearch%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%2F</url>
      <content type="text"><![CDATA[Elasticsearch基础概念学习。 核心概念 集群，一个或多个ES服务器节点组成集群，一个集群由一个唯一的名字标识，成为cluster name，默认名elasticsearch。具有相同集群名称的节点才会组成一个集群 节点，是一个集群中的一个服务器，可以通过配置集群名称的方式来加入一个指定的集群，有三类：数据data节点，持有数据，提供对数据的搜索功能；主节点master，负责控制其他结点工作，一个集群只有一个主节点；部落结点tribe，可以像桥梁一样连接起多个集群，允许在多个集群上执行类似在单个集群上的功能 索引，文档集合，数据结构是倒排索引。一个索引由一个名字来标识，必须全部小写字母，集群中可定义任意多的索引，ES内部使用Lucene写入或搜索数据 类型，在一个索引中，可以定义一种或多种类型，类型是索引的一个逻辑上的分类或分区，通常会为具有一组共同字段的文档定义一个类型 文档，是一个可被索引的基础信息单元，文档由字段构成。 分片，创建索引的时候可指定分片数量，分片本身是一个功能完善且独立的索引。分片允许水平分割扩展，分片上可进行分布式并行的操作提高性能和吞吐量 副本，分片的一份或多份拷贝，副本不和主分片在同一个节点，保证高可用。 映射，mapping，存储分析链所需要的信息，写入索引的时候可按照映射来存储。 对比RDMS RDMS Elasticsearch 数据库database 索引index 表table 类型type 行row 文档document 列column 字段field 表结构schema 映射Mapping 索引 全文索引 sql 查询DSL select * from table GET http://… update table set PUT http://… delete DELETE http://… 字段类型核心类型 类型 具体类型 字符串类型 string、text、keyword 数字类型 long、integer、short、byte、double、float、half_float、scaled_float 日期类型 date 布尔类型 boolean 二进制类型 binary 范围类型 range string，es5.x之后不再支持string，由text或keyword取代 text，要被全文搜索，字段内容会被分析，被分词器分成词项，生成倒排索引；text类型字段不用于排序，很少用于聚合 keyword，适用于索引结构化的字段，通常用于过滤、排序、聚合，keyword类型字段只能通过精确值搜索到 数字类型，尽可能选择范围小的数据类型，字段长度越短，索引和搜索的效率越高 date，es内部使用长整型毫秒数存储 boolean，true、false binary，接受base64编码的字符串 复合类型 类型 具体类型 数组类型 array 对象类型 object 嵌套类型 nested array，es没有专用数组类型，一个数组中值必须是同一种类型 object，JSON具有层级关系，文档内部包含对象，内部对象还包含内部对象，但是写入到es后文档就会被索引成简单的扁平key-value对 nested，是object类型的一个特例，当对象数组独立索引和查询，Lucene没有内部对象概念，es将对象层次扁平化，转化成字段名字和值构成的简单列表 地理类型 类型 具体类型 地理坐标 geo_point 地理图形 geo_shape geo_point，存储地理位置信息的经纬度，可查找一定范围内的地理位置；通过地理位置或相对中心点距离来聚合文档；把距离因素整合到文档评分中；通过距离对文档排序 geo_shape，可以存储一块区域，比如矩形、三角形等，GeoJSON是一种对各种地理数据结构进行编码的格式 特殊类型 类型 具体类型 IP类型 ip 范围类型 completion 令牌计数类型 token_count 附件类型 attachment 抽取类型 precolator ip，存储IPv4或IPv6的地址 range，range类型使用场景包括时间选择表单、年龄范围选择表单等 token_count，用于统计字符串分词后的词项个数，本质上是一个整形字段 元字段元字段是映射中描述文档本身的字段。 文档属性的元字段 具体属性 作用 _index 文档所属索引 _uid 包含_type和_id的复合字段 _type 文档的类型 _id 文档id _index，多索引查询时，支持对索引名进行term、terms查询、聚合分析、使用脚本和排序。是一个虚拟字段 _type，可根据该元字段进行查询、聚合、脚本和排序 _id，可用于term查询、terms查询、match查询、query_string查询、simple_query_string查询，但不能用于聚合、脚本、排序 _uid，是_type和_id的组合，取值为{type}#{id} 源文档的元字段 具体属性 作用 _source 文档的原始JSON字符串 _size _source字段的大小 索引的元字段 具体属性 作用 _all 包含索引全部字段的超级字段 _field_names 文档中包含非空值的所有字段 路由的元字段 具体属性 作用 _parent 指定文档间的父子关系 _routing 将文档路由到特定分片的自定义路由值 自定义元字段 具体属性 作用 _meta 用于自定义元数据 映射参数 analyzer，用于指定文本段的分词器，对索引和查询都有效 search_analyzer normalizer，用于解析前标准化配置，比如把所有字符转化为小写 boost，用于设置字段的权重 coerce，用于清除脏数据 copy_to，用于自定义_all字段，可以把多个字段的值复制到一个超级字段 doc_values，为了加快排序、聚合操作，在建立倒排索引的时候，额外增加一个列式存储映射，是一种空间换时间的做法 dynamic，用于检测新发现的字段 enabled，ES默认会索引所有字段，有些字段只需要存储，没有查询和聚合的需求，可以使用该参数来控制 fielddata，text字段在查询时会生成一个fielddata数据结构，在字段首次被聚合、排序或者使用脚本的时候生成 format，用于指定日期格式 ignore_above，用于指定字段分词和索引的字符串最大长度，超过最大长度会被忽略，只用于keyword类型 ignore_malformed，可忽略不规则数据 include_in_all，用指定字段的值是否包含在_all字段中 index，指定字段是否索引，不索引就不可搜索 index_options，控制索引时存储哪些信息到倒排索引中 fields，可让同一字段有多种不同的索引方式 norms，用于标准化文档，以便查询时计算文档的相关性 null_value，可让值为null的字段显式的可索引可搜索 position_increment_gap，为支持近似或短语查询，text类型字段被解析的时候会考虑词项的位置信息 properties，类型的映射、普通字段、object类型和nested类型字段都称为properties similarity，用于指定文档评分模型 store，可设置不存储 term_vector，词向量 参考 从Lucene到Elasticsearch全文检索实战 深入理解ElasticSearch]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Lucene总体架构]]></title>
      <url>%2F2018%2F06%2F16%2FLucene%E6%80%BB%E4%BD%93%E6%9E%B6%E6%9E%84%2F</url>
      <content type="text"><![CDATA[Lucene基础学习。 基础概念 文档document，索引和搜索的主要数据载体，包含一个或多个字段，存放写入索引的数据 字段field，文档的一个片段，包含字段名称和字段内容 词项term，搜索时的一个单位，代表文本中的一个词 词条token，词项在field文本中的一次出现包括词项的文本、开始和结束的偏移以及词条类型 每个索引由多个段segment组成，每个段写入一次但可查询多次。索引期间一个段创建以后不可再修改，文档被删除后删除信息单独保存在一个文件中，段本身没有被修改。 多个段将会在段合并阶段被合并在一起，或者强制执行段合并，或者由Lucene内在机制触发段合并。合并后段数量变少，段大小可能变大。 段合并非常耗I/O，合并期间会清理掉被删除的文档。 文档文档是Lucene索引基本单位，比文档更小的单位是字段，字段由三个部分组成： name type value Lucene字段类型 TextField，字段内容会被索引并词条化，但不保存词向量 StringField，只会对该字段内容索引，不词条化，也不保存词向量，字符串值会被索引为一个单独的词项 IntPoint，适合索引值为int类型的字段 LongPoint，long类型 FloatPoint，float类型 DoublePoint，double类型 SortedDocValuesField，存储多值域的DocValues字段，适合索引字段值为文本并且需要按值进行分组、聚合等操作字段 NumbericDocValuesField，存储单个数值类型的DocValues字段 SortedNumbericDocValuesField，存储数值类型的有序数组列表的DocValues字段 StoredField，适合索引只需要保存字段值不进行其他操作的字段 参考 从Lucene到Elasticsearch全文检索实战 深入理解ElasticSearch]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Elasticsearc之信息检索基础概念]]></title>
      <url>%2F2018%2F06%2F16%2FElasticsearch%E4%B9%8B%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%2F</url>
      <content type="text"><![CDATA[信息检索基础概念学习，包括分词算法、倒排索引等等。 分词算法英文分词原理：输入文本、词汇分隔、词汇过滤（去除停留词）、词干提取（形态还原）、大写转小写、结果输出 中文分词原理，中文分词主要有三种方法： 基于词典匹配的分词 基于语义理解的分词 基于词频统计的分词 词典匹配分词按照一定的匹配策略将输入的字符串与机器字典词条进行匹配，实际上就是把一个句子从左向右扫描一遍，遇到字典中有的词就标识出来，遇到复合词就找到最长的次匹配，遇到不认识的字串则切分成单个单词。 常用词典分词方法： 正向最大匹配，从左到右方向 逆向最大匹配，从右到左方向 最少切分，每一句中切除的词数最小 语义理解分词模拟人脑对语言和句子的理解，达到识别词汇单元的效果。基本模式是把分词、句法、语义分析并行进行，利用句法和语义信息来处理分词的歧义。 词频统计分词词频统计分词方法只需要对语料中的字组频度进行统计，不需要切分词典。 倒排索引Inverted Index，也被称为反向索引，用来存储在全文搜索下某个单词在一个文档或一组文档中的存储位置的映射。 布尔检索模型布尔检索法是指利用布尔运算符连接各个检索词，由计算机进行逻辑运算，找出所需信息的一种检索方法。 有三种逻辑运算： AND* OR+ NOT- 优先级：NOT &gt; AND &gt; OR tf-idf权重计算tf-idf，词频-逆文档频率，用以计算词项对于一个文档集或一个语料库中的一份文件的重要程度。词项在一篇文档中出现的频率非常高，说明其重要性比较高，如果这个词项在文档集中的其他文档出现的频率也很高，说明这个词语可能是比较通用比较常见的。 tf（term frequency），词项频率，词在整篇文档中出现的次数。$$词频(tf_{t, d}) = \frac{单词在文档中的出现次数}{文档的总次数}$$Lucene采用了另外一种词频标准化方法：$$词频(tf_{t, d}) = \sqrt{单词在文档中的出现次数}$$ df（document frequency），文档频率，代表文档集中包含某个词的所有文档数目。df通常比较大，把它映射到一个较小的取值范围，用逆文档频率idf（inverse document frequency）来表示。$$逆文档频率(idf_t) = log(\frac{文档集总的文档数}{包含某个词的文档数+1})=log(\frac{N}{df_t + 1})$$上式中分母越大，说明词越常见，逆文档频率越小。分母加1是为了防止文档不包含某个词时分母为0的情况。 词项权重TF-IDF计算公式：$$tf-idf = 词频(tf_{t, d}) * 逆文档频率(idf_t)$$ 向量空间模型数学、数学 概率检索模型概率检索模型从概率排序原理推导而来，基本思想：给定一个查询，返回的文档能够按照查询和用户需求的相关性得分高低来排序。 数学、数学 参考 从Lucene到Elasticsearch全文检索实战 深入理解ElasticSearch]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Kafka中的事务]]></title>
      <url>%2F2018%2F05%2F25%2FKafka%E4%B8%AD%E7%9A%84%E4%BA%8B%E5%8A%A1%2F</url>
      <content type="text"><![CDATA[Kafka的事务学习。 消息中间件一般有三种交付语义： at most once，最多一次，消息可能会丢失，但是不会重复 at least once，最少一次，消息不会丢失，但可能会重复 exactly once，恰好一次，消息肯定并且只会被传输一次 Kafka的消息生产者提供的交付语义是at least once： 消息不会丢失：一旦消息被提交到日志文件，由于有多副本机制存在，消息就不会丢失 消息可能重复：发送消息后由于网络问题，生产者可能会重试消息发送，会导致消息重复写入 消费者交付语义和消费者处理消息提交消费位移的顺序有关： 消费者拉取完消息后，先处理消息再提交消费位移，可能在提交位移之前宕机，消费者重新上线后会从上一次位移提交位置拉取消息，出现重复消费，这对应了at least once 消费者拉取完消息后，先提交消费位移再处理消息，提交完位移后宕机，重新上线后，会从已经提交的位移处重新消费，发生消息丢失，这对应了at most once Kafka从0.11.0.0开始引入幂等和事务，来实现exactly once semantics（EOS）。 幂等生产者幂等性： 每个新生产者实例在初始化的时候会被分配一个PID（Producer Id） 每个PID发送消息到每个分区都有对应的序列号，序列号从0开始单挑递增，生产者每发送一条消息，就会将&lt;PID, 分区&gt;对应的序列号加1。序列号会被保存在日志中，即使分区Leader副本挂掉，新选出来的Leader也能执行消息去重。 Broker端： Broker会在内存中为每一对&lt;PID, 分区&gt;维护一个序列号，收到消息时，只有当他的序列号值比Broker中维护的序列号值大1，才会接收该消息。 Kafka幂等只能保证单个生产者中单分区的幂等。 事务幂等性不能跨分区，事务可以弥补，事务保证对多个分区写入操作的原子性。 为了实现事务，生产者应用程序必须提供一个唯一的transactionId。 消费者事务保证的语义比较弱，Kafka不能保证已提交的事务中所有消息都能被消费： 采用了日志压缩策略，事务中某些消息，比如相同key的可能会被清理掉 事务消息可能在同一分区的多个日志段中，老的日志段被删除时，对应消息可能会丢失 消费者可通过seek方法访问任意offset消息，可能漏掉事务中部分消息 消费者消费时，可能没有分配到事务内所有分区，就不能读取事务中所有消息 日志文件中还有一种消息，叫做控制消息，一种有两种类型：COMMIT和ABORT，用来表示事务已经成功提交或被成功终止。消费者可通过这个消息来判断对应事务是被提交还是被终止了。 Kafka还引入了事务协调器（TransactionCoordinator）来负责处理事务，每个生产者都会被指派一个特定的TransactionCoordinator，所有事务逻辑包括分派PID都由事务协调器来负责，事务协调器会把事务状态持久化到内部Topic__transaction_state中。 流程： 查找事务协调器 获取PID 开启事务 执行 提交或终止事务 查找事务协调器生产者会先找到事务协调器所在的Broker，Kafka收到FindCoordinatorRequet请求后，根据transactionId查找到对应的事务协调器节点，找到分区以及此分区的Leader副本所在Broker节点。 获取PID找到事务协调器节点后，需要为生产者分配一个PID。事务协调器收到InitProducerIdRequest 后，会把transactionId和对应的PID以消息的形式保存到Topic__transaction_state中。 开启事务生产者通过beginTransaction方法开启事务，生产者本地会标记已经开启了一个新事务，生产者发送第一条消息后，事务协调器才认为事务已经开启 执行 生产者给新分区发送消息前，会先向事务协调器发送AddPartitionsToTxnRequest请求，事务协调器会把&lt;transactionId, TopicPartition&gt;对应关系存储在主题__transaction_state中 生产者发送消息 生产者调用sendOffsetsToTransaction方法，可以再一个事务批次里处理消息的消费和发送，会先向事务协调器节点发送AddOffsetsToTxnRequest，事务协调器会将分区保存在__transaction_state中；之后生产者会发送TxnOffsetCommitRequest请求给事务协调器，将本次事务中包含的位移信息保存在主题__consumer_offset中。 提交或终止事务生产者可调用commitTransaction方法或abortTransaction方法来结束当前事务： 生产者发送EndTxnRequest到事务协调器节点，事务协调器会将PREPARE_COMMIT或PREPARE_ABORT消息写入__transaction_state主题中 事务协调器向事务中各个分区的Leader节点发消息，通过WriteTxnMarkerRequest请求将COMMIT或ABORT写入用户所使用的普通主题和__consumer_offsets中，写入的是控制消息，用来标识事务的终结。 将COMPLETE_COMMIT或COMPLETE_ABORT写入到主题__transaction_state中 参考 Apache kafka实战 深入理解Kafka：核心设计与实践原理]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Kafka为什么这么快]]></title>
      <url>%2F2018%2F05%2F25%2FKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB%2F</url>
      <content type="text"><![CDATA[Kafka的高吞吐量和低延迟，速度快，原因大概是：顺序写盘、内存映射、页缓存、零拷贝、批量发送。 顺序写盘Kafka采用顺序写盘的方式，文件追加来写入消息，避免随机磁盘访问，所以写文件是很快的。 页缓存、内存映射文件Kafka大量使用操作系统页缓存，把磁盘中的数据缓存到内存中，把对磁盘的访问转换为对内存的访问。进程准备读取磁盘上的文件内容时，操作系统会先查看数据是否在页缓存中，如果命中直接返回，避免了对磁盘IO操作，没有命中的话，操作系统会向磁盘发起读请求并将读取的数据存入页缓存，再返回给进程。 写操作会把数据写入到操作系统的页缓存中，操作系统负责刷盘任务。 零拷贝零拷贝技术，就是指将数据从磁盘文件复制到网卡设备中，不需要经由应用程序转发，减少内核和用户模式的上下文切换。 如果不使用零拷贝，读取数据的过程如下： 操作系统从磁盘读取数据，写到内核空间读缓冲区中 应用程序从内核空间将数据读取到用户空间缓冲区 应用程序将数据写回到内和空间的Socket缓冲区 操作系统将Socket缓冲区中的数据拷贝到网卡缓冲区中 如果使用零拷贝，数据会从内核空间的读缓冲区直接拷贝到Socket缓冲区，再拷贝到网卡缓冲区中。省去了写入到用户空间和从用户空间拷贝的时间。 批量发送Kafka在发送消息的时候，会将消息缓存到消息累加器中，然后缓存的消息可以进行批量发送，从而减少网络传输带来的资源消耗。 参考 Apache kafka实战 深入理解Kafka：核心设计与实践原理]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Kafka中的副本]]></title>
      <url>%2F2018%2F05%2F23%2FKafka%E4%B8%AD%E7%9A%84%E5%89%AF%E6%9C%AC%2F</url>
      <content type="text"><![CDATA[Kafka的副本学习。 Kafka分区本质上是一个备份日志，利用多份相同的备份共同提供冗余机制来保持系统高可用性。这些备份称为副本replica。 Kafka会把分区的所有副本均匀的分配到所有Broker上，并从这些副本中选一个作为Leader对外提供读写服务，其他的副本是Follower副本，只能向Leader请求数据，保持与Leader的同步。 如果Leader副本宕机，Follower副本会竞争成为新的Leader，但不是所有的Follower都有资格去成为Leader，对于落后Leader太多的是没有资格竞选Leader的。 ISRISR in-sync replicas，Kafka集群动态维护一组同步副本集合，每个Topic分区都有自己的ISR列表，ISR中所有副本都与Leader保持同步状态，Leader副本总是在ISR列表中。 只有在ISR中的副本才有资格选举为Leader。Producer写入的一条消息只有被ISR中所有副本都接收到，才被视为已提交。 参考 Apache kafka实战 深入理解Kafka：核心设计与实践原理]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Kafka中的负载均衡]]></title>
      <url>%2F2018%2F05%2F20%2FKafka%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
      <content type="text"><![CDATA[Kafka的负载均衡学习。 生产者发消息的负载均衡生产者发消息时，会根据Partition的策略来决定将消息发往哪个分区： 如果消息中指定了partition字段，就往指定的这个分区中发消息 如果没有指定partition，需要依赖分区器，根据key来计算partition的值。可以使用Kafka默认分区器或者我们自定义分区器 Kafka默认分区器默认分区器是DefaultPartitioner： 如果key不为null，默认对key进行哈希计算，来得到分区号。可以保证相同的key被发送到相同分区上 如果key为null，消息将以轮询的方式发送到主题的各个可用分区。 消费者的负载均衡消费者客户端可以使用partition.assignment.strategy来设置消费者与订阅主题之间的分区分配策略，有三种分区分配策略：RangeAssignor、RoundRobinAssignor、StickyAssignor，默认是RangeAssignor RangeAssignor，按照消费者总数和分区总数进行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，保证分区尽可能均匀的分配给所有消费者。会将消费组内所有订阅了这个主题的消费者按照名称字典序排序，然后为每个消费者划分固定的分区范围，如果不够平均分配，靠前的消费者会被多分配一个分区 RoundRobinAssignor，将消费组内所有消费者以及消费者订阅的主题分区按照字典序排序，通过轮询的方式将各个分区一次分配给每个消费者。 StickyAssignor，这种分配策略尽可能均匀分配、重分配时分配的分区尽可能与上次分配的保持相同。 再均衡/重平衡 新版消费者客户端，每个消费组在服务端对应一个GroupCoordinator，GroupCoordinator用于管理消费组的组件。消费者客户端中的ConsumerCoordinator组件负责与GroupCoordinator进行交互。 触发消费者再均衡的操作 消费组成员发生变化，有新的消费者加入消费组；消费者宕机下线，真的宕机或者长时间GC、网络延迟导致心跳失败，GroupCoordinator会认为消费者已下线；有消费者主动退出消费组，发送LeaveGroupRequest请求，比如客户端取消对某些主题的订阅 消费组对应的GroupCoorinator节点发生了变更 消费组订阅的任一主题或主题分区数量发生变化 再均衡的流程 消费组先确定GroupCoordinator所在的Broker，并和Broker建立连接 加入组 同步更新分配方案 确定GroupCoordinator位置消费组在执行rebalance之前会先确定GroupCoordinator所在的Broker，创建和该Broker的连接。确定GroupCoordinator的算法和确定offset被提交到__consumer_offsets的算法相同。 加入组消费者组内的所有的消费者向GroupCoordinator发送JoinGroup请求。当收集完JoinGroup请求后，GroupCoordinator会从中选择一个消费者作为消费者组的Leader，把所有成员信息以及它们的订阅信息发送给这个Leader。 同步更新分配方案上一步选出来的消费者Leader开始指定分配方案，根据分配策略（range、round robin、sticky）决定每个消费者都负责哪些topic的哪些分区。分配完成后，Leader会把这个分配方案封装进SyncGroup请求发送给GroupCoordinator，GroupCoordinator接收到分配方案后，把属于每个消费者的方案单独抽取出来作为SyncGroup请求的response返还给各自的消费者。 参考 Apache kafka实战 深入理解Kafka：核心设计与实践原理]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Kafka中的日志存储]]></title>
      <url>%2F2018%2F05%2F19%2FKafka%E4%B8%AD%E7%9A%84%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8%2F</url>
      <content type="text"><![CDATA[Kafka的日志存储学习。 日志索引kafka中的索引文件以稀疏索引的方式构造消息索引，不保证每个消息在索引文件中都有对应索引项，每当写入一定量的消息时，偏移量索引文件和时间戳索引文件分别增加一个索引项。 稀疏索引通过MappedByteBuffer将索引文件映射到内存中，以加快索引的查询速度。 磁盘存储 Kafka在设计时采用文件追加的方式来写入消息，属于典型的顺序写盘操作。 页缓存技术 零拷贝，直接从磁盘文件复制到网卡设备中，不需要经过应用程序。 参考 Apache kafka实战 深入理解Kafka：核心设计与实践原理]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Kafka中的主题和分区]]></title>
      <url>%2F2018%2F05%2F15%2FKafka%E4%B8%AD%E7%9A%84%E4%B8%BB%E9%A2%98%E5%92%8C%E5%88%86%E5%8C%BA%2F</url>
      <content type="text"><![CDATA[Kafka的主题和分区学习。 主题和分区是逻辑上的概念 分区可以有一到多个副本，每个副本对应一个日志文件，每个日志文件对应一到多个日志分段LogSegment，每个日志分段还可细分为索引文件、日志存储文件、快照文件。 分区使用多副本机制提升可靠性，只有leader副本对外提供读写服务，follower副本只负责在内部进行消息同步。如果一个分区的leader副本不可用，Kafka会从剩余的follower副本中挑选一个新的leader副本来继续对我提供服务 参考 Apache kafka实战 深入理解Kafka：核心设计与实践原理]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Kafka中的Consumer]]></title>
      <url>%2F2018%2F05%2F13%2FKafka%E4%B8%AD%E7%9A%84Consumer%2F</url>
      <content type="text"><![CDATA[Kafka的Consumer学习。 Consumer，消费者，负责订阅Kafka中的Topic，从订阅的主题上拉取消息 Consumer Group，消费组，每个消费者都有一个对应的消费组，消息发布到主题后，只会被投递给订阅它的每个消费组中的一个消费者 如果所有消费者都属于同一个消费组，所有消息会被均衡的投递给每一个消费者，每条消息只会被一个消费者处理，相当于是点对点模式 如果所有消费者都隶属于不同的消费组，所有消息都会被广播给所有消费者，每条消息都会被所有消费者处理，相当于发布订阅模式 反序列化，Deserializer 消息消费消息消费 一般有：推模式和拉模式，推模式是服务端主动将消息推送给消费者；拉模式是消费者主动向服务端发起请求来拉取消息。 Kafka的消费是基于拉模式的。 消费者消费到的每条消息的类型为CnsumerRecord ConsumerRecords表示一次拉取所获得的消息集，内部包含了若干ConsumerRecord 位移提交消费者端调用poll方法时，返回的是还没有被消费的消息集，这就需要记录上一次消费时的消费位移，并且需要做持久化。旧的消费者客户端中，消费位移是存储在Zookeeper中，新的消费者客户端，消费位移存储在Kafka内部主题__consumer_offsets中，把消费位移持久化的动作称为提交。消费者再消费完消息之后需要执行消费位移的提交。 控制或关闭消费KafkaConsumer提供了对消费速度进行控制的方法，pause和resume方法。 指定位移消费Kafka中当消费者查找不到所记录的消费位移时，会根据消费者客户端参数auto.offset.reset的配置来决定从何处开始消费： latest，从分区末尾开始消费消息 earliest，从起始处开始消费 none，找不到消费位移，会抛异常 seek方法可以指定分区和位移，来实现从指定的唯一处开始消费。 参考 Apache kafka实战 深入理解Kafka：核心设计与实践原理]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Kafka中的Producer]]></title>
      <url>%2F2018%2F05%2F13%2FKafka%E4%B8%AD%E7%9A%84Producer%2F</url>
      <content type="text"><![CDATA[Kafka的Producer学习。 序列化，生产者需要用序列化器Serializer把对象转化成字节数组，才能通过网络发送给Kafka 分区器，Partitioner，为消息分配分区，默认分区器DefaultPartitioner，key不为null，会对key进行哈希来计算分区号；如果key为null，消息会以轮询的方式发往主题内各个可用分区 拦截器，Interceptor Producer架构 RecordAccumulator，消息累加器或者消息收集器，用来缓存消息，以便Sender线程可以批量发送，减少网络传输的消耗提升性能。RecordAccumulator内部为每个分区维护一个双端队列，发送的消息都被追加到双端队列中，队列中内容是ProducerBatch，ProducerBatch中包含一个或多个ProducerRecord。 Sender，会从RecordAccumulator中获取缓存的消息，将消息发送出去 Request，是Kafka的各种协议请求，这里是ProduceRequest InFlightRequests，用来缓存已经发出去但还没有收到响应的请求 Producer是线程安全的，可以在多线程环境中复用。 参考 Apache kafka实战 深入理解Kafka：核心设计与实践原理]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Kafka中的Broker]]></title>
      <url>%2F2018%2F05%2F03%2FKafka%E4%B8%AD%E7%9A%84Broker%2F</url>
      <content type="text"><![CDATA[Kafka的Broker学习。 Broker主要功能是持久化消息和将消息队列中的消息从发送端传输到消费端。 消息设计Kafka消息实现方式本质使用ByteBuffer保存消息，同时依赖文件系统提供的页缓存机制，不依靠Java的堆缓存。ByteBuffer是紧凑的二进制字节结构，不需要padding操作，省去了很多不必要的对象开销。 V0消息格式 CRC，4字节，CRC校验码 magic，1字节，版本号，V0、V1、V2分别是0、1、2 attribute，1字节，属性，目前只使用低3位表示消息压缩类型 key长度，4字节，未指定key为-1 key值 value长度，4字节，未指定value为-1 value值 V1消息格式 V1增加了时间戳信息 attribute字段第4位用于指定时间戳类型 V0、V1日志项格式 V2消息格式 消息总长度 时间戳增量，不再使用8字节保存时间戳信息，而是保存增量 位移增量 消息头部，用来满足一些定制化需求 去除消息级CRC校验 废弃attribute字段 V2 batch格式 CRC，消息级的CRC移除，放入batch attribute，消息级的attribute被废弃。低3位保存压缩类型，第4位保存时间戳类型，5、6位保存事务类型和控制类型 集群管理Kafka支持自动化服务发现和成员管理，是基于Zookeeper实现，当一个Broker启动的时候会将自己注册到Zookeeper下的一个节点。 副本和ISRKafka分区本质上是一个备份日志，利用多份相同的备份共同提供冗余机制来保持系统高可用性。这些备份称为副本replica。 Kafka把分区所有副本均匀的分配到所有broker上，并从这个副本中挑选一个作为leader副本对外提供服务，其他副本称为follower副本，只能被动向leader副本请求数据，保持和leader的同步。 ISR，in-sync replicas，是Kafka集群动态维护的一组同步副本集合，每个topic分区都有自己的ISR列表，ISR中的所有副本都于leader保持同步状态，leader副本总是包含在ISR中的，只有ISR中的副本才有资格被选举为leader。Producer写入的一条消息只有被ISR中所有副本都接收到，才被视为已提交状态。 参考 Apache kafka实战]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Kafka概要]]></title>
      <url>%2F2018%2F05%2F01%2FKafka%E6%A6%82%E8%A6%81%2F</url>
      <content type="text"><![CDATA[初识Kafka。 Kafka设计初衷是为了解决互联网公司超大量级数据的实时传输，需要考虑以下问题： 吞吐量、延时，每次写操作会把数据写到OS的页缓存中，OS负责刷盘，Kafka采用追加方式，避免磁盘随机写操作；消费的时候读取消息会尝试从OS的页缓存中读取，命中缓存后直接发送到Socket上，就是零拷贝技术。 消息持久化 负载均衡、故障转移 伸缩性 基本概念 Zookeeper集群，kafka用Zookeeper来负责集群元数据管理、控制器的选举等操作 Producer，生产者，负责创建消息，投递到Kafka中 Consumer，消费者，消费消息，连接到Kafka接收消息 Broker，服务代理节点，负责存储消息 Topic，消息以主题为单位归类，是一个逻辑概念，代表一类消息，通常可使用topic来区分实际业务。 topic通常会被多个消费者订阅。 Partition，分区，主题是逻辑概念，可以细分为多个分区，一个分区只属于单个主题。同一主题下的不同分区包含消息是不同的，partition是不可修改的有序消息序列。用户对partition唯一能做的操作就是在消息序列尾部追加写入消息。partition上的每条消息都会被分配一个唯一的序列号，叫做位移offset Offset，topic的partition下每条消息都被分配一个唯一的offset，消费端也有offset概念，用来表示消费partition的消费进度。 Replica，Kafka的备份日志称为副本replica，防止数据丢失。副本分为两类：领导者副本leader replica和追随者副本follower replica。follower replica不负责响应客户端发来的消息写入和消费者请求，只是被动的向leader replica获取数据。leader replica所在broker宕机时，Kafka会从剩余的replica中选举新的leader继续提供服务 Leader，leader对外提供服务 Follower，follower被动追随leader状态，保持与leader同步，当做leader后备。leader挂掉后就会有一个follower备选举成新的leader。 ISR，ISR是in-sync replica，与leader replica保持同步的replica集合。Kafka为partition动态维护一个replica，该集合中所有replica保存的消息日志都与leader replica保持同步，只有这个集合中的replica才能被选举为leader，只有该集合中所有replica都接到了同一条消息，Kafka才会认为消息是已提交状态，也就是消息发送成功。如果replica落后于leader replica的进度，当达到一定程度时，Kaffka会将这些replica踢出ISR，当这些replica追上了leader进度时，Kafka会将他们加入到ISR中。 HW，Hight Watermark，高水位，标识了一个特定的消息偏移量，消费者只能拉取到这个offset之前的消息 LEO，Log End Offset，标识当前日志文件中下一条待写入消息的offset 消息消息由消息头部、key、value组成： CRC，4字节 版本号，1字节 属性，1字节 时间戳，8字节 key长度，4字节 key，k个字节，消息键，对消息做partition时使用，决定消息保存在某个topic下的哪个partition value长度，4字节 value，v个字节，消息体，保存实际的消息数据 Kafka使用紧凑的二进制字节数组来保存消息，没有多余的比特位浪费。 使用场景适合处理生产环境中流式数据： 消息传输 网站行为日志追踪 审计数据收集 日志收集 Event Sourcing 流式处理 参考 Apache kafka实战 深入理解Kafka：核心设计与实践原理]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL的覆盖索引]]></title>
      <url>%2F2018%2F04%2F20%2FMySQL%E7%9A%84%E8%A6%86%E7%9B%96%E7%B4%A2%E5%BC%95%2F</url>
      <content type="text"><![CDATA[MySQL的覆盖索引学习。 如果一个索引包含所有需要查询的字段，称为覆盖索引。只需要扫描索引无需回查表就可以得到需要的数据。 优点： 索引项通常比记录小，只访问索引可以得到数据，无需再回表操作，减少IO次数，提高速度 索引都按值的大小顺序排序，相对于随机访问记录，需要的IO次数更少 大多数引擎能缓存索引，比如MyISAM只缓存索引 InnoDB使用聚集索引组织数据，如果二级索引中包含查找所需数据，就不需要再聚集索引中再次查找了 覆盖索引必须要存储索引列的值，哈希索引和Full-Text索引不存储值，不能使用覆盖索引。 如果要使用覆盖索引，不可以使用select * ，而要使用指定的列。 不能使用的情况： 如果select选择的字段中有不在索引中的字段，则不能选择覆盖查询。 where条件中如果有对索引进行like的操作，不能使用 参考 https://blog.csdn.net/jh993627471/article/details/79421363 https://www.cnblogs.com/chenpingzhao/p/4776981.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL的事务和实现]]></title>
      <url>%2F2018%2F04%2F19%2FMySQL%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%92%8C%E5%AE%9E%E7%8E%B0%2F</url>
      <content type="text"><![CDATA[MySQL的事务和实现学习。 事务四个特性ACID： Atomicity原子性 Consistency一致性 Isolation隔离性 Durability持久性 原子性在一个事务中的一系列操作要么全部都执行，要么都不执行。事务的原子性需要保证在发生异常或者用户执行rollback操作时，对已经执行的操作进行回滚。 InnoDB原子性是使用undo log来实现的，undo log是实现事务原子性和隔离性的基础。 事务对数据库的修改操作都会先记录到undo log中，然后再对数据库的数据进行操作，如果事务执行失败或者用户执行rollback导致事务需要回滚，就可以利用undolog中的信息将数据回滚到之前的样子。 undo log会先于数据持久化到硬盘上。undo log属于逻辑日志，记录的是sql执行的相关信息。发生回滚操作时，InnoDB会根据undo log的内容做与之前相反的工作。 持久性一旦数据库事务被提交，数据一定会被写入到数据库中并持久化存储。也就是如果数据被写入到数据库中，那么数据也一定能够被安全的存储到磁盘上。 事务的持久性是通过redo log来实现，redo log由两部分组成： 内存中的redo log缓冲区 磁盘中的redo log文件 MySQL数据存储是在磁盘上的，如果每次读写数据都需要磁盘IO，效率会很低，因此InnoDB提供了缓存，缓存中包含了磁盘中部分数据页的映射，当更新数据时，会先写缓存，缓存中的数据会定期刷新到磁盘中，如果发生宕机，没有写到磁盘中的数据就可能会丢失，这样就没办法保证事务的持久性。InnoDB使用redo log来保证事务的持久性。 在一个事务中更新数据时，会先更新内存缓存中的数据，然后生成一条redo log并写入到redo log缓冲区中，当事务提交的时候会调用fsync先把redo log缓冲区中的内容刷新到redo log文件中，再将内存中的数据更新到磁盘上。 InnoDB中redo log都是以512字节的块形式进行存储，块大小和磁盘扇区大小一样，redo log日志的写入可以保证原子性。 数据库的修改会产生redo log，undo log也需要持久化，所以undo log也会创建对应的redo log。 undo log和redo log能保证： 发生错误或者需要回滚的事务能够成功回滚（ 原子性） 在事务提交后，数据没来得及写盘就宕机时，在下次重新启动后能够成功恢复数据（持久性） 事务提交的时候需要将redo log写入磁盘，但为什么比把缓存中数据修改写入磁盘要快呢？主要原因： 脏数据的刷盘操作是随机IO，redo log是顺序IO，顺序IO比随机IO效率要高很多 脏数据是以数据页Page为单位，MySQL默认页是16KB，一个Page上的一个小修改都需要将整个页写入，redo log是512字节的块，大小和扇区大小一样，并且只包含真正需要写入的部分，无效IO会大大减少 隔离性原子性和持久性侧重于事物本身，隔离性则是不同事物之间的相互影响。隔离性是指事物内部操作与其他事务是隔离的，并发执行的各个事务之间不能相互干扰。严格的隔离性对应事务隔离级别中的Serializable，但实际应用中出于性能考虑很少使用Serializable，大多数数据库默认隔离级别Read Committed，InnoDB则默认使用Repeatable Read。 四个隔离级别 Read Uncommited，使用查询语句不会加锁，会读到其他事务未提交的行，脏读Dirty Read Read Commited，只对记录加记录锁，不会在记录之间加间隙锁，多次查询会得到不同结果，不可重复读 Repeatable Read，多次读取同一范围的数据会返回第一次查询的快照，不会返回不同的数据行，但可能发生幻读 Serializable，InnoDB会隐式的将全部查询语句加上共享锁，可以解决幻读问题 数据库对隔离级别的实现是使用并发控制机制对在同一时间执行的事务进行控制。 并发控制机制 锁，在事务中对需要访问的数据加锁，读锁可保证读操作的并发执行，写锁保证更新数据库时不会有其他事务访问 时间戳，乐观锁 MVCC、快照隔离，通过多版本并发控制维护多个版本数据 InnoDB中使用的机制是锁和MVCC 一个事务写操作对另一个事务写操作的隔离使用锁机制保证 一个事务写操作对另一个事务读操作的隔离使用MVCC保证 锁机制隔离性要求同一时刻只能有一个事务对数据进行写操作，锁机制是在事务开始修改数据前需要先获取锁（行锁或表锁），获取锁后事务就可以修改数据，在本事务操作期间，数据是锁定的，其他的事务要想修改这些数据，需要阻塞等待本事务提交事务或者回滚事务。 MVCCInnoDB中Repeatable Read解决了脏读、不可重复读、幻读等问题，是使用MVCC来解决的，在同一时刻不同事务读取到的数据可能是不同版本。 MVCC读不加锁，读写不冲突，并发性能好。InnoDB的MVCC实现主要通过数据的隐藏列和undo log来实现，隐藏列包含该行数据版本号、删除版本号、执行undo log的指针等。 InnoDB通过Next-Key Lock解决幻读问题，Next-Key Lock是行锁和间隙锁结合，会锁定记录本身也会锁定一个范围。 一致性一个事务原子的在一个一致的数据库中独立运行，执行事务之后，数据库的状态一定是一致的。 一致性是事务追求的最终目标，原子性、持久性、隔离性都是为了保证数据状态的一致性。应用实现方面也需要保证一致性。 参考 https://draveness.me/mysql-transaction/ https://www.cnblogs.com/kismetv/p/10331633.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL的一致性读、快照读、锁定读、当前读]]></title>
      <url>%2F2018%2F04%2F18%2FMySQL%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7%E8%AF%BB%E3%80%81%E5%BF%AB%E7%85%A7%E8%AF%BB%E3%80%81%E9%94%81%E5%AE%9A%E8%AF%BB%E3%80%81%E5%BD%93%E5%89%8D%E8%AF%BB%2F</url>
      <content type="text"><![CDATA[MySQL的一致性读、快照读、锁定读、当前读学习。 一致性读（快照读）一致性读，也称为快照读，读取的是快照版本。普通的select是快照读。在事务中select的时候会生成一个快照，不同隔离级别生成快照的时机不一样： Read Committed隔离级别，在一个事务中每次读取都会重新生成一个快照，每次快照都是最新的，所以当前事务中每次select操作都可以看到其他已提交事务所做更改 Repeatable Read隔离级别，在一个事务中的第一次select执行的时候生成快照，只有在当前事务中对数据的修改才会更新快照。只有第一次select之前其他已提交事务所做更改可以看到，第一次select之后其他事务提交的更改当前事务是看不到的 一致性读，主要基于MVCC实现，多版本控制核心是数据快照，InnoDB通过undo log存储数据快照。 使用MVCC优势是不加锁，并发度高，但是读取的数据不是实时数据。 锁定读（当前读）锁定读，也叫当前读，读取的是最新版本，update、delete、insert、select…lock in share mode、select…for update都是锁定读。 通过加record lock和gap lock间隙锁来实现，也就是next-key lock。使用next-key lock优势是获取实时数据，但是需要加锁。 参考 https://blog.csdn.net/z69183787/article/details/81709743]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL的undo log和redo log]]></title>
      <url>%2F2018%2F04%2F18%2FMySQL%E7%9A%84undo%20log%E5%92%8Credo%20log%2F</url>
      <content type="text"><![CDATA[MySQL的undo log和redo log学习。 InnoDB引擎提供了两种事务日志：redo log和undo log。redo log用于保证事务的持久性，undo log是事务原子性和隔离性实现的基础。 undo log回滚日志保存了事务发生之前的数据的一个版本，用于回滚和提供一致性读（MVCC）。 在事务开始之前，当前版本行数据生成undo log，undo log也会产生redo log来保证undo log的可靠性；事务提交之后undo log不会立马删除，会放入待清理的链表，由purge线程判断是否有其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log。 undo log是逻辑格式的日志，执行undo仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作。undo log也会产生对应的redo log。 undo log是为了实现事务的原子性，undo log还可以用来实现MVCC。操作任何数据前线将数据备份到undo log，然后进行数据修改，如果出现错误或者执行了rollback，系统可以利用undo log中备份将数据恢复到事务开始之前的状态。 当事务提交的时候，InnoDB不会立即删除undo log，因为后续还可能会用到undo log。事务提交的时候会将该事物对应的undo log放入到删除列表，未来通过purge来删除，提交事务时还会判断undo log分配的页是否可以重用，如果可以重用，则分配给后面来的事务，避免为每个事务分配独立的undo log页面浪费存储空间和性能。 delete操作不会直接删除数据，而是将delete对象打上delete标记，标记为删除，最终删除操作是通过purge线程完成的 update操作的列如果是主键列，update会先删除该行，在插入一行目标行；如果update的不是主键列，在undo log中直接反向记录是如何update的。 redo log重做日志可以确保事务的持久性，防止在发生故障的时候，脏页没有刷盘。重启MySQL服务的时候可以根据redo log进行重做，从而达到事务持久性这一特性。 事务开始之后就会产生redo log，事务执行过程中就会逐步将redo log落盘。当事务对应的脏页写到磁盘后，redo log就没用了。 redo log是物理格式的日志，记录的是物理数据页的修改信息，而不是某些行修改成怎样，redo log是顺序写入redo log file的物理文件中去的。 redo log会先写到Innodb_log_buffer缓冲区，然后通过以下方式再将缓冲区日志刷新到磁盘上： Master Thread每秒执行刷新Innodb_log_buffer到redo log 文件中 每个事务提交时会将redo log刷新到redo log文件中 当重做日志缓存可用空间少于一半时，重做日志缓存被刷新到redo log文件中 redo log记录的是新数据的备份，事务提交之前只要将redo log持久化即可，不需要持久化数据。系统崩溃时虽然数据没有持久化，但是redo log已经持久化，可以根据redo log内容将所有数据恢复到最新状态。 redo log以块为单位进行存储，每块大小512字节。redo log缓冲区刷到redo log文件时，是追加写入的方式，也就是顺序写盘。 参考 https://www.cnblogs.com/wy123/p/8365234.html https://yq.aliyun.com/articles/592937 https://www.cnblogs.com/kismetv/p/10331633.html https://www.cnblogs.com/f-ck-need-u/p/9010872.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL的行锁、间隙锁和next-key lock]]></title>
      <url>%2F2018%2F04%2F18%2FMySQL%E7%9A%84%E8%A1%8C%E9%94%81%E3%80%81%E9%97%B4%E9%9A%99%E9%94%81%E5%92%8Cnext-key%20lock%2F</url>
      <content type="text"><![CDATA[MySQL的行锁、间隙锁和next-key lock学习。 行锁Record Lock，行锁，InnoDB行锁是针对索引进行加锁，不是对记录加锁，如果索引失效就会从行锁升级为表锁。 使用行锁开销大，加锁慢，会出现死锁，但是行锁的锁粒度小，并发度高。 加锁的方式： 自动加锁，update、delete、insert操作，InnoDB引擎都会自动给涉及到的数据加排它锁，select语句不会加锁。 显示加锁，使用select…lock in share mode或select…for update 间隙锁间隙锁，锁定索引记录间隙，确保索引记录间隙不变。间隙锁在Repeatable Read以上的隔离级别才可用。间隙锁为了解决同一事务中出现幻读的问题。 自动使用间隙锁的条件： 必须在Repeatable Read级别下 检索条件必须有索引，如果没有索引会变成表锁锁定整张表。 Next-Key Lock行锁和间隙锁组合起来叫做Next-Key Lock。 InnoDB引擎中Repeatable Read隔离级别下也不会出现幻读，是用的就是Next-Key Lock（行锁加间隙锁）来解决的。当InnoDB扫描索引记录的时候，先对索引记录加上行锁，再对索引记录两边的间隙加上间隙锁，之后其他事务就不能在这个间隙修改或者插入记录。 Next-Key Lock是行锁和间隙锁组合，对数据进行条件检索、范围检索时，对其范围内间隙进行加锁。InnoDB对行的查询都采用Next-Key Lock的算法，但当查询的索引含有唯一属性（唯一索引、主键索引）时，InnoDB会给Next-Key Lock进行优化，降为行锁，仅锁住索引本身，而不是范围。如果是普通辅助索引，会使用Next-Key Lock进行范围锁定。 幻读解决 快照读，使用MVCC解决幻读 当前读，依赖间隙锁解决幻读 参考 https://www.cnblogs.com/itdragon/p/8194622.html https://www.cnblogs.com/zhoujinyi/p/3435982.html https://blog.csdn.net/liqfyiyi/article/details/72771845 https://www.cnblogs.com/aspirant/p/9177978.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL的四种隔离级别]]></title>
      <url>%2F2018%2F04%2F17%2FMySQL%E7%9A%84%E5%9B%9B%E7%A7%8D%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%2F</url>
      <content type="text"><![CDATA[MySQL的四种隔离级别学习。 SQL标准定义了四类隔离级别，用来限定事务内外的哪些改变是可见的，哪些改变是不可见的。低的隔离级别一般支持更高的并发处理，拥有更低的系统开销。 四种隔离级别 Read Uncommitted，未提交读，所有事务可看到其他未提交事务的执行结果。读取未提交的数据，称为脏读Dirty Read。会导致脏读、不可重复读、幻读 Read Committed，提交读，一个事务只能看见已经提交事务所做的改变。会导致不可重复读，同一事务的其他实例在当前实例处理期间可能会有新的提交，可能导致同一select返回不同结果。会导致不可重复读、幻读 Repeatable Read，可重复读，可保证同一事务的多个实例在并发读数据时，会看到同样的数据。该级别只允许读取已提交记录，而且在一个事务两次读取一个记录期间，其他事务包含自己，不更新该记录。但是会导致幻读。当用户读取某一范围数据时，另外一个事务又在该范围内插入新行，当用户再读取该范围数据时，会发现有新的幻影行。会导致幻读。InnoDB使用MVCC解决幻读 Serializable，串行化，通过强制事务排序，解决幻读问题。在每个读的数据行上加上共享锁，可能会导致大量超时现象和锁竞争 脏读、不可重复读、幻读 脏读，第一个事务已更新一份数据，另外一个事务在此时读取了这份数据，第一个事务回滚了更新，第二个事务目前读取到的数据就是不正确的 不可重复读，同一个事务里，两次查询的结果不一致，可能是两次查询过程中插入了一个事务更新导致原有数据改变了 幻读，在一个事务中，两次查询的数据数量不一致，第一个事务第一次查询了几行数据，另外一个事务此时插入了新的数据行，第一个事务再次查询会发现多了几行数据 参考 https://www.jianshu.com/p/8d735db9c2c0]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL中InnoDB的MVCC]]></title>
      <url>%2F2018%2F04%2F16%2FMySQL%E4%B8%ADInnoDB%E7%9A%84MVCC%2F</url>
      <content type="text"><![CDATA[MySQL的InnoDB引擎的MVCC学习。 当前读（锁定读）当前读就是加锁读，读取的是记录的最新版本，MySQL会加锁保证其他并发事务不能修改当前记录，直到当前事务释放锁。 当前读的操作主要包括： 显式加锁的读操作：select ... lock in share mode;和select ... for update 写操作insert、update、delete update语句执行时，MySQL server会根据where条件读取第一条满足的记录，然后InnoDB会将第一条记录返回并加锁，MySQL server收到这条加锁记录后，会再发起一个update请求更新这条记录，这条记录操作完成后会继续读取下一条记录直到完成所有记录。update操作内部包含了当前读。 delete操作和update操作一样。 insert操作可能会触发Unique Key的冲突检查，也会有当前读操作。 快照读（一致性读）快照读是不加锁读，读取记录的快照版本，而不是记录的最新版本，使用MVCC实现。 InnoDB默认的事务隔离级别Repeatable Read，读操作是快照读，如果显式加了锁的读操作不是快照读，是当前读。保证了事务执行过程中只有第一次读之前提交的修改和自己的修改可见，其他事务的修改当前事务均不可见。 MVCCMVCC：多版本并发控制，用来解决读写冲突的无锁并发控制，读不加任何锁，读写不冲突，多操作多于写操作的应用可极大增加系统并发性能。只在Repeatable Read和Read Committed两个隔离级别下工作。 InnoDB默认隔离级别Repeatable Read的不加锁的读操作是快照读，使用MVCC实现。 InnoDB的MVCC是在每行记录后面添加两个隐藏列来实现：一个保存行的创建版本号；一个保存行的删除版本号。事务开始时候的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号比较。没开始一个新的事务，系统版本号会递增。 Repeatable Read隔离级别下的MVCC操作： select操作：InnoDB只查找版本早于当前事务版本的数据行，可以确保事务读取的行要么是在事务开始前已存在的，要么是事务自身插入或修改过的；行的删除版本要么没有定义，要么大于当前事务版本号，可以确保事务读取到的行在事务开始之前未被删除 insert操作，InnoDB为新插入的每一行保存当前系统版本号作为行版本号 delete操作，InnoDB为删除的每一行保存当前系统版本号为行删除标识 update操作，InnoDB会插入一行新纪录，保存当前系统版本号为新行版本号，同时将当前系统版本号作为原来行的行删除标识 MVCC只在Read Committed和Repeatable Read两个隔离级别下工作，Read Uncommitted读取的总是最新的数据行，Serializable会对所有读取行加共享锁。 MySQL的MVCCInnoDB默认隔离级别是Repeatable Read，通过MVCC解决了不可重复读。使用间隙锁解决幻读。 不可重复读发生是因为读和写没有互斥，如果使用读写互斥，又会导致并发度降低，MVCC可解决读写互不阻塞和不可重复读问题。 COLUMN1 COLUMN2 …… DATA_TRX_ID DATA_ROLL_PTR DB_ROW_ID 列1 列2 …… 事务ID 回滚段指针 隐藏单调自增ID InnoDB每一行都会有两个隐藏列： DATA_TRX_ID，记录最近更新这条记录的事务ID，6字节大小 DATA_ROLL_PTR，指向该行回滚段的指针，7字节大小。InnoDB可通过这个指针找到之前版本的数据。该行记录上所有的旧版本都在undo日志中通过链表形式组织 DB_ROW_ID，隐藏的单调自增ID，6字节大小。如果表没有指定主键，InnoDB会自动生成一个隐藏的自增主键，就是这个列。 每条记录的头信息还有一个专门的位表示当前记录是否已经被删除 更新行的过程： 对当前行加排它锁 把当前行的值拷贝到undo log中 修改当前行的值，更新当前行DATA_TRX_ID为当前事务ID，将DATA_ROLL_PTR指向刚才拷贝到undo log中的记录 记录redo log，包括undo log中的修改 参考 https://segmentfault.com/a/1190000014133576 https://zhuanlan.zhihu.com/p/91208953 https://zhuanlan.zhihu.com/p/64576887]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL中InnoDB的意向锁]]></title>
      <url>%2F2018%2F04%2F16%2FMySQL%E4%B8%ADInnoDB%E7%9A%84%E6%84%8F%E5%90%91%E9%94%81%2F</url>
      <content type="text"><![CDATA[MySQL的InnoDB引擎的意向锁学习。 InnoDB支持多粒度锁，允许行级锁和表级锁共存。意向锁是一种不与行级锁冲突的表级锁。 意向共享锁（IS），事务在获取行的共享锁之前，需要先获得表的意向共享锁 意向排它锁（IX），事务在获取行的排它锁之前，需要先获得表的意向排它锁 互斥性意向锁是表级锁，只会和表级锁冲突，不会和行级锁冲突。 意向共享锁和意向排它锁两者之间是兼容的，不互斥的 意向共享锁和表共享锁兼容，意向共享锁和表的排它锁是互斥的 意向排它锁和表共享锁以及表排它锁都互斥 意向锁和行级锁是兼容的 如果事务A获取了一行的排它锁，此时事务A会有两个锁：表意向排它锁和行的排它锁。如果事务B此时要获取表的共享锁，那么事务B就会先检测发现事务A持有表的意向排它锁，则事务B的加锁就会被阻塞，事务B无需检测表中的每一行数据是否有排它锁，只需检测事务A持有意向排它锁。 参考 https://zhuanlan.zhihu.com/p/29150809 https://juejin.im/post/5b85124f5188253010326360]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL中的锁]]></title>
      <url>%2F2018%2F04%2F16%2FMySQL%E4%B8%AD%E7%9A%84%E9%94%81%2F</url>
      <content type="text"><![CDATA[MySQL锁学习。 共享锁和排它锁 共享锁（读锁），读取数据时的锁，其他事务可以并发读数据，但不能写 排它锁（写锁），写数据时的锁，其他事务既不能读，也不能写 MyISAM和InnoDB的锁粒度锁粒度 表级锁，table-level locking 页面锁，page-level locking 行级锁，row-level locking MyISAM的锁粒度：表级锁MyISAM引擎使用的是表级锁，可以设置读锁和写锁的优先级来避免线程一直得不到执行。 MyISAM会自动给select操作和update、delete、insert操作涉及的表添加读锁和写锁。 InnoDB的锁粒度：表级锁和行级锁InnoDB引擎支持行级锁和表级锁，默认是用的是行级锁。 InnoDB行级锁 共享锁（S），允许当前事务和其他事务读取同一行数据，但其他事务不能修改数据 排它锁（X），允许获得排它锁的事务更新数据，其他事务不能读和写该数据 InnoDB行锁是针对索引加的锁，不是针对记录加锁，只有在通过索引检索数据的时候才使用行级锁，如果不通过索引检索数据则使用表级锁。 InnoDB意向锁意向锁是一种不与行级锁冲突的表级锁。InnoDB支持多粒度锁，允许行级锁和表级锁共存。 意向共享锁（IS），事务给数据行加行共享锁前，必须先取得该表的意向共享锁 意向排它锁（IX），事务给数据行加行排它锁前，必须先取得该表的意向排它锁 InnoDB意向锁是InnoDB引擎自动加的，不需要用户显式指定。update、delete、insert操作InnoDB会自动添加排它锁。select操作InnoDB不会加锁，需要用户显式加锁： 给select添加共享锁：select * from table_name where ... lock in share mode; 给select添加排它锁：select * frome table_name where ... for update; 表级锁、页面锁、行级锁 表级锁，开销小、加锁快、锁粒度大，不会出现死锁，并发度比较低 行级锁，开销大、加锁慢、锁粒度小，会出现死锁，并发度高 页面锁，开销和加锁时间界于表锁和行锁之间，会出现死锁，并发度一般 InnoDB间隙锁使用范围条件检索数据，而不是使用相等条件检索数据，如果要请求共享锁或排它锁时，InnoDB会给符合条件的并且是已存在的数据记录索引项加锁。而键值在条件范围内但不存在的记录叫做间隙GAP，InnoDB会对这个间隙加锁，这种就是间隙锁（Next-Key锁） 使用间隙锁目的： 防止幻读 满足恢复和复制需要 MySQL通过binlog记录更新的sql语句，slave机器基于binlog进行同步，重新执行binlog中的sql语句，binlog中的sql语句是按照事务提交的先后顺序记录，恢复的时候也是按照这个顺序进行，在一个事务未提交之前，其他并发事务不能插入满足其锁定条件的任何记录，不允许出现幻读。 锁算法 Record Lock，记录锁，锁定一个行记录 Gap Lock，间隙锁，锁定一个区间 Next-key Lock，记录锁+间隙锁，锁定区间和行记录 InnoDB的Repeatable Read隔离级别下的等值查询锁算法示例： 主键索引（聚簇索引），对主键索引记录加记录锁 唯一索引，对辅助索引加记录锁，对主键索引也加记录锁 普通索引，对相关的辅助索引加Next-key Lock，对对应的主键索引加记录锁 不使用索引，对全表加Next-key Lock 参考 https://zhuanlan.zhihu.com/p/29150809 https://juejin.im/post/5b85124f5188253010326360 https://segmentfault.com/a/1190000014133576]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL索引及实现原理]]></title>
      <url>%2F2018%2F04%2F15%2FMySQL%E7%B4%A2%E5%BC%95%E5%8F%8A%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
      <content type="text"><![CDATA[MySQL索引、数据结构、算法等学习。 只看MyISAM和InnoDB两个存储引擎。 MySQL索引MyISAM引擎MyISAM使用B+树作为索引结构，叶节点存放的是数据记录地址。MyISAM的索引文件仅存放数据记录的地址，主索引和辅助索引在结构上没有任何区别，主索引要求key是唯一的，辅助索引key可以重复。 MyISAM的索引方式被称为：非聚集索引。 MyISAM中索引检索算法为：首先按照B+树算法搜索索引，如果指定的key存在，取出其data中的值，然后以data中的值为地址读取对应地址存放的数据记录。 InnoDB引擎InnoDB使用B+树作为索引结构，叶节点保存了完整的数据记录，InnoDB表数据文件本身就是主索引。 InnoDB的索引方式被称为：聚集索引。 InnoDB数据文件本身按主键聚集，所以InnoDB要求表必须具有主键，如果没有显式指定，则MySQL会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，字段长度6字节，长整型。 InnoDB的辅助索引叶节点上记录的是主键。InnoDB使用主键搜索很高效，但是使用辅助索引搜索会先检索获得主键，再根据主键到主索引中检索才能获得数据记录。 为什么使用B+树B-树的内结点存储data，而B+树的内结点不存储data只存储key。B+树更适合实现外存储索引结构。 一般数据库系统或文件系统中使用的B+树都进行了优化，增加了顺序访问指针，提高区间访问性能。 索引文件一般以文件的形式存储在外部磁盘上，使用索引的时候需要磁盘IO，磁盘操作需要寻道和旋转，速度很慢，相当耗时。 局部性原理：当一个数据被使用到时，附近的数据也通常会马上被使用到。 磁盘预读：当从磁盘读取数据时，除了读取需要的数据，还会向后预读一定长度的数据放入内存。 索引查询效率高的指标就是IO次数少，采用B+树，可以使用很低的高度来存储很多的数据，相比红黑树这类适合内存的树，B+树更适合做磁盘索引数据结构。 参考 https://blog.codinglabs.org/articles/theory-of-mysql-index.html https://tech.meituan.com/2014/06/30/mysql-index.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL中InnoDB存储引擎索引简介]]></title>
      <url>%2F2018%2F04%2F14%2FMySQL%E4%B8%ADInnoDB%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E7%B4%A2%E5%BC%95%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[InnoDB存储引擎支持以下几种常见的索引：B+树索引、全文索引、哈希索引。 哈希索引，InnoDB支持自适应哈希索引，会根据表的使用情况自动为表生成哈希索引。 B+树索引，不能找到一个给定键值的具体行，只能找到被查找数据行所在的页，然后数据库把页读入内存，再在内存中进行查找，最后找到要查找的数据。 B+树索引B+树索引分为聚集索引和辅助索引，聚集索引的叶子节点存放的是一整行数据，辅助索引叶子节点存放的是主键数据。 聚集索引InnoDB存储引擎是索引组织表，表中数据按照主键顺序存放，聚集索引就是按照每张表的主键构造一颗B+树，叶子节点存放的是行记录数据。索引聚集索引的数据也是索引的一部分，每个数据页通过一个双向链表来连接。 每张表只能有一个聚集索引。 聚集索引对于主键的排序查找和范围查找速度很快。 辅助索引辅助索引也称非聚集索引，叶子节点不包含行记录数据，而是包含聚集索引键，也就是主键数据。 每张表可以有多个辅助索引。 联合索引联合索引使用最左匹配。 覆盖索引覆盖索引就是从辅助索引中就可以查到记录，而不需要从聚集索引中查询。 优化器选择不使用索引的情况有些情况优化器不选择索引查找数据，而是扫描聚集索引，直接进行全表扫描来得到数据，一般发生在范围查找、JOIN链接操作等。 全文索引全文索引通常使用倒排索引，在辅助表中存储了单词与单词自身在一个或者多个文档所在位置之间的映射。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL存储引擎简介]]></title>
      <url>%2F2018%2F04%2F08%2FMySQL%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[MySQL提供插件式的表存储引擎，常用的存储引擎有：InnoDB、MyISAM。 InnoDB和MyISAM简介InnoDB存储引擎 支持事务 支持行锁 支持外键 支持非锁定读，默认读取操作不加锁 使用MVCC（多版本并发控制）实现并发 实现SQL的4中隔离级别，默认REPEATABLE级别 使用next-key locking策略避免幻读 数据存储使用聚集索引，表的数据都是按照主键的顺序进行存放 没有指定主键时，InnoDB会默认为每一行生成一个6字节的ROWID，作为主键 不保存表的总行数，count(*)会全表扫描来统计 MyISAM存储引擎 不支持事务 只支持表锁 支持全文引擎 保存表的总行数，count(*)直接返回总数 InnoDB存储引擎InnoDB后台线程后台线程主要负责刷新内存中的数据，保证内存缓存的是最新数据，还需要将已修改数据同步到磁盘文件，保证数据库发生异常时InnoDB能恢复到正常运行状态。 Master Thread，将缓冲区中的数据异步刷新到磁盘，包括脏页刷新、合并插入缓冲、UNDO页回收。 IO Thread，InnoDB使用AIO处理写IO请求 Purge Thread，事务提交后，undolog可能不再需要，该线程可以回收已分配的undo页 Page Cleaner Thread，脏页刷新操作 内存内存中的页同步到磁盘的操作，不是每次更新都触发，而是基于Checkpoint的机制刷新回磁盘。 内存中数据页类型有： 索引页 数据页 undo页 插入缓冲 自适应哈希索引 锁信息 数据字典信息 内存管理 LRU List Free List Flush List 使用LRU算法管理内存，InnoDB在LRU列表中加入了midpoint位置，读取到的新页不是直接放到LRU首部，而是放到LRU的midpoint位置。 LRU列表中的页被修改后，成为脏页，会通过Checkpoint机制将脏页刷新回磁盘，Flush列表中的页就是脏页列表，脏页在LRU列表和Flush列表中都存在。 redo log buffer重做日志缓冲区，InnoDB会先将重做日志放到这个缓冲区，在按照一定频率刷新到重做日志文件。 Master Thread每一秒将重做日志刷新到重做日志文件中 每个事务提交会将重做日志缓存刷新到重做日志文件中 重做日志缓冲区剩余空间小于二分之一时将重做日志缓存刷新到重做日志文件中 Checkpoint技术InnoDB不是在每次操作了页记录就刷新到磁盘，而是使用Checkpoint技术来刷新缓存。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL体系架构简介]]></title>
      <url>%2F2018%2F04%2F07%2FMySQL%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[MySQL逻辑架构可以分为三层：应用层、MySQL服务层、存储引擎层。 MySQL架构体系如图： 连接池组件 管理服务和工具组件 SQL接口 SQL解析器 查询优化器 缓存组件 存储引擎，插件式表存储引擎 物理文件 应用层应用层也就是连接池组件，主要分为： 连接处理，使用线程池 用户鉴权，校验用户名密码 安全管理，判断用户的权限，看用户有哪些可执行的操作 MySQL服务层 管理服务和工具组件，提供数据库管理功能：备份和恢复、安全管理、复制管理、集群管理、分区分库分表管理、元数据管理 SQL接口，接收用户的SQL命令并处理：DML、DDL、存储过程、视图、触发器 SQL解析器，解析查询语句，生成语法树。 查询优化器，对查询语句进行优化，选择合适的索引等。 缓存，提高查询效率。 存储引擎层 存储引擎，与文件打交道的子系统，是插件式的表存储引擎。 物理文件，包括：redolog、undolog、binlog、errorlog、querylog、slowlog、data、index等。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[上传Zip文件不解压读取文件内容时ZipEntry的size为-1的问题]]></title>
      <url>%2F2018%2F03%2F03%2F%E4%B8%8A%E4%BC%A0Zip%E6%96%87%E4%BB%B6%E4%B8%8D%E8%A7%A3%E5%8E%8B%E8%AF%BB%E5%8F%96%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9%E6%97%B6ZipEntry%E7%9A%84size%E4%B8%BA-1%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
      <content type="text"><![CDATA[简介这几天在做通过流下载zip文件以及上传zip文件不解压读取zip文件内容的功能，在读取zip文件内容的时候遇到了size为-1的情况，在此记录下遇到的情况、解决办法、以及未解决的问题。 示例将上传和下载zip文件的功能做成了一个示例，放到了github上，链接：export-import-zip-use-stream，可以尝试运行下。 遇到的问题通过流下载zip文件之后，再次导入该zip文件，不解压读取zip文件内容，发现ZipEntry的size()返回-1，如下图所示： 简介这几天在做通过流下载zip文件以及上传zip文件不解压读取zip文件内容的功能，在读取zip文件内容的时候遇到了size为-1的情况，在此记录下遇到的情况、解决办法、以及未解决的问题。 示例将上传和下载zip文件的功能做成了一个示例，放到了github上，链接：export-import-zip-use-stream，可以尝试运行下。 遇到的问题通过流下载zip文件之后，再次导入该zip文件，不解压读取zip文件内容，发现ZipEntry的size()返回-1，如下图所示： 但是尝试使用系统自带的压缩软件压缩了一个zip文件，并上传读取，发现一切正常，size不为-1。使用zipinfo命令查看两个文件作为对比，如下： 可以看到上面文件是通过导出功能生成的，红框里缺少size。而下面的是系统压缩软件压缩的zip文件，红框里面带有size大小。故猜测可能是由于代码里生成ZipEntry的时候没有设置size，compressize，crc32等属性的原因。 读取zip文件时ZipEntry的size为-1解决办法直接读取当前ZipEntry的流，直到为-1为止，代码如下： 123456789101112131415161718192021222324252627282930313233343536@PostMapping("import")@ResponseBodypublic void importZip(@RequestParam("file")MultipartFile file) throws IOException &#123; ZipInputStream zipInputStream = new ZipInputStream(file.getInputStream()); ZipEntry zipEntry; while ((zipEntry = zipInputStream.getNextEntry()) != null) &#123; if (zipEntry.isDirectory()) &#123; // do nothing &#125;else &#123; String name = zipEntry.getName(); long size = zipEntry.getSize(); // unknown size // ZipEntry的size可能为-1，表示未知 // 通过上面的几种方式下载，就会产生这种情况 if (size == -1) &#123; ByteArrayOutputStream baos = new ByteArrayOutputStream(); while (true) &#123; int bytes = zipInputStream.read(); if (bytes == -1) break; baos.write(bytes); &#125; baos.close(); System.out.println(String.format("Name:%s,Content:%s",name,new String(baos.toByteArray()))); &#125; else &#123; // ZipEntry的size正常 byte[] bytes = new byte[(int) zipEntry.getSize()]; zipInputStream.read(bytes, 0, (int) zipEntry.getSize()); System.out.println(String.format("Name:%s,Content:%s",name,new String(bytes))); &#125; &#125; &#125; zipInputStream.closeEntry(); zipInputStream.close();&#125; 此时可以正确读取文件内容。 下载文件时设置size的解决办法需要设置ZipEntry的size，compresSize以及crc32等属性。 但是尝试使用系统自带的压缩软件压缩了一个zip文件，并上传读取，发现一切正常，size不为-1。使用zipinfo命令查看两个文件作为对比，如下： 简介这几天在做通过流下载zip文件以及上传zip文件不解压读取zip文件内容的功能，在读取zip文件内容的时候遇到了size为-1的情况，在此记录下遇到的情况、解决办法、以及未解决的问题。 示例将上传和下载zip文件的功能做成了一个示例，放到了github上，链接：export-import-zip-use-stream，可以尝试运行下。 遇到的问题通过流下载zip文件之后，再次导入该zip文件，不解压读取zip文件内容，发现ZipEntry的size()返回-1，如下图所示： 但是尝试使用系统自带的压缩软件压缩了一个zip文件，并上传读取，发现一切正常，size不为-1。使用zipinfo命令查看两个文件作为对比，如下： 可以看到上面文件是通过导出功能生成的，红框里缺少size。而下面的是系统压缩软件压缩的zip文件，红框里面带有size大小。故猜测可能是由于代码里生成ZipEntry的时候没有设置size，compressize，crc32等属性的原因。 读取zip文件时ZipEntry的size为-1解决办法直接读取当前ZipEntry的流，直到为-1为止，代码如下： 123456789101112131415161718192021222324252627282930313233343536@PostMapping("import")@ResponseBodypublic void importZip(@RequestParam("file")MultipartFile file) throws IOException &#123; ZipInputStream zipInputStream = new ZipInputStream(file.getInputStream()); ZipEntry zipEntry; while ((zipEntry = zipInputStream.getNextEntry()) != null) &#123; if (zipEntry.isDirectory()) &#123; // do nothing &#125;else &#123; String name = zipEntry.getName(); long size = zipEntry.getSize(); // unknown size // ZipEntry的size可能为-1，表示未知 // 通过上面的几种方式下载，就会产生这种情况 if (size == -1) &#123; ByteArrayOutputStream baos = new ByteArrayOutputStream(); while (true) &#123; int bytes = zipInputStream.read(); if (bytes == -1) break; baos.write(bytes); &#125; baos.close(); System.out.println(String.format("Name:%s,Content:%s",name,new String(baos.toByteArray()))); &#125; else &#123; // ZipEntry的size正常 byte[] bytes = new byte[(int) zipEntry.getSize()]; zipInputStream.read(bytes, 0, (int) zipEntry.getSize()); System.out.println(String.format("Name:%s,Content:%s",name,new String(bytes))); &#125; &#125; &#125; zipInputStream.closeEntry(); zipInputStream.close();&#125; 此时可以正确读取文件内容。 下载文件时设置size的解决办法需要设置ZipEntry的size，compresSize以及crc32等属性。 可以看到上面文件是通过导出功能生成的，红框里缺少size。而下面的是系统压缩软件压缩的zip文件，红框里面带有size大小。故猜测可能是由于代码里生成ZipEntry的时候没有设置size，compressize，crc32等属性的原因。 读取zip文件时ZipEntry的size为-1解决办法直接读取当前ZipEntry的流，直到为-1为止，代码如下： 123456789101112131415161718192021222324252627282930313233343536@PostMapping("import")@ResponseBodypublic void importZip(@RequestParam("file")MultipartFile file) throws IOException &#123; ZipInputStream zipInputStream = new ZipInputStream(file.getInputStream()); ZipEntry zipEntry; while ((zipEntry = zipInputStream.getNextEntry()) != null) &#123; if (zipEntry.isDirectory()) &#123; // do nothing &#125;else &#123; String name = zipEntry.getName(); long size = zipEntry.getSize(); // unknown size // ZipEntry的size可能为-1，表示未知 // 通过上面的几种方式下载，就会产生这种情况 if (size == -1) &#123; ByteArrayOutputStream baos = new ByteArrayOutputStream(); while (true) &#123; int bytes = zipInputStream.read(); if (bytes == -1) break; baos.write(bytes); &#125; baos.close(); System.out.println(String.format("Name:%s,Content:%s",name,new String(baos.toByteArray()))); &#125; else &#123; // ZipEntry的size正常 byte[] bytes = new byte[(int) zipEntry.getSize()]; zipInputStream.read(bytes, 0, (int) zipEntry.getSize()); System.out.println(String.format("Name:%s,Content:%s",name,new String(bytes))); &#125; &#125; &#125; zipInputStream.closeEntry(); zipInputStream.close();&#125; 此时可以正确读取文件内容。 下载文件时设置size的解决办法需要设置ZipEntry的size，compresSize以及crc32等属性。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[RocketMQ中Consumer的rebalance]]></title>
      <url>%2F2018%2F01%2F23%2FRocketMQ%E4%B8%ADConsumer%E7%9A%84rebalance%2F</url>
      <content type="text"><![CDATA[RocketMQ的rebalance学习。 rebalance场景： 消费者发送心跳到Broker，Broker端发现有新的消费者进来或者新增了topic订阅信息或者删除了topic订阅信息，Broker会通知所有消费者NOTIFY_CONSUMER_IDS_CHANGED，消费者收到请求后会立刻进行rebalance：MQClientInstance#rebalanceImmediately DefaultMQPushConsumerImpl#start最后会调用MQClientInstance#rebalanceImmediately开始rebaplace RebalanceService每隔20秒会执行一次rebalance draw io源文件RocketMQ中Consumer的rebalance.drawio 参考]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[RocketMQ中Consumer的心跳发送]]></title>
      <url>%2F2018%2F01%2F23%2FRocketMQ%E4%B8%ADConsumer%E7%9A%84%E5%BF%83%E8%B7%B3%E5%8F%91%E9%80%81%2F</url>
      <content type="text"><![CDATA[RocketMQ Consumer的心跳发送学习。 Consumer和Broker保持长连接，Consumer会向Broker发送心跳信息，心跳信息中包含了当前消费者的订阅信息。 发送心跳的场景 在DefaultMQPushConsumerImpl#start启动后会发送心跳 在DefaultMQPushConsumerImpl#subscribe订阅topic和tag的时候会发送心跳 在RebalancePushImpl#messageQueueChanged消息队列有变化后会发送心跳 在MQClientInstance#startScheduledTask启动定时任务时会启动一个定时任务发送心跳 在DefaultMQProducerImpl#start启动后会发送心跳 发送和处理过程 Consumer向每个Broker发送心跳，包含消费者订阅信息 Broker处理心跳请求 获取消费组订阅配置信息，不存在就新建，并持久化 注册重试队列，新注册后会向Nameserver广播请求更新路由信息 注册消费者到消费者表中，没有则新增消费者，新增完消费者后需要通知所有消费者进行rebalance 注册生产者 订阅关系一致性一个消费组中的所有消费者订阅的信息必须完全一致，如果不一致的话回产生消费混乱，丢失消息。因为在Broker中消费者订阅信息是以消费组为维度存放的，如果一个消费组中的的消费者订阅不一样，后面的消费者会覆盖前面消费者在消费组中的订阅信息。 draw io源文件和图片draw io源文件：RocketMQ中Consumer的心跳发送.drawio 参考]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[RocketMQ中的订阅关系一致]]></title>
      <url>%2F2018%2F01%2F22%2FRocketMQ%E4%B8%AD%E7%9A%84%E8%AE%A2%E9%98%85%E5%85%B3%E7%B3%BB%E4%B8%80%E8%87%B4%2F</url>
      <content type="text"><![CDATA[RocketMQ的订阅关系一致学习。 订阅关系一致是指同一个消费者组下所有的消费者实例处理逻辑必须完全一致，所有消费者订阅的Topic以及Topic中的Tag必须一致。如果订阅关系不一致，消费逻辑就会混乱，导致消息丢失。 因为在Broker中消费者订阅信息是以消费组为维度存放的，如果一个消费组中的的消费者订阅不一样，后面的消费者会覆盖前面消费者在消费组中的订阅信息。 可参考：[RocketMQ中Consumer的心跳发送][https://www.cxis.me/2018/01/23/RocketMQ中Consumer的心跳发送/]这篇文章中Consumer心跳发送和Broker中处理心跳的流程 参考 https://www.alibabacloud.com/help/zh/doc-detail/43523.htm]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[RocketMQ中Consumer启动流程]]></title>
      <url>%2F2018%2F01%2F22%2FRocketMQ%E4%B8%ADConsumer%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[RocketMQ Consumer启动流程学习。 draw io源文件：RocketMQ中Consumer启动流程.drawio 参考]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[RocketMQ中的事务消息]]></title>
      <url>%2F2018%2F01%2F21%2FRocketMQ%E4%B8%AD%E7%9A%84%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%2F</url>
      <content type="text"><![CDATA[RocketMQ的事务消息学习。 RocketMQ事务消息实现原理基于两阶段提交和定时事务状态回查机制： 应用程序在事务内完成相关业务数据落库，需要同步调用RocketMQ消息发送接口，发送状态为prepare的消息，发送成功后，RocketMQ服务器会回调发送者的事件监听程序，记录消息本地事务状态，该标记与本地业务同属于一个事务，确保消息发送与本地事务的原子性。 RocketMQ收到prepare消息时，会先备份消息的原Topic与原消费队列，然后将消息存储在主题为RMQ_SYS_TRANS_HALF_TOPIC的消息消费队列中。 MQ消息服务器开启一个定时任务，消费RMQ_SYS_TRANS_HALF_TOPIC的消息，向消息发送端发起事务状态回查，应用程序根据保存的事务状态告诉MQ服务器事务状态，如果是提交或者回滚，消息服务器提交或回滚，如果是未知，MQ在超过回查次数后依然无法知道消息事务状态，就默认回滚消息。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[RocketMQ中的主从复制]]></title>
      <url>%2F2018%2F01%2F20%2FRocketMQ%E4%B8%AD%E7%9A%84%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
      <content type="text"><![CDATA[RocketMQ的主从复制学习。 为提高消息消费的高可用，避免Broker单点故障引起消息无法及时消费，RocketMQ采用Broker主备机制，消息到到主服务器后需要将消息同步到从服务器。 HA实现原理： 主服务器启动，在特定端口上监听从服务器连接 从服务器主动连接主服务器，主服务器接收客户端的连接，建立TCP连接 从服务器主动向主服务器发送待拉取消息偏移量，主服务器解析请求并返回消息给从服务器 从服务器保存消息并继续发送信息的消息同步请求]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[RocketMQ中的顺序消息]]></title>
      <url>%2F2018%2F01%2F20%2FRocketMQ%E4%B8%AD%E7%9A%84%E9%A1%BA%E5%BA%8F%E6%B6%88%E6%81%AF%2F</url>
      <content type="text"><![CDATA[RocketMQ的顺序消息学习。 rocketmq有两种顺序级别： 普通顺序消息，producer将相关联的消息发送到相同的消息队列。 完全严格顺序，在普通顺序消费的基础上，consumer严格顺序消费。 普通顺序消费，需要我们自己提供MessageQueueSelector来选择具体的消息队列，要自己保证能选择到同一个队列的算法。 严格顺序消费，需要有三把锁来保证严格顺序消费： Broker消息队列锁，分布式锁。在集群模式下Consumer从Broker获得该锁后，才能进行消息拉取、消费。广播模式下，Consumer无需该锁。 Consumer消息队列锁，本地锁。Consumer获得该锁才能操作消息队列。 Consumer消息处理队列消费锁，本地锁。Consumer获得该锁才能消费消息队列。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[RocketMQ中的消息消费]]></title>
      <url>%2F2018%2F01%2F11%2FRocketMQ%E4%B8%AD%E7%9A%84%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%2F</url>
      <content type="text"><![CDATA[RocketMQ的消息消费学习。 一个消费组内可以包含多个消费者，每个消费组可订阅多个Topic。消费组之间有集群模式和广播模式： 集群模式，Topic下的同一条消息只允许被其中一个消费者消费。 广播模式，Topic下的同一条消息被集群内所有消费者消费一次。 消息服务器与消费者之间的消息传送有推模式和拉模式： 拉模式，消费者主动发起拉消息的请求 推模式，消息到达消息服务器后，推送给消息消费者，RocketMQ的推模式基于拉模式，在拉模式上包装一层，一个拉取任务完成后开始下一个拉取任务 一个消息队列同一时间只允许被一个消费者消费，一个消费者可以消费多个消息队列。 RocketMQ支持局部顺序消息消费，保证同一消息队列上的消息顺序消费。不支持全局顺序消费，如果要实现某个Topic的全局顺序消费，可将该Topic的队列设置为1，牺牲了高可用性。 消费者启动流程 构建主题订阅信息SubscriptionData并加入到RebalanceImpl订阅消息中，订阅信息主要有通过subscribe方法订阅，订阅重试主题消息。 初始化MQClientInstance、RebalanceImpl等 初始化消息进度，集群模式的消息进度存储在Broker上，广播模式的消费进度存储在消费端。 根据是否是顺序消费，创建消费端消费线程服务。 向MQClientInstance注册消费者，并启动MQClientInstance，MQClientInstance在一个JVM只存在一个实例。 消息拉取 封装拉取消息的请求 消息服务器查找消息，返回 客户端处理拉取到的消息 消息队列负载和重新分布机制消息队列重新分布是由RebalanceService线程来实现，每隔20s执行一次doRebalance方法。 RocketMQ默认提供5中分分配算法： 平均分配，如果有8个消费队列q1，q2，q3，q4，q5，q6，q7，q8，有三个消费者c1，c2，c3，则消息队列分配如下：c1对应q1，q2，q3；c2对应q4，q5，q6；c3对应q8 平均轮询分配，消息队列分配如下：c1对应q1，q4，q7；c2对应q2，q5，q8；c3对应q3，q6 一致性哈希，不推荐，消息队列负载信息不容易跟踪 根据配置，为每个消费者配置固定的消息队列 根据Broker部署机房名，对每个消费者负责不同的Broker上的队列]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[RocketMQ中的消息存储]]></title>
      <url>%2F2018%2F01%2F06%2FRocketMQ%E4%B8%AD%E7%9A%84%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8%2F</url>
      <content type="text"><![CDATA[RocketMQ的消息存储学习。 RocketMQ存储主要文件有： Commitlog，存储消息，顺序写文件，所有Topic的消息都存储在Commitlog文件中 ConsumeQueue，消息消费队列文件，每个Topic包含多个消息消费队列，每个消息队列有一个消息文件，消息写入Commitlog文件后，异步转发到消息队列中 IndexFile，索引文件，为了加速消息的检索性能，根据消息属性快速从Commitlog文件中检索消息，主要存储key和offset对应关系 事务状态服务，存储每条消息的事务状态。 定时消息服务，每个延迟级别对应一个消息消费队列，存储延迟队列的消息拉取进度。 消息存储流程 如果当前Broker不可用、Broker为SLAVE角色、当前不支持写入、消息Topic长度超过256个字符、属性长度超过65536字符，则拒绝写入 如果消息延迟级别大于0，将消息原来Topic名称和原来消息ID存入消息属性中，用延迟消息主题SCHEDULE_TOPIC、消息队列ID更新原来主题和队列 获取当前可写入的Commitlog文件 写入Commitlog之前先申请putMessageLock锁 设置消息存储时间，如果mappedFile为空，说明本次消息是第一次发送，使用偏移量0创建第一个commit文件 将消息追加到MappedFile中 创建全局唯一消息ID，消息ID组成：4字节ip，4字节端口号，8字节消息偏移量 获取该消息在消息队列的偏移量 根据消息体长度、主题长度、属性长度计算消息总长度 如果消息长度+END_FILE_MIN_BLANK_LENGTH大于Commitlog文件空闲空间，返回END_OF_FILE，Broker会重新创建一个新的Commitlog文件来存储该消息 消息内容存储到ByteBuffer中，然后创建AppendMessageResult，这里只是将消息存储在MappedFile对应的内存Buffer中，没有刷盘。 根据同步刷盘还是异步刷盘，将内存中数据持久化到磁盘 Commitlog文件Commitlog文件存储在${ROCKET_HOME}/store/commitlog/，每个文件默认1G。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[RocketMQ中的消息发送]]></title>
      <url>%2F2018%2F01%2F04%2FRocketMQ%E4%B8%AD%E7%9A%84%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%2F</url>
      <content type="text"><![CDATA[RocketMQ的消息发送过程学习。 RocketMQ发送消息有三种方式：同步发送、异步发送、单向发送。 同步发送，Producer发送消息，同步等待，直到服务器返回发送结果 异步发送，Producer发送消息，指定回调方法，发送消息后立刻返回。回调任务会在新线程中执行。 单向发送，Producer发送消息，直接返回，不等待返回结果也不注册回调方法。 消息组成 topic，消息所属的Topic flag，消息的Flag properties，消息扩展属性 消息体 消息扩展属性消息扩展属性包括： tag，消息tag，用于过滤消息 keys，消息索引键，多个用空格隔开，可以使用这些key快速检索到消息 waitStoreMsgOk，消息发送时是否等待消息存储完成后再返回 delayTimeLevel，消息延迟级别，用于定时消息或消息重试 消息发送流程 验证消息 查找路由 消息发送 异常处理 验证消息 确保生产者处于运行状态 验证消息符合规范，topic名称、消息体不能为空、消息长度不能等于0，且不能超过4M 查找路由消息发送前会先根据Topic获取路由信息，找到要发送的Broker信息。会先从缓存中查找路由信息，如果缓存中不存在，则从NameServer中查询Topic对应的路由信息。如果最后还是找不到，抛异常。 根据Topic获取到路由信息后，会从路由信息中选择一个要发送的消息队列，选择消息队列分两种情况：未开启故障规避机制和开启了故障规避机制 选择发送的消息队列时采用的算法就是轮询。未开启故障规避的话，如果选择的队列所在Broker不可用，这时候轮询到下一个队列，可能还会在同一个Broker上，有可能队列还是不能用。如果开启故障规避的话，如果选择的当前队列所在Broker不可用，在轮询找下个对列的时候，会把这个Broker直接规避掉，从其他的Broker上的队列选取一个。 消息发送 选择好队列后，从队列中获取到Broker的地址 为消息分配全局唯一ID 入股消息体超过4K，会采用zip压缩，并将消息系统标记记位COMPRESSED_FLAG 如果是事务Prepared消息，将消息系统标记记为TRANSACTION_PREPARED_TYPE 如果注册了消息发送钩子方法，消息发送前会先执行 构建消息发送请求包，包括：生产者组、topic名称、默认创建topic的key、topic在单个broker默认队列数、队列ID、消息系统标记、发送时间、消息标记、扩展属性、消息重试次数、是否批量消息等 根据发送方式，同步、异步、单向等进行网络传输 如果注册了消息发送钩子方法，执行发送后的逻辑]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[RocketMQ中的NameServer]]></title>
      <url>%2F2018%2F01%2F01%2FRocketMQ%E4%B8%AD%E7%9A%84NameServer%2F</url>
      <content type="text"><![CDATA[RocketMQ的NameServer学习。 NameServer存储Topic和Broker的信息，Broker启动的时候会向所有的NameServer注册。Producer在发送消息之前会先从NameServer获取Broker地址列表，按照负载均衡算法从列表中选择一台Broker服务器发送消息。 NameServer和Broker保持长连接，每隔30s检测Broker是否存活，如果Broker宕机，从路由注册表中删除。路由变化不会马上通知Producer，这样实现降低了NameServer实现复杂度，Producer会通过容错机制来保证消息发送高可用。 NameServer路由注册NameServer主要存储了： topicQueueTable，Topic队列路由信息，发消息时根据路由表进行负载均衡 borkerAddrTable，Broker基础信息，包含Broker名字、所属集群名称、主备Broker地址 clusterAddrTable，Broker集群信息，存储集群中所有Broker名称 brokerLiveTable，Broker状态信息，NameServer每次收到心跳包就会更新该状态信息 filterServerTable，Broker上的FilterServer列表，用于类模式消息过滤 路由注册通过Broker和NameServer的心跳功能实现，Broker启动时，向集群中所有NameServer发送心跳，每隔30秒向集群所有NameServer发心跳包。 NameServer收到心跳包后，更新brokerLiveTable缓存中的信息。 NameServer每隔10秒扫描brokerLiveTable，如果连续120s没有收到心跳包，NameServer会移除Broker的路由信息，同时关闭Socket连接。 NameServer与Broker保持长连接。 NameServer路由删除Broker每隔30s向所有NameServer发送心跳包，NameServer每隔10s扫描brokerLiveTable状态，如果超过120秒Broker状态没更新，认为Broker失效，移除Broker并且关闭与Broker的连接。 Broker如果是正常关闭，会触发路由删除。 路由发现Topic路由发生变化后，NameServer不会主动推送给客户端，而是由客户端定时拉取Topic最新路由。根据Topic名称拉取路由信息。 路由信息包括： orderTopicConfig，顺序消息配置内容 queueData，topic队列元数据 brokerDatas，topic分布的Broker元数据]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[RocketMQ架构]]></title>
      <url>%2F2018%2F01%2F01%2FRocketMQ%E6%9E%B6%E6%9E%84%2F</url>
      <content type="text"><![CDATA[RocketMQ包括：NameServer、Broker、Producer、Consumer。 NameServer NameServer存储Topic、Broker关系信息，NameServer间没有通信，单台宕机不影响其他NameServer和集群，整个NameServer集群宕机，已正常工作的Producer、Consumer、Broker能正常工作，新起来的就无法工作。 管理brokers，Broker服务启动时，会注册到NameServer上，两者保持心跳检测机制，保证NameServer知道Broker的存活。 NameServer存有全部Broker集群信息和生产者消费者客户端的请求信息。 Broker 负责存储消息、转发消息。 Broker节点与所有的NameServer节点保持长连接和心跳，定时将Topic信息注册到NameServer上。 Producer 消息生产者，负责产生消息 Consumer 消息消费者，消费消息 支持PUSH和PULL模式，支持集群消费和广播消费]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM中类文件结构和字节码指令示例]]></title>
      <url>%2F2017%2F08%2F20%2FJVM%E4%B8%AD%E7%B1%BB%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84%E5%92%8C%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E7%A4%BA%E4%BE%8B%2F</url>
      <content type="text"><![CDATA[JVM中类文件结构和字节码指令示例。 class文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586Classfile /xxxxx/me/cxis/dcc/loader/ConfigLoaderDelegate.class Last modified xxxx-x-x; size 1668 bytes MD5 checksum 26fb18f78a9fff6fccbe73d445ee8c58 Compiled from "ConfigLoaderDelegate.java"public class me.cxis.dcc.loader.ConfigLoaderDelegate // 次版本号 minor version: 0 // 主版本号 major version: 52 // 类的访问标志 // ACC_PUBLIC：是否public类型 // ACC_SUPER：是否允许使用invokespecial字节码指令的新语意，JDK1.0.2之后编译出来的类的这个标志都必须为真 flags: ACC_PUBLIC, ACC_SUPER// 常量池，存放字面量和符号引用// 字面量类似Java中的常量，如文本字符串、final常量等// 符号引用包括：类和接口的全限定名、字段的名称和描述符、方法的名称和描述符Constant pool: // 方法的符号引用，指向第12和第42个常量 // 最后结果是：java/lang/Object."&lt;init&gt;":()V // 调用父类Object的构造方法，该方法返回值是V表示void #1 = Methodref #12.#42 // java/lang/Object."&lt;init&gt;":()V // 字段的符号引用，指向第7和第43常量 // 最后结果是：me/cxis/dcc/loader/ConfigLoaderDelegate.configLoader:Lme/cxis/dcc/loader/ConfigLoader; // 对应源码的：private ConfigLoader configLoader; #2 = Fieldref #7.#43 // me/cxis/dcc/loader/ConfigLoaderDelegate.configLoader:Lme/cxis/dcc/loader/ConfigLoader; // 类或接口的符号引用，指向第44个常量：me/cxis/dcc/loader/ZookeeperConfigLoader #3 = Class #44 // me/cxis/dcc/loader/ZookeeperConfigLoader // 方法的符号引用，指向第3和第42个常量 // 最后结果是：me/cxis/dcc/loader/ZookeeperConfigLoader."&lt;init&gt;":()V // 对应源码中无参构造方法 #4 = Methodref #3.#42 // me/cxis/dcc/loader/ZookeeperConfigLoader."&lt;init&gt;":()V // 方法的符号引用，指向第7和第45个常量 // 最后结果是：me/cxis/dcc/loader/ConfigLoaderDelegate.getInstance:(Lme/cxis/dcc/loader/ConfigLoader;)Lme/cxis/dcc/loader/ConfigLoaderDelegate; // 对应源码中的带参数的静态方法：public static ConfigLoaderDelegate getInstance(ConfigLoader configLoader) // 方法参数：Lme/cxis/dcc/loader/ConfigLoader; L表示是对象类型 // 方法返回值：Lme/cxis/dcc/loader/ConfigLoaderDelegate; #5 = Methodref #7.#45 // me/cxis/dcc/loader/ConfigLoaderDelegate.getInstance:(Lme/cxis/dcc/loader/ConfigLoader;)Lme/cxis/dcc/loader/ConfigLoaderDelegate; // 字段的符号引用，指向第7和第46常量 // 最后结果是：me/cxis/dcc/loader/ConfigLoaderDelegate.configLoaderDelegate:Lme/cxis/dcc/loader/ConfigLoaderDelegate; // 对应源码的：private static volatile ConfigLoaderDelegate configLoaderDelegate; #6 = Fieldref #7.#46 // me/cxis/dcc/loader/ConfigLoaderDelegate.configLoaderDelegate:Lme/cxis/dcc/loader/ConfigLoaderDelegate; // 类或接口的符号引用，指向第47个常量：me/cxis/dcc/loader/ConfigLoaderDelegate #7 = Class #47 // me/cxis/dcc/loader/ConfigLoaderDelegate // 方法的符号引用，指向第7和第48个常量 // 最后结果是：me/cxis/dcc/loader/ConfigLoaderDelegate."&lt;init&gt;":(Lme/cxis/dcc/loader/ConfigLoader;)V // 对应源码中的有参构造方法：private ConfigLoaderDelegate(ConfigLoader configLoader) // 参数是：Lme/cxis/dcc/loader/ConfigLoader; 返回值是：V #8 = Methodref #7.#48 // me/cxis/dcc/loader/ConfigLoaderDelegate."&lt;init&gt;":(Lme/cxis/dcc/loader/ConfigLoader;)V // 接口中方法的符号引用，指向第49和50个常量 // 最后结果是：me/cxis/dcc/loader/ConfigLoader.get:(Ljava/lang/String;)Ljava/lang/String; // 表示的是ConfigLoader.get方法，参数是String类型，返回值是String类型 #9 = InterfaceMethodref #49.#50 // me/cxis/dcc/loader/ConfigLoader.get:(Ljava/lang/String;)Ljava/lang/String; // 接口中方法的符号引用，指向第49和51个常量 // 最后结果是：me/cxis/dcc/loader/ConfigLoader.addConfigListener:(Lme/cxis/dcc/listener/ConfigListener;)V // 表示的是ConfigLoader.addConfigListener方法，参数是ConfigListener类型，返回值是V #10 = InterfaceMethodref #49.#51 // me/cxis/dcc/loader/ConfigLoader.addConfigListener:(Lme/cxis/dcc/listener/ConfigListener;)V // 接口中方法的符号引用，指向第49和52个常量 // 最后结果是：me/cxis/dcc/loader/ConfigLoader.addConfigListener:(Ljava/lang/String;Lme/cxis/dcc/listener/ConfigListener;)V // 表示的是ConfigLoader.addConfigListener方法，参数是String类型和ConfigListener类型，返回值是V #11 = InterfaceMethodref #49.#52 // me/cxis/dcc/loader/ConfigLoader.addConfigListener:(Ljava/lang/String;Lme/cxis/dcc/listener/ConfigListener;)V // 类或接口的符号引用，指向第53个常量：java/lang/Object #12 = Class #53 // java/lang/Object // UTF-8编码的字符串，表示configLoader变量的名字 #13 = Utf8 configLoader // UTF-8编码的字符串，ConfigLoader的描述符 #14 = Utf8 Lme/cxis/dcc/loader/ConfigLoader; // UTF-8编码的字符串，configLoaderDelegate变量的名字 #15 = Utf8 configLoaderDelegate // UTF-8编码的字符串，ConfigLoaderDelegate类描述符 #16 = Utf8 Lme/cxis/dcc/loader/ConfigLoaderDelegate; // UTF-8编码的字符串，系统生成实例的初始化方法名字 #17 = Utf8 &lt;init&gt; // UTF-8编码的字符串，方法的描述符常量，无参空返回 #18 = Utf8 ()V // UTF-8编码的字符串，Code属性，用在方法表中，Java代码编译成的字节码指令 #19 = Utf8 Code // UTF-8编码的字符串，LineNumberTable属性，用在Code属性中，Java源码的行号与字节码指令的对应关系 #20 = Utf8 LineNumberTable // UTF-8编码的字符串，LocalVariableTable属性，用在Code属性中，方法的局部变量描述 #21 = Utf8 LocalVariableTable // UTF-8编码的字符串，当前实例this #22 = Utf8 this // UTF-8编码的字符串，方法的描述符常量，参数为ConfigLoader返回值为V #23 = Utf8 (Lme/cxis/dcc/loader/ConfigLoader;)V // UTF-8编码的字符串，方法表，JDK8新增属性，用于支持将方法名编译进Class文件并可运行时获取 #24 = Utf8 MethodParameters // UTF-8编码的字符串，方法名称常量 #25 = Utf8 getInstance // UTF-8编码的字符串，方法的描述符常量，参数为空，返回值为ConfigLoaderDelegate #26 = Utf8 ()Lme/cxis/dcc/loader/ConfigLoaderDelegate; // UTF-8编码的字符串，方法的描述符常量，参数为ConfigLoader，返回值为ConfigLoaderDelegate #27 = Utf8 (Lme/cxis/dcc/loader/ConfigLoader;)Lme/cxis/dcc/loader/ConfigLoaderDelegate; // UTF-8编码的字符串，StackMapTable属性，用在Code属性中，JDK6新增属性， // 供新的类型检查验证器检查和处理目标方法的局部变量和操作数栈所需要的类型是否匹配 #28 = Utf8 StackMapTable // 类或接口的符号引用，指向第53个常量：java/lang/Object #29 = Class #53 // java/lang/Object // 类或接口的符号引用，指向第54个常量：java/lang/Throwable #30 = Class #54 // java/lang/Throwable // UTF-8编码的字符串，方法名称常量 #31 = Utf8 get // UTF-8编码的字符串，方法的描述符常量，参数为String返回值为String #32 = Utf8 (Ljava/lang/String;)Ljava/lang/String; // UTF-8编码的字符串，// TODO #33 = Utf8 key // UTF-8编码的字符串，String类描述符 #34 = Utf8 Ljava/lang/String; // UTF-8编码的字符串，方法名称常量 #35 = Utf8 addConfigListener // UTF-8编码的字符串，方法的描述符常量 #36 = Utf8 (Lme/cxis/dcc/listener/ConfigListener;)V // UTF-8编码的字符串，// TODO #37 = Utf8 configListener // UTF-8编码的字符串，ConfigListener接口描述符 #38 = Utf8 Lme/cxis/dcc/listener/ConfigListener; // UTF-8编码的字符串，方法的描述符常量 #39 = Utf8 (Ljava/lang/String;Lme/cxis/dcc/listener/ConfigListener;)V // UTF-8编码的字符串，SourceFile属性，用在类文件，记录源文件名称 #40 = Utf8 SourceFile // UTF-8编码的字符串，源文件名称 #41 = Utf8 ConfigLoaderDelegate.java // 字段或方法的部分符号引用，指向第17和第18个常量 // "&lt;init&gt;" 方法名 ()参数为空 V返回值为void #42 = NameAndType #17:#18 // "&lt;init&gt;":()V // 字段或方法的部分符号引用，指向第13和第14个常量 // configLoader变量名，Lme/cxis/dcc/loader/ConfigLoader;变量类型 #43 = NameAndType #13:#14 // configLoader:Lme/cxis/dcc/loader/ConfigLoader; // UTF-8编码的字符串，ZookeeperConfigLoader类描述符 #44 = Utf8 me/cxis/dcc/loader/ZookeeperConfigLoader // 字段或方法的部分符号引用，指向第25和第27个常量 // getInstance方法名，(Lme/cxis/dcc/loader/ConfigLoader;) 参数，Lme/cxis/dcc/loader/ConfigLoaderDelegate;返回值 #45 = NameAndType #25:#27 // getInstance:(Lme/cxis/dcc/loader/ConfigLoader;)Lme/cxis/dcc/loader/ConfigLoaderDelegate; // 字段或方法的部分符号引用，configLoaderDelegate常量 #46 = NameAndType #15:#16 // configLoaderDelegate:Lme/cxis/dcc/loader/ConfigLoaderDelegate; // UTF-8编码的字符串，类描述符 #47 = Utf8 me/cxis/dcc/loader/ConfigLoaderDelegate // 字段或方法的部分符号引用，有参构造方方法 #48 = NameAndType #17:#23 // "&lt;init&gt;":(Lme/cxis/dcc/loader/ConfigLoader;)V // 类或接口的符号引用，指向第55个常量：me/cxis/dcc/loader/ConfigLoader #49 = Class #55 // me/cxis/dcc/loader/ConfigLoader // 字段或方法的部分符号引用，get方法 #50 = NameAndType #31:#32 // get:(Ljava/lang/String;)Ljava/lang/String; // 字段或方法的部分符号引用，addConfigListener方法 #51 = NameAndType #35:#36 // addConfigListener:(Lme/cxis/dcc/listener/ConfigListener;)V // 字段或方法的部分符号引用，addConfigListener方法 #52 = NameAndType #35:#39 // addConfigListener:(Ljava/lang/String;Lme/cxis/dcc/listener/ConfigListener;)V // UTF-8编码的字符串，Object类描述符 #53 = Utf8 java/lang/Object // UTF-8编码的字符串，Throwable描述符 #54 = Utf8 java/lang/Throwable // UTF-8编码的字符串，ConfigLoader类描述符 #55 = Utf8 me/cxis/dcc/loader/ConfigLoader&#123; // configLoader变量，类型ConfigLoader，访问标示符private， private me.cxis.dcc.loader.ConfigLoader configLoader; descriptor: Lme/cxis/dcc/loader/ConfigLoader; flags: ACC_PRIVATE // configLoaderDelegate变量，类型ConfigLoaderDelegate，访问标示符private，static，volatile private static volatile me.cxis.dcc.loader.ConfigLoaderDelegate configLoaderDelegate; descriptor: Lme/cxis/dcc/loader/ConfigLoaderDelegate; flags: ACC_PRIVATE, ACC_STATIC, ACC_VOLATILE // 无参构造方法 private me.cxis.dcc.loader.ConfigLoaderDelegate(); // 无参数，返回值void descriptor: ()V // 方法访问标志private flags: ACC_PRIVATE // Code属性 Code: // stack：最大操作数栈，JVM运行时会根据这个值来分配栈帧中的操作栈深度，此处为1 // locals：局部变量所需的存储空间，单位是Slot变量槽， // byte、char、float、int、short、boolean和returnAddress等长度不超过32位的数据类型，每个局部变量占用一个变量槽， // 而double和long这两种64位的数据类型则需要两个变量槽来存放 // 方法参数（包括实例方法中的隐藏参数“this”）、显式异常处理程序的参数（Exception HandlerParameter，就是try-catch语句中catch块中所定义的异常）、 // 方法体中定义的局部变量都需要依赖局部变量表来存放 // args_size：方法参数个数，此处的1是指实例方法的隐式参数this stack=1, locals=1, args_size=1 // 将第1个局部变量槽中引用类型的本地变量推送到操作数栈顶 // 从下面的局部变量表LocalVariableTable中可以看到只有一个this 0: aload_0 // invokespecial：调用父类构造方法、实例初始化方法、私有方法 // #1在常量池中是一个方法引用，指向：java/lang/Object."&lt;init&gt;":()V // 这里就是调用父类Object的构造方法，方法的接收者是上一步aload_0推送到栈顶的对象，就是this当前对象 1: invokespecial #1 // Method java/lang/Object."&lt;init&gt;":()V // return：从方法返回，返回值是void 4: return // 源码行号和字节码行号对应关系 LineNumberTable: line 12: 0 line 14: 4 // 栈帧中局部变量与源码中定义的变量之间的关系 LocalVariableTable: // Start： 局部变量的生命周期开始的字节码偏移量，也就是该局部变量在哪一行开始可见 // Length：作用范围覆盖的长度，也就是可见行数 // Slot：代表这个局部变量所在栈帧的局部变量表槽的位置 // Name：局部变量名称，这里是隐式参数this // Signature：局部变量描述符，这里是当前ConfigLoaderDelegate类 Start Length Slot Name Signature 0 5 0 this Lme/cxis/dcc/loader/ConfigLoaderDelegate; // 带参数的构造方法 private me.cxis.dcc.loader.ConfigLoaderDelegate(me.cxis.dcc.loader.ConfigLoader); // 参数ConfigLoader，返回值void descriptor: (Lme/cxis/dcc/loader/ConfigLoader;)V // 访问标示符：private flags: ACC_PRIVATE // Code属性 Code: // 最大操作数栈，2 // 两个本地变量槽 // 两个参数 stack=2, locals=2, args_size=2 // 将第1个局部变量槽中引用类型本地变量推送到栈顶 0: aload_0 // 调用父类的构造方法 1: invokespecial #1 // Method java/lang/Object."&lt;init&gt;":()V // 将第1个局部变量槽中引用类型本地变量推送到栈顶，this 4: aload_0 // 将第2个局部变量槽中引用类型本地变量推送到栈顶，参数configLoader 5: aload_1 // 为指定类的实例域赋值，#2是字段引用 6: putfield #2 // Field configLoader:Lme/cxis/dcc/loader/ConfigLoader; // 返回 void 9: return // 行号表 LineNumberTable: line 16: 0 line 17: 4 line 18: 9 // 本地变量表 LocalVariableTable: // this和configLoader两个局部变量 Start Length Slot Name Signature 0 10 0 this Lme/cxis/dcc/loader/ConfigLoaderDelegate; 0 10 1 configLoader Lme/cxis/dcc/loader/ConfigLoader; // JDK8新增，用在方法表中的变长属性，作用是记录方法的各个形参名称和信息 // 这里形参是configLoader MethodParameters: Name Flags configLoader // getInstance方法 public static me.cxis.dcc.loader.ConfigLoaderDelegate getInstance(); // 无参，返回值：ConfigLoaderDelegate descriptor: ()Lme/cxis/dcc/loader/ConfigLoaderDelegate; // 访问标示符 public static flags: ACC_PUBLIC, ACC_STATIC // Code属性 Code: // 最大操作数栈深度2 // 本地变量0 // 参数0 stack=2, locals=0, args_size=0 // 创建一个对象并将其引用压入栈顶，创建ZookeeperConfigLoader对象 0: new #3 // class me/cxis/dcc/loader/ZookeeperConfigLoader // 复制栈顶数值，并将复制值压入栈顶 3: dup // 调用ZookeeperConfigLoader的构造方法 4: invokespecial #4 // Method me/cxis/dcc/loader/ZookeeperConfigLoader."&lt;init&gt;":()V // 调用静态方法getInstance 7: invokestatic #5 // Method getInstance:(Lme/cxis/dcc/loader/ConfigLoader;)Lme/cxis/dcc/loader/ConfigLoaderDelegate; // 返回对象引用 10: areturn // 行号表 LineNumberTable: line 21: 0 // getInstance方法 public static me.cxis.dcc.loader.ConfigLoaderDelegate getInstance(me.cxis.dcc.loader.ConfigLoader); // 参数ConfigLoader，返回值ConfigLoaderDelegate descriptor: (Lme/cxis/dcc/loader/ConfigLoader;)Lme/cxis/dcc/loader/ConfigLoaderDelegate; // 访问标示符public static flags: ACC_PUBLIC, ACC_STATIC // Code属性 Code: // 最大操作数栈深度3 // 本地变量表3 // 参数1个 stack=3, locals=3, args_size=1 // 获取#6指向的静态域configLoaderDelegate，并将其压入栈顶 0: getstatic #6 // Field configLoaderDelegate:Lme/cxis/dcc/loader/ConfigLoaderDelegate; // 栈顶数据出栈，判断栈顶引用是否为null，不为null时跳转到38，38是获取#6指向的静态域configLoaderDelegate，并将其压入栈顶 3: ifnonnull 38 // 将#7从常量池中推送到栈顶，这个是锁对象 6: ldc #7 // class me/cxis/dcc/loader/ConfigLoaderDelegate // 复制栈顶数值，并将复制值压入栈顶，这个是备份锁对象 8: dup // 将栈顶的引用推送到第二个本地变量槽，将备份的锁对象放到本地变量表中 9: astore_1 // 获得对象的锁, 用于同步方法或同步块，此时栈中的锁对象会出栈 10: monitorenter // 获取#6指向的静态域configLoaderDelegate，并将其压入栈顶 11: getstatic #6 // Field configLoaderDelegate:Lme/cxis/dcc/loader/ConfigLoaderDelegate; // 不为null时跳转到28 14: ifnonnull 28 // 创建一个对象并将其引用压入栈顶，创建ConfigLoaderDelegate对象 17: new #7 // class me/cxis/dcc/loader/ConfigLoaderDelegate // 复制栈顶数值，并将复制值压入栈顶 20: dup // 将第一个本地变量槽中的引用推送到栈顶，configLoader 21: aload_0 // invokespecial：调用父类构造方法、实例初始化方法、私有方法，也就是调用ConfigLoaderDelegate带参的构造方法 22: invokespecial #8 // Method "&lt;init&gt;":(Lme/cxis/dcc/loader/ConfigLoader;)V // 为指定类的静态域赋值，configLoaderDelegate域赋值刚才new的ConfigLoaderDelegate对象 25: putstatic #6 // Field configLoaderDelegate:Lme/cxis/dcc/loader/ConfigLoaderDelegate; // 将第二个本地变量槽中的引用推送到栈顶，引用是ConfigLoaderDelegate，就是锁对象的备份 28: aload_1 // 释放对象的锁, 用于同步方法或同步块，将锁对象出栈 29: monitorexit // 无条件跳转到38 30: goto 38 // 将栈顶的引用推送到第三个本地变量槽 33: astore_2 // 将第二个本地变量槽中的引用推送到栈顶，锁对象的备份 34: aload_1 // 释放对象的锁, 用于同步方法或同步块，将锁对象出栈 35: monitorexit // 将第三个本地变量槽中的引用推送到栈顶 36: aload_2 // 将栈顶的异常抛出 37: athrow // 获取#6指向的静态域configLoaderDelegate，并将其压入栈顶 38: getstatic #6 // Field configLoaderDelegate:Lme/cxis/dcc/loader/ConfigLoaderDelegate; // 返回对象引用 41: areturn // 异常表 Exception table: // from：起始行 // to：结束行，但不包括结束行 // target：跳转到继续处理的行 // 要处理的异常情况，any表示任意异常 from to target type 11 30 33 any 33 36 33 any // 行号表 LineNumberTable: line 25: 0 line 26: 6 line 27: 11 line 28: 17 line 30: 28 line 32: 38 // 本地变量表 LocalVariableTable: Start Length Slot Name Signature 0 42 0 configLoader Lme/cxis/dcc/loader/ConfigLoader; // JDK6新增，是一个变长属性，位于Code属性中，这个属性会在虚拟机类加载的字节码验证阶段被新类型检查验证器（Type Checker）使用 // 目的在于代替以前比较消耗性能的基于数据流分析的类型推导验证器。 // 包含零至多个栈映射帧（Stack Map Frame），每个栈映射帧都显式或隐式地代表了一个字节码偏移量，用于表示执行到该字节码时局部变量表和操作数栈的验证类型 // TODO StackMapTable: number_of_entries = 3 frame_type = 252 /* append */ offset_delta = 28 locals = [ class java/lang/Object ] frame_type = 68 /* same_locals_1_stack_item */ stack = [ class java/lang/Throwable ] frame_type = 250 /* chop */ offset_delta = 4 // JDK8新增，用在方法表中的变长属性，作用是记录方法的各个形参名称和信息 // 这里形参是configLoader MethodParameters: Name Flags configLoader // get方法 public java.lang.String get(java.lang.String); // 参数String，返回值String descriptor: (Ljava/lang/String;)Ljava/lang/String; // 访问标识public flags: ACC_PUBLIC // Code属性 Code: // 最大操作数栈深度2 // 本地变量2 // 参数2 stack=2, locals=2, args_size=2 // 将第一个本地变量槽中的引用推送到栈顶，本地变量槽中第一个是ConfigLoaderDelegate引用 0: aload_0 // 获取指定类的实例域, 并将其压入栈顶， 也就是获取实例域configLoader 1: getfield #2 // Field configLoader:Lme/cxis/dcc/loader/ConfigLoader; // 将第二个本地变量槽中的引用推送到栈顶，本地变量槽中第二个是形参String 4: aload_1 // 调用接口方法，ConfigLoader的get方法 5: invokeinterface #9, 2 // InterfaceMethod me/cxis/dcc/loader/ConfigLoader.get:(Ljava/lang/String;)Ljava/lang/String; // 返回对象引用 10: areturn // 行号表 LineNumberTable: line 41: 0 // 本地变量表 LocalVariableTable: Start Length Slot Name Signature 0 11 0 this Lme/cxis/dcc/loader/ConfigLoaderDelegate; 0 11 1 key Ljava/lang/String; // JDK8新增，用在方法表中的变长属性，作用是记录方法的各个形参名称和信息 // 这里形参是key MethodParameters: Name Flags key // addConfigListener方法 public void addConfigListener(me.cxis.dcc.listener.ConfigListener); // 参数ConfigListener，返回值void descriptor: (Lme/cxis/dcc/listener/ConfigListener;)V // 访问标示符public flags: ACC_PUBLIC // Code属性 Code: // 操作数栈最大深度2 // 本地变量表2 // 参数两个 stack=2, locals=2, args_size=2 // 将第一个本地变量槽中的引用推送到栈顶，本地变量槽中第一个是ConfigLoaderDelegate引用 0: aload_0 // 获取指定类的实例域, 并将其压入栈顶， 也就是获取实例域configLoader 1: getfield #2 // Field configLoader:Lme/cxis/dcc/loader/ConfigLoader; // 将第二个本地变量槽中的引用推送到栈顶，本地变量槽中第二个是形参ConfigListener 4: aload_1 // 调用接口方法，ConfigLoader的addConfigListener方法 5: invokeinterface #10, 2 // InterfaceMethod me/cxis/dcc/loader/ConfigLoader.addConfigListener:(Lme/cxis/dcc/listener/ConfigListener;)V // 返回void 10: return // 行号表 LineNumberTable: line 45: 0 line 46: 10 // 本地变量表 LocalVariableTable: Start Length Slot Name Signature 0 11 0 this Lme/cxis/dcc/loader/ConfigLoaderDelegate; 0 11 1 configListener Lme/cxis/dcc/listener/ConfigListener; // JDK8新增，用在方法表中的变长属性，作用是记录方法的各个形参名称和信息 // 这里形参是configListener MethodParameters: Name Flags configListener // addConfigListener方法 public void addConfigListener(java.lang.String, me.cxis.dcc.listener.ConfigListener); // 参数ConfigListener，返回值void descriptor: (Ljava/lang/String;Lme/cxis/dcc/listener/ConfigListener;)V // 访问标示符public flags: ACC_PUBLIC // Code属性 Code: // 操作数栈最大深度3 // 本地变量表3 // 参数三个 stack=3, locals=3, args_size=3 // 将第一个本地变量槽中的引用推送到栈顶，本地变量槽中第一个是ConfigLoaderDelegate引用 0: aload_0 // 获取指定类的实例域, 并将其压入栈顶， 也就是获取实例域configLoader 1: getfield #2 // Field configLoader:Lme/cxis/dcc/loader/ConfigLoader; // 将第二个本地变量槽中的引用推送到栈顶，本地变量槽中第二个是形参String 4: aload_1 // 将第三个本地变量槽中的引用推送到栈顶，本地变量槽中第三个是形参ConfigListener 5: aload_2 // 调用接口方法，ConfigLoader的addConfigListener方法 6: invokeinterface #11, 3 // InterfaceMethod me/cxis/dcc/loader/ConfigLoader.addConfigListener:(Ljava/lang/String;Lme/cxis/dcc/listener/ConfigListener;)V // 返回void 11: return // 行号表 LineNumberTable: line 49: 0 line 50: 11 // 本地变量表 LocalVariableTable: Start Length Slot Name Signature 0 12 0 this Lme/cxis/dcc/loader/ConfigLoaderDelegate; 0 12 1 key Ljava/lang/String; 0 12 2 configListener Lme/cxis/dcc/listener/ConfigListener; // JDK8新增，用在方法表中的变长属性，作用是记录方法的各个形参名称和信息 // 这里形参是key和configListener MethodParameters: Name Flags key configListener&#125;SourceFile: "ConfigLoaderDelegate.java" ConfigLoaderDelegate源文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class ConfigLoaderDelegate &#123; private ConfigLoader configLoader; private static volatile ConfigLoaderDelegate configLoaderDelegate; private ConfigLoaderDelegate() &#123; &#125; private ConfigLoaderDelegate(ConfigLoader configLoader) &#123; this.configLoader = configLoader; &#125; public static ConfigLoaderDelegate getInstance() &#123; return getInstance(new ZookeeperConfigLoader()); &#125; public static ConfigLoaderDelegate getInstance(ConfigLoader configLoader) &#123; if (configLoaderDelegate == null) &#123; synchronized (ConfigLoaderDelegate.class) &#123; if (configLoaderDelegate == null) &#123; configLoaderDelegate = new ConfigLoaderDelegate(configLoader); &#125; &#125; &#125; return configLoaderDelegate; &#125; /** * 根据key获取value * @param key $&#123;projectName&#125;.key * @return */ public String get(String key) &#123; return configLoader.get(key); &#125; public void addConfigListener(ConfigListener configListener) &#123; configLoader.addConfigListener(configListener); &#125; public void addConfigListener(String key, ConfigListener configListener) &#123; configLoader.addConfigListener(key, configListener); &#125;&#125; ConfigLoader源文件12345678910public interface ConfigLoader &#123; String get(String key); String parseKey(String key); void addConfigListener(ConfigListener configListener); void addConfigListener(String key, ConfigListener configListener);&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM中的字节码指令]]></title>
      <url>%2F2017%2F08%2F19%2FJVM%E4%B8%AD%E7%9A%84%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%2F</url>
      <content type="text"><![CDATA[JVM中的字节码指令学习。 JVM采用面向操作数栈而不是面向寄存器的架构，所以大多数指令都不包含操作数，只包含一个操作码，指令参数都放在操作数栈中。 大部分与数据类型相关的字节码指令，操作码助记符都有特殊字符来表明为哪种数据类型服务： i表示int类型 l表示long s表示short b表示byte c表示char f表示float d表示double a表示reference 大部分指令没有支持整数型byte、char、short，没有任何指令支持boolean类型。是因为编译器在编译期或者运行期时： 将byte和short类型数据带符号扩展为相应int类型数据 将boolean和char类型数据零位扩展为相应int类型数据 加载指令加载用于将数据从局部变量表加载到操作数栈中。 将一个局部变量加载到操作数栈 字节码 助记符 含义 0x15 iload 将指定的int型变量推送到栈顶 0x1a iload_0 将第一个int型变量推送到栈顶 0x1b iload_1 将第二个int型变量推送到栈顶 0x1c iload_2 将第三个int型变量推送到栈顶 0x1d iload_3 将第四个int型变量推送到栈顶 字节码 助记符 含义 0x16 lload 将指定的long型变量推送到栈顶 0x1e lload_0 将第一个long型变量推送到栈顶 0x1f lload_1 将第二个long型变量推送到栈顶 0x20 lload_2 将第三个long型变量推送到栈顶 0x21 lload_3 将第四个long型变量推送到栈顶 字节码 助记符 含义 0x17 fload 将指定的fload型变量推送到栈顶 0x22 fload_0 将第一个fload型变量推送到栈顶 0x23 fload_1 将第二个fload型变量推送到栈顶 0x24 fload_2 将第三个fload型变量推送到栈顶 0x25 fload_3 将第四个fload型变量推送到栈顶 字节码 助记符 含义 0x18 dload 将指定的double型变量推送到栈顶 0x26 dload_0 将第一个double型变量推送到栈顶 0x27 dload_1 将第二个double型变量推送到栈顶 0x28 dload_2 将第三个double型变量推送到栈顶 0x29 dload_3 将第四个double型变量推送到栈顶 字节码 助记符 含义 0x19 aload 将指定的引用类型变量推送到栈顶 0x2a aload_0 将第一个引用类型变量推送到栈顶 0x2b aload_1 将第二个引用类型变量推送到栈顶 0x2c aload_2 将第三个引用类型变量推送到栈顶 0x2d aload_3 将第四个引用类型变量推送到栈顶 字节码 助记符 含义 0x2e iaload 将int型数组指定索引的值推送至栈顶 0x2f laload 将long型数组指定索引的值推送至栈顶 0x30 faload 将float型数组指定索引的值推送至栈顶 0x31 daload 将double型数组指定索引的值推送至栈顶 0x32 aaload 将引用类型数组指定索引的值推送至栈顶 0x33 baload 将boolean或byte型数组指定索引的值推送至栈顶 0x34 caload 将char型数组指定索引的值推送至栈顶 0x35 saload 将short型数组指定索引的值推送至栈顶 将一个常量加载到操作数栈 字节码 助记符 含义 0x01 aconst_null 将null推送至栈顶 字节码 助记符 含义 0x02 iconst_m1 将int型常量-1推送至栈顶 0x03 iconst_0 将int型常量0推送至栈顶 0x04 iconst_1 将int型常量1推送至栈顶 0x05 iconst_2 将int型常量2推送至栈顶 0x06 iconst_3 将int型常量3推送至栈顶 0x07 iconst_4 将int型常量4推送至栈顶 0x08 iconst_5 将int型常量5推送至栈顶 字节码 助记符 含义 0x09 lconst_0 将long型常量0推送至栈顶 0x0a lconst_1 将long型常量1推送至栈顶 字节码 助记符 含义 0x0b fconst_0 将float型常量0推送至栈顶 0x0c fconst_1 将float型常量1推送至栈顶 0x0d fconst_2 将float型常量2推送至栈顶 字节码 助记符 含义 0x0e dconst_0 将double型常量0推送至栈顶 0x0f dconst_1 将double型常量1推送至栈顶 字节码 助记符 含义 0x10 bipush 将byte型常量值(-128~127)推送至栈顶 0x11 sipush 将一个short型常量(-32768~32767)推送至栈顶 将一个常量从常量池加载到操作数栈 字节码 助记符 含义 0x12 ldc 将int,float或String型常量值从常量池中推送至栈顶 0x13 ldc_w 将int,float或String型常量值从常量池中推送至栈顶(宽索引) 0x14 ldc2_w 将long或double型常量值从常量池中推送至栈顶(宽索引) 存储指令存储用于将数据从操作数栈存储到局部变量表中。 字节码 助记符 含义 0x36 istore 将栈顶int型数值存入指定局部变量 0x3b istore_0 将栈顶int型数值存入第一个局部变量 0x3c istore_1 将栈顶int型数值存入第二个局部变量 0x3d istore_2 将栈顶int型数值存入第三个局部变量 0x3e istore_3 将栈顶int型数值存入第四个局部变量 字节码 助记符 含义 0x37 lstore 将栈顶long型数值存入指定局部变量 0x3f lstore_0 将栈顶long型数值存入第一个局部变量 0x40 lstore_1 将栈顶long型数值存入第二个局部变量 0x41 lstore_2 将栈顶long型数值存入第三个局部变量 0x42 lstore_3 将栈顶long型数值存入第四个局部变量 字节码 助记符 含义 0x38 fstore 将栈顶float型数值存入指定局部变量 0x43 fstore_0 将栈顶float型数值存入第一个局部变量 0x44 fstore_1 将栈顶float型数值存入第二个局部变量 0x45 fstore_2 将栈顶float型数值存入第三个局部变量 0x46 fstore_3 将栈顶float型数值存入第四个局部变量 字节码 助记符 含义 0x39 dstore 将栈顶double型数值存入指定局部变量 0x47 dstore_0 将栈顶double型数值存入第一个局部变量 0x48 dstore_1 将栈顶double型数值存入第二个局部变量 0x49 dstore_2 将栈顶double型数值存入第三个局部变量 0x4a dstore_3 将栈顶double型数值存入第四个局部变量 字节码 助记符 含义 0x3a astore 将栈顶引用类型数值存入指定局部变量 0x4b astore_0 将栈顶引用型数值存入第一个局部变量 0x4c astore_1 将栈顶引用型数值存入第二个局部变量 0x4d astore_2 将栈顶引用型数值存入第三个局部变量 0x4e astore_3 将栈顶引用型数值存入第四个局部变量 字节码 助记符 含义 0x4f iastore 将栈顶int型数值存入指定数组的指定索引位置 0x50 lastore 将栈顶long型数值存入指定数组的指定索引位置 0x51 fastore 将栈顶float型数值存入指定数组的指定索引位置 0x52 dastore 将栈顶double型数值存入指定数组的指定索引位置 0x53 aastore 将栈顶引用型数值存入指定数组的指定索引位置 0x54 bastore 将栈顶boolean或byte型数值存入指定数组的指定索引位置 0x55 castore 将栈顶char型数值存入指定数组的指定索引位置 0x56 sastore 将栈顶short型数值存入指定数组的指定索引位置 运算指令运算指令用于对两个操作数栈上的值进行某种特定运算，并把结果重新存到操作数栈顶。 加法指令 字节码 助记符 含义 0x60 iadd 将栈顶两int型数值相加并将结果压入栈顶 0x61 ladd 将栈顶两long型数值相加并将结果压入栈顶 0x62 fadd 将栈顶两float型数值相加并将结果压入栈顶 0x63 dadd 将栈顶两double型数值相加并将结果压入栈顶 减法指令 字节码 助记符 含义 0x64 isub 将栈顶两int型数值相减并将结果压入栈顶 0x65 lsub 将栈顶两long型数值相减并将结果压入栈顶 0x66 fsub 将栈顶两float型数值相减并将结果压入栈顶 0x67 dsub 将栈顶两double型数值相减并将结果压入栈顶 乘法指令 字节码 助记符 含义 0x68 imul 将栈顶两int型数值相乘并将结果压入栈顶 0x69 lmul 将栈顶两long型数值相乘并将结果压入栈顶 0x6a fmul 将栈顶两float型数值相乘并将结果压入栈顶 0x6b dmul 将栈顶两double型数值相乘并将结果压入栈顶 除法指令 字节码 助记符 含义 0x6c idiv 将栈顶两int型数值相除并将结果压入栈顶 0x6d ldiv 将栈顶两long型数值相除并将结果压入栈顶 0x6e fdiv 将栈顶两float型数值相除并将结果压入栈顶 0x6f ddiv 将栈顶两double型数值相除并将结果压入栈顶 取模运算指令 字节码 助记符 含义 0x70 irem 将栈顶两int型数值作取模运算并将结果压入栈顶 0x71 lrem 将栈顶两long型数值作取模运算并将结果压入栈顶 0x72 frem 将栈顶两float型数值作取模运算并将结果压入栈顶 0x73 drem 将栈顶两double型数值作取模运算并将结果压入栈顶 取反运算指令 字节码 助记符 含义 0x74 ineg 将栈顶int型数值取负并将结果压入栈顶 0x75 lneg 将栈顶long型数值取负并将结果压入栈顶 0x76 fneg 将栈顶float型数值取负并将结果压入栈顶 0x77 dneg 将栈顶double型数值取负并将结果压入栈顶 位移指令 字节码 助记符 含义 0x78 ishl 将int型数值左移指定位数并将结果压入栈顶 0x79 lshl 将long型数值左移指定位数并将结果压入栈顶 0x7a ishr 将int型数值右(带符号)移指定位数并将结果压入栈顶 0x7b lshr 将long型数值右(带符号)移指定位数并将结果压入栈顶 0x7c iushr 将int型数值右(无符号)移指定位数并将结果压入栈顶 0x7d lushr 将long型数值右(无符号)移指定位数并将结果压入栈顶 按位与指令 字节码 助记符 含义 0x7e iand 将栈顶两int型数值”按位与”并将结果压入栈顶 0x7f land 将栈顶两long型数值”按位与”并将结果压入栈顶 按位或指令 字节码 助记符 含义 0x80 ior 将栈顶两int型数值”按位或”并将结果压入栈顶 0x81 lor 将栈顶两long型数值”按位或”并将结果压入栈顶 按位异或指令 字节码 助记符 含义 0x82 ixor 将栈顶两int型数值”按位异或”并将结果压入栈顶 0x83 lxor 将栈顶两long型数值”按位异或”并将结果压入栈顶 局部变量自增指令 字节码 助记符 含义 0x84 iinc 将指定int型变量增加指定值(如i++, i–, i+=2等) 比较指令 字节码 助记符 含义 0x94 lcmp 比较栈顶两long型数值大小并将结果(1, 0或-1)压入栈顶 0x95 fcmpl 比较栈顶两float型数值大小并将结果(1, 0或-1)压入栈顶; 当其中一个数值为NaN时, 将-1压入栈顶 0x96 fcmpg 比较栈顶两float型数值大小并将结果(1, 0或-1)压入栈顶; 当其中一个数值为NaN时, 将1压入栈顶 0x97 dcmpl 比较栈顶两double型数值大小并将结果(1, 0或-1)压入栈顶; 当其中一个数值为NaN时, 将-1压入栈顶 0x98 dcmpg 比较栈顶两double型数值大小并将结果(1, 0或-1)压入栈顶; 当其中一个数值为NaN时, 将1压入栈顶 类型转换指令类型转换指令可以将两种不同数值类型相互转换。 宽化类型转换，JVM直接支持小范围到大范围类型的安全转换，无需显式使用转换指令 窄化类型转换，JVM在处理大范围类型到小范围类型的转换时，需要显式的使用转换指令。窄化类型转换可能导致结果产生不同的正负号、不同数量级，数值的精度也可能会丢失；int或long类型窄化转换时，仅仅是简单丢弃最低位N字节以外的内容，可能会导致转换结果与输入值有不同的正负号。 字节码 助记符 含义 0x85 i2l 将栈顶int型数值强制转换为long型数值并将结果压入栈顶 0x86 i2f 将栈顶int型数值强制转换为float型数值并将结果压入栈顶 0x87 i2d 将栈顶int型数值强制转换为double型数值并将结果压入栈顶 0x91 i2b 将栈顶int型数值强制转换为byte型数值并将结果压入栈顶 0x92 i2c 将栈顶int型数值强制转换为char型数值并将结果压入栈顶 0x93 i2s 将栈顶int型数值强制转换为short型数值并将结果压入栈顶 字节码 助记符 含义 0x88 l2i 将栈顶long型数值强制转换为int型数值并将结果压入栈顶 0x89 l2f 将栈顶long型数值强制转换为float型数值并将结果压入栈顶 0x8a l2d 将栈顶long型数值强制转换为double型数值并将结果压入栈顶 字节码 助记符 含义 0x8b f2i 将栈顶float型数值强制转换为int型数值并将结果压入栈顶 0x8c f2l 将栈顶float型数值强制转换为long型数值并将结果压入栈顶 0x8d f2d 将栈顶float型数值强制转换为double型数值并将结果压入栈顶 字节码 助记符 含义 0x8e d2i 将栈顶double型数值强制转换为int型数值并将结果压入栈顶 0x8f d2l 将栈顶double型数值强制转换为long型数值并将结果压入栈顶 0x90 d2f 将栈顶double型数值强制转换为float型数值并将结果压入栈顶 对象创建与访问指令对象和数组创建 字节码 助记符 含义 0xbb new 创建一个对象, 并将其引用引用值压入栈顶 字节码 助记符 含义 0xbc newarray 创建一个指定的原始类型(如int, float, char等)的数组, 并将其引用值压入栈顶 0xbd anewarray 创建一个引用型(如类, 接口, 数组)的数组, 并将其引用值压入栈顶 字节码 助记符 含义 0xc5 multianewarray 创建指定类型和指定维度的多维数组(执行该指令时, 操作栈中必须包含各维度的长度值), 并将其引用压入栈顶 访问指令 字节码 助记符 含义 0xb2 getstatic 获取指定类的静态域, 并将其压入栈顶 0xb3 putstatic 为指定类的静态域赋值 0xb4 getfield 获取指定类的实例域, 并将其压入栈顶 0xb5 putfield 为指定类的实例域赋值 取数组长度指令 字节码 助记符 含义 0xbe arraylength 获取数组的长度值并压入栈顶 检查类实例类型的指令 字节码 助记符 含义 0xc0 checkcast 检验类型转换, 检验未通过将抛出 ClassCastException 0xc1 instanceof 检验对象是否是指定类的实际, 如果是将1压入栈顶, 否则将0压入栈顶 操作数栈管理指令直接操作操作数栈的指令 字节码 助记符 含义 0x57 pop 将栈顶数值弹出(数值不能是long或double类型的) 0x58 pop2 将栈顶的一个(对于非long或double类型)或两个数值(对于非long或double的其他类型)弹出 0x59 dup 复制栈顶数值并将复制值压入栈顶 0x5a dup_x1 复制栈顶数值并将两个复制值压入栈顶 0x5b dup_x2 复制栈顶数值并将三个(或两个)复制值压入栈顶 0x5c dup2 复制栈顶一个(对于long或double类型)或两个(对于非long或double的其他类型)数值并将复制值压入栈顶 0x5d dup2_x1 dup_x1指令的双倍版本 0x5e dup2_x2 dup_x2指令的双倍版本 0x5f swap 将栈顶最顶端的两个数值互换(数值不能是long或double类型) 控制转移指令控制转移指令可以让JVM有条件或无条件的从指定位置指令的下一条指令继续执行程序，可认为控制指令就是在有条件或者无条件的修改PC寄存器的值。 条件分支 字节码 助记符 含义 0x99 ifeq 当栈顶int型数值等于0时跳转 0x9a ifne 当栈顶int型数值不等于0时跳转 0x9b iflt 当栈顶int型数值小于0时跳转 0x9c ifge 当栈顶int型数值大于等于0时跳转 0x9d ifgt 当栈顶int型数值大于0时跳转 0x9e ifle 当栈顶int型数值小于等于0时跳转 0x9f if_icmpeq 比较栈顶两int型数值大小, 当结果等于0时跳转 0xa0 if_icmpne 比较栈顶两int型数值大小, 当结果不等于0时跳转 0xa1 if_icmplt 比较栈顶两int型数值大小, 当结果小于0时跳转 0xa2 if_icmpge 比较栈顶两int型数值大小, 当结果大于等于0时跳转 0xa3 if_icmpgt 比较栈顶两int型数值大小, 当结果大于0时跳转 0xa4 if_icmple 比较栈顶两int型数值大小, 当结果小于等于0时跳转 0xa5 if_acmpeq 比较栈顶两引用型数值, 当结果相等时跳转 0xa6 if_acmpne 比较栈顶两引用型数值, 当结果不相等时跳转 复合条件分支 字节码 助记符 含义 0xaa tableswitch 用于switch条件跳转, case值连续(可变长度指令) 0xab lookupswitch 用于switch条件跳转, case值不连续(可变长度指令) 无条件分支 字节码 助记符 含义 0xa7 goto 无条件跳转 0xa8 jsr 跳转至指定的16位offset位置, 并将jsr的下一条指令地址压入栈顶 0xa9 ret 返回至本地变量指定的index的指令位置(一般与jsr或jsr_w联合使用) 0xc8 goto_w 无条件跳转(宽索引) 0xc9 jsr_w 跳转至指定的32位offset位置, 并将jsr_w的下一条指令地址压入栈顶 对于boolean类型、byte类型、char类型和short类型的条件分支比较操作，都使用int类型的比较指令来完成 对于long类型、float类型和double类型的条件分支比较操作，则会先执行相应类型的比较运算指令（dcmpg、dcmpl、fcmpg、fcmpl、lcmp），运算指令会返回一个整型值到操作数栈中，随后再执行int类型的条件分支比较操作来完成整个分支跳转 方法调用和返回指令 字节码 助记符 含义 0xb6 invokevirtual 调用实例方法，根据对象的实际类型进行分派（虚方法分派） 0xb7 invokespecial 调用超类构建方法, 实例初始化方法, 私有方法 0xb8 invokestatic 调用静态方法 0xb9 invokeinterface 调用接口方法，它会在运行时搜索一个实现了这个接口方法的对象，找出适合的方法进行调用。 0xba invokedynamic 调用动态方法 字节码 助记符 含义 0xac ireturn 从当前方法返回int 0xad lreturn 从当前方法返回long 0xae freturn 从当前方法返回float 0xaf dreturn 从当前方法返回double 0xb0 areturn 从当前方法返回对象引用 0xb1 return 从当前方法返回void 异常处理指令 字节码 助记符 含义 0xbf athrow 将栈顶的异常抛出 同步指令Java虚拟机可以支持方法级的同步和方法内部一段指令序列的同步，这两种同步结构都是使用管程（Monitor，锁）来实现的。 方法级的同步是隐式的，无须通过字节码指令来控制，它实现在方法调用和返回操作之中。虚拟机可以从方法常量池中的方法表结构中的ACC_SYNCHRONIZED访问标志得知一个方法是否被声明为同步方法。当方法调用时，调用指令将会检查方法的ACC_SYNCHRONIZED访问标志是否被设置，如果设置了，执行线程就要求先成功持有管程，然后才能执行方法，最后当方法完成（无论是正常完成还是非正常完成）时释放管程。在方法执行期间，执行线程持有了管程，其他任何线程都无法再获取到同一个管程。如果一个同步方法执行期间抛出了异常，并且在方法内部无法处理此异常，那这个同步方法所持有的管程将在异常抛到同步方法边界之外时自动释放。 字节码 助记符 含义 0xc2 monitorenter 获得对象的锁, 用于同步方法或同步块 0xc3 monitorexit 释放对象的锁, 用于同步方法或同步块 扩展本地变量宽度 字节码 助记符 含义 0xc4 wide 扩展本地变量的宽度 参考 《深入理解Java虚拟机》 https://segmentfault.com/a/1190000008722128]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM中的Class类文件结构]]></title>
      <url>%2F2017%2F08%2F19%2FJVM%E4%B8%AD%E7%9A%84Class%E7%B1%BB%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84%2F</url>
      <content type="text"><![CDATA[JVM中的Class类文件结构学习。 Class文件是一组以8字节位基础单位的二进制流，使用类似C语言结构体的伪结构存储数据，只有两种数据类型：无符号数和表。 无符号数用来描述数字、索引引用、数量值或者按照UTF8编码构成的字符串值，分为： u1，1个字节 u2，2个字节 u4，4个字节 u8，8个字节 表由多个无符号数或者其他表作为数据项，构成了复合数据类型。 文件格式如下表： 类型 名称 数量 u4 magic 1 u2 minor_version 1 u2 major_version 1 u2 constant_pool_count 1 cp_info constant_pool constant_pool_count - 1 u2 access_flags 1 u2 this_class 1 u2 super_class 1 u2 interfaces_count 1 u2 interfaces interfaces_count u2 fields_count 1 field_info fields fields_count u2 methods_count 1 method_info methods methods_count u2 attributes_count 1 attribute_info attributes attributes_count 可以这样记忆，前面几个先记住： 魔数 次版本号 主版本号 常量池数量 常量池 后面几个按照我们平时写一个类的顺序来记忆： 访问标志 this_class 父类 接口数量 接口 字段数量 字段 方法数量 方法 属性数量 属性 描述符描述符用来描述： 字段的数据类型 方法的参数列表（包括数量、类型以及顺序） 返回值 描述符标识字符含义： 数组类型，每一维度使用一个前置的[字符来描述。 描述方法时，按照先参数列表，后返回值的顺序描述 魔数Class文件头4个字节是魔数Magic Number，用来确定这个文件是否为一个能被虚拟机接受的Class文件，值是：0xCAFEBABE 主次版本号第5个字节和6个字节是次版本号Minor Version，第7字节和8字节是主版本号Major Version。 高版本的JDK能向下兼容以前版本的Class文件，但不能运行更高版本的Class文件。 常量池一个u2类型表示常量池的容量计数constant_pool_count，从1开始。 常量池主要用来存放：字面量和符号引用。 字面量比较接近Java语言层面的常量概念，比如：文本字符串、被声明为final的常量值等。 符号引用，主要包括： 被模块导出或者开放的包（Package） 类和接口的全限定名（Fully Qualified Name） 字段的名称和描述符（Descriptor） 方法的名称和描述符 方法句柄和方法类型（Method Handle、Method Type、Invoke Dynamic） 动态调用点和动态常量（Dynamically-Computed Call Site、Dynamically-Computed Constant） 常量池中的常量都是一个表，表的其实第一位是u1类型的标志位，代表当前常量属于哪种常量类型，共有17种常量类型： 类型 标志 描述 CONSTANT_Utf8_info 1 UTF-8编码的字符串 CONSTANT_Integer_info 3 整形字面量 CONSTANT_Float_info 4 浮点型字面量 CONSTANT_Long_info 5 长整型字面量 CONSTANT_Double_info 6 双精度浮点型字面量 CONSTANT_Class_info 7 类或接口的符号引用 CONSTANT_String_info 8 字符串类型字面量 CONSTANT_Fieldref_info 9 字段的符号引用 CONSTANT_Methodref_info 10 类中方法的符号引用 CONSTANT_InterfaceMethodRef_info 11 接口中方法的符号引用 CONSTANT_NameAndType_info 12 字段或方法的部分符号引用 CONSTANT_MethodHandle_info 15 方法句柄 CONSTANT_MethodType_info 16 方法类型 CONSTANT_Dynamic_info 17 动态计算常量 CONSTANT_InvokeDynamic_info 18 动态方法调用点 CONSTANT_Module_info 19 模块 CONSTANT_Package_info 20 模块中开放或导出的包 CONSTANT_Class_info 类型 名称 数量 u1 tag 1 u2 name_index 1 tag，标志位，用来区分常量类型，CONSTANT_Class_info是7 name_index，是常量池的索引值，指向常量池中一个CONSTANT_Utf8_info类型常量，代表这个类或接口的全限定名 CONSTANT_Utf8_info 类型 名称 数量 u1 tag 1 u2 length 1 u1 bytes length tag，标志位，用来区分常量类型，CONSTANT_Utf8_info是1 length，表示这个UTF-8编码的字符串长度是多少字节 bytes，使用UTF-8缩略编码表示的字符串，长度是length Class文件中方法、字段等都需要引用CONSTANT_Utf8_info类型常量来描述名称，所以Java中方法、字段名的最大程度就是CONSTANT_Utf8_info类型的常量的最大长度，也就是length，u2类型，最大值65535，64KB。 常量池数据类型结构汇总图 访问标志常量池后面两个字节表示访问标志，access_flags，表示类或接口层次的访问信息，包括是类还是接口、是否public类型、是否abstract类型，类是否是final等等。 this_classthis_class类索引，u2类型，用来确定这个类的全限定名，指向一个类型为CONSTANT_Class_info的类描述符常量，通过CONSTANT_Class_info中的索引值可以找到CONSTANT_Utf8_info类型的常量中的全限定名字符串。 super_classsuper_class父类索引，u2类型，用来确定父类的全限定名，指向一个类型为CONSTANT_Class_info的类描述符常量，通过CONSTANT_Class_info中的索引值可以找到CONSTANT_Utf8_info类型的常量中的全限定名字符串。 interfacesinterfaces接口索引集合，是一组u2类型的数据集合，描述类实现了哪些接口。 interfaces前面有个u2类型的interfaces_count，表示接口索引表容量。 字段表集合field_info字段表，描述类或者接口中声明的变量，包括：静态变量、实例变量，不包括方法中的局部变量。 类型 名称 数量 u2 access_flags 1 u2 name_index 1 u2 descriptor_index 1 u2 attributes_count 1 attribute_info attributes attributes_count access_flags字段修饰符，u2类型，如下 name_indexname_index是对常量池项的引用，表示字段的简单名称。 descriptor_indexdescriptor_index是对常量池项的引用，表示字段和方法的描述符。 attributes属性表集合，存储一些额外信息，比如final static int m = 123可能会存在一项名为ConstantValue的属性，指向常量123。 字段表集合不会列出从父类或者父接口继承来的字段，但有可能会出现Java代码中不存在的字段，比如内部类中为了保持对外部类的访问性，编译器会自动添加指向外部类实例的字段。 方法表集合method_info方法表集合： 类型 名称 数量 u2 access_flags 1 u2 name_index 1 u2 descriptor_index 1 u2 attributes_count 1 attribute_info attributes attributes_count access_flags 方法的代码经过编译器编译成字节码指令后，存放在方法属性表集合中的Code属性里。 如果父类方法在子类没有被重写，方法表中不会出现来自父类的方法信息。 可能会出现编译器自动添加的方法，比如类构造器&lt;clinit&gt;和实例构造器&lt;init&gt;。 属性表集合属性表集合图： 属性表结构： 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u1 info attribute_length attribute_name_index，名称指向常量池中的一个CONSTANT_Utf8_info类型的常量。 attribute_length，存储属性值占用的位数。 Code属性方法里面的代码经过编译器编译成字节码后，存储在Code属性里。Code属性出现在方法表的属性集合中，接口或者抽象类中的方法不存在Code属性。 Code属性结构： 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 max_stack 1 u2 max_locals 1 u4 code_length 1 u1 code code_length u2 exception_table_length 1 exception_info exception_table exception_table_length u2 attributes_count 1 attribute_info attributes attributes_count attribute_name_index，指向CONSTANT_Utf8_info类型的常量索引，固定为“Code”，表示该属性的属性名称。 attribute_length，属性值的长度 max_stack，操作数栈深度的最大值 max_locals，局部变量表需要的存储空间，单位是：变量槽Slot。byte、char、float、int、short、boolean、returnAddress占用一个变量槽，double和long需要两个变量槽。方法参数（包括this）、显式异常处理程序的参数（catch中定义的异常）、方法体中的局部变量等都需要依赖局部变量表来存放。 code_length，字节码长度 code，存储编译后生成的字节码 异常表集合异常表属性结构： 类型 名称 数量 u2 start_pc 1 u2 end_pc 1 u2 handler_pc 1 u2 catch_type 1 start_pc，从第start_pc行开始 end_pc，到第end_pc行，不包含end_pc行 handler_pc，转到第handler_pc行继续处理 catch_type，出现了catch_type或子类的异常，catch_type指向一个CONSTANT_Class_info类型的常量索引 Exceptions属性Exceptions，出现在方法表的属性集合中，用来列举出方法中可能抛出的受检查的异常，就是方法描述在throws后见列举的异常。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 number_of_exceptions 1 u2 exception_index_table number_of_exceptions number_of_exceptions，表示方法可能抛出number_of_exceptions个异常，每一个异常使用exception_index_table项表示 exception_index_table，指向一个常量池中CONSTANT_Class_info型常量的索引 LineNumberTable属性LineNumberTable用于描述Java源码行号与字节码行号对应关系 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 line_number_table_length 1 line_number_info line_number_table line_number_table_length line_number_info表中包含start_pc和line_number两个u2类型的数据项，start_pc是字节码行号，line_number是Java源码行号 LocalVariableTable属性LocalVariableTable用于描述栈帧中局部变量表的变量与Java源码中定义的变量间的关系。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 local_variable_table_length 1 local_variable_info local_variable_table local_variable_table_length local_variable_info，代表了栈帧与源码中的局部变量的关联 local_variable_info 类型 名称 数量 u2 start_pc 1 u2 length 1 u2 name_index 1 u2 descriptor_index 1 u2 index 1 start_pc，局部变量的生命周期开始的字节码偏移量 length，局部变量生命周期作用范围覆盖长度 name_index，指向常量池CONSTANT_Utf8_info类型常量索引，表示局部变量名称 descriptor_index，指向常量池CONSTANT_Utf8_info类型常量索引，表示局部变量的描述符 index，是局部变量在栈帧的局部变量表中变量槽的位置 LocalVariableTypeTable和LocalVariableTable相似，仅仅把记录的字段描述符的descriptor_index替换成了字段的特征签名Signature。 非泛型类型，描述符和特征签名描述的信息是一致的。泛型类型，描述符中的参数化类型被擦除掉，描述符不能准确描述泛型类型，就出现了LocalVariableTypeTable属性，使用字段的特征签名来完成泛型的描述 SourceFileSourceFile用于记录生成这个Class文件的源码文件名称。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 sourcefile_index 1 sourcefile_index，指向常量池中CONSTANT_Utf8_info类型常量索引，是源码文件名 SourceDebugExtensionSourceDebugExtension，用来存储额外的代码调试信息。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u1 debug_extension[attribute_length] 1 debug_extension，存储的是额外的调试信息，通过一组变长UTF-8格式来表示的字符串，一个类最多只有一个SourceDebugExtension属性。 ConstantValue属性ConstantValue用来通知虚拟机自动为静态变量赋值，static修饰的变量可以使用这个属性。 实例变量赋值是在实例构造器&lt;init&gt;中进行，类变量有两种方式：在类构造器&lt;clinit&gt;方法中或者使用ConstantValue属性。 Oracle的编译器是：如果是final static修饰，也就是一个常量，并且类型是基本类型或者是String类型，就会使用ConstantValue来进行初始化；如果没有被final修饰，或者类型非基本类型以及字符串，会选择在&lt;clinit&gt;方法中进行初始化。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 constantvalue_index 1 attribute_length，固定为2 constant_value，表示常量池中个一个字面量的引用，根据字段类型不同，字面量可以是：CONSTANT_Long_info、CONSTANT_Float_info、CONSTANT_Double_info、CONSTANT_Integer_info、CONSTANT_String_info InnerCalsses属性InnerClasses属性记录内部类和宿主类之间的关联，属性结构： 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 number_of_classes 1 inner_classes_info inner_classes number_of_classes inner_classes_info代表每个内部类信息 inner_classes_info 类型 名称 数量 u2 inner_class_info_index 1 u2 outer_class_info_index 1 u2 inner_name_index 1 u2 inner_class_access_flags 1 inner_class_info_index，指向常量池CONSTANT_Class_info类型常量索引，代表内部类的符号引用 outer_class_info_index，指向常量池CONSTANT_Class_info类型常量索引，代表外部类的符号引用 inner_name_index，指向常量池CONSTANT_Utf8_info类型常量索引，代表内部类名称，匿名内部类为0 inner_class_access_flags，内部类的访问标志 Deprecated属性Deprecated是布尔类型属性，表示某个类、字段、方法已经被标记为不推荐使用 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 attribute_length为0x00000000，因为没有任何属性值需要设置 Synthetic属性Synthetic属性表示字段或方法不是由Java源码直接产生，而是编译器自行添加的。最典型的例子就是枚举类中自动生成的枚举元素数组和嵌套类的桥接方法。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 attribute_length为0x00000000，因为没有任何属性值需要设置 Signature属性Signature在JDK5中增加，是一个可选定长属性，用于类、字段表、方法表结构的属性表中。用来记录泛型签名信息，Java泛型采用擦除法实现伪泛型，字节码Code属性中没有泛型信息。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 signature_index 1 signature_index必须是对一个常量池的有效索引，并且该索引是CONSTANT_Utf8_info结构，表示类签名或方法类型签名或字段类型签名。 MethodParameters属性MethodParameters在JDK8新加入的，用在方法表中的变长属性，记录方法的各个形参名称和信息。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u1 parameters_count 1 parameter parameters parameters_count parameter属性结构： 类型 名称 数量 u2 name_index 1 u4 access_flags 1 name_index指向常量池CONSTANT_Utf8_info类型的索引值，表示参数名称。 access_flags，参数的状态，包含：ACC_FIANL被final修饰、ACC_SYNTHETIC编译器自动生成、ACC_MANDATED表示该参数是在源文件中隐式定义，比如this关键字。 运行时注解属性JDK1.5：RuntimeVisibleAnnotations、RuntimeInvisibleAnnotations、RuntimeVisibleParameterAnnotations、RuntimeInvisibleParameterAnnotations用来存储源码中注解信息 JDK1.8：RuntimeVisibleTypeAnnotations、RuntimeInvisibleTypeAnnotations，用来存储源码中类型注解信息]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM中的锁优化]]></title>
      <url>%2F2017%2F07%2F30%2FJVM%E4%B8%AD%E7%9A%84%E9%94%81%E4%BC%98%E5%8C%96%2F</url>
      <content type="text"><![CDATA[JVM中的锁优化学习。 锁优化包括：自适应自旋、锁消除、锁膨胀、轻量级锁、偏向锁等。 自旋锁与自适应自旋 互斥同步的阻塞影响性能，挂起和恢复线程需要转入内核态完成。 共享数据的锁定只会持续很短时间，在这很短时间内挂起和恢复线程很浪费。 所以可以让后面请求锁的线程不放弃处理器，执行忙循环（自旋）来等待锁的释放，这就是自旋锁。 自旋锁在锁的占用时间很短的情况下，自旋等待效果很好，但是如果锁被长时间占有，自旋就只会消耗处理器资源了。所以自旋等待必须有限度，超过了限定的次数还没有获取到锁，就使用传统的方式挂起线程。 如果固定了自旋次数，JVM中所有的锁都会使用这个次数，对不同的锁有可能不太适用。JDK6引入了自适应自旋，也就是自旋的次数不是固定的，而是由前一次在同一个锁上的自选时间以及锁的拥有者的状态来决定。 如果在同一个锁对象上，自选等待刚刚成功获取锁，并且持有锁的线程正在运行中，JVM就会认为这次自旋也很有可能再次成功，就允许自选等待持续更长时间。 如果对于某个锁，自旋很少能成功获取锁，以后要获取这个锁时可能会直接忽略自旋，避免浪费处理器资源。 锁消除JVM在即时编译器运行时，对一些代码中需要进行同步，但是检测到不可能存在共享数据竞争，就可以进行锁消除。 锁粗化JVM检测到有一连串零碎的操作都对同一个对象加锁，就会把锁同步范围粗化到整个操作序列的外部。 轻量级锁JDK6加入的新型锁机制。在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。绝大部分的锁，在整个同步周期都是不存在竞争的，轻量级锁通过CAS操作避免了使用互斥量的开销。如果有竞争的话，除了互斥量的开销还有CAS操作开销，轻量级锁就比重量级锁要慢。 轻量级锁工作过程： 代码即将进入同步块的时候，如果此同步对象没有被锁定，锁标志位01状态，JVM会首先在当前线程的栈帧中建立一个锁记录空间，用于存储锁对象目前的Mark Word拷贝。 然后JVM使用CAS尝试把对象的Mark Word更新为指向锁记录的指针，如果成功，表示该线程拥有了这个对象的锁，并且对象的Mark Word锁标志位变成00表示轻量级锁。如果操作失败，表示有其他线程竞争这个对象的锁，JVM会先检查对象的Mark Word是否指向当前线程的栈帧，如果是的话，就说明当前已经拥有了这个对象的锁，直接继续同步；否则说明这个锁对象已经被其他线程抢占了。如果出现竞争锁的情况，轻量级锁需要膨胀为重量级锁，锁标志变为10，Mark Word中存储的是指向重量级锁的指针，后面等待锁的线程必须进入阻塞状态。 轻量级锁解锁也是使用CAS，如果对象的Mark Word仍然指向线程的锁记录，就使用CAS把对象的Mark Word和线程锁记录中的Mark Word替换回来，如果能够成功，就完成了；如果替换失败，说明有其他线程尝试获取过该锁，在释放锁的同时，唤醒被挂起的线程。 偏向锁轻量级锁在无竞争情况下使用CAS去消除同步使用的互斥量，偏向锁是在无竞争的情况下把整个同步都消除掉。 偏向锁工作过程： 当锁对象第一次被线程获取的时候，JVM会把对象头中的锁标志位设置为01，偏向模式设置为1，表示偏向锁模式。同时使用CAS操作把获取到这个锁的线程ID记录到对象头的Mark Word中，如果CAS操作成功，持有偏向锁的线程以后每次进入到这个锁相关的同步块时，JVM不再进行任何同步操作。 一旦出现另外一个线程尝试获取这个锁，偏向锁模式就立马结束。根据锁对象目前是否处于被锁定的被锁定的状态决定是否撤销偏向模式，撤销后锁标志恢复到未锁定01状态或者轻量级锁00状态，后续操作会按照轻量级锁那样去执行。 当一个对象已经计算过一致性哈希码后，它就再也无法进入偏向锁状态了；而当一个对象当前正处于偏向锁状态，又收到需要计算其一致性哈希码请求[1]时，它的偏向状态会被立即撤销，并且锁会膨胀为重量级锁。在重量级锁的实现中，对象头指向了重量级锁的位置，代表重量级锁的ObjectMonitor类里有字段可以记录非加锁状态（标志位为“01”）下的Mark Word，其中自然可以存储原来的哈希码。 如果程序中大多数的锁都总是被多个不同的线程访问，那偏向模式就是多余的。 JVM中使用锁的过程 一个普通对象，Mark Word中记录对象的哈希码、GC分代年龄，锁标志位为01，偏向锁模式位为0. 当对象被当做同步锁，并且有一个线程抢到了锁，锁标志位还是01，偏向锁模式位为1，前23位记录抢到锁的线程的id，接着是偏向锁时间戳、GC分代年龄，目前是偏向锁模式。 当同一个线程再来获取锁，JVM发现锁对象的处于偏向锁模式，Mark Word中线程id是当前线程，说明当前线程持有锁，可以继续执行同步代码。 当另外一个线程来获取锁，JVM发现所对象处于偏向锁状态，Mark Word中线程id不是当前线程，当前线程会先使用CAS尝试获取锁，有可能获取成功，因为持有偏向锁的线程不会自动释放偏向锁。如果当前线程抢锁成功，就把锁对象的Mark Word的线程改为当前线程的id，当前线程获取到了偏向锁。 如果获取偏向锁抢锁失败，说明锁对象有竞争，偏向锁升级为轻量级锁。JVM会在当前线程的栈帧中创建一个锁记录空间，用来保存锁对象的Mark Word，同时在锁对象的Mark Word中保存指向这个锁记录空间的指针，如果上述操作成功，当前线程抢到了锁，锁标志位修改为00轻量级锁模式，如果失败了，说明有竞争，继续执行下面的步骤。 轻量级锁抢锁失败后，JVM会使用自旋锁，当前线程自旋，如果规定的自旋时间内获取到锁，就说明成功获取锁，执行同步代码块，如果自旋不能成功获取，就会升级为重量级锁。 自旋不能成功获取锁，锁会升级为重量级锁，锁标志位10，锁对象的MarkWord存储指向重量级锁的指针。后面获取锁的线程都会阻塞。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM中的对象头]]></title>
      <url>%2F2017%2F07%2F30%2FJVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1%E5%A4%B4%2F</url>
      <content type="text"><![CDATA[JVM中的对象和对象头学习。 Hotspot虚拟机对象在堆内存中可划分为三部分： 对象头Header 实例数据Instance Data 对齐填充Padding 对象头32位Hotspot虚拟机的对象头： 图片来自《深入理解Java虚拟机》 对象头也叫Mark Word，包括两类信息： 第一部分：用于存储对象自身的运行时数据 第二部分：是类型指针，对象指向它的类型元数据的指针 存储对象自身的运行时数据对象头第一部分是用来存储对象自身的运行时数据，包括：哈希码、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。这部分长度在32位和64位虚拟机分别是32bit和64bit，不同状态下存储的内容不同： 无锁状态：25位存储对象的哈希码，4位存储对象分代年龄，1位固定为0，2位用来存储锁标志位01 轻量级锁：30位指向调用栈中锁记录的指针，2位用来存储锁标志位00 重量级锁：30位指向重量级锁的指针，2位用来存储锁标志位10 GC标记：30位为空，2位用来存储锁标志位11 可偏向锁：23位偏向线程ID，2位偏向时间戳，4位对象分代年龄，1位固定为1，2位用来存储锁标志01 类型指针类型指针是对象指向它的类型元数据的指针，通过这个指针来确定对象是哪个类的实例。如果对象是数组，对象头还有一块用来记录数组长度的数据 实例数据实例数据存储的就是我们程序代码里定义的各种类型的字段内容，从父类继承下来的、自己定义的字段都必须记录起来。 对齐填充Hotspot要求对象起始地址必须是8字节的整数倍，如果对象实例数据没有对齐的话，需要用填充来补全对齐。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM中的Java虚拟机栈]]></title>
      <url>%2F2017%2F07%2F16%2FJVM%E4%B8%AD%E7%9A%84Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88%2F</url>
      <content type="text"><![CDATA[JVM中的Java虚拟机栈学习。 Java虚拟机栈（Java Virtual Machine Stack）是线程私有的，每个线程都会有自己的Java虚拟机栈。用于存储栈帧（Frame）。 栈帧栈帧是用来存储数据和部分过程结果的数据结构，也用来处理动态链接、方法返回值、异常分派。栈帧中存储着：局部变量表、操作数栈、动态链接、方法出口等信息。 栈帧中局部变量表和操作数栈的容量是编译期确定的，通过方法的Code属性保存以及提供给栈帧使用。 局部变量表局部变量表，长度在编译期就可知，存放方法参数和方法内部定义的局部变量，包括各种基本类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型）、returnAddress类型（指向一条字节码指令的地址）。其中long和double类型的数据使用两个局部变量保存，其他的使用一个局部变量保存。 当一个方法被调用时，JVM会使用局部变量表完成参数值到参数变量列表的传递过程，即实参到形参的传递，如果执行的是实例方法，局部变量表中第0位索引的变量槽默认是用于传递方法所属对象的引用，方法中可以通过this来访问这个参数。 操作数栈是一个后进先出（LIFO）栈，典型应用就是算数运算。计算过程就是借助操作数栈来完成的。 动态链接栈帧内部包含一个指向运行时常量池的引用来支持当前方法的代码实现动态链接。Class文件中通过符号引用来描述一个方法调用其他方法或者访问其成员变量，动态链接作用就是将符号引用转换为直接引用。 Class文件中的符号引用一部分会在类加载阶段或者第一次使用的时候被转化为直接引用，称为静态解析；另外一部分在每一次运行期间都转化为直接引用，称为动态链接。 在类加载的解析阶段，其中一部分符号引用会转化为直接引用，也就是方法在程序运行之前就有一个可确定的调用版本，并且这个调用版本在运行时是不可变的，在编译期间就完全确定，主要有：静态方法、私有方法、实例构造器、父类方法、被final修饰的方法。 分派分派分为： 静态分派：静态单分派、静态多分派 动态分派：动态单分派、动态多分派 静态分派12public abstract class A &#123;&#125;public class B extends A &#123;&#125; 代码A a = new B();中： A称为变量的静态类型（Static Type）或者叫外观类型（Apparent Type） B称为变量的实际类型（Actual Type）或者叫运行时类型（Runtime Type）。 静态类型和实际类型在程序中都可能会发生变化： 静态类型的变化仅仅在使用时发生，变量本身的静态类型不会改变，最终的静态类型在编译期是可知的； 实际类型变化的结果在运行期才可确定，编译器在编译程序的时候并不知道对象的实际类型是什么。 所有依赖静态类型来决定方法执行版本的分派，称为静态分派，发生在编译阶段，典型应用：方法重载。 动态分派动态分派和重写有密切关系。 invokevirtual指令运行时的解析过程： 找到操作数栈顶的第一个元素所指向的对象的实际类型，计作C。 如果在类型C中找到与常量中的描述符和简单名称都相符的方法，则进行访问权限校验，如果通过则返回这个方法的直接引用，查找结束；不通过则返回IllegalAccessError异常。 如果找不到，则按照继承关系从下往上依次对C的各个父类进行第二步的搜索和验证。 如果没有找到合适的方法，抛出AbstractMethodError异常。 invokevirtual第一步在运行期确定接收者的实际类型，invokevirtual指令不是把常量池中方法的符号引用解析到直接引用上就完成了，还会根据方法接收者的实际类型来选择方法版本，这就是Java中的重写本质。 这种在运行期根据实际类型确定方法执行版本的分派过程称为动态分派。 单分派和多分派方法的接收者和方法的参数称为方法的宗量，根据分派基于多少种宗量，可以将分派分为单分派和多分派： 单分派，根据一个宗量对目标方法进行选择。Java的动态分派属于单分派。 多分派，根据多个宗量对目标方法进行选择。Java的静态分派属于多分派。 Java是静态多分派、动态单分派。 虚拟机动态分派的实现动态分派的方法版本选择过程需要运行时在接收者类型的方法元数据中搜索合适的目标方法，JVM机遇性能考虑，运行时不会反复搜素类型元数据，而是在方法区建立一个虚方法表，用来代替元数据查找，提高性能。 虚方法表中存放各个方法的实际入口地址，某个方法没有被子类重写，子类的虚方法表中的地址入口和父类相同方法的入口是一样的，都指向父类的实现入口。如果子类重写了这个方法，子类虚方法表的地址会被替换为子类实现版本的入口地址。 类加载的解析阶段回顾熟悉了上面的之后，可以回头来看下类加载的解析阶段。类加载过程有：加载、连接（验证、准备、解析）、初始化，其中的解析阶段是将常量池中的符号引用转换为直接引用，但是Java虚拟机规范中没有规定解析阶段发生的具体时间，只要求了在执行anewarray、checkcast、getfield、getstatic、instanceof、invokedynamic、invokeinterface、invokespecial、invokestatic、invokevirtual、ldc、ldc_w、ldc2_w、multianewarray、new、putfield和putstatic这17个用于操作符号引用的字节码指令之前，先对它们所使用的符号引用进行解析。所以虚拟机实现可以根据需要来自行判断，到底是在类被加载器加载时就对常量池中的符号引用进行解析，还是等到一个符号引用将要被使用前才去解析它。 在类加载的解析阶段，其中一部分符号引用会转化为直接引用，也就是方法在程序运行之前就有一个可确定的调用版本，并且这个调用版本在运行时是不可变的，在编译期间就完全确定，主要有：静态方法、私有方法、实例构造器、父类方法、被final修饰的方法。 动态分派可以在运行时进行解析。 方法返回地址一个方法执行完毕，需要返回之前调用的地方，栈帧中需要保存一个方法的返回地址。 方法正常调用完成 在方法的执行过程中没有任何异常（JVM抛出的异常和throw显式抛出的异常）抛出，就是正常调用完成。正常调用完成可能会有返回值返回给调用者。 方法异常调用完成 异常调用是指JVM抛出的异常或者throw显式抛出的异常，并且异常在该方法中没有处理，方法就不会有返回值返回给调用者。 无论正常还是异常调用完成，都必须返回到方法被调用的位置，方法返回时需要在栈帧中保存一些信息，用来恢复调用者这个方法的那个方法的执行状态。方法正常调用完成，调用者的程序计数器可以作为返回地址；方法异常完成，返回地址使用异常处理器表来确定。 方法退出的过程实际上等同于把当前栈帧出栈，因此退出时可能执行的操作有：恢复上层方法的局部变量表和操作数栈，把返回值（如果有的话）压入调用者栈帧的操作数栈中，调整PC计数器的值以指向方法调用指令后面的一条指令等。 参考 《深入理解Java虚拟机》 《Java虚拟机规范》]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM中的程序计数器]]></title>
      <url>%2F2017%2F07%2F16%2FJVM%E4%B8%AD%E7%9A%84%E7%A8%8B%E5%BA%8F%E8%AE%A1%E6%95%B0%E5%99%A8%2F</url>
      <content type="text"><![CDATA[JVM中的程序计数器学习。 Java虚拟机支持多线程同时执行，每个线程都有自己的程序计数器Progrom Counter Register，任意时刻一个线程只会执行一个方法的代码，程序计数器会保存正在执行的字节码指令的地址，如果方法是native的，程序计数器的值是undefined。 PC寄存器的容量至少应当能保存一个returnAddress类型的数据或者一个与平台相关的本地指针的值。 JVM的多线程是通过线程切换来实现，同一时刻在同一个cpu上只会执行一个线程中的指令，当当前线程被切换出去后，执行另外的线程，就需要在程序计数器中记录当前线程执行到了哪个字节码指令，后面再切换会这个线程的时候，就可以继续按照程序计数器中记录的字节码指令执行下去。 native方法不是由JVM执行，所以没有JVM中定义的程序计数器。 在Java虚拟机的概念模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM中的方法区、永久代以及Metaspace]]></title>
      <url>%2F2017%2F07%2F14%2FJVM%E4%B8%AD%E7%9A%84%E6%96%B9%E6%B3%95%E5%8C%BA%E3%80%81%E6%B0%B8%E4%B9%85%E4%BB%A3%E4%BB%A5%E5%8F%8AMetaspace%2F</url>
      <content type="text"><![CDATA[JVM中的方法区、永久代、元空间学习。 JVM运行时数据区域： 图片来自：https://blog.codecentric.de/en/2010/01/the-java-memory-architecture-1-act/ 图片来自：https://blog.jamesdbloom.com/JVMInternals.html Sun HotSopt的实现： 图片来自：https://blog.codecentric.de/en/2010/01/the-java-memory-architecture-1-act/ 方法区定义的实现是永久代。 方法区：Java虚拟机规范中有方法区的概念，线程共享，存储每一个类的结构信息，比如运行时常量池、字段、方法数据、构造函数、和普通方法的字节码内容、还包括一些在类、实例、接口初始化时用到的特殊方法。虽然方法区是堆的逻辑组成部分，但是简单虚拟机实现可以选择在这个区域不实现垃圾收集。 永久代：是对方法区定义的实现，永久代是Hotspot中定义的，其他的虚拟机是没有永久代的。 运行时常量池：是一个类或接口的常量池的运行时表示形式，包括编译器可知的字面量、运行期解析后才能获得的方法或字段引用。每个运行时常量池都分配在JVM的方法区中。 字符串常量池：在永久代中。 永久代中包含了：字符串常量池和方法区规范中定义的具体实现。 在JDK1.6以及之前存在永久代，永久代包含字符串常量池和方法区具体实现 在JDK1.7版本中仍然存在永久代，但是字符串常量池被移到了堆中，符号引用移到了本地内存、类的静态变量移到了堆中。 在JDK1.8版本移除了永久代，使用与堆不相连的Metaspace元空间来代替永久代，并且元空间不在虚拟机内存中，是用的是本地内存。元空间也是对Java虚拟机规范中的方法区定义的具体实现。 为什么移除永久代 字符串常量池存在永久代中，容易出现性能问题和内存溢出 永久代大小不容易确定，PermSize指定太小容易造成永久代OOM 永久代会为GC带来不必要的复杂度，并且回收效率偏低 Oracle 可能会将HotSpot 与 JRockit 合二为一 方法区中存储了什么 存储每一个类的结构信息，比如运行时常量池、字段、方法数据、构造函数、和普通方法的字节码内容、还包括一些在类、实例、接口初始化时用到的特殊方法。 《Java虚拟机规范》 已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据 《深入理解Java虚拟机》 Class文件信息存储着加载的Class文件信息，Class文件信息中包含了Class文件常量池，文件常量池中存放着字面量和符号引用。 运行时常量池类加载完后，JVM会将Class文件中的文件常量池转移到运行时常量池中，还会把一部分的符号引用转换为直接引用。 初始化时的特殊方法 &lt;init&gt;，是实例的初始化方法，表示的是Java语言中的构造方法，这个名称由编译器命名，实例初始化方法只能在实例的初始化期间，通过JVM的invokespecial指令来调用，只有实例正在构造的时候，实例化初始化方法才可以被调用访问。 &lt;clinit&gt;，表示的是类或者接口的初始化方法，这个是一个不包含参数的静态方法，名字是由编译器命名。类或接口的初始化方法由JVM自身隐式调用，在类的初始化阶段中被虚拟机自身调用。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM中的常量池]]></title>
      <url>%2F2017%2F07%2F08%2FJVM%E4%B8%AD%E7%9A%84%E5%B8%B8%E9%87%8F%E6%B1%A0%2F</url>
      <content type="text"><![CDATA[JVM中的常量池有：运行时常量池、Class文件常量池、字符串常量池、包装类常量池。 可以先看下JVM运行时数据区域图： 图片来自：https://blog.jamesdbloom.com/JVMInternals.html 在Non Heap非堆中包含了Code Cache和永久代，永久代中包含Interned String和方法区，方法区中包含了运行时常量池。 Class文件常量池编译后的class文件中，除了包含类的版本、字段、方法、接口等的描述信息外，还包含常量池表（Constant Pool Table），用来存放编译器生成的字面量（Literal）和符号引用（Symbolic References）。 字面量字面量比较接近于Java语言层面的常量概念，比如： 文本字符串，private String s = &quot;xxx&quot;;中的&quot;xxx&quot;是字面量 被声明为final的常量值，包括静态变量、实例变量、局部变量的值。private final static int i = 3;中的3是字面量 符号引用符号引用属于编译原理方面的概念，包括： 被模块导出或者开放的包（Package） 类和接口的全限定名（Fully Qualified Name） 字段的名称和描述符（Descriptor） 方法的名称和描述符 方法句柄和方法类型（Method Handle、Method Type、Invoke Dynamic） 动态调用点和动态常量（Dynamically-Computed Call Site、Dynamically-Computed Constant） Java代码在编译的时候，没有连接这一步，而是在JVM加载Class文件的时候在解析这一步进行动态连接，将符号引用替换为直接引用。也就是说Class文件中不会保存方法、字段等在内存中的布局信息。而是在类加载的解析这一步将符号引用翻译为具体的内存地址。 运行时常量池Class文件中存在一个Class文件常量池，编译期生成的字面量和符号引用存在Class文件常量池中。Class文件常量池中的内容在类加载的时候会放到方法区的运行时常量池中。 运行时常量池（Runtime Constant Pool）是方法区的一部分。 JVM类加载过程的加载阶段，会将class文件中的静态结构转化为方法区的运行时数据结构，这里就包含了Class文件常量池加载进运行时常量池中。在解析阶段会把会把符号引用替换为直接引用。 运行时常量池具有动态性，运行时常量池中内容不全部来自Class文件常量池，在运行时可以通过代码生成常量并将其放入运行时常量池中，比如：String.intern()。 字符串常量池 为了避免多次创建字符串对象，JVM开辟出一块字符串常量池空间用来存储不重复的字符串。 直接使用双引号&quot;&quot;声明的字符串，比如String s = &quot;abcd&quot;;，JVM会先去常量池中查找有没有相同的字符串常量，如果有就把常量池的引用返回给变量；如果没有就会在字符串常量池中创建一个字符串常量，然后把这个引用返回给变量。 使用new关键字创建String对象，比如String s = new String(&quot;abcd&quot;);，如果字符串常量池中不存在这个字符串常量，会创建两个对象，一个是在字符串常量池中的字符串常量：abcd，一个是在堆中的String对象，返回给变量的是String对象引用。如果字符串常量池中已经存在这个字符串常量，则会创建一个对象，是在堆中的String对象，返回给变量的是String对象引用。 字符串常量池的位置 HotSpot在JDK1.6以及之前，字符串常量池在永久代中。 在JDK1.7以及之后，字符串常量池移动到了堆中。 字符串常量池的实现在HotSpot中，字符串常量池是一个叫做StringTable的全局的哈希表，也就是一个Hashtable。 字符串常量里存的是什么 JDK1.6以及之前存放的是字符串常量 JDK1.7以及之后存放的是字符串常量和字符串对象的引用，字符串对象存在堆中。 String.intern()方法intern方法可以在运行时可以通过代码生成常量并将其放入运行时常量池中。 JDK1.6以及以前，调用intern方法，会先判断常量池中是否已经存在该字符串常量，如果存在，则直接返回该字符串常量；如果不存在，则在常量池中加入该字符串常量。 JDK1.7以及以后，调用intern方法，会先判断常量池中是否已经存在该字符串常量，如果存在，则直接返回该字符串常量；如果不存在，说明该字符串常量在堆中，则需要把堆中该对对象的引用加入到字符串常量池中。 为什么要把字符串常量池移到堆中JDK1.6以及之前字符串常量池是放在永久代，也就是方法区中的，方法区中存储类的结构信息，例如运行时常量池、字段、方法数据、构造函数、普通方法的字节码内容、还包括一些在类、实例、接口初始化时用到的特殊方法。一旦大量使用intern方法，常量池会被大量占用，会产生java.lang.OutOfMemoryError: PermGen space错误。 字符串常量池几个实例分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103public class Test &#123; public static void main(String[] args) &#123; /** * 创建两个对象： * 字符串常量池中创建字符串常量：abc * 堆中创建一个String对象，str1指向String对象 */ String str1 = new String("abc"); /** * 这里会先查看字符串常量池中有没有abc字符串， * 这里是有的，直接返回。 * str2指向字符串常量池中的常量 */ String str2 = str1.intern(); /** * str1指向堆中String对象 * str2指向常量池中的常量 * false */ System.out.println(str1 == str2); /** * abc存在于字符串常量池，str3直接指向字符串常量池中的该常量 */ String str3 = "abc"; /** * str1指向堆中String对象 * str3指向常量池中的常量 * false */ System.out.println(str1 == str3); /** * str2指向常量池中的常量 * str3指向常量池中的常量 * true */ System.out.println(str2 == str3); /** * 底层会使用StringBuilder将de和de拼接成dede * dede字符串对象在堆中创建 * str4指向堆中的dede对象 */ String str4 = new String("de") + new String("de"); /** * dede在字符串常量池中不存在， * jdk1.6以及以前，会把在字符串常量池中创建字符串常量dede，str5指向字符串常量池中 * jdk1.7以及以后，会把堆中dede的引用放到字符串常量池中，str5指向dede的引用 */ String str5 = str4.intern(); /** * jdk1.6以及以前： * str4指向堆中的dede对象 * str5指向字符串常量池中 * 所以这里是false * * jdk1.7以及以后： * str4指向堆中的dede对象 * str5指向dede堆中的引用 * 所以这里是true */ System.out.println(str4 == str5); /** * jdk1.6以及以前，str6会指向字符串常量池中 * jdk1.7以及以后，str6指向dede堆中的引用 */ String str6 = "dede"; /** * jdk1.6以及以前： * str4指向堆中的dede对象 * str6会指向字符串常量池中 * 所以这里是false * * jdk1.7以及以后： * str4指向堆中的dede对象 * str6指向dede堆中的引用 * 所以这里是true */ System.out.println(str4 == str6); /** * jdk1.6以及以前： * str5指向字符串常量池中 * str6会指向字符串常量池中 * 所以这里是true * * jdk1.7以及以后： * str5指向dede堆中的引用 * str6指向dede堆中的引用 * 所以这里是true */ System.out.println(str5 == str6); &#125;&#125; 包装类常量池Byte、Short、Integer、Long、Character、Boolean这些包装类使用了常量池技术，对应值在-128~127时可以使用常量池，也就是缓存。 Float，Double这两个包装类没有使用常量池。 总结 字符串常量池，全局只有一个，存放字符串常量 Class文件常量池，每个class文件都有一个，编译阶段生成，存放编译器生成的字面量和符号引用 运行时常量池，每个class都有一个运行时常量池，在类加载的时候会把Class文件常量池中的信息放到运行时常量池，解析阶段会把符号引用替换为直接引用。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM空间分配担保]]></title>
      <url>%2F2017%2F07%2F01%2FJVM%E7%A9%BA%E9%97%B4%E5%88%86%E9%85%8D%E6%8B%85%E4%BF%9D%2F</url>
      <content type="text"><![CDATA[当发生YGC时，JVM先检查老年代最大的可用连续空间是否大于新生代所有对象总和，如果大于，这次YGC是安全的；如果不大于则会看HandlePromotionFailure参数配置的值。 HandlePromotionFailure为true表示允许担保失败，JVM会继续检查老年代最大可用连续空间是否大于历次晋升到老年代的对象的平均大小，如果大于，则尝试进行一次YGC，但这次YGC是有风险的；如果小于则进行一次Full GC。 HandlePromotionFailure为false表示不允许担保失败，JVM会进行一次Full GC。 上面说的YGC是有风险的解释： 新生代使用复制算法，如果出现大量对象在YGC之后都存活，Suvivor放不下这些对象，就需要空间分配担保，把这些对象放进老年代。老年代如果根据历次晋升到老年代的对象的平均大小来做判断，并不一定会准确，有可能会出现担保失败，出现担保失败就会触发一次Full GC。虽然有这种概率出现，但是大部分情况都能分配担保成功，可以避免频繁Full GC。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM中的CMS垃圾收集器]]></title>
      <url>%2F2017%2F07%2F01%2FJVM%E4%B8%AD%E7%9A%84CMS%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2F</url>
      <content type="text"><![CDATA[CMS是老年代的垃圾收集器，使用标记-清除算法，是并发的收集器。可与Serial收集器和Parallel New收集器配合使用。 CMS尽可能的缩短垃圾收集时用户线程的停顿时间。分为四个阶段： 初始标记 并发标记 重新标记 并发清除 优点： 并发收集器 GC过程中暂停时间短。 缺点： 对CPU资源敏感，并发阶段不会停顿，但是占用一部分县城，总吞吐量降低。 无法处理浮动垃圾，并发清理阶段，程序运行还会产生新的垃圾。 CMS基于标记-清除算法，收集结束后会产生空间碎片。 触发CMS垃圾收集的条件周期性的，JVM默认2秒触发一次CMS的GC；主动触发，YGC发生了Promotion Failed，会触发对老年代进行回收，或者System.gc()触发。 如果触发了主动的GC，周期性的GC会被夺取掉执行权，并记录 concurrent mode failure 或者 concurrent mode interrupted。 触发的条件： 如果没有设置UseCMSInitiatingOccupancyOnly参数，CMS默认会根据JVM运行时统计数据来判断是否触发CMS GC。 如果设置了UseCMSInitiatingOccupancyOnly参数，并且配置了-XX:CMSInitiatingOccupancyFraction参数，会根据这个配置的参数来判断老年代使用率是否超过阈值来决定是否开启CMS GC。 如果设置了UseCMSInitiatingOccupancyOnly参数，但没有配置-XX:CMSInitiatingOccupancyFraction参数，默认在使用率到92%的时候触发CMS GC。 CMS默认不会对永久代进行垃圾收集，如果需要对永久代收集，需要设置参数-XX:+CMSClassUnloadingEnabled，CMS就会根据永久代内存使用率，默认92%，来判断是否开启CMS GC。 新生代晋升担保失败，会触发CMS GC。 GC过程可分为四个大的阶段： 初始标记 并发标记 重新标记 并发清除 按照GC日志中显示的，可以细分为7个阶段： 初始标记（CMS Initial Mark），会Stop The World 并发标记（CMS-concurrent-mark） 预清理（CMS-concurrent-preclean） 可被终止的预清理（CMS-concurrent-abortable-preclean） 重新标记（CMS Final Remark），会Stop The World 并发清除（CMS-concurrent-sweep） 重置状态（CMS-concurrent-reset），重置CMS实现的内部数据结构 初始标记初始标记会Stop The World，标记GC Root能直接关联到的对象，速度很快。包含两部分： 标记GC Roots直接可达的老年代对象。 标记新生代中活着的对象引用到的老年代对象。 并发标记并发标记阶段和应用线程兵法执行。遍历初始标记阶段的被标记的对象，继续递归标记这些对象的可达对象。 由于该阶运行的过程中用户线程也在运行，这就可能会发生这样的情况，已经被遍历过的对象的引用被用户线程改变等，如果发生了这样的情况，JVM就会标记这个区域为Dirty Card。后续只需要扫描这些Dirty Card，可以避免扫描整个老年代。 这个阶段是和用户线程并发的，可能会导致concurrent mode failure。 预清理用来处理并发标记阶段的Dirty Card，遍历这些对象重新标记。 可终止的预清理在预清理完成后，会判断Eden的占用量是否大于CMSScheduleRemarkEdenSizeThreshold(默认为2M)，如果大于就会启动当前可终止的预清理阶段，直到Eden区占用量达到CMSScheduleRemarkEdenPenetration(默认50%)，或达到5秒钟。但是如果ygc在这个阶段中没有发生的话，是达不到理想效果的。此时可以指定CMSMaxAbortablePrecleanTime，但是，等待一般都不是什么好的策略，可以采用CMSScavengeBeforeRemark，使remark之前发生一次YGC，从而减少remark阶段暂停的时间。 重新标记重新标记阶段会Stop The World，该阶段的任务是完成标记整个年老代的所有的存活对象，尽管先前的pre clean阶段尽量应对处理了并发运行时用户线程改变的对象应用的标记，但是不可能跟上对象改变的速度，只是为final remark阶段尽量减少了负担。 并发清除清除那些没有被标记的可以回收的对象，由于这一阶段应用程序线程也在运行，这时候产生的浮动垃圾就不能被处理，只能等到下一次GC时在清理。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM中FullGC耗时过高]]></title>
      <url>%2F2017%2F06%2F24%2FJVM%E4%B8%ADFullGC%E8%80%97%E6%97%B6%E8%BF%87%E9%AB%98%2F</url>
      <content type="text"><![CDATA[分析一下FullGC耗时过高的原因 暂时还没遇到实际例子，后面生产环境遇到了之后再来补充。 针对不同的垃圾收集器，Full GC的触发条件可能不都一样。按HotSpot VM的serial GC的实现来看，触发条件是： 当准备要触发一次Young GC时，如果发现统计数据说之前Young GC的平均晋升大小比目前老年代剩余的空间大，则不会触发Young GC而是转为触发Full GC（因为HotSpot VM的GC里，除了CMS的并发收集之外，其它能收集老年代的GC都会同时收集整个GC堆，包括新生代，所以不需要事先触发一次单独的Young GC）。 如果有永久代（方法区）的话，要在永久代分配空间但已经没有足够空间时，也要触发一次Full GC。 System.gc()、heap dump带GC，默认也是触发Full GC。 老年代空间不足，新生代对象转入以及创建大对象大数组时，空间不足，会导致Full GC；或者空间足够，但是没有足够的连续空间存放对象，会导致Full GC。CMS垃圾收集器提供了一个可配置的参数-XX:+UseCMSCompactAtFullCollection，用于在Full GC后进行碎片整理的，内存整理的过程无法并发的，需要stop the world，JVM还提供了另外一个参数-XX:CMSFullGCsBeforeCompaction用于设置在执行多少次不压缩的Full GC后，跟着来一次带压缩的。 CMS GC出现promotion failed和concurrent mode failure会导致Full GC，promotion failed是在进行YGC时，survivor区放不下、对象只能放入老年代，而此时老年代也放不下造成的；concurrent mode failure是在执行CMS GC的过程中同时有对象要放入老年代，而此时老年代空间不足造成的（有时候空间不足是CMS GC时当前的浮动垃圾过多导致暂时性的空间不足触发Full GC）。 而在 Parallel Scavenge 收集器下，默认是在要触发 Full GC前先执行一次 YGC，并且两次GC之间能让应用程序稍微运行一小下，以期降低 Full GC的暂停时间 (因为 YGC 会尽量清理了新生代的死对象，减少了 Full GC的工作量)，控制这个行为的VM参数是-XX:+ScavengeBeforeFullGC。 并发GC的触发条件就不一样，以 CMS GC为例，它主要是定时去检查老年代的使用量，但使用量超过了触发比例就会启动一次 CMS GC，对老年代做并发收集。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM中FullGC频繁]]></title>
      <url>%2F2017%2F06%2F24%2FJVM%E4%B8%ADFullGC%E9%A2%91%E7%B9%81%2F</url>
      <content type="text"><![CDATA[分析一下FullGC频繁的原因 暂时还没遇到实际例子，后面生产环境遇到了之后再来补充。 针对不同的垃圾收集器，Full GC的触发条件可能不都一样。按HotSpot VM的serial GC的实现来看，触发条件是： 当准备要触发一次Young GC时，如果发现统计数据说之前Young GC的平均晋升大小比目前老年代剩余的空间大，则不会触发Young GC而是转为触发Full GC（因为HotSpot VM的GC里，除了CMS的并发收集之外，其它能收集老年代的GC都会同时收集整个GC堆，包括新生代，所以不需要事先触发一次单独的Young GC）。 如果有永久代（方法区）的话，要在永久代分配空间但已经没有足够空间时，也要触发一次Full GC。 System.gc()、heap dump带GC，默认也是触发Full GC。 老年代空间不足，新生代对象转入以及创建大对象大数组时，空间不足，会导致Full GC；或者空间足够，但是没有足够的连续空间存放对象，会导致Full GC。CMS垃圾收集器提供了一个可配置的参数-XX:+UseCMSCompactAtFullCollection，用于在Full GC后进行碎片整理的，内存整理的过程无法并发的，需要stop the world，JVM还提供了另外一个参数-XX:CMSFullGCsBeforeCompaction用于设置在执行多少次不压缩的Full GC后，跟着来一次带压缩的。 CMS GC出现promotion failed和concurrent mode failure会导致Full GC，promotion failed是在进行YGC时，survivor区放不下、对象只能放入老年代，而此时老年代也放不下造成的；concurrent mode failure是在执行CMS GC的过程中同时有对象要放入老年代，而此时老年代空间不足造成的（有时候空间不足是CMS GC时当前的浮动垃圾过多导致暂时性的空间不足触发Full GC）。 而在 Parallel Scavenge 收集器下，默认是在要触发 Full GC前先执行一次 YGC，并且两次GC之间能让应用程序稍微运行一小下，以期降低 Full GC的暂停时间 (因为 YGC 会尽量清理了新生代的死对象，减少了 Full GC的工作量)，控制这个行为的VM参数是-XX:+ScavengeBeforeFullGC。 并发GC的触发条件就不一样，以 CMS GC为例，它主要是定时去检查老年代的使用量，但使用量超过了触发比例就会启动一次 CMS GC，对老年代做并发收集。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM中YoungGC耗时过高]]></title>
      <url>%2F2017%2F06%2F24%2FJVM%E4%B8%ADYoungGC%E8%80%97%E6%97%B6%E8%BF%87%E9%AB%98%2F</url>
      <content type="text"><![CDATA[分析一下YGC耗时过高的原因 目前还没有遇到具体的例子。 可能的原因： 新生代空间太大 对象引用链较长，可达性分析时间长 新生代Survivor区太小，清理后剩余的对象不能装进去需要移动到老年代，造成移动开销。 内存分配担保失败，由YGC转化为Full GC 采用的垃圾收集器效率较低，比如新生代使用serial收集器]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM中YoungGC频繁]]></title>
      <url>%2F2017%2F06%2F24%2FJVM%E4%B8%ADYoungGC%E9%A2%91%E7%B9%81%2F</url>
      <content type="text"><![CDATA[分析一下YGC频繁的原因。 GC log分析log中打印的参数12345678Java HotSpot(TM) 64-Bit Server VM (25.172-b11) for linux-amd64 JRE (1.8.0_172-b11), built on Mar 28 2018 21:44:09 by &quot;java_re&quot; with gcc 4.3.0 20080428 (Red Hat 4.3.0-8)Memory: 4k page, physical 8028236k(5004928k free), swap 4096572k(4096572k free)CommandLine flags: -XX:CMSInitiatingOccupancyFraction&#x3D;70 -XX:+CMSScavengeBeforeRemark -XX:CompressedClassSpaceSize&#x3D;528482304 -XX:+DisableExplicitGC -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;&#x2F;home&#x2F;admin&#x2F;service_heap_dump_20190409134805.hprof -XX:InitialHeapSize&#x3D;4294967296 -XX:MaxHeapSize&#x3D;4294967296 -XX:MaxMetaspaceSize&#x3D;536870912 -XX:MaxNewSize&#x3D;2147483648 -XX:NewSize&#x3D;2147483648 -XX:OldPLABSize&#x3D;16 -XX:-OmitStackTraceInFastThrow -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+ScavengeBeforeFullGC -XX:SurvivorRatio&#x3D;8 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:+UseParNewGC Memory: 4k page physical 8028236k(5004928k free)，物理内存，7.6G（4.77G空闲） swap 4096572k(4096572k free)，交换空间，4G（4G空闲） -XX:CMSInitiatingOccupancyFraction=70，CMS垃圾收集器，当老年代达到指定阈值时，触发CMS垃圾回收，这里是70% -XX:+CMSScavengeBeforeRemark，CMS在remark之前进行一次YGC，由于新生代存在引用老年代对象的情况，因此CMS remark阶段会将新生代作为老年代的GC ROOTS进行扫描，防止回收了不该回收的对象。而配置CMSScavengeBeforeRemark参数，在CMS GC的remark阶段开始前先进行一次YGC，有利于减少新生代对老年代的无效引用，降低remark阶段的时间开销。 -XX:CompressedClassSpaceSize=528482304，设置Klass Metaspace的大小，500M -XX:+DisableExplicitGC，禁止代码中显示调用GC -XX:+HeapDumpOnOutOfMemoryError，当JVM发生OOM时，自动生成DUMP文件 -XX:HeapDumpPath=/home/admin/service_heap_dump_20190409134805.hprof，生成DUMP文件的路径 -XX:InitialHeapSize=4294967296，也就是-Xms指定的参数，初始堆内存大小，4G -XX:MaxHeapSize=4294967296，也就是-Xmx指定的参数，最大堆内存大小，4G -XX:MaxMetaspaceSize=536870912，Metaspace大小，512M -XX:MaxNewSize=2147483648，新生代可被分配的内存的最大上限，2G -XX:NewSize=2147483648，新生代初始化内存的大小，2G（-Xmn可同时对XX:NewSize和XX:MaxNewSize参数设置） -XX:OldPLABSize=16，老年代空间 PLAB 大小 -XX:-OmitStackTraceInFastThrow，禁用Fast Throw优化 -XX:+PrintGC，打印GC日志 -XX:+PrintGCDateStamps，输出GC的时间戳 -XX:+PrintGCDetails，打印GC的详细信息 -XX:+PrintGCTimeStamps，输出GC时间戳 -XX:+ScavengeBeforeFullGC，Full GC前执行一次YGC -XX:SurvivorRatio=8，Eden和两个Survivor的比例：8:1:1 -XX:+UseCompressedClassPointers，压缩类指针 -XX:+UseCompressedOops，压缩对象指针，oops指的是普通对象指针(ordinary object pointers)，Java堆中对象指针会被压缩成32位 -XX:+UseConcMarkSweepGC，老年代收集器为CMS -XX:+UseParNewGC，新生代收集器为ParNew 实际启动参数1-server -Xms4g -Xmx4g -Xmn2g -XX:MaxMetaspaceSize&#x3D;512m -XX:SurvivorRatio&#x3D;8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction&#x3D;70 -XX:+ScavengeBeforeFullGC -XX:+CMSScavengeBeforeRemark -XX:+DisableExplicitGC -XX:-OmitStackTraceInFastThrow -XX:+PrintGCDateStamps -verbose:gc -XX:+PrintGCDetails -Xloggc:$&#123;HOME&#125;&#x2F;service_gc_&#96;date +%Y%m%d%H%M%S&#96;.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;$&#123;HOME&#125;&#x2F;service_heap_dump_&#96;date +%Y%m%d%H%M%S&#96;.hprof -Xms4g，初始堆大小，4G -Xmx4g，最大堆大小，4G -Xmn2g，新生代初始内存和最大内存都是2G Eden=1.6g，Suvivor0=0.2g，Suvivor1=0.2g GC log12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788892019-04-10T20:04:51.945+0800: 109006.832: [GC (GCLocker Initiated GC) 2019-04-10T20:04:51.945+0800: 109006.832: [ParNew: 1823929K-&gt;209664K(1887488K), 0.1568521 secs] 2587624K-&gt;1013834K(3984640K), 0.1572354 secs] [Times: user&#x3D;0.58 sys&#x3D;0.00, real&#x3D;0.16 secs] 2019-04-10T20:04:53.556+0800: 109008.442: [GC (Allocation Failure) 2019-04-10T20:04:53.556+0800: 109008.442: [ParNew: 1887488K-&gt;188658K(1887488K), 0.0834678 secs] 2691658K-&gt;1039814K(3984640K), 0.0837781 secs] [Times: user&#x3D;0.33 sys&#x3D;0.00, real&#x3D;0.08 secs] 2019-04-10T20:04:54.928+0800: 109009.815: [GC (Allocation Failure) 2019-04-10T20:04:54.928+0800: 109009.815: [ParNew: 1866482K-&gt;147763K(1887488K), 0.0521302 secs] 2717638K-&gt;999285K(3984640K), 0.0524123 secs] [Times: user&#x3D;0.20 sys&#x3D;0.00, real&#x3D;0.05 secs] 2019-04-10T20:04:56.314+0800: 109011.200: [GC (Allocation Failure) 2019-04-10T20:04:56.314+0800: 109011.201: [ParNew: 1825587K-&gt;164545K(1887488K), 0.1519752 secs] 2677109K-&gt;1084741K(3984640K), 0.1522695 secs] [Times: user&#x3D;0.56 sys&#x3D;0.00, real&#x3D;0.15 secs] 2019-04-10T20:04:57.954+0800: 109012.841: [GC (Allocation Failure) 2019-04-10T20:04:57.954+0800: 109012.841: [ParNew: 1842369K-&gt;194192K(1887488K), 0.1914321 secs] 2762565K-&gt;1234446K(3984640K), 0.1916991 secs] [Times: user&#x3D;0.70 sys&#x3D;0.00, real&#x3D;0.19 secs] 2019-04-10T20:04:59.497+0800: 109014.384: [GC (Allocation Failure) 2019-04-10T20:04:59.497+0800: 109014.384: [ParNew: 1872016K-&gt;160741K(1887488K), 0.0486877 secs] 2912270K-&gt;1201078K(3984640K), 0.0489626 secs] [Times: user&#x3D;0.19 sys&#x3D;0.00, real&#x3D;0.05 secs] 2019-04-10T20:05:00.812+0800: 109015.699: [GC (Allocation Failure) 2019-04-10T20:05:00.813+0800: 109015.699: [ParNew: 1835736K-&gt;151823K(1887488K), 0.1376864 secs] 2876073K-&gt;1255445K(3984640K), 0.1380070 secs] [Times: user&#x3D;0.51 sys&#x3D;0.00, real&#x3D;0.14 secs] 2019-04-10T20:05:02.554+0800: 109017.440: [GC (Allocation Failure) 2019-04-10T20:05:02.554+0800: 109017.440: [ParNew: 1829647K-&gt;171511K(1887488K), 0.1798695 secs] 2933269K-&gt;1387182K(3984640K), 0.1801425 secs] [Times: user&#x3D;0.67 sys&#x3D;0.00, real&#x3D;0.18 secs] 2019-04-10T20:05:04.059+0800: 109018.946: [GC (Allocation Failure) 2019-04-10T20:05:04.059+0800: 109018.946: [ParNew: 1849335K-&gt;167007K(1887488K), 0.0483309 secs] 3065006K-&gt;1383074K(3984640K), 0.0486151 secs] [Times: user&#x3D;0.16 sys&#x3D;0.00, real&#x3D;0.05 secs] 2019-04-10T20:05:05.628+0800: 109020.515: [GC (Allocation Failure) 2019-04-10T20:05:05.628+0800: 109020.515: [ParNew: 1844831K-&gt;209664K(1887488K), 0.1480378 secs] 3060898K-&gt;1457657K(3984640K), 0.1483184 secs] [Times: user&#x3D;0.57 sys&#x3D;0.00, real&#x3D;0.15 secs] 2019-04-10T20:05:07.079+0800: 109021.966: [GC (Allocation Failure) 2019-04-10T20:05:07.079+0800: 109021.966: [ParNew: 1887488K-&gt;170162K(1887488K), 0.0579737 secs] 3135481K-&gt;1418544K(3984640K), 0.0582560 secs] [Times: user&#x3D;0.23 sys&#x3D;0.00, real&#x3D;0.06 secs] 2019-04-10T20:05:08.604+0800: 109023.491: [GC (Allocation Failure) 2019-04-10T20:05:08.604+0800: 109023.491: [ParNew: 1847986K-&gt;209664K(1887488K), 0.1702964 secs] 3096368K-&gt;1587027K(3984640K), 0.1705767 secs] [Times: user&#x3D;0.63 sys&#x3D;0.00, real&#x3D;0.18 secs] 2019-04-10T20:05:10.186+0800: 109025.073: [GC (Allocation Failure) 2019-04-10T20:05:10.186+0800: 109025.073: [ParNew: 1887488K-&gt;200295K(1887488K), 0.1819795 secs] 3264851K-&gt;1676149K(3984640K), 0.1822649 secs] [Times: user&#x3D;0.67 sys&#x3D;0.00, real&#x3D;0.18 secs] 2019-04-10T20:05:10.372+0800: 109025.259: [GC (CMS Initial Mark) [1 CMS-initial-mark: 1475854K(2097152K)] 1694195K(3984640K), 0.0302480 secs] [Times: user&#x3D;0.07 sys&#x3D;0.00, real&#x3D;0.03 secs] 2019-04-10T20:05:10.403+0800: 109025.289: [CMS-concurrent-mark-start]2019-04-10T20:05:10.565+0800: 109025.452: [CMS-concurrent-mark: 0.162&#x2F;0.162 secs] [Times: user&#x3D;0.36 sys&#x3D;0.00, real&#x3D;0.17 secs] 2019-04-10T20:05:10.565+0800: 109025.452: [CMS-concurrent-preclean-start]2019-04-10T20:05:10.571+0800: 109025.458: [CMS-concurrent-preclean: 0.006&#x2F;0.006 secs] [Times: user&#x3D;0.01 sys&#x3D;0.00, real&#x3D;0.00 secs] 2019-04-10T20:05:10.571+0800: 109025.458: [CMS-concurrent-abortable-preclean-start]2019-04-10T20:05:11.842+0800: 109026.729: [GC (GCLocker Initiated GC) 2019-04-10T20:05:11.842+0800: 109026.729: [ParNew: 1849355K-&gt;187949K(1887488K), 0.1785371 secs] 3357977K-&gt;1840092K(3984640K), 0.1789082 secs] [Times: user&#x3D;0.65 sys&#x3D;0.00, real&#x3D;0.18 secs] 2019-04-10T20:05:13.012+0800: 109027.899: [CMS-concurrent-abortable-preclean: 2.251&#x2F;2.441 secs] [Times: user&#x3D;6.67 sys&#x3D;0.00, real&#x3D;2.44 secs] 2019-04-10T20:05:13.013+0800: 109027.900: [GC (CMS Final Remark) [YG occupancy: 1220076 K (1887488 K)]2019-04-10T20:05:13.013+0800: 109027.900: [GC (CMS Final Remark) 2019-04-10T20:05:13.014+0800: 109027.900: [ParNew: 1220076K-&gt;154513K(1887488K), 0.1657934 secs] 2872219K-&gt;1924261K(3984640K), 0.1660497 secs] [Times: user&#x3D;0.60 sys&#x3D;0.00, real&#x3D;0.17 secs] 2019-04-10T20:05:13.180+0800: 109028.066: [Rescan (parallel) , 0.0454351 secs]2019-04-10T20:05:13.225+0800: 109028.112: [weak refs processing, 0.0001084 secs]2019-04-10T20:05:13.225+0800: 109028.112: [class unloading, 0.0520415 secs]2019-04-10T20:05:13.277+0800: 109028.164: [scrub symbol table, 0.0156959 secs]2019-04-10T20:05:13.293+0800: 109028.180: [scrub string table, 0.0014593 secs][1 CMS-remark: 1769747K(2097152K)] 1924261K(3984640K), 0.3026953 secs] [Times: user&#x3D;0.87 sys&#x3D;0.00, real&#x3D;0.31 secs] 2019-04-10T20:05:13.316+0800: 109028.203: [CMS-concurrent-sweep-start]2019-04-10T20:05:14.813+0800: 109029.700: [GC (Allocation Failure) 2019-04-10T20:05:14.813+0800: 109029.700: [ParNew: 1832337K-&gt;209664K(1887488K), 0.1690814 secs] 2401415K-&gt;829430K(3984640K), 0.1694105 secs] [Times: user&#x3D;0.64 sys&#x3D;0.00, real&#x3D;0.17 secs] 2019-04-10T20:05:15.076+0800: 109029.963: [CMS-concurrent-sweep: 1.586&#x2F;1.760 secs] [Times: user&#x3D;5.11 sys&#x3D;0.00, real&#x3D;1.76 secs] 2019-04-10T20:05:15.076+0800: 109029.963: [CMS-concurrent-reset-start]2019-04-10T20:05:15.080+0800: 109029.967: [CMS-concurrent-reset: 0.004&#x2F;0.004 secs] [Times: user&#x3D;0.01 sys&#x3D;0.00, real&#x3D;0.00 secs] 2019-04-10T20:05:16.566+0800: 109031.452: [GC (Allocation Failure) 2019-04-10T20:05:16.566+0800: 109031.452: [ParNew: 1887488K-&gt;209664K(1887488K), 0.0852347 secs] 2376299K-&gt;751020K(3984640K), 0.0855516 secs] [Times: user&#x3D;0.34 sys&#x3D;0.00, real&#x3D;0.08 secs] 2019-04-10T20:05:16.655+0800: 109031.541: [GC (GCLocker Initiated GC) 2019-04-10T20:05:16.655+0800: 109031.542: [ParNew: 226066K-&gt;69094K(1887488K), 0.1444585 secs] 767423K-&gt;723085K(3984640K), 0.1446827 secs] [Times: user&#x3D;0.42 sys&#x3D;0.00, real&#x3D;0.15 secs] 2019-04-10T20:05:18.192+0800: 109033.079: [GC (Allocation Failure) 2019-04-10T20:05:18.193+0800: 109033.079: [ParNew: 1746918K-&gt;121493K(1887488K), 0.0520770 secs] 2400909K-&gt;775483K(3984640K), 0.0523791 secs] [Times: user&#x3D;0.21 sys&#x3D;0.00, real&#x3D;0.05 secs] 2019-04-10T20:05:19.766+0800: 109034.653: [GC (Allocation Failure) 2019-04-10T20:05:19.766+0800: 109034.653: [ParNew: 1799317K-&gt;172147K(1887488K), 0.2003248 secs] 2453307K-&gt;940006K(3984640K), 0.2009707 secs] [Times: user&#x3D;0.71 sys&#x3D;0.00, real&#x3D;0.20 secs] 2019-04-10T20:05:21.337+0800: 109036.224: [GC (Allocation Failure) 2019-04-10T20:05:21.337+0800: 109036.224: [ParNew: 1850818K-&gt;173032K(1887488K), 0.2056822 secs] 2618676K-&gt;1080561K(3984640K), 0.2060002 secs] [Times: user&#x3D;0.72 sys&#x3D;0.00, real&#x3D;0.20 secs] 2019-04-10T20:05:21.546+0800: 109036.433: [GC (GCLocker Initiated GC) 2019-04-10T20:05:21.547+0800: 109036.433: [ParNew: 190483K-&gt;57139K(1887488K), 0.0843375 secs] 1098011K-&gt;1080787K(3984640K), 0.0845775 secs] [Times: user&#x3D;0.29 sys&#x3D;0.00, real&#x3D;0.08 secs] 2019-04-10T20:05:23.036+0800: 109037.923: [GC (Allocation Failure) 2019-04-10T20:05:23.036+0800: 109037.923: [ParNew: 1734963K-&gt;142250K(1887488K), 0.0654108 secs] 2758611K-&gt;1165898K(3984640K), 0.0657093 secs] [Times: user&#x3D;0.25 sys&#x3D;0.00, real&#x3D;0.07 secs] 2019-04-10T20:05:24.549+0800: 109039.435: [GC (GCLocker Initiated GC) 2019-04-10T20:05:24.549+0800: 109039.436: [ParNew: 1820074K-&gt;168253K(1887488K), 0.1858657 secs] 2843722K-&gt;1321273K(3984640K), 0.1861676 secs] [Times: user&#x3D;0.68 sys&#x3D;0.00, real&#x3D;0.18 secs] 2019-04-10T20:05:26.085+0800: 109040.972: [GC (Allocation Failure) 2019-04-10T20:05:26.085+0800: 109040.972: [ParNew: 1846077K-&gt;154005K(1887488K), 0.0462496 secs] 2999097K-&gt;1307234K(3984640K), 0.0465630 secs] [Times: user&#x3D;0.18 sys&#x3D;0.00, real&#x3D;0.05 secs] 2019-04-10T20:05:27.460+0800: 109042.347: [GC (GCLocker Initiated GC) 2019-04-10T20:05:27.460+0800: 109042.347: [ParNew: 1857495K-&gt;209664K(1887488K), 0.0913403 secs] 3010724K-&gt;1371383K(3984640K), 0.0916332 secs] [Times: user&#x3D;0.36 sys&#x3D;0.00, real&#x3D;0.09 secs] 2019-04-10T20:05:28.944+0800: 109043.831: [GC (GCLocker Initiated GC) 2019-04-10T20:05:28.944+0800: 109043.831: [ParNew: 1887488K-&gt;204384K(1887488K), 0.1025569 secs] 3049209K-&gt;1406621K(3984640K), 0.1028616 secs] [Times: user&#x3D;0.39 sys&#x3D;0.00, real&#x3D;0.11 secs] 2019-04-10T20:05:30.291+0800: 109045.178: [GC (Allocation Failure) 2019-04-10T20:05:30.291+0800: 109045.178: [ParNew: 1882208K-&gt;171428K(1887488K), 0.0444964 secs] 3084445K-&gt;1373752K(3984640K), 0.0448216 secs] [Times: user&#x3D;0.14 sys&#x3D;0.00, real&#x3D;0.04 secs] 2019-04-10T20:05:31.769+0800: 109046.656: [GC (Allocation Failure) 2019-04-10T20:05:31.769+0800: 109046.656: [ParNew: 1840540K-&gt;209664K(1887488K), 0.1070460 secs] 3042865K-&gt;1414779K(3984640K), 0.1073485 secs] [Times: user&#x3D;0.41 sys&#x3D;0.00, real&#x3D;0.10 secs] 2019-04-10T20:05:33.293+0800: 109048.180: [GC (Allocation Failure) 2019-04-10T20:05:33.293+0800: 109048.180: [ParNew: 1887488K-&gt;174620K(1887488K), 0.1014037 secs] 3092603K-&gt;1426287K(3984640K), 0.1017165 secs] [Times: user&#x3D;0.39 sys&#x3D;0.00, real&#x3D;0.10 secs] 2019-04-10T20:05:34.713+0800: 109049.600: [GC (Allocation Failure) 2019-04-10T20:05:34.713+0800: 109049.600: [ParNew: 1852444K-&gt;149718K(1887488K), 0.0388156 secs] 3104111K-&gt;1401511K(3984640K), 0.0391062 secs] [Times: user&#x3D;0.13 sys&#x3D;0.00, real&#x3D;0.04 secs] 2019-04-10T20:05:36.300+0800: 109051.187: [GC (Allocation Failure) 2019-04-10T20:05:36.300+0800: 109051.187: [ParNew: 1827542K-&gt;209664K(1887488K), 0.1370734 secs] 3079335K-&gt;1482894K(3984640K), 0.1373627 secs] [Times: user&#x3D;0.52 sys&#x3D;0.00, real&#x3D;0.13 secs] 2019-04-10T20:05:37.822+0800: 109052.709: [GC (Allocation Failure) 2019-04-10T20:05:37.823+0800: 109052.709: [ParNew: 1887488K-&gt;168568K(1887488K), 0.0630131 secs] 3160718K-&gt;1442889K(3984640K), 0.0633086 secs] [Times: user&#x3D;0.25 sys&#x3D;0.00, real&#x3D;0.06 secs] 2019-04-10T20:05:39.229+0800: 109054.116: [GC (GCLocker Initiated GC) 2019-04-10T20:05:39.229+0800: 109054.116: [ParNew: 1862776K-&gt;199264K(1887488K), 0.1551475 secs] 3137097K-&gt;1600406K(3984640K), 0.1554344 secs] [Times: user&#x3D;0.57 sys&#x3D;0.00, real&#x3D;0.15 secs] 2019-04-10T20:05:40.850+0800: 109055.736: [GC (Allocation Failure) 2019-04-10T20:05:40.850+0800: 109055.737: [ParNew: 1877088K-&gt;165034K(1887488K), 0.1900999 secs] 3278230K-&gt;1682137K(3984640K), 0.1904167 secs] [Times: user&#x3D;0.69 sys&#x3D;0.00, real&#x3D;0.19 secs] 2019-04-10T20:05:41.041+0800: 109055.928: [GC (CMS Initial Mark) [1 CMS-initial-mark: 1517102K(2097152K)] 1698563K(3984640K), 0.0451473 secs] [Times: user&#x3D;0.11 sys&#x3D;0.00, real&#x3D;0.04 secs] ParNew日志12019-04-10T20:04:53.556+0800: 109008.442: [GC (Allocation Failure) 2019-04-10T20:04:53.556+0800: 109008.442: [ParNew: 1887488K-&gt;188658K(1887488K), 0.0834678 secs] 2691658K-&gt;1039814K(3984640K), 0.0837781 secs] [Times: user&#x3D;0.33 sys&#x3D;0.00, real&#x3D;0.08 secs] GC，表示是一次YGC Allocation Failure，表示失败类型 ParNew，收集器名称，ParNew收集器，多线程，并行，Stop the World 1887488K-&gt;188658K，收集前后新生代情况，1.8G -&gt; 184M (1887488K)，新生代容量，1.8G 0.0834678 secs，新生代GC花费的时间 2691658K-&gt;1039814K，收集前后整个堆的使用情况，2.5G -&gt; 0.99G (3984640K)，整个堆的容量，3.8G 0.0837781 secs，GC总时间，ParNew 收集器标记和复制新生代活着的对象所花费的时间（包括和老年代通信的开销、对象晋升到老年代开销、垃圾收集周期结束一些最后的清理对象等的花销） Times: user=0.33 sys=0.00, real=0.08 secs user，GC线程在垃圾收集期间使用的CPU总时间 sys，系统调用或者等待系统事件花费的时间 real，应用被暂停的时间，GC 线程是多线程的，导致了 real 小于 (user+sys)，如果是 gc 线程是单线程的话，real 是接近于 (user+sys) 时间 收集前新生代大小1887488K-&gt;收集后新生代大小188658K(新生代总大小1887488K)，YGC后新生代大小减少了1698830K；收集前堆大小2691658K-&gt;收集后堆大小1039814K(堆总大小3984640K)，YGC后新生代大小减少了1651844K，晋升到老年代的大小为：1698830K - 1651844K = 46986K CMS日志12345678910111213141516171819202122232019-04-10T20:05:10.372+0800: 109025.259: [GC (CMS Initial Mark) [1 CMS-initial-mark: 1475854K(2097152K)] 1694195K(3984640K), 0.0302480 secs] [Times: user&#x3D;0.07 sys&#x3D;0.00, real&#x3D;0.03 secs] 2019-04-10T20:05:10.403+0800: 109025.289: [CMS-concurrent-mark-start]2019-04-10T20:05:10.565+0800: 109025.452: [CMS-concurrent-mark: 0.162&#x2F;0.162 secs] [Times: user&#x3D;0.36 sys&#x3D;0.00, real&#x3D;0.17 secs] 2019-04-10T20:05:10.565+0800: 109025.452: [CMS-concurrent-preclean-start]2019-04-10T20:05:10.571+0800: 109025.458: [CMS-concurrent-preclean: 0.006&#x2F;0.006 secs] [Times: user&#x3D;0.01 sys&#x3D;0.00, real&#x3D;0.00 secs] 2019-04-10T20:05:10.571+0800: 109025.458: [CMS-concurrent-abortable-preclean-start]2019-04-10T20:05:11.842+0800: 109026.729: [GC (GCLocker Initiated GC) 2019-04-10T20:05:11.842+0800: 109026.729: [ParNew: 1849355K-&gt;187949K(1887488K), 0.1785371 secs] 3357977K-&gt;1840092K(3984640K), 0.1789082 secs] [Times: user&#x3D;0.65 sys&#x3D;0.00, real&#x3D;0.18 secs] 2019-04-10T20:05:13.012+0800: 109027.899: [CMS-concurrent-abortable-preclean: 2.251&#x2F;2.441 secs] [Times: user&#x3D;6.67 sys&#x3D;0.00, real&#x3D;2.44 secs] 2019-04-10T20:05:13.013+0800: 109027.900: [GC (CMS Final Remark) [YG occupancy: 1220076 K (1887488 K)]2019-04-10T20:05:13.013+0800: 109027.900: [GC (CMS Final Remark) 2019-04-10T20:05:13.014+0800: 109027.900: [ParNew: 1220076K-&gt;154513K(1887488K), 0.1657934 secs] 2872219K-&gt;1924261K(3984640K), 0.1660497 secs] [Times: user&#x3D;0.60 sys&#x3D;0.00, real&#x3D;0.17 secs] 2019-04-10T20:05:13.180+0800: 109028.066: [Rescan (parallel) , 0.0454351 secs]2019-04-10T20:05:13.225+0800: 109028.112: [weak refs processing, 0.0001084 secs]2019-04-10T20:05:13.225+0800: 109028.112: [class unloading, 0.0520415 secs]2019-04-10T20:05:13.277+0800: 109028.164: [scrub symbol table, 0.0156959 secs]2019-04-10T20:05:13.293+0800: 109028.180: [scrub string table, 0.0014593 secs][1 CMS-remark: 1769747K(2097152K)] 1924261K(3984640K), 0.3026953 secs] [Times: user&#x3D;0.87 sys&#x3D;0.00, real&#x3D;0.31 secs] 2019-04-10T20:05:13.316+0800: 109028.203: [CMS-concurrent-sweep-start]2019-04-10T20:05:14.813+0800: 109029.700: [GC (Allocation Failure) 2019-04-10T20:05:14.813+0800: 109029.700: [ParNew: 1832337K-&gt;209664K(1887488K), 0.1690814 secs] 2401415K-&gt;829430K(3984640K), 0.1694105 secs] [Times: user&#x3D;0.64 sys&#x3D;0.00, real&#x3D;0.17 secs] 2019-04-10T20:05:15.076+0800: 109029.963: [CMS-concurrent-sweep: 1.586&#x2F;1.760 secs] [Times: user&#x3D;5.11 sys&#x3D;0.00, real&#x3D;1.76 secs] 2019-04-10T20:05:15.076+0800: 109029.963: [CMS-concurrent-reset-start]2019-04-10T20:05:15.080+0800: 109029.967: [CMS-concurrent-reset: 0.004&#x2F;0.004 secs] [Times: user&#x3D;0.01 sys&#x3D;0.00, real&#x3D;0.00 secs] 初始标记阶段122019-04-10T20:05:10.372+0800: 109025.259: [GC (CMS Initial Mark) [1 CMS-initial-mark: 1475854K(2097152K)] 1694195K(3984640K), 0.0302480 secs] [Times: user&#x3D;0.07 sys&#x3D;0.00, real&#x3D;0.03 secs] GC (CMS Initial Mark)，CMS收集器的初始标记阶段 1475854K(2097152K)，老年代占用1475854K（1.4G），老年代容量2097152K（2G） 1694195K(3984640K)，整个堆的占用1694195K（1.6G），整个堆的容量3984640K（3.8G） 0.0302480 secs，本次标记耗时 该阶段从垃圾回收的根对象开始，且只扫描直接与根对象直接关联的对象，并做标记，需要Stop The Word，速度很快。 并发标记123456782019-04-10T20:05:10.403+0800: 109025.289: [CMS-concurrent-mark-start]2019-04-10T20:05:10.565+0800: 109025.452: [CMS-concurrent-mark: 0.162&#x2F;0.162 secs] [Times: user&#x3D;0.36 sys&#x3D;0.00, real&#x3D;0.17 secs] 2019-04-10T20:05:10.565+0800: 109025.452: [CMS-concurrent-preclean-start]2019-04-10T20:05:10.571+0800: 109025.458: [CMS-concurrent-preclean: 0.006&#x2F;0.006 secs] [Times: user&#x3D;0.01 sys&#x3D;0.00, real&#x3D;0.00 secs]2019-04-10T20:05:10.571+0800: 109025.458: [CMS-concurrent-abortable-preclean-start]2019-04-10T20:05:11.842+0800: 109026.729: [GC (GCLocker Initiated GC) 2019-04-10T20:05:11.842+0800: 109026.729: [ParNew: 1849355K-&gt;187949K(1887488K), 0.1785371 secs] 3357977K-&gt;1840092K(3984640K), 0.1789082 secs] [Times: user&#x3D;0.65 sys&#x3D;0.00, real&#x3D;0.18 secs] 2019-04-10T20:05:13.012+0800: 109027.899: [CMS-concurrent-abortable-preclean: 2.251&#x2F;2.441 secs] [Times: user&#x3D;6.67 sys&#x3D;0.00, real&#x3D;2.44 secs] CMS-concurrent-mark-start，表示并发标记阶段开始，会遍历整个年老代并且标记活着的对象 CMS-concurrent-mark: 0.162/0.162 secs表示该阶段持续的时间和时钟时间，耗时0.162秒，耗时稍长。由于该阶运行的过程中用户线程也在运行，这就可能会发生这样的情况，已经被遍历过的对象的引用被用户线程改变，如果发生了这样的情况，JVM就会标记这个区域为Dirty Card。 CMS-concurrent-preclean-start，预清理开始，该阶段检查并发标记阶段时从新生代晋升的对象，或新分配的对象，或被应用程序线程更新过的对象，（也就是上一个阶段被标记为Dirty Card的对象），帮助减少重新标记阶段的暂停时间。如果在此之后，Eden的占用量&gt;CMSScheduleRemarkEdenSizeThreshold(默认为2M),会启动CMS-concurrent-abortable-preclean，预清理阶段只是一个取样过程，它将新生代按一定间隔进行分块，标记起始位置，以便remark时可以并行的的对块进行trace。不必从开头一点一点进行trace，预清理阶段时，最好发生一次ygc CMS-concurrent-preclean: 0.006/0.006 secs，预清理耗时 CMS-concurrent-abortable-preclean-start，并发预清理开始，继续预清理，至到Eden区占用量达到CMSScheduleRemarkEdenPenetration(默认50%)，或达到5秒钟。但是如果ygc在这个阶段中没有发生的话，是达不到理想效果的。此时可以指定CMSMaxAbortablePrecleanTime，但是，等待一般都不是什么好的策略，可以采用CMSScavengeBeforeRemark，使remark之前发生一次YGC，从而减少remark阶段暂停的时间。 CMS-concurrent-abortable-preclean: 2.251/2.441 secs，并发预清理耗时 重新标记阶段12345672019-04-10T20:05:13.013+0800: 109027.900: [GC (CMS Final Remark) [YG occupancy: 1220076 K (1887488 K)]2019-04-10T20:05:13.013+0800: 109027.900: [GC (CMS Final Remark) 2019-04-10T20:05:13.014+0800: 109027.900: [ParNew: 1220076K-&gt;154513K(1887488K), 0.1657934 secs] 2872219K-&gt;1924261K(3984640K), 0.1660497 secs] [Times: user&#x3D;0.60 sys&#x3D;0.00, real&#x3D;0.17 secs] 2019-04-10T20:05:13.180+0800: 109028.066: [Rescan (parallel) , 0.0454351 secs]2019-04-10T20:05:13.225+0800: 109028.112: [weak refs processing, 0.0001084 secs]2019-04-10T20:05:13.225+0800: 109028.112: [class unloading, 0.0520415 secs]2019-04-10T20:05:13.277+0800: 109028.164: [scrub symbol table, 0.0156959 secs]2019-04-10T20:05:13.293+0800: 109028.180: [scrub string table, 0.0014593 secs][1 CMS-remark: 1769747K(2097152K)] 1924261K(3984640K), 0.3026953 secs] [Times: user&#x3D;0.87 sys&#x3D;0.00, real&#x3D;0.31 secs] [GC (CMS Final Remark)，CMS重新标记阶段，该阶段的任务是完成标记整个年老代的所有的存活对象，尽管先前的pre clean阶段尽量应对处理了并发运行时用户线程改变的对象应用的标记，但是不可能跟上对象改变的速度，只是为final remark阶段尽量减少了负担。会Stop The World。 YG occupancy: 1220076 K (1887488 K)，新生代当前内存占用情况，占用1220076k（1.1G），容量1887488K（1.8G），通常Final Remark阶段要尽量运行在年轻代是足够干净的时候，这样可以消除紧接着的连续的几个STW阶段。 Rescan (parallel) 0.0454351 secs，整个final remark阶段扫描对象的用时总计，该阶段会重新扫描CMS堆中剩余的对象，重新从“根对象”开始扫描，并且也会处理对象关联。本次扫描共耗时0.0454351秒。 weak refs processing, 0.0001084 secs，对弱引用处理的耗时 class unloading, 0.0520415 secs，卸载无用类的耗时 scrub symbol table, 0.0156959 secs，scrub string table, 0.0014593 secs，清理分别包含类级元数据和内部化字符串的符号和字符串表的耗时 1 CMS-remark: 1769747K(2097152K)，经历了上面阶段后老年代使用情况，老年代占用1769747K（1.6g），老年代容量2097152K(2G） 1924261K(3984640K), 0.3026953 secs，表示经历了final remark后整个堆的使用情况和final remark耗时，堆占用1924261K（1.8G），堆容量3984640K（3.8G） 并发清除阶段1234562019-04-10T20:05:13.316+0800: 109028.203: [CMS-concurrent-sweep-start]2019-04-10T20:05:14.813+0800: 109029.700: [GC (Allocation Failure) 2019-04-10T20:05:14.813+0800: 109029.700: [ParNew: 1832337K-&gt;209664K(1887488K), 0.1690814 secs] 2401415K-&gt;829430K(3984640K), 0.1694105 secs] [Times: user&#x3D;0.64 sys&#x3D;0.00, real&#x3D;0.17 secs] 2019-04-10T20:05:15.076+0800: 109029.963: [CMS-concurrent-sweep: 1.586&#x2F;1.760 secs] [Times: user&#x3D;5.11 sys&#x3D;0.00, real&#x3D;1.76 secs] 2019-04-10T20:05:15.076+0800: 109029.963: [CMS-concurrent-reset-start]2019-04-10T20:05:15.080+0800: 109029.967: [CMS-concurrent-reset: 0.004&#x2F;0.004 secs] [Times: user&#x3D;0.01 sys&#x3D;0.00, real&#x3D;0.00 secs] CMS-concurrent-sweep-start，并发清除阶段开始，清除之前标记阶段没有被标记的无用对象并回收内存 CMS-concurrent-sweep: 1.586/1.760 secs，清除没有标记的无用对象并回收内存的耗时 CMS-concurrent-reset-start，重新设置CMS算法内部数据结构开始 CMS-concurrent-reset: 0.004/0.004 secs，重置CMS内部算法数据结构耗时 YGC频繁报警提示YGC频繁，日志显示每秒一次YGC，单次耗时50ms - 200ms，一分钟多一次Major GC 参数： 堆大小：4G，新生代大小：2G，Eden：1.6G，Survivor0：200M，Suvivor1:200M YGC触发原因： Eden区满的时候，会触发YGC YGC频繁的原因： 产生了太多的短期对象，导致频繁的YGC 新生代的空间太小 这里场景是需要根据一个优惠券查询所有绑定了这个优惠券的商品，如果是商户优惠券或者类目优惠券，一个券将会有上万的商品关系，一次券的操作就会产生大量的对象并且都是一次性的。 调整： 堆大小增加到6G，新生代大小4G，-XX:SurvivorRatio=6，Eden：3.2G，Suvivor0：1.4g，Survivor1：1.4g 程序优化并且调整了参数后，没再发生过YGC频繁报警，Eden增大后并且Suvivor增大后，YGC次数下降，并且由于Suvivor增大，很多短期对象不再晋升到老年代，Major GC次数也减少了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM四种引用类型]]></title>
      <url>%2F2017%2F06%2F18%2FJVM%E4%B8%AD%E5%9B%9B%E7%A7%8D%E5%BC%95%E7%94%A8%E7%B1%BB%E5%9E%8B%2F</url>
      <content type="text"><![CDATA[Java提供了四种引用类型：强引用、软引用、弱引用、虚引用，这几种不同引用类型主要体现在GC上。 强引用，StrongReference，默认引用形式，我们通过new关键字创建一个对象，就是强引用。一个对象具有强引用，不会被垃圾回收器回收，内存不足的时候即使跑出OutOfMemoryError也不会回收强引用。 软引用，SoftReference，如果内存足够，软引用不会被回收，如果内存不足，软引用就会被垃圾回收器回收，可用来实现缓存。 弱引用，WeakReference，当JVM进行垃圾回收的时候发现有弱引用，不管空间是否足够用，都会回收弱引用。 虚引用，PhantomReference，任何时候都能被垃圾回收器回收。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM动态对象年龄判断]]></title>
      <url>%2F2017%2F06%2F17%2FJVM%E5%8A%A8%E6%80%81%E5%AF%B9%E8%B1%A1%E5%B9%B4%E9%BE%84%E5%88%A4%E6%96%AD%2F</url>
      <content type="text"><![CDATA[JVM中新生代对象晋升到老年代的时候，对象会有个年龄最大阈值，但是除了这个年龄最大阈值外，JVM还会对对象年龄进行动态判断，不等到年龄最大阈值就可以晋升到老年代。 有两个参数：-XX:MaxTenuringThreshold、-XX:TargetSurvivorRatio： -XX:MaxTenuringThreshold，晋升年龄最大阈值，默认15（年龄存在MarkWord中，4位，最大值是15），新生代中经过数次YGC后，对象仍然存活并且达到了晋升年龄阈值，该对象就会晋升到老年代中。 ``-XX:TargetSurvivorRatio`，设置Suvivor区的目标使用率，默认50，表示Survivor区对象目标使用率为50%。 JVM虚拟机不总是要求对象年龄达到MaxTenuringThreshold指定的阈值才能晋升到老年代，而是会根据各个年龄段的对象的和占用Survivor空间的比率，来判断哪些年龄的的对象可以晋升到老年代。 动态年龄判断的原因如果有很多对象的年龄都没达到MaxTenuringThreshold指定的阈值，这些对象就一直保留在Survivor区中，新对象进来可能就没办法移动到Survivor区，这些对象会进入老年代，如果触发了老年代GC，会把新生代存活的对象全部放入老年代，老年代对象增多容易造成Full GC。 动态年龄判断的计算JVM会记录每个年龄段的对象的大小，将每个年龄段的大小从小到大累加，如果加入某个年龄段大小后的和超过了(Survivor区大小 * TargetSurvivorRatio)/100，也就是这些和超过了Suvivor容量的50%，就会取这个年龄和MaxTenuringThreshold两者中较小的那个值，从这个值往上的所有年龄段的对象晋升到老年代。 比如：Suvivor区大小10M，年龄段1大小3M，年龄段2大小2M，年龄段3大小3M，年龄段4大小1M，TargetSurvivorRatio设置为50，MaxTenuringThreshold设置为15，则（年龄段1+年龄段2+年龄段3）&gt; (10 * 50)/100，此时得到的年龄段是3，3和15比较，取3，下次YGC时所有年龄段3和年龄段4的对象晋升到老年代。 MaxTenuringThreshold值大小的影响 如果设置过大，有很多对象的年龄都没达到MaxTenuringThreshold指定的阈值，这些对象就一直保留在Survivor区中，新对象进来可能就没办法移动到Survivor区，这些对象会进入老年代，如果触发了老年代GC，会把新生代存活的对象全部放入老年代，老年代对象增多容易造成Full GC。 如果设置过小，大量短期对象都会晋升到老年代，频繁引起老年代GC。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM中的MinorGC-MajorGC-FullGC]]></title>
      <url>%2F2017%2F06%2F17%2FJVM%E4%B8%AD%E7%9A%84MinorGC-MajorGC-FullGC%2F</url>
      <content type="text"><![CDATA[Minor GC、Major GC、Full GC HotSpot VM实现，GC分为两种： Partial GC（局部GC），不收集整个GC堆的模式 Young GC（Minor GC），只收集新生代的GC。 Old GC，只收集老年代的GC，只有CMS的并发收集是这个模式。 Mixed GC，收集整个新生代以及部分老年代的GC，是有G1有这个模式。 Full GC，收集整个堆，包括新生代、老年代、永久代所有部分的模式。 Major GC通常是跟Full GC是等价的，收集整个GC堆。但因为HotSpot VM发展了这么多年，外界对各种名词的解读已经完全混乱了，当有人说“Major GC”的时候一定要问清楚他想要指的是上面的Full GC还是Old GC。 Young GC（Minor GC）发生在新生代的GC，当新生代中的Eden区满的时候触发。Young GC中有部分存活对象会晋升到老年代，所以Young GC后老年代的占用量通常会有所升高。 新生代分为Eden区和两个Survivor区，发生YGC的时候，Eden区和一个Survivor区中存活的对象被复制到另外一个空闲Survivor区。 晋升到老年代的条件 新生代的Eden区满的时候，会进行一次YGC，当Eden和Survivor区中依然存活的对象无法放到Survivor区中，通过分配担保机制提前转移到老年代中。这称为过早提升(Premature Promotion)，这会导致老年代中短期存活对象的增长，可能会引发严重的性能问题。在Minor GC过程中，如果老年代满了而无法容纳更多的对象，YGC 之后通常就会进行Full GC,这将导致遍历整个Java堆，这称为提升失败(Promotion Failure)。 新建对象太大，新生代无法容纳这个对象，会直接在老年代分配，参数-XX:PretenureSizeThreshold用来设置这个门限值，此参数只对Serial及ParNew两款收集器有效。 长期存活的对象进入老年代，对象头的Mark Word中包含对象的年龄，年龄达到了参数-XX:MaxTenuringThreshold指定的阈值（默认15，Mark Word中记录年轻的字段有4位），会晋升到老年代中。每一YGC后对象还能存活的话，年龄就会加1。 动态年龄对象判定，虚拟机不总是要求对象年龄必须达到-XX:MaxTenuringThreshold设置的值后才能晋升到老年代，如果在Survivor区中相同年龄的对象的所有大小之和超过Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，不需要等到参数-XX:MaxTenuringThreshold设置的阈值。 Young GC和卡表YGC存在一个问题，老年代对象可能引用新生代对象，在标记存活对象的时候，就需要扫描老年代的对象，如果该对象拥有对新生代对象的引用，那么这个引用也会被作为 GC Roots。这相当于就做了全堆扫描。为了避免全堆扫描，JVM使用了卡表技术： 卡表的具体策略是：将老年代的空间分成大小为 512B的若干张卡，并且维护一个卡表，卡表本省是字节数组，数组中的每个元素对应着一张卡，其实就是一个标识位，这个标识位代表对应的卡是否可能存有指向新生代对象的引用，如果可能存在，那么我们认为这张卡是脏的，即脏卡。如上图所示，卡表3被标记为脏。 在进行YGC的时候，我们便可以不用扫描整个老年代，而是在卡表中寻找脏卡，并将脏卡中的老年代指向新生代的引用加入到 Minor GC的GC Roots里，当完成所有脏卡的扫描之后，Java 虚拟机便会将所有脏卡的标识位清零。这样虚拟机以空间换时间，避免了全表扫描。 空间分配担保YGC之前，JVM会先检查老年代最大可用连续空间大小是否大于新生代所有对象的总大小，如果大于新生代所有对象总大小，这次YGC就是安全的。 如果小于新生代所有对象总大小，JVM会查看HandlePromotionFailure设置的值，如果设置为false表示不允许失败担保，则进行一次Full GC；如果设置为true表示允许担保失败，JVM会检查老年大最大可用连续空间大小是否大于历次晋升到老年代的对象的平均大小，如果大于的话则可以继续进行一次YGC，但是这次YGC是有风险的；如果小于的话，则进行一次Full GC。 Full GC针对不同的垃圾收集器，Full GC的触发条件可能不都一样。按HotSpot VM的serial GC的实现来看，触发条件是： 当准备要触发一次Young GC时，如果发现统计数据说之前Young GC的平均晋升大小比目前老年代剩余的空间大，则不会触发Young GC而是转为触发Full GC（因为HotSpot VM的GC里，除了CMS的并发收集之外，其它能收集老年代的GC都会同时收集整个GC堆，包括新生代，所以不需要事先触发一次单独的Young GC）。 如果有永久代（方法区）的话，要在永久代分配空间但已经没有足够空间时，也要触发一次Full GC。 System.gc()、heap dump带GC，默认也是触发Full GC。 老年代空间不足，新生代对象转入以及创建大对象大数组时，空间不足，会导致Full GC；或者空间足够，但是没有足够的连续空间存放对象，会导致Full GC。CMS垃圾收集器提供了一个可配置的参数-XX:+UseCMSCompactAtFullCollection，用于在Full GC后进行碎片整理的，内存整理的过程无法并发的，需要stop the world，JVM还提供了另外一个参数-XX:CMSFullGCsBeforeCompaction用于设置在执行多少次不压缩的Full GC后，跟着来一次带压缩的。 CMS GC出现promotion failed和concurrent mode failure会导致Full GC，promotion failed是在进行YGC时，survivor区放不下、对象只能放入老年代，而此时老年代也放不下造成的；concurrent mode failure是在执行CMS GC的过程中同时有对象要放入老年代，而此时老年代空间不足造成的（有时候空间不足是CMS GC时当前的浮动垃圾过多导致暂时性的空间不足触发Full GC）。 而在 Parallel Scavenge 收集器下，默认是在要触发 Full GC前先执行一次 YGC，并且两次GC之间能让应用程序稍微运行一小下，以期降低 Full GC的暂停时间 (因为 YGC 会尽量清理了新生代的死对象，减少了 Full GC的工作量)，控制这个行为的VM参数是-XX:+ScavengeBeforeFullGC。 并发GC的触发条件就不一样，以 CMS GC为例，它主要是定时去检查老年代的使用量，但使用量超过了触发比例就会启动一次 CMS GC，对老年代做并发收集。 参考 引用自R大（加粗加大这一行）：https://www.zhihu.com/question/41922036/answer/93079526]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM垃圾收集算法和垃圾收集器]]></title>
      <url>%2F2017%2F06%2F11%2FJVM%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E7%AE%97%E6%B3%95%E5%92%8C%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2F</url>
      <content type="text"><![CDATA[JVM的垃圾收集算法和垃圾收集器学习。 判断对象存活算法引用计数法引用计数法是给每个对象设置一个计数器，当有地方引用这个对象的时候，就将这个计数器加一，当引用时效的时候就将这个计数器减一。当计数器为0的时候，就代表这个对象不再被使用，可以回收。 引用计数算法实现简单，效率高，但是无法解决循环引用的问题。 可达性分析算法可达性分析算法使用一系列的“GC Roots”对象作为起始点，从这些起始点开始向下搜索，搜索通过的路径称为引用链。当一个对象到GC Roots没有任何引用链相连，说明这个对象是不可用的。 可以作为GC Roots对象有： 虚拟机栈（栈帧中的局部变量表）中引用的对象。 方法区中静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI引用的对象。 JVM垃圾收集算法标记-清除算法标记-清除算法（Mark-Sweep），分为两个阶段：标记阶段和清除阶段。在标记阶段，首先根据根节点标记所有的可达对象，未被标记的对象就是可以回收的对象。在标记完成之后，清除阶段就可以清除掉所有的垃圾对象。 缺点： 效率问题，标记和清除阶段的效率都不高。 空间问题，清除后会产生大量的不连续的内存碎片，如果需要分配大的对象，可能由于找不到足够的连续内存而提前触发另一次垃圾收集动作。 标记-整理算法标记整理算法与标记清除算法类似，只不过在标记完成后，不是对可回收对象进行清除，而是将所有存活对象移向一端，然后清理掉边界以外的内存。 缺点： 效率问题，标记和整理的过程效率都不高。 优点： 相对于标记-清除算法，解决了内存碎片问题。 复制算法复制算法可以解决效率问题，它将可用内存按照容量划分成大小相等的两块，每次只使用其中的一块，当一块内存用完了，就将还存活着的对象移到另外一块上，然后把已经使用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配不用考虑内存碎片的问题。 优点： 效率高，没有内存碎片。 缺点： 需要浪费一半的内存空间。 如果对象的存活率较高，需要进行较多的复制，效率会变的很低。 分代收集算法根据对象存活周期的不同，将内存划分为几块，一般把Java堆分为新生代和老年代，然后根据各个年代的特点采用不同的垃圾收集算法。在新生代中，每次垃圾回收都会有大批的对象死去，只有少量对象存活，可以选用复制算法；在老年代中对象存活率较高，没有额外空间进行担保，就必须使用标记-清除或者标记-清理来进行回收。 对象分配策略 对象优先在Eden区域分配，如果对象过大直接分配到老年代。 长期存活对象进入老年代。 垃圾收集器 Serial收集器 ParNew收集器 Parallel Scavenge收集器 Serial Old收集器 Parallel Old收集器 CMS收集器 G1收集器 Serial收集器Serial收集器是单线程收集器，进行垃圾收集时必须暂停其他所有的工作线程，直到收集结束。是Client模式下的默认新生代收集器。 特点： 单线程，简单高效，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程效率。 复制算法 stop the world ParNew收集器ParNew收集器其实是Serial收集器的多线程版本，Server模式下的首选的新生代收集器。ParNew收集器默认开启收集线程数与CPU数量相同。 特点： 多线程 复制算法 stop the world Parallel Scavenge收集器Parallel Scavenge收集器是一个新生代收集器，使用复制算法，是并行的多线程收集器，目标是达到一个可控制的吞吐量。 特点： 多线程 复制算法 可控制吞吐量 自适应调节策略 Serial Old收集器Serial Old收集器是Serial收集器的老年代版本，是一个单线程收集器，使用标记-整理算法。主要给Client模式下使用。如果用在Server模式下，有两种用途： 与Parallel Scavenge收集器搭配 作为CMS的后备方案，在并发收集发生Concurrent Mode Failure时使用 特点： 单线程 标记-整理算法 stop the world Parallel Old收集器Parallel Old收集器是Parallel Scavenge收集器的老年代版本，使用多线程和标记-整理算法。在注重吞吐量和CPU敏感的场合，优先考虑Parallel Scavenge + Parallel Old组合。 特点： 多线程 标记-整理算法 CMS收集器CMS收集器是真正意义上的并发收集器，实现了让垃圾收集线程和用户线程同时工作。尽可能的缩短垃圾收集时用户线程的停顿时间。CMS收集器是基于标记-清除算法实现的，总共分四个步骤： 初始标记 并发标记 重新标记 并发清除 初始标记和重新标记需要Stop The World，初始标记仅仅是标记一下GC Roots能关联到的对象，速度很快。并发标记就是进行GC Roots Tracing的过程。重新标记是为了修正并发标记期间因用户程序继续运行而导致的变动的对象，这个阶段停顿时间一般会比初始标记阶段稍长，但远比并发标记时间段。 整个过程耗时最长的是并发标记和并发清除，但这两个过程可以合用户线程一起工作。 优点： 并发收集 低停顿 缺点： CMS收集器对CPU非常敏感，并发阶段会占用一部分线程，导致应用变慢，吞吐量降低。 CMS无法处理浮动垃圾，可能出现Concurrent Mode Failure失败而导致另一次Full GC产生。 CMS是基于标记-清除算法实现的，会有大量内存空间碎片问题。 G1收集器G1是面向服务端应用的垃圾收集器。特点如下： 并行与并发，能充分利用CPU，多核环境下的硬件优势，缩短Stop-The-World停顿时间，同时可以通过并发的方式让Java程序继续执行。 分代收集，可以不需要其他收集器的配合管理整个堆，但是仍采用不同的方式去处理分代对象。 空间整合，从整体上看是基于标记-整理算法，从局部看是采用复制算法实现。 可预测停顿，G1将整个Java堆划分为多个大小相等的独立区域，跟踪各个Region里面的垃圾堆积的价值大小，在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。 参考 https://blog.jamesdbloom.com/JVMInternals.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM类加载器]]></title>
      <url>%2F2017%2F06%2F04%2FJVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%2F</url>
      <content type="text"><![CDATA[JVM类加载器有三种：启动类加载器、扩展类加载器、应用类加载器。 JVM类加载器有三种： 启动类加载器：Bootstrap ClassLoader，负责加载$JAVA_HOME/jre/lib目录下的或者被-Xbootclasspath参数指定的路径中的类库，C++实现，无法被Java程序直接引用。 扩展类加载器：Extension ClassLoader，负责加载$JAVA_HOME/jre/lib/ext目录下的或者被java.ext.dirs指定的路径中的类库。 应用类加载器：Application ClassLoader，（系统类加载器System ClassLoader）负责加载用户类路径（classpath）下的指定的类，可以直接使用该类加载器。 JVM类加载器加载类的机制 当一个类加载器负责加载某个类时，该类所依赖的和引用的其他类也由该类加载器负责载入，除非程序中显式使用另一个类加载器来载入。 加载一个类的时候，先让父类加载器进行尝试，如果父类无法加载类，才从当前类加载器的类路径下加载该类。 所有加载过的类都会被缓存，类加载器会先从缓存区寻找该类，缓存不存在才会进行加载。 类加载的三种方式 命令行启动应用时候由JVM初始化加载。 通过Class.forName()方法动态加载。 通过ClassLoader.loadClass()方法动态加载。 Class.forName()会将class文件加载到JVM中，并且会对类进行解释，执行类中的static块。同时也有个带参数的方法可以控制是否加载static块。只有调用了newInstance()方法才会调用构造方法、创建类的对象。 ClassLoader.loadClass()只是将class文件加载到JVM中，不会执行static块的内容，只有在newInstance()时才会执行static块。 双亲委派模型 当AppClassLoader加载一个类时，它会首先把类加载请求委托给父类加载器ExtClassLoader去完成。 当ExtClassLoader加载一个类时，他会首先把类加载请求委托给父类加载器BootstrapClassLoader去完成。 如果BootstrapClassLoader加载失败，会使用ExtClassLoader进行类加载。 如果ExtClassLoader加载失败，会使用AppClassLoader进行类加载。 如果AppClassLoader加载失败，抛出异常ClassNotFoundException。 双亲委派模型可以防止内存中出现多份同样的字节码；也可以保证Java的安全。 怎么打破双亲委派模型打破双亲委派模型，需要自己定义一个类加载器，重写loadClass方法，重写findClass方法。双亲委派模型是在loadClass方法中实现的，所以自定义类加载器重写这个方法就可以打破双亲委派模型。 打破双亲委派模型的例子 使用SPI加载的，如JNDI、JDBC、JCE、JAXB、JBI等等，使用线程上下文类加载器来加载第三方厂商的类。SPI的接口属于Java核心库，存在于rt.jar中，由BootstrapClassLoader加载，但是SPI实现是由第三方实现，位于classpath下，BootstrapClassLoader无法直接加载这种实现，委托给ContextClassLoader来加载，实现了Java核心代码内部去调用外部实现类。 tomcat中的web容器类加载器也打破了双亲委派模型，自定义的WebClassLoader除了核心类库外，都优先加载自己路径下的类，加载不到时再交给CommonClassLoader进行双亲委派机制加载。 OSGI也打破了双亲委派模型，OSGI是网状结构的。 参考 https://blog.jamesdbloom.com/JVMInternals.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM类加载机制]]></title>
      <url>%2F2017%2F06%2F03%2FJVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%2F</url>
      <content type="text"><![CDATA[JVM中类的生命周期有加载、连接（验证、准备、解析）初始化、使用、卸载。 类的生命周期总共分为七个阶段： 加载 连接（验证、准备、解析） 初始化 使用 卸载 使用drawio画了一张图，这里是源文件：JVM类加载机制 加载类加载过程的第一步就是加载阶段，加载阶段主要做的事情有： 通过一个类的全限定名获取其定义的二进制字节流。 将字节流代表的静态存储结构转化为方法区的运行时数据结构。 在Java堆中生成一个代表这个类的java.lang.Class对象，作为方法区中这个类的访问的入口。 加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区中，同时在堆中生成了一个java.lang.Class对象，这样就可以通过该对象访问方法区中的类的数据。 连接类加载的第二个大阶段是连接，连接又包括了验证、准备、解析三个阶段。 验证其中验证阶段主要做的事情是确保被加载的类的正确性，主要分为4个阶段的验证： 文件格式验证：验证二进制字节流是否符合Class文件格式的规范。例如是否以0xCAFEBABE开头、次版本号和主版本号是否正确、常量池中常量是否有不被支持的类型等等。 元数据的验证：对字节码描述的信息进行语义分析，保证描述的信息符合Java语言的规范要求，如：这个类是否有父类，除了java.lnag.Object之外。 字节码的验证：通过数据流和控制流分析，确定程序语意是合法的、符合逻辑的。 符号引用验证：确保解析动作能正确执行。 验证阶段是非常重要的，但是不是必须的，可以关闭来缩短虚拟机类加载的时间。 准备准备阶段是为类变量分配内存，并设置类变量的初始值阶段，内存都将在方法区中分配。有几点需要注意： 这时候进行的内存分配仅包括类变量（static），而不包括实例变量，实例变量会在对象实例化的时候随着对象一起分配在Java堆中。 这里设置的初始值通常情况下是数据类型默认的零值（0，0L，null，false等），而不是在Java代码中显式赋予的值。而把代码中显式赋予的值赋值给变量的操作是在初始化阶段执行的，存放于类构造器&lt;clinit&gt;()中。 关于默认值也有几点要注意的： 如果是基本数据类型，对于类变量（static）和全局变量，如果不显式的对其赋值而直接使用， 系统会为其赋予默认零值；而对于局部变量来说，使用前必须显式的为其赋值，否则编译不通过。 如果是同时被static和final修饰的常量，必须在声明的时候为其显式的赋值，否则编译不通过；对于只被final修饰的常量，既可以在声明时显式的为其赋值，也可以在类初始化的时候为其显式的赋值，总之，在使用前必须为其显式的赋值，系统不会为其赋予默认零值。 如果是引用数据类型reference，如果没有显示的赋值，则会赋予默认零值：null。 如果是数组，在初始化的时候没有对数组中的各元素赋值，那么其中的元素将根据对应的数据类型赋予默认的零值。 如果类字段的字段表属性中存在ConstantValue属性，即同时被final和static修饰，那么在准备阶段变量就会被初始化为ConstantValue。如：public static final int value = 3，编译时会为value生成ConstantValue属性，在准备阶段虚拟机会根据ConstantValue的设置将value赋值为3。static final常量在编译期就将其结果放入了调用它的类的常量池中。 解析解析阶段是要把类中的符号引用转换为直接引用的阶段。虚拟机将常量池中的符号引用替换为直接引用。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄、调用点限定符等7类符号引用进行。 初始化初始化阶段为类的静态变量赋予正确的初始值。JVM负责对类进行初始化，主要是对类变量进行初始化，Java中对类变量进行初始值设定有两种方式： 声明类变量的时候指定初始值。 在静态代码块中为类变量指定初始值。 类初始化的先后顺序 如果一个类还没有被加载和连接，则先进行加载和连接。 如果该类的父类还没有被初始化，则先初始化直接父类。 如果该类中有初始化语句，则系统依次执行这些初始化语句。 类初始化的时机可分为主动引用和被动引用： 主动引用，会触发初始化。 被动引用，不会触发初始化。 主动引用情形主动引用会触发类的初始化： 使用new关键字创建类的实例。 访问某个类或接口的静态变量，或者为该静态变量赋值。 调用一个类的静态方法。 通过反射调用。 初始某个类的子类，则其父类也会被初始化。 Java虚拟机启动时被标明为启动类的类。 当使用 JDK.7 的动态语言支持时，如果一个java.lang.invoke.MethodHandle 实例最后的解析结果为 REF_getStatic, REF_putStatic, REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。 被动引用情形被动引用不会触发类的初始化： 子类引用父类的静态字段，不会导致子类初始化，只有直接定义静态字段的类才会被触发初始化，所以子类不会初始化。 通过数组来引用类，不会触发类的初始化，初始化的是数组，数组应用的类并不需要初始化。 常量不会触发类的初始化，常量在编译阶段会存入常量池中。 结束生命周期 执行System.exit()方法。 程序正常执行结束。 程序在执行过程中遇到了异常或错误而终止。 操作系统出现错误导致Java虚拟机进程终止。 类初始化顺序总结不考虑有父类的： 1静态变量\静态代码块 --&gt; 实例变量\实例代码块 --&gt; 构造方法 有父类的： 1父类静态变量\静态代码块 --&gt; 子类静态变量\静态代码块 --&gt; 父类实例变量\实例代码块 --&gt; 父类构造方法 --&gt; 子类实例变量\实例代码块 --&gt; 子类构造方法 参考 https://blog.jamesdbloom.com/JVMInternals.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM创建对象的过程简介]]></title>
      <url>%2F2017%2F06%2F01%2FJVM%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1%E7%9A%84%E8%BF%87%E7%A8%8B%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[记录一下JVM创建对象的过程，就是new一个对象的时候发生了哪些事情。Java程序执行的过程在此不作说明，对象的创建过程只是程序执行过程的一部分。有关整个程序执行的过程，等熟悉了虚拟机之后在作说明。 Java中对象的创建就是在堆上分配内存空间的过程，此处说的对象创建仅限于new关键字创建的普通Java对象，不包括数组对象的创建。 大致过程如下： 检测类是否被加载 为对象分配内存 为分配的内存空间初始化零值 对对象进行其他设置 执行init方法 使用drawio画了一张图，这里是源文件：JVM类加载机制 检测类是否被加载当虚拟机执行到new时，会先去常量池中查找这个类的符号引用。如果能找到符号引用，说明此类已经被加载到方法区（方法区存储虚拟机已经加载的类的信息），可以继续执行；如果找不到符号引用，就会使用类加载器执行类的加载过程，类加载完成后继续执行。类加载过程可以参考：JVM类加载机制 为对象分配内存类加载完成以后，虚拟机就开始为对象分配内存，此时所需内存的大小就已经确定了。只需要在堆上分配所需要的内存即可。 具体的分配内存有两种情况：第一种情况是内存空间绝对规整，第二种情况是内存空间是不连续的。 对于内存绝对规整的情况相对简单一些，虚拟机只需要在被占用的内存和可用空间之间移动指针即可，这种方式被称为指针碰撞。 对于内存不规整的情况稍微复杂一点，这时候虚拟机需要维护一个列表，来记录哪些内存是可用的。分配内存的时候需要找到一个可用的内存空间，然后在列表上记录下已被分配，这种方式成为空闲列表。 分配内存的时候也需要考虑线程安全问题，有两种解决方案： 第一种是采用同步的办法，使用CAS来保证操作的原子性。 另一种是每个线程分配内存都在自己的空间内进行，即是每个线程都在堆中预先分配一小块内存，称为本地线程分配缓冲（TLAB），分配内存的时候再TLAB上分配，互不干扰。 为分配的内存空间初始化零值对象的内存分配完成后，还需要将对象的内存空间都初始化为零值，这样能保证对象即使没有赋初值，也可以直接使用。 对对象进行其他设置分配完内存空间，初始化零值之后，虚拟机还需要对对象进行其他必要的设置，设置的地方都在对象头中，包括这个对象所属的类，类的元数据信息，对象的hashcode，GC分代年龄等信息。 执行init方法执行完上面的步骤之后，在虚拟机里这个对象就算创建成功了，但是对于Java程序来说还需要执行init方法才算真正的创建完成，因为这个时候对象只是被初始化零值了，还没有真正的去根据程序中的代码分配初始值，调用了init方法之后，这个对象才真正能使用。 到此为止一个对象就产生了，这就是new关键字创建对象的过程。过程如下： 1检测类是否被加载 --&gt; 为对象分配内存空间 --&gt; 初始零值 --&gt; 进行必要的设置 --&gt; 调用init方法进行初始化。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM运行时数据区域介绍]]></title>
      <url>%2F2017%2F05%2F20%2FJVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%9F%9F%E4%BB%8B%E7%BB%8D%2F</url>
      <content type="text"><![CDATA[此处的内容是根据Java虚拟机规范（Java SE 7）相关内容以及深入理解Java虚拟机等做的总结。可能有不对的地方。了解这些区域，可以从总体上看下虚拟机内部是怎么构造的，网上也有相关的图片介绍，可以适当的记下图片内容，这样可以有一个立体的感受，更容易记忆。 Java虚拟机定义了程序运行期间使用到的运行时数据区域，其中一些与虚拟机生命周期相同，另外一些与线程的生命周期相同。JVM运行时数据区域分为： 程序计数器（Program Counter） Java虚拟机栈（Java Virtual Machine Stack） 堆（Heap） 方法区（Method Area） 本地方法栈（Native Method Stack） 图片来自：https://blog.jamesdbloom.com/JVMInternals.html 程序计数器（Program Counter）程序计数器是线程私有的，每条线程都有自己的程序计数器。 Java虚拟机是支持多线程的，多线程是通过线程的轮流切换来实现的，也就是说每次切换都需要在上次停顿的地方重新开始运行，这时候就需要程序计数器来保存当前线程正在执行的字节码指令的地址，切换到该线程的时候，就能知道该执行哪一个字节码指令了。 如果一个线程正在执行的方法是Java方法，程序计数器保存的是Java虚拟机正在执行的字节码指令的地址；如果正在执行的方法是native的，程序计数器的值为undefined。 Java虚拟机栈（Java Virtual Machine Stack）Java虚拟机栈也是线程私有的，与线程同时创建，用于存储栈帧（Fremas），栈帧用来存储局部变量，操作数栈、指向当前方法所属类的运行时常量池、处理动态链接、方法返回值和异常分派。方法从调用到执行完成的过程就对应着一个栈帧从入栈到出栈的过程。 Java虚拟机栈可以被实现为固定大小的，此时每一条线程的Java虚拟机栈在线程创建的时候容量就已经确定；还可以被实现为根据计算动态扩展和收缩的。 Java虚拟机栈可能会发生异常： 如果线程请求的栈容量超过Java虚拟机栈允许的最大容量，会抛出StackOverflowError异常。 如果虚拟机栈可动态扩展，申请不到足够的内存去完成扩展，或者建立新线程时没有足够的内存去创建虚拟机栈，会抛出OutOfMemoryError异常。 栈帧栈帧是线程私有的，随着方法的调用而创建，随着方法的结束而销毁。栈帧分配在Java虚拟机栈中，存储着局部变量表，操作数栈，和指向当前方法所属类的运行时常量池的引用。 局部变量表和操作数栈的容量是编译期确定的。 局部变量表局部变量表存在于栈帧中，长度在编译期决定，存储在类和接口的二进制表示中，也就是存储在方法的Code属性中并提供给栈帧使用。 局部变量表可以保存类型为boolean、byte、char、short、int、float、reference、returnAddress，而long和double类型需要两个局部变量表来存储。 局部变量表用来完成方法调用时的参数传递。当方法被调用时，参数会传递到从0开始的连续局部变量表位置上。当实例方法被调用时，第0个局部变量存储的是this。 操作数栈操作数栈存在于栈帧中，是一个LIFO的栈，长度由编译期确定，也是存储在方法的Code属性中提供给栈帧使用。 操作数栈会有一个确定的栈深度，一个long或者double类型的数据会占用两个单位的栈深度，其他数据类型则会占用一个单位深度。 动态链接栈帧内部包含一个指向运行时常量池的引用（运行时常量池的解释在下面，可以先看一下运行时常量池），这个引用用来支持当前方法的代码实现动态链接。 Class文件中，一个方法调用其他方法或者访问其成员变量是通过符号引用来表示的，动态链接作用就是将符号引用转换为实际的直接引用。 堆（Heap）堆是各个线程共享的运行时内存区域，也是所有的类实例和数组对象分配内存的区域。堆在虚拟机启动的时候被创建，存储了被垃圾收集器所管理的各种对象。 堆的容量可以是固定大小的，也可以是动态扩展和自动收缩的。Java堆的内存不需要保证是连续的。 Java堆可能发生异常情况： 实际所需的堆超过了最大容量，抛出OutOfMemoryError异常。 堆内存分配根据对象存活的时间不同，JVM对于GC策略采用分代垃圾回收，这就需要把堆内存划分为不同的区域进行管理。堆内存通常分为新生代和老年代两个区域，新生代分为一个Eden区域和两个Survivor区域。 绝大部分的对象都很短命。这样分代之后，可以对不同的代选择不同的垃圾回收算法。 新生代（Young Generation）分为Eden区域、From Survivor和To Survivor三个区域。对象的内存分配优先在Eden区上，少数情况下会直接分配到老年代上。一个Eden区域和一个Survivor的比例是8:1。Survivor区域用于存放每次垃圾回收之后存活的对象。老年代主要用来存放大对象和长期存活的对象。 方法区（Method Area）方法区也是被各个线程所共享的运行时内存区域。用于存储类的结构信息，例如运行时常量池、字段、方法数据、构造函数、普通方法的字节码内容、还包括一些在类、实例、接口初始化时用到的特殊方法。 方法区在虚拟机启动的时候被创建，是堆的逻辑组成部分。方法区的容量可以是固定大小的，也可以是动态扩展和自动收缩的。内存空间不需要保证是连续的。 方法区可能发生异常的情况： 方法区的内存不能满足内存分配时，会抛出OutOfMemoryError异常。 永久代Hotspot虚拟机中永久代就是方法区。而在Java8之后，永久代被移除，被Metaspace所取代。 在新生代发生的垃圾回收叫Minor GC，当新生代区域满了之后，会触发GC，只对新生代进行回收。 在老年代发生的垃圾回收叫Full GC或者Major GC，当老年代区域满了之后，会触发GC，Full GC会对新生代，老年代和永久代进行回收。 运行时常量池运行时常量池分配在方法区中，类和接口被加载到虚拟机之后，运行时常量池就被创建了。 运行时常量池是类或接口的常量池的运行时表示形式，于存储编译期生成的各种字面量和符号引用。 可能会发生异常的情况： 构造运行时常量池所需的内存空间超过了方法区能提供的最大值，会抛出OutOfMemoryError异常。 本地方法栈（Native Method Stack）用来支持native方法。跟虚拟机栈功能类似。本地方法栈被实现成固定大小或者是动态扩展和收缩的。 可能会发生的异常情况： 如果线程请求的栈容量超过本地方法栈允许的最大容量，会抛出StackOverflowError异常。 如果本地方法栈可动态扩展，申请不到足够的内存去完成扩展，或者建立新线程时没有足够的内存去创建对应的本地方法栈，会抛出OutOfMemoryError异常。 简要总结程序计数器为线程私有，用来指示程序运行时的位置。 Java虚拟机栈是线程私有的，用来存储局部变量表等，出栈入栈对应着方法的结束开始。 堆是线程共享的区域，虚拟机启动时创建，创建的实例对象和数组都分配在堆上。 方法区是线程共享的区域，虚拟机启动时创建，用来存储类的信息，常量字段等等。 本地方法栈用来执行本地方法的。 参考 https://blog.jamesdbloom.com/JVMInternals.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[tomcat7中Digester的使用以及对server.xml的解析过程分析]]></title>
      <url>%2F2017%2F05%2F17%2Ftomcat7%E4%B8%ADDigester%E7%9A%84%E4%BD%BF%E7%94%A8%E4%BB%A5%E5%8F%8A%E5%AF%B9server.xml%E7%9A%84%E8%A7%A3%E6%9E%90%E8%BF%87%E7%A8%8B%E5%88%86%E6%9E%90%2F</url>
      <content type="text"><![CDATA[tomcat在启动的时候，会调用Catalina的load的方法启动一个新的Server实例，在这里会有关于Digester的使用，以及对server.xml的解析过程。 load方法的代码如下： 1234567891011121314151617public void load() &#123; ... &#x2F;&#x2F; Create and execute our Digester Digester digester &#x3D; createStartDigester(); ... try &#123; inputSource.setByteStream(inputStream); digester.push(this); digester.parse(inputSource); &#125; ...&#125; 代码做了精简，只保留了Digester的最重要部分。首先是创建并配置要用来启动的Digester实例，然后获取到server.xml文件的输入流之后，使用digester进行解析。 Digester介绍在进行具体步骤的解析之前，首先看一下Digester的简单介绍，Digester用来处理xml，是对SAX的包装，所以也是基于文件流来解析xml的。Digester使用的步骤也很简单： 创建一个Digester实例 设置相关属性 设置具体的规则 调用parse方法进行解析 createStartDigester此方法用来创建和配置Digester，对应着上面的前三个步骤，具体代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576protected Digester createStartDigester() &#123; long t1&#x3D;System.currentTimeMillis(); &#x2F;&#x2F;创建一个digester实例 Digester digester &#x3D; new Digester(); &#x2F;&#x2F;是否需要验证xml文档的合法性，false表示不需要进行DTD规则校验 digester.setValidating(false); &#x2F;&#x2F;是否需要进行节点设置规则校验 digester.setRulesValidation(true); &#x2F;&#x2F;将xml节点中的className作为假属性，不用调用默认的setter方法 &#x2F;&#x2F;在解析时，调用相应对象的setter方法来设置属性值，setter的参数就是节点属性， &#x2F;&#x2F;而有className的话，则直接使用className来直接实例化对象 HashMap&lt;Class&lt;?&gt;, List&lt;String&gt;&gt; fakeAttributes &#x3D; new HashMap&lt;Class&lt;?&gt;, List&lt;String&gt;&gt;(); ArrayList&lt;String&gt; attrs &#x3D; new ArrayList&lt;String&gt;(); attrs.add(&quot;className&quot;); fakeAttributes.put(Object.class, attrs); digester.setFakeAttributes(fakeAttributes); digester.setUseContextClassLoader(true); &#x2F;&#x2F;下面添加各种规则 &#x2F;&#x2F;遇到xml中Server节点，就创建一个StandardServer对象 digester.addObjectCreate(&quot;Server&quot;, &quot;org.apache.catalina.core.StandardServer&quot;, &quot;className&quot;); &#x2F;&#x2F;根据Server节点中的属性信息，调用属性的setter方法，比如说server节点中会有port&#x3D;“8080”属性，则会调用setPort方法 digester.addSetProperties(&quot;Server&quot;); &#x2F;&#x2F;在上面的load方法中有个digester.push(this)，this对象就是栈顶了 &#x2F;&#x2F;这里将Server节点对应的对象作为参数，调用this对象，也就是Catalina对象的setServer方法 digester.addSetNext(&quot;Server&quot;, &quot;setServer&quot;, &quot;org.apache.catalina.Server&quot;); &#x2F;&#x2F;Server节点下的GlobalNamingResources节点，创建一个NamingResource对象 digester.addObjectCreate(&quot;Server&#x2F;GlobalNamingResources&quot;, &quot;org.apache.catalina.deploy.NamingResources&quot;); digester.addSetProperties(&quot;Server&#x2F;GlobalNamingResources&quot;); digester.addSetNext(&quot;Server&#x2F;GlobalNamingResources&quot;, &quot;setGlobalNamingResources&quot;, &quot;org.apache.catalina.deploy.NamingResources&quot;); &#x2F;&#x2F;Server下的Listener节点 digester.addObjectCreate(&quot;Server&#x2F;Listener&quot;, null, &#x2F;&#x2F; MUST be specified in the element &quot;className&quot;); digester.addSetProperties(&quot;Server&#x2F;Listener&quot;); digester.addSetNext(&quot;Server&#x2F;Listener&quot;, &quot;addLifecycleListener&quot;, &quot;org.apache.catalina.LifecycleListener&quot;); &#x2F;&#x2F;Server下的Service节点 digester.addObjectCreate(&quot;Server&#x2F;Service&quot;, &quot;org.apache.catalina.core.StandardService&quot;, &quot;className&quot;); digester.addSetProperties(&quot;Server&#x2F;Service&quot;); digester.addSetNext(&quot;Server&#x2F;Service&quot;, &quot;addService&quot;, &quot;org.apache.catalina.Service&quot;); &#x2F;&#x2F;Service节点下的Listener节点 digester.addObjectCreate(&quot;Server&#x2F;Service&#x2F;Listener&quot;, null, &quot;className&quot;); digester.addSetProperties(&quot;Server&#x2F;Service&#x2F;Listener&quot;); digester.addSetNext(&quot;Server&#x2F;Service&#x2F;Listener&quot;, &quot;addLifecycleListener&quot;, &quot;org.apache.catalina.LifecycleListener&quot;); &#x2F;&#x2F;Executor节点 digester.addObjectCreate(&quot;Server&#x2F;Service&#x2F;Executor&quot;, &quot;org.apache.catalina.core.StandardThreadExecutor&quot;, &quot;className&quot;); digester.addSetProperties(&quot;Server&#x2F;Service&#x2F;Executor&quot;); digester.addSetNext(&quot;Server&#x2F;Service&#x2F;Executor&quot;, &quot;addExecutor&quot;, &quot;org.apache.catalina.Executor&quot;); &#x2F;&#x2F;给Connector添加规则，就是当遇到Connector的时候，会调用ConnectorCreateRule里面定义的规则 &#x2F;&#x2F;跟上面的作用是一样的，只不过该节点的规则比较多，就创建一个规则类 digester.addRule(&quot;Server&#x2F;Service&#x2F;Connector&quot;, new ConnectorCreateRule()); digester.addRule(&quot;Server&#x2F;Service&#x2F;Connector&quot;, new SetAllPropertiesRule(new String[]&#123;&quot;executor&quot;&#125;)); digester.addSetNext(&quot;Server&#x2F;Service&#x2F;Connector&quot;, &quot;addConnector&quot;, &quot;org.apache.catalina.connector.Connector&quot;); digester.addObjectCreate(&quot;Server&#x2F;Service&#x2F;Connector&#x2F;Listener&quot;, null, &quot;className&quot;); digester.addSetProperties(&quot;Server&#x2F;Service&#x2F;Connector&#x2F;Listener&quot;); digester.addSetNext(&quot;Server&#x2F;Service&#x2F;Connector&#x2F;Listener&quot;, &quot;addLifecycleListener&quot;, &quot;org.apache.catalina.LifecycleListener&quot;); &#x2F;&#x2F;给嵌入元素添加RuleSet自定义规则 &#x2F;&#x2F;每个rule规则，都会有tomcat对自身业务逻辑的判断和处理 digester.addRuleSet(new NamingRuleSet(&quot;Server&#x2F;GlobalNamingResources&#x2F;&quot;)); digester.addRuleSet(new EngineRuleSet(&quot;Server&#x2F;Service&#x2F;&quot;)); digester.addRuleSet(new HostRuleSet(&quot;Server&#x2F;Service&#x2F;Engine&#x2F;&quot;)); digester.addRuleSet(new ContextRuleSet(&quot;Server&#x2F;Service&#x2F;Engine&#x2F;Host&#x2F;&quot;)); addClusterRuleSet(digester, &quot;Server&#x2F;Service&#x2F;Engine&#x2F;Host&#x2F;Cluster&#x2F;&quot;); digester.addRuleSet(new NamingRuleSet(&quot;Server&#x2F;Service&#x2F;Engine&#x2F;Host&#x2F;Context&#x2F;&quot;)); &#x2F;&#x2F; When the &#39;engine&#39; is found, set the parentClassLoader. digester.addRule(&quot;Server&#x2F;Service&#x2F;Engine&quot;, new SetParentClassLoaderRule(parentClassLoader)); addClusterRuleSet(digester, &quot;Server&#x2F;Service&#x2F;Engine&#x2F;Cluster&#x2F;&quot;); return (digester);&#125; 上面创建完Digester对象，并设置了属性和各种规则之后，接下来主要的就是解析工作。 parse解析parse方法代码如下： 12345678public Object parse(InputSource input) throws IOException, SAXException &#123; &#x2F;&#x2F;解析前的配置，默认什么也没做，需要子类去实现 configure(); &#x2F;&#x2F;获取解析器去解析 getXMLReader().parse(input); return (root);&#125; 解析完成之后，Server,Service等等在server.xml中存在的节点，就会有对应的对象存在，后续就可以使用这些对象进行初始化和启动了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[tomcat7的server.xml解析]]></title>
      <url>%2F2017%2F05%2F16%2Ftomcat7%E7%9A%84server.xml%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[这里对tomcat7的server.xml文件进行解释一下，方便在分析启动源码的时候理解Digester做的事情。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;?xml version&#x3D;&#39;1.0&#39; encoding&#x3D;&#39;utf-8&#39;?&gt;&lt;Server port&#x3D;&quot;8005&quot; shutdown&#x3D;&quot;SHUTDOWN&quot;&gt; &lt;Listener className&#x3D;&quot;org.apache.catalina.startup.VersionLoggerListener&quot; &#x2F;&gt; &lt;Listener className&#x3D;&quot;org.apache.catalina.security.SecurityListener&quot; &#x2F;&gt; &lt;Listener className&#x3D;&quot;org.apache.catalina.core.AprLifecycleListener&quot; SSLEngine&#x3D;&quot;on&quot; &#x2F;&gt; &lt;Listener className&#x3D;&quot;org.apache.catalina.core.JasperListener&quot; &#x2F;&gt; &lt;Listener className&#x3D;&quot;org.apache.catalina.core.JreMemoryLeakPreventionListener&quot; &#x2F;&gt; &lt;Listener className&#x3D;&quot;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener&quot; &#x2F;&gt; &lt;Listener className&#x3D;&quot;org.apache.catalina.core.ThreadLocalLeakPreventionListener&quot; &#x2F;&gt; &lt;GlobalNamingResources&gt; &lt;Resource name&#x3D;&quot;UserDatabase&quot; auth&#x3D;&quot;Container&quot; type&#x3D;&quot;org.apache.catalina.UserDatabase&quot; description&#x3D;&quot;User database that can be updated and saved&quot; factory&#x3D;&quot;org.apache.catalina.users.MemoryUserDatabaseFactory&quot; pathname&#x3D;&quot;conf&#x2F;tomcat-users.xml&quot; &#x2F;&gt; &lt;&#x2F;GlobalNamingResources&gt; &lt;Service name&#x3D;&quot;Catalina&quot;&gt; &lt;Executor name&#x3D;&quot;tomcatThreadPool&quot; namePrefix&#x3D;&quot;catalina-exec-&quot; maxThreads&#x3D;&quot;150&quot; minSpareThreads&#x3D;&quot;4&quot;&#x2F;&gt; &lt;Connector port&#x3D;&quot;8080&quot; protocol&#x3D;&quot;HTTP&#x2F;1.1&quot; connectionTimeout&#x3D;&quot;20000&quot; redirectPort&#x3D;&quot;8443&quot; &#x2F;&gt; &lt;Connector executor&#x3D;&quot;tomcatThreadPool&quot; port&#x3D;&quot;8080&quot; protocol&#x3D;&quot;HTTP&#x2F;1.1&quot; connectionTimeout&#x3D;&quot;20000&quot; redirectPort&#x3D;&quot;8443&quot; &#x2F;&gt; &lt;Connector port&#x3D;&quot;8443&quot; protocol&#x3D;&quot;org.apache.coyote.http11.Http11Protocol&quot; maxThreads&#x3D;&quot;150&quot; SSLEnabled&#x3D;&quot;true&quot; scheme&#x3D;&quot;https&quot; secure&#x3D;&quot;true&quot; clientAuth&#x3D;&quot;false&quot; sslProtocol&#x3D;&quot;TLS&quot; &#x2F;&gt; &lt;Connector port&#x3D;&quot;8009&quot; protocol&#x3D;&quot;AJP&#x2F;1.3&quot; redirectPort&#x3D;&quot;8443&quot; &#x2F;&gt; &lt;Engine name&#x3D;&quot;Catalina&quot; defaultHost&#x3D;&quot;localhost&quot;&gt; &lt;Cluster className&#x3D;&quot;org.apache.catalina.ha.tcp.SimpleTcpCluster&quot;&#x2F;&gt; &lt;Realm className&#x3D;&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt; &lt;Realm className&#x3D;&quot;org.apache.catalina.realm.UserDatabaseRealm&quot; resourceName&#x3D;&quot;UserDatabase&quot;&#x2F;&gt; &lt;&#x2F;Realm&gt; &lt;Host name&#x3D;&quot;localhost&quot; appBase&#x3D;&quot;webapps&quot; unpackWARs&#x3D;&quot;true&quot; autoDeploy&#x3D;&quot;true&quot;&gt; &lt;Valve className&#x3D;&quot;org.apache.catalina.authenticator.SingleSignOn&quot; &#x2F;&gt; &lt;Valve className&#x3D;&quot;org.apache.catalina.valves.AccessLogValve&quot; directory&#x3D;&quot;logs&quot; prefix&#x3D;&quot;localhost_access_log.&quot; suffix&#x3D;&quot;.txt&quot; pattern&#x3D;&quot;%h %l %u %t &quot;%r&quot; %s %b&quot; &#x2F;&gt; &lt;&#x2F;Host&gt; &lt;&#x2F;Engine&gt; &lt;&#x2F;Service&gt;&lt;&#x2F;Server&gt; Servertomcat中Server代表一个tomcat实例，所以只会存在一个Server，而在配置文件中也是作为顶级元素出现，代码如下： 123&lt;Server port&#x3D;&quot;8005&quot; shutdown&#x3D;&quot;SHUTDOWN&quot;&gt;。。。&lt;&#x2F;Server&gt; port，监听shutdown命令的端口，-1表示禁用shutdown命令。 shutdown，关闭tomcat的指令。 Listener监听器，用来监听某些事件的发生。 &lt;Listener className=&quot;org.apache.catalina.startup.VersionLoggerListener&quot; /&gt; VersionLoggerListener，启动时对tomcat，java，操作系统信息打印日志。 &lt;Listener className=&quot;org.apache.catalina.security.SecurityListener&quot; /&gt; SecurityListener，启动tomcat时，做一些安全检查。 &lt;Listener className=&quot;org.apache.catalina.core.AprLifecycleListener&quot; SSLEngine=&quot;on&quot; /&gt; AprLifecycleListener，用来监听Apache服务器相关的。 &lt;Listener className=&quot;org.apache.catalina.core.JasperListener&quot; /&gt; JasperListener，Jasper 2 JSP 引擎，主要负责对更新之后的jsp进行重新编译。 &lt;Listener className=&quot;org.apache.catalina.core.JreMemoryLeakPreventionListener&quot; /&gt; JreMemoryLeakPreventionListener，防止内存溢出的监听器。 &lt;Listener className=&quot;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener&quot; /&gt; GlobalResourcesLifecycleListener，初始化定义在元素GlobalNamingResources下的全局JNDI资源 &lt;Listener className=&quot;org.apache.catalina.core.ThreadLocalLeakPreventionListener&quot; /&gt; ThreadLocalLeakPreventionListener，防止ThreadLocal溢出监听器。 GlobalNamingResourcesGlobalNamingResources定义Server的全局JNDI资源。可以为所有的引擎应用程序引用。 1234567&lt;GlobalNamingResources&gt; &lt;Resource name&#x3D;&quot;UserDatabase&quot; auth&#x3D;&quot;Container&quot; type&#x3D;&quot;org.apache.catalina.UserDatabase&quot; description&#x3D;&quot;User database that can be updated and saved&quot; factory&#x3D;&quot;org.apache.catalina.users.MemoryUserDatabaseFactory&quot; pathname&#x3D;&quot;conf&#x2F;tomcat-users.xml&quot; &#x2F;&gt;&lt;&#x2F;GlobalNamingResources&gt; 配置文件中定义了一个JNDI，名为UserDatabase，通过conf/tomcat-users.xml的内容，来得到一个用于授权用户的数据库，是一个内存数据库。 Service123&lt;Service name&#x3D;&quot;Catalina&quot;&gt;。。。&lt;&#x2F;Service&gt; Server下面可以有多个Service，Service下面有多个Connector和一个Engine。这里默认的Service名字为Catalina，下面有两个Connector：Http和AJP。 name，Service显示的名称，名字必须唯一。 Connector123&lt;Connector port&#x3D;&quot;8080&quot; protocol&#x3D;&quot;HTTP&#x2F;1.1&quot; connectionTimeout&#x3D;&quot;20000&quot; redirectPort&#x3D;&quot;8443&quot; &#x2F;&gt; 上面是用来处理http请求的Connector。 port，端口号8080。 protocol，协议，http协议 connectionTimeout，响应的最大等待时间，20秒 redirectPort，ssl请求会重定向到8443端口 1234&lt;Connector executor&#x3D;&quot;tomcatThreadPool&quot; port&#x3D;&quot;8080&quot; protocol&#x3D;&quot;HTTP&#x2F;1.1&quot; connectionTimeout&#x3D;&quot;20000&quot; redirectPort&#x3D;&quot;8443&quot; &#x2F;&gt; 上面是使用线程池，处理http请求。 123&lt;Connector port&#x3D;&quot;8443&quot; protocol&#x3D;&quot;org.apache.coyote.http11.Http11Protocol&quot; maxThreads&#x3D;&quot;150&quot; SSLEnabled&#x3D;&quot;true&quot; scheme&#x3D;&quot;https&quot; secure&#x3D;&quot;true&quot; clientAuth&#x3D;&quot;false&quot; sslProtocol&#x3D;&quot;TLS&quot; &#x2F;&gt; 上面处理ssl请求，端口是8443。 1&lt;Connector port&#x3D;&quot;8009&quot; protocol&#x3D;&quot;AJP&#x2F;1.3&quot; redirectPort&#x3D;&quot;8443&quot; &#x2F;&gt; 上面处理AJP请求，可以将tomcat和apache的http服务器一起运行。 EngineEngine是容器，一个Service中只包含一个Engine： 123&lt;Engine name&#x3D;&quot;Catalina&quot; defaultHost&#x3D;&quot;localhost&quot;&gt;...&lt;&#x2F;Engine&gt; Engine下面可以包含一个多或者多个Host。Engine从http请求的头信息中的主机名或者ip映射到真确的主机上。 name，Engine的名字，需要唯一。 defaultHost，默认主机名 Cluster集群相关的配置。tomcat支持服务器集群，可以复制整个集群的回话和上下文属性，也可以部署一个war包到所有的集群上。 1&lt;Cluster className&#x3D;&quot;org.apache.catalina.ha.tcp.SimpleTcpCluster&quot;&#x2F;&gt; Realm1234&lt;Realm className&#x3D;&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt; &lt;Realm className&#x3D;&quot;org.apache.catalina.realm.UserDatabaseRealm&quot; resourceName&#x3D;&quot;UserDatabase&quot;&#x2F;&gt;&lt;&#x2F;Realm&gt; Realm是一个包含user、password、role的数据库，Realm可以定义在任何容器中。这里通过外部资源UserDatabase进行认证。 Host123456789&lt;Host name&#x3D;&quot;localhost&quot; appBase&#x3D;&quot;webapps&quot; unpackWARs&#x3D;&quot;true&quot; autoDeploy&#x3D;&quot;true&quot;&gt; &lt;Valve className&#x3D;&quot;org.apache.catalina.authenticator.SingleSignOn&quot; &#x2F;&gt; &lt;Valve className&#x3D;&quot;org.apache.catalina.valves.AccessLogValve&quot; directory&#x3D;&quot;logs&quot; prefix&#x3D;&quot;localhost_access_log.&quot; suffix&#x3D;&quot;.txt&quot; pattern&#x3D;&quot;%h %l %u %t &quot;%r&quot; %s %b&quot; &#x2F;&gt;&lt;&#x2F;Host&gt; Host虚拟主机，定义在Engine下面，一个Engine下面可以有多个Host，在一个Host下面可以有多个Context。 name，虚拟主机的网络名称，必须有一个host的名字和Engine的defaulHost一样。 appBase，虚拟主机应用的根目录，默认是webapps。 unpackWARs，在webapps目录下的war文件是否应该解压。 autoDeploy，值为true时，tomcat会定时检查appBase等目录，对新的web应用和Context描述文件进行部署。 Value12345&lt;Valve className&#x3D;&quot;org.apache.catalina.authenticator.SingleSignOn&quot; &#x2F;&gt;&lt;Valve className&#x3D;&quot;org.apache.catalina.valves.AccessLogValve&quot; directory&#x3D;&quot;logs&quot; prefix&#x3D;&quot;localhost_access_log.&quot; suffix&#x3D;&quot;.txt&quot; pattern&#x3D;&quot;%h %l %u %t &quot;%r&quot; %s %b&quot; &#x2F;&gt; Value在这里是阀门的意思，可以拦截http请求，可以定义在任何容器中。 SingleSignOn 是单点登录，AccessLogValve是访问日志的记录。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[tomcat7启动流程源码分析]]></title>
      <url>%2F2017%2F05%2F10%2Ftomcat7%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
      <content type="text"><![CDATA[主要介绍下tomcat7的启动流程，以及相关源码的分析。这里从我们常用的tomcat7的启动脚本为分析入口，然后进入到tomcat7相关源码中去。使用到的tomcat的版本为tomcat 7.0.77。 在正式进入源码分析之前，首先需要了解下tomcat的类加载器的东西。请参考tomcat7类加载器解析 启动脚本startup.sh平时启动tomcat都是从这里开始，先看下这里都做了什么，下面是startup.sh源码： 12345678# CATALINA服务启动脚本。。。# 执行的脚本是catalina.shEXECUTABLE&#x3D;catalina.sh。。。# 执行catalina.sh脚本，参数是startexec &quot;$PRGDIR&quot;&#x2F;&quot;$EXECUTABLE&quot; start &quot;$@&quot; catalina.sh这里脚本有点长，我们只看有关start的部分，其他的都暂先省略掉。 12算了，这里不装逼了，脚本基本上内容都不太了解。不解析了，直接看最主要的一句org.apache.catalina.startup.Bootstrap &quot;$@&quot; start \ 上面这句就是要调用org.apache.catalina.startup.Bootstrap的main方法，参数是start，这里就进入了我们的源码。 Bootstrap类org.apache.catalina.startup.BootStrap，BootStrap类中的main方法是我们要分析的入口，是通过脚本启动tomcat的主方法和入口。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public static void main(String args[]) &#123; if (daemon &#x3D;&#x3D; null) &#123; &#x2F;&#x2F; Don&#39;t set daemon until init() has completed Bootstrap bootstrap &#x3D; new Bootstrap(); try &#123; &#x2F;&#x2F;初始化 bootstrap.init(); &#125; catch (Throwable t) &#123;。。。&#125; daemon &#x3D; bootstrap; &#125; else &#123; Thread.currentThread().setContextClassLoader(daemon.catalinaLoader); &#125; try &#123; String command &#x3D; &quot;start&quot;; if (args.length &gt; 0) &#123; command &#x3D; args[args.length - 1]; &#125; &#x2F;&#x2F;暂不知是啥意思 if (command.equals(&quot;startd&quot;)) &#123; args[args.length - 1] &#x3D; &quot;start&quot;; daemon.load(args); daemon.start(); &#125; else if (command.equals(&quot;stopd&quot;)) &#123; args[args.length - 1] &#x3D; &quot;stop&quot;; daemon.stop(); &#125; else if (command.equals(&quot;start&quot;)) &#123; &#x2F;&#x2F;start命令 daemon.setAwait(true); daemon.load(args); daemon.start(); &#125; else if (command.equals(&quot;stop&quot;)) &#123; &#x2F;&#x2F;stop命令 daemon.stopServer(args); &#125; else if (command.equals(&quot;configtest&quot;)) &#123; daemon.load(args); if (null&#x3D;&#x3D;daemon.getServer()) &#123; System.exit(1); &#125; System.exit(0); &#125; else &#123;。。。&#125; &#125; catch (Throwable t) &#123; 。。。 System.exit(1); &#125;&#125; main方法做的事情也不复杂，当我们第一次启动的时候，首先初始化，然后调用start方法。 初始化初始化的时候做的工作也不复杂，大概如下： 首先设置catalina home和catalina base目录。 初始化类加载器，这是很重要的步骤 设置上下文类加载器和安全相关类加载器 加载启动类，创建启动类的实例 设置启动类实例的parentClassLoader为sharedLoader 初始化BootStrap方法代码如下： 12345678910111213141516171819202122232425262728293031public void init() throws Exception &#123; &#x2F;&#x2F;设置catalina.home属性，如果不存在就使用当前工作目录 setCatalinaHome(); &#x2F;&#x2F; 设置catalina.base属性，如果不存在就使用当前工作目录 setCatalinaBase(); &#x2F;&#x2F;初始化类加载器 initClassLoaders(); &#x2F;&#x2F;设置当前线程的类加载器 Thread.currentThread().setContextClassLoader(catalinaLoader); SecurityClassLoad.securityClassLoad(catalinaLoader); &#x2F;&#x2F; 使用catalinaLoader类加载器加载Catalina类 Class&lt;?&gt; startupClass &#x3D; catalinaLoader.loadClass(&quot;org.apache.catalina.startup.Catalina&quot;); &#x2F;&#x2F;创建启动类的实例 Object startupInstance &#x3D; startupClass.newInstance(); &#x2F;&#x2F;以下设置启动类实例的parentClassLoader为sharedLoader String methodName &#x3D; &quot;setParentClassLoader&quot;; Class&lt;?&gt; paramTypes[] &#x3D; new Class[1]; paramTypes[0] &#x3D; Class.forName(&quot;java.lang.ClassLoader&quot;); Object paramValues[] &#x3D; new Object[1]; paramValues[0] &#x3D; sharedLoader; Method method &#x3D; startupInstance.getClass().getMethod(methodName, paramTypes); method.invoke(startupInstance, paramValues); &#x2F;&#x2F;启动实例 catalinaDaemon &#x3D; startupInstance;&#125; 初始化类加载器重点看下有关类加载器的初始化，代码如下： 123456789101112131415private void initClassLoaders() &#123; try &#123; &#x2F;&#x2F;创建CommonClassLoader，common对应的是配置文件中的common.loader &#x2F;&#x2F;这里和下面的配置文件指的是conf&#x2F;catalina.properties文件 commonLoader &#x3D; createClassLoader(&quot;common&quot;, null); if( commonLoader &#x3D;&#x3D; null ) &#123; &#x2F;&#x2F;配置文件中没有配置common，就使用当前类的ClassLoader commonLoader&#x3D;this.getClass().getClassLoader(); &#125; &#x2F;&#x2F;创建ServerClassLoader，对应配置文件中的server.loader catalinaLoader &#x3D; createClassLoader(&quot;server&quot;, commonLoader); &#x2F;&#x2F;创建SharedClassLoader，对应配置文件中的shared.loader sharedLoader &#x3D; createClassLoader(&quot;shared&quot;, commonLoader); &#125; catch (Throwable t) &#123;。。。&#125;&#125; 这里会创建三个ClassLoader，commonLoader，catalinaLoader，sharedLoader，配置文件conf/catalina.properties中server.loader和shared.loader是空的，所以在运行时这两个Loader和commonLoader是一样的，这一点可以在下面的源码中看到。目前只有commonLoader具备实际的意义。 看下createClassLoader方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152private ClassLoader createClassLoader(String name, ClassLoader parent) throws Exception &#123; &#x2F;&#x2F;CatalinaProperties对应着conf&#x2F;catalina.properties文件 &#x2F;&#x2F;配置文件中配置：common.loader&#x3D;$&#123;catalina.base&#125;&#x2F;lib,$&#123;catalina.base&#125;&#x2F;lib&#x2F;*.jar,$&#123;catalina.home&#125;&#x2F;lib,$&#123;catalina.home&#125;&#x2F;lib&#x2F;*.jar &#x2F;&#x2F;先从配置文件中获取name对应的name.loader &#x2F;&#x2F;分别是common.loader、server.loader、shared.loader String value &#x3D; CatalinaProperties.getProperty(name + &quot;.loader&quot;); &#x2F;&#x2F;如果value为空，就直接返回parent &#x2F;&#x2F;这里也验证了上面说到的，运行时由于server.loader、shared.loader是空的，所以之前说的三个Loader其实是同一个CommonLoader if ((value &#x3D;&#x3D; null) || (value.equals(&quot;&quot;))) return parent; &#x2F;&#x2F;将value中$&#123;catalina.base&#125;和$&#123;catalina.home&#125;替换成实际的目录 value &#x3D; replace(value); &#x2F;&#x2F;仓库列表，仓库指的是指定的目录，比如lib；或者是*.jar等 List&lt;Repository&gt; repositories &#x3D; new ArrayList&lt;Repository&gt;(); &#x2F;&#x2F;逗号分割 StringTokenizer tokenizer &#x3D; new StringTokenizer(value, &quot;,&quot;); while (tokenizer.hasMoreElements()) &#123; String repository &#x3D; tokenizer.nextToken().trim(); if (repository.length() &#x3D;&#x3D; 0) &#123; continue; &#125; &#x2F;&#x2F;仓库封装着对应的位置和类型，添加进list中保存 &#x2F;&#x2F;这里是URL类型的 try &#123; URL url &#x3D; new URL(repository); repositories.add( new Repository(repository, RepositoryType.URL)); continue; &#125; catch (MalformedURLException e) &#123; &#x2F;&#x2F; Ignore &#125; &#x2F;&#x2F;本地仓库 if (repository.endsWith(&quot;*.jar&quot;)) &#123;&#x2F;&#x2F;多个jar repository &#x3D; repository.substring (0, repository.length() - &quot;*.jar&quot;.length()); repositories.add( new Repository(repository, RepositoryType.GLOB)); &#125; else if (repository.endsWith(&quot;.jar&quot;)) &#123;&#x2F;&#x2F;单个jar repositories.add( new Repository(repository, RepositoryType.JAR)); &#125; else &#123;&#x2F;&#x2F;目录类型的 repositories.add( new Repository(repository, RepositoryType.DIR)); &#125; &#125; &#x2F;&#x2F;使用ClassLoaderFactory的createClassLoader方法来创建ClassLoader &#x2F;&#x2F;仓库是上面解析过的仓库 return ClassLoaderFactory.createClassLoader(repositories, parent);&#125; 继续往下看createClassLoader方法，创建新的类加载器： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public static ClassLoader createClassLoader(List&lt;Repository&gt; repositories, final ClassLoader parent) throws Exception &#123; Set&lt;URL&gt; set &#x3D; new LinkedHashSet&lt;URL&gt;(); &#x2F;&#x2F;将各种类型的repository解析成url，保存进set中 if (repositories !&#x3D; null) &#123; for (Repository repository : repositories) &#123; if (repository.getType() &#x3D;&#x3D; RepositoryType.URL) &#123; URL url &#x3D; buildClassLoaderUrl(repository.getLocation()); set.add(url); &#125; else if (repository.getType() &#x3D;&#x3D; RepositoryType.DIR) &#123; File directory &#x3D; new File(repository.getLocation()); directory &#x3D; directory.getCanonicalFile(); if (!validateFile(directory, RepositoryType.DIR)) &#123; continue; &#125; URL url &#x3D; buildClassLoaderUrl(directory); set.add(url); &#125; else if (repository.getType() &#x3D;&#x3D; RepositoryType.JAR) &#123; File file&#x3D;new File(repository.getLocation()); file &#x3D; file.getCanonicalFile(); if (!validateFile(file, RepositoryType.JAR)) &#123; continue; &#125; URL url &#x3D; buildClassLoaderUrl(file); set.add(url); &#125; else if (repository.getType() &#x3D;&#x3D; RepositoryType.GLOB) &#123; File directory&#x3D;new File(repository.getLocation()); directory &#x3D; directory.getCanonicalFile(); if (!validateFile(directory, RepositoryType.GLOB)) &#123; continue; &#125; String filenames[] &#x3D; directory.list(); if (filenames &#x3D;&#x3D; null) &#123; continue; &#125; for (int j &#x3D; 0; j &lt; filenames.length; j++) &#123; String filename &#x3D; filenames[j].toLowerCase(Locale.ENGLISH); if (!filename.endsWith(&quot;.jar&quot;)) continue; File file &#x3D; new File(directory, filenames[j]); file &#x3D; file.getCanonicalFile(); if (!validateFile(file, RepositoryType.JAR)) &#123; continue; &#125;; URL url &#x3D; buildClassLoaderUrl(file); set.add(url); &#125; &#125; &#125; &#125; &#x2F;&#x2F; Construct the class loader itself final URL[] array &#x3D; set.toArray(new URL[set.size()]); &#x2F;&#x2F;使用上面解析到的url来新建URLClassLoader实例 return AccessController.doPrivileged( new PrivilegedAction&lt;URLClassLoader&gt;() &#123; @Override public URLClassLoader run() &#123; if (parent &#x3D;&#x3D; null) return new URLClassLoader(array); else return new URLClassLoader(array, parent); &#125; &#125;);&#125; 这里进行新的类加载器创建，过程并不复杂，首先根据不同类型解析仓库，然后根据解析到的url新建URLClassLoader的实例。URLClassLoader是ClassLoader的子类，用于从目录的url或者jar文件来加载类和资源。 创建启动类并创建新实例上面创建完成三个ClassLoader之后，然后设置当前上下文的ClassLoader和安全ClassLoader为catalinaLoader，接下来一步就是使用catalinaLoader加载org.apache.catalina.startup.Catalina启动类。 1234Class&lt;?&gt; startupClass &#x3D; catalinaLoader.loadClass (&quot;org.apache.catalina.startup.Catalina&quot;);Object startupInstance &#x3D; startupClass.newInstance(); 调用start方法启动Catalina上面init方法完成之后，ClassLoader已经被创建，catalinaDaemon为启动的新实例。然后就该调用start方法了，调用的位置如下： 123456789else if (command.equals(&quot;start&quot;)) &#123; &#x2F;&#x2F;这个是让服务器启动之后，保持运行状态，监听后面发来的命令。 daemon.setAwait(true); &#x2F;&#x2F;对tomcat的相关的配置文件进行加载解析 &#x2F;&#x2F;对tomcat各个组件进行初始化配置操作 daemon.load(args); &#x2F;&#x2F;启动Catalina daemon.start();&#125; 启动前的三个步骤如下： 设置await状态，让服务器启动之后，保持运行状态，监听后面发来的命令。 load方法，对tomcat的相关的配置文件进行加载解析，并对各个组件进行初始化配置操作。 start方法，真正启动Catalina load方法加载和初始化load方法主要对tomcat的相关配置文件进行加载解析，对各个组件进行初始化配置操作，代码如下： 1234567891011121314151617181920212223private void load(String[] arguments) throws Exception &#123; &#x2F;&#x2F;要调用的load()方法 String methodName &#x3D; &quot;load&quot;; &#x2F;&#x2F;启动时候参数的处理 Object param[]; Class&lt;?&gt; paramTypes[]; if (arguments&#x3D;&#x3D;null || arguments.length&#x3D;&#x3D;0) &#123; paramTypes &#x3D; null; param &#x3D; null; &#125; else &#123; paramTypes &#x3D; new Class[1]; paramTypes[0] &#x3D; arguments.getClass(); param &#x3D; new Object[1]; param[0] &#x3D; arguments; &#125; &#x2F;&#x2F;下面调用Catalina的load方法 Method method &#x3D; catalinaDaemon.getClass().getMethod(methodName, paramTypes); method.invoke(catalinaDaemon, param);&#125; 这里没有做详细处理，只是使用反射调用Catalina实例的load方法，Catalina实例是我们上面使用反射新建的实例。接续往下看Catalina的load方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public void load() &#123; &#x2F;&#x2F;记录初始化开始的时间 long t1 &#x3D; System.nanoTime(); &#x2F;&#x2F;初始化目录，还有embedded的目录处理 initDirs(); &#x2F;&#x2F;初始化命名空间？这里不太理解还，应该是跟JNDI有关系 initNaming(); &#x2F;&#x2F;创建并配置一个Digester实例，并设置相关规则属性，Digester用来解析xml，采用的是SAX方式。 Digester digester &#x3D; createStartDigester(); InputSource inputSource &#x3D; null; InputStream inputStream &#x3D; null; File file &#x3D; null; try &#123; try &#123; &#x2F;&#x2F;配置文件，默认是conf&#x2F;server.xml file &#x3D; configFile(); inputStream &#x3D; new FileInputStream(file); inputSource &#x3D; new InputSource(file.toURI().toURL().toString()); &#125; catch (Exception e) &#123;。。。&#125; if (inputStream &#x3D;&#x3D; null) &#123; try &#123; inputStream &#x3D; getClass().getClassLoader() .getResourceAsStream(getConfigFile()); inputSource &#x3D; new InputSource (getClass().getClassLoader() .getResource(getConfigFile()).toString()); &#125; catch (Exception e) &#123;。。。&#125; &#125; &#x2F;&#x2F;上面没有找到配置文件，就找server-embed.xml if( inputStream&#x3D;&#x3D;null ) &#123; try &#123; inputStream &#x3D; getClass().getClassLoader() .getResourceAsStream(&quot;server-embed.xml&quot;); inputSource &#x3D; new InputSource (getClass().getClassLoader() .getResource(&quot;server-embed.xml&quot;).toString()); &#125; catch (Exception e) &#123;。。。&#125; &#125; if (inputStream &#x3D;&#x3D; null || inputSource &#x3D;&#x3D; null) &#123; 。。。 return; &#125; &#x2F;&#x2F;解析配置文件 try &#123; inputSource.setByteStream(inputStream); digester.push(this); digester.parse(inputSource); &#125; catch (SAXParseException spe) &#123;。。。&#125; &#125; finally &#123; if (inputStream !&#x3D; null) &#123; try &#123; inputStream.close(); &#125; catch (IOException e) &#123;。。。&#125; &#125; &#125; &#x2F;&#x2F;解析配置文件中会实例化server，是一个StandardServer &#x2F;&#x2F;设置server的catalina getServer().setCatalina(this); &#x2F;&#x2F;重定向流 &#x2F;&#x2F;使用自定义的PrintStream代替System.out和System.err initStreams(); &#x2F;&#x2F;初始化新的server try &#123; &#x2F;&#x2F;对Server进行初始化 getServer().init(); &#125; catch (LifecycleException e) &#123;。。。&#125; &#x2F;&#x2F;启动结束时间 long t2 &#x3D; System.nanoTime();&#125; load方法做的事情如下： 初始化目录，还有embedded的目录处理。 初始化命名空间。 创建并配置一个Digester实例，并设置相关规则属性，Digester用来解析xml，采用的是SAX方式。 读取解析配置文件。 调用解析配置文件时候已经初始化过的StandardServer的init方法，对Server进行初始化。 前面的步骤先不解析，直接看Server的init方法，刚方法实现在LifecycleBase类中。 初始化ServerLifecycleBase中的init方法如下： 123456789101112131415public final synchronized void init() throws LifecycleException &#123; &#x2F;&#x2F;状态不为new，抛异常 if (!state.equals(LifecycleState.NEW)) &#123; invalidTransition(Lifecycle.BEFORE_INIT_EVENT); &#125; try &#123; &#x2F;&#x2F;设置状态为INITIALIZING setStateInternal(LifecycleState.INITIALIZING, null, false); &#x2F;&#x2F;初始化 initInternal(); &#x2F;&#x2F;设置状态为INITIALIZED setStateInternal(LifecycleState.INITIALIZED, null, false); &#125; catch (Throwable t) &#123;。。。&#125;&#125; 继续往下看initInternal方法，在子类中实现，这里是在StandardServer中，对于下面的Engine，Host，Context的初始化也是这种步骤： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849protected void initInternal() throws LifecycleException &#123; &#x2F;&#x2F;调用父类方法，设置oname super.initInternal(); &#x2F;&#x2F;？？？ onameStringCache &#x3D; register(new StringCache(), &quot;type&#x3D;StringCache&quot;); &#x2F;&#x2F; 注册MBeanFactory MBeanFactory factory &#x3D; new MBeanFactory(); factory.setContainer(this); onameMBeanFactory &#x3D; register(factory, &quot;type&#x3D;MBeanFactory&quot;); &#x2F;&#x2F;注册naming资源 globalNamingResources.init(); &#x2F;&#x2F; Populate the extension validator with JARs from common and shared &#x2F;&#x2F; class loaders &#x2F;&#x2F;使用从common和shared类加载器加载的类来填充扩展验证器 if (getCatalina() !&#x3D; null) &#123; ClassLoader cl &#x3D; getCatalina().getParentClassLoader(); &#x2F;&#x2F;遍历类加载器，对于SystemClassLoader不处理 while (cl !&#x3D; null &amp;&amp; cl !&#x3D; ClassLoader.getSystemClassLoader()) &#123; &#x2F;&#x2F;URLClassLoader if (cl instanceof URLClassLoader) &#123; URL[] urls &#x3D; ((URLClassLoader) cl).getURLs(); for (URL url : urls) &#123; if (url.getProtocol().equals(&quot;file&quot;)) &#123; try &#123; File f &#x3D; new File (url.toURI()); if (f.isFile() &amp;&amp; f.getName().endsWith(&quot;.jar&quot;)) &#123; ExtensionValidator.addSystemResource(f); &#125; &#125; catch (URISyntaxException e) &#123; &#x2F;&#x2F; Ignore &#125; catch (IOException e) &#123; &#x2F;&#x2F; Ignore &#125; &#125; &#125; &#125; cl &#x3D; cl.getParent(); &#125; &#125; &#x2F;&#x2F;调用各个service的init方法，一个Server下面可能有多个Service for (int i &#x3D; 0; i &lt; services.length; i++) &#123; services[i].init(); &#125;&#125; 初始化Service也是先调用LifecycleBase中的init方法，然后initInternal方法由子类实现，这里是StandardService： 1234567891011121314151617181920212223242526protected void initInternal() throws LifecycleException &#123; super.initInternal(); &#x2F;&#x2F;调用Container的init方法，这里是StandardEngine if (container !&#x3D; null) &#123; container.init(); &#125; &#x2F;&#x2F;实例化线程池 for (Executor executor : findExecutors()) &#123; if (executor instanceof LifecycleMBeanBase) &#123; ((LifecycleMBeanBase) executor).setDomain(getDomain()); &#125; executor.init(); &#125; &#x2F;&#x2F;实例化Connector，可能有多个Connector synchronized (connectorsLock) &#123; for (Connector connector : connectors) &#123; try &#123; &#x2F;&#x2F;调用Connector的init方法 connector.init(); &#125; catch (Exception e) &#123;...&#125; &#125; &#125;&#125; 首先实例化Container，然后实例化Connector。 初始化Container这里的Container是StandardEngine，看下init方法： 12345protected void initInternal() throws LifecycleException &#123; &#x2F;&#x2F;启动之前确保Realm存在 getRealm(); super.initInternal();&#125; 初始化ConnectorConnector用来处理和客户端的通信相关内容。 Connector初始化，也是调用Connector的initInternal方法： 1234567891011121314151617181920212223protected void initInternal() throws LifecycleException &#123; super.initInternal(); &#x2F;&#x2F; CoyoteAdapter，用来处理请求 adapter &#x3D; new CoyoteAdapter(this); &#x2F;&#x2F;protocolHandler对于不同请求会有不同的Handler &#x2F;&#x2F;我们这里重点看http请求的处理，即是Http11Protocol protocolHandler.setAdapter(adapter); &#x2F;&#x2F; Make sure parseBodyMethodsSet has a default if( null &#x3D;&#x3D; parseBodyMethodsSet ) &#123; setParseBodyMethods(getParseBodyMethods()); &#125; try &#123; &#x2F;&#x2F;处理器初始化 protocolHandler.init(); &#125; catch (Exception e) &#123;。。。&#125; &#x2F;&#x2F; 初始化 mapper listener mapperListener.init();&#125; 初始化的时候先初始化Service，然后是Container，然后是Connector。往下还有对protocolHandler的初始化和mapperListener的初始化。 初始化protocolHandler这里主要看下对于http请求的处理，对应的Handler为Http11Protocol。初始化方法为init，实现在Http11Protocol的父类AbstractHttp11JsseProtocol中： 123456public void init() throws Exception &#123; &#x2F;&#x2F; SSL implementation needs to be in place before end point is &#x2F;&#x2F; initialized sslImplementation &#x3D; SSLImplementation.getInstance(sslImplementationName); super.init();&#125; 调用父类的init方法： 12345678910111213141516171819202122232425262728293031public void init() throws Exception &#123; if (oname &#x3D;&#x3D; null) &#123; &#x2F;&#x2F; Component not pre-registered so register it oname &#x3D; createObjectName(); if (oname !&#x3D; null) &#123; Registry.getRegistry(null, null).registerComponent(this, oname, null); &#125; &#125; if (this.domain !&#x3D; null) &#123; try &#123; tpOname &#x3D; new ObjectName(domain + &quot;:&quot; + &quot;type&#x3D;ThreadPool,name&#x3D;&quot; + getName()); Registry.getRegistry(null, null).registerComponent(endpoint, tpOname, null); &#125; catch (Exception e) &#123;。。。&#125; rgOname&#x3D;new ObjectName(domain + &quot;:type&#x3D;GlobalRequestProcessor,name&#x3D;&quot; + getName()); Registry.getRegistry(null, null).registerComponent( getHandler().getGlobal(), rgOname, null ); &#125; String endpointName &#x3D; getName(); endpoint.setName(endpointName.substring(1, endpointName.length()-1)); try &#123; &#x2F;&#x2F;endpoint的初始化 endpoint.init(); &#125; catch (Exception ex) &#123;。。。&#125;&#125; 关于oname和domain先不讲解，主要看初始化endpoint。 初始化endpointendpoint提供底层的网络io实现。init方法实现在AbstractEndpoint中： 12345678public final void init() throws Exception &#123; testServerCipherSuitesOrderSupport(); if (bindOnInit) &#123; &#x2F;&#x2F;绑定方法，该对底层的Socket之类的进行处理了。 bind(); bindState &#x3D; BindState.BOUND_ON_INIT; &#125;&#125; bind方法的实现在子类中，这里使用的是JioEndpoint： 123456789101112131415161718192021222324252627282930313233343536public void bind() throws Exception &#123; &#x2F;&#x2F;初始化acceptor的默认线程总数 if (acceptorThreadCount &#x3D;&#x3D; 0) &#123; acceptorThreadCount &#x3D; 1; &#125; &#x2F;&#x2F;初始化最大连接数 if (getMaxConnections() &#x3D;&#x3D; 0) &#123; setMaxConnections(getMaxThreadsInternal()); &#125; if (serverSocketFactory &#x3D;&#x3D; null) &#123; &#x2F;&#x2F;https的处理 if (isSSLEnabled()) &#123; serverSocketFactory &#x3D; handler.getSslImplementation().getServerSocketFactory(this); &#125; else &#123; &#x2F;&#x2F;处理http请求的serversocket工厂 serverSocketFactory &#x3D; new DefaultServerSocketFactory(this); &#125; &#125; if (serverSocket &#x3D;&#x3D; null) &#123; &#x2F;&#x2F;创建serverSocket try &#123; if (getAddress() &#x3D;&#x3D; null) &#123; serverSocket &#x3D; serverSocketFactory.createSocket(getPort(), getBacklog()); &#125; else &#123; serverSocket &#x3D; serverSocketFactory.createSocket(getPort(), getBacklog(), getAddress()); &#125; &#125; catch (BindException orig) &#123;。。。&#125; &#125;&#125; 创建ServerSocket代码如下： 1234public ServerSocket createSocket (int port, int backlog, InetAddress ifAddress) throws IOException &#123; return new ServerSocket (port, backlog, ifAddress);&#125; 创建ServerSocket，根据端口号和地址直接返回一个ServerSocket实例。到这里对于Handler的处理已经完成。接下来初始化mapperListener。 初始化mapperListenerMapperListener用来建立配置的URL映射的管理，即Host，Context，Wrapper（Servlet）和URL的映射关系。 init方法在LifecycleMBeanBase的initInternal方法中实现，没有做啥事。 初始化完成之后，就开始调用Catalina的start方法进行启动了。 初始化过程总结整个初始化过程层次还是很清晰的： 首先初始化Server 然后初始化Service 接着初始化Container，Executor，Connector 初始化Connector的时候，需要初始化protocolHandler和mapperListener 初始化protocolHandler，这里需要初始化endpoint，初始化endpoint就是返回一个ServerSocket实例 start方法启动CatalinaCatalina的start方法代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public void start() &#123; &#x2F;&#x2F;没有Server实例，就走一遍load if (getServer() &#x3D;&#x3D; null) &#123; load(); &#125; &#x2F;&#x2F;还是没有Server实例，有错误！ if (getServer() &#x3D;&#x3D; null) &#123; log.fatal(&quot;Cannot start server. Server instance is not configured.&quot;); return; &#125; long t1 &#x3D; System.nanoTime(); &#x2F;&#x2F;启动新的Server try &#123; &#x2F;&#x2F;这里Server是StandardServer getServer().start(); &#125; catch (LifecycleException e) &#123; try &#123; &#x2F;&#x2F;异常，需要销毁 getServer().destroy(); &#125; catch (LifecycleException e1) &#123;。。。&#125; return; &#125; long t2 &#x3D; System.nanoTime(); &#x2F;&#x2F; 注册关闭钩子 if (useShutdownHook) &#123; if (shutdownHook &#x3D;&#x3D; null) &#123; shutdownHook &#x3D; new CatalinaShutdownHook(); &#125; Runtime.getRuntime().addShutdownHook(shutdownHook); LogManager logManager &#x3D; LogManager.getLogManager(); if (logManager instanceof ClassLoaderLogManager) &#123; ((ClassLoaderLogManager) logManager).setUseShutdownHook( false); &#125; &#125; &#x2F;&#x2F;如果是await状态 if (await) &#123; await(); stop(); &#125;&#125; 这里主要的步骤是调用Server的start方法，启动服务。这里Server是StandardServer。 启动ServerStandardServer的start方法，start方法在LifecycleBase中： 1234567891011121314151617181920212223242526272829public final synchronized void start() throws LifecycleException &#123; if (LifecycleState.STARTING_PREP.equals(state) || LifecycleState.STARTING.equals(state) || LifecycleState.STARTED.equals(state)) &#123; return; &#125; &#x2F;&#x2F;init if (state.equals(LifecycleState.NEW)) &#123; init(); &#125; else if (state.equals(LifecycleState.FAILED)) &#123; &#x2F;&#x2F;stop stop(); &#125; else if (!state.equals(LifecycleState.INITIALIZED) &amp;&amp; !state.equals(LifecycleState.STOPPED)) &#123; invalidTransition(Lifecycle.BEFORE_START_EVENT); &#125; try &#123; setStateInternal(LifecycleState.STARTING_PREP, null, false); startInternal(); if (state.equals(LifecycleState.FAILED)) &#123; stop(); &#125; else if (!state.equals(LifecycleState.STARTING)) &#123; invalidTransition(Lifecycle.AFTER_START_EVENT); &#125; else &#123; setStateInternal(LifecycleState.STARTED, null, false); &#125; &#125; catch (Throwable t) &#123;。。。&#125;&#125; 上面也是调用startInternal()方法进行启动，在子类中实现，这里是在StandardServer中： 1234567891011121314protected void startInternal() throws LifecycleException &#123; &#x2F;&#x2F;暂先不解释 fireLifecycleEvent(CONFIGURE_START_EVENT, null); setState(LifecycleState.STARTING); &#x2F;&#x2F;暂先不解释 globalNamingResources.start(); &#x2F;&#x2F;启动Service synchronized (servicesLock) &#123; for (int i &#x3D; 0; i &lt; services.length; i++) &#123; services[i].start(); &#125; &#125;&#125; 这里调用Service方法的start启动Service。 启动ServiceStandardService的start方法，具体的实现是在StandardService的startInternal方法中： 12345678910111213141516171819202122232425262728protected void startInternal() throws LifecycleException &#123; setState(LifecycleState.STARTING); &#x2F;&#x2F;启动Container if (container !&#x3D; null) &#123; synchronized (container) &#123; container.start(); &#125; &#125; &#x2F;&#x2F;启动线程池 synchronized (executors) &#123; for (Executor executor: executors) &#123; executor.start(); &#125; &#125; &#x2F;&#x2F;启动Connector synchronized (connectorsLock) &#123; for (Connector connector: connectors) &#123; try &#123; if (connector.getState() !&#x3D; LifecycleState.FAILED) &#123; connector.start(); &#125; &#125; catch (Exception e) &#123;。。。&#125; &#125; &#125;&#125; 启动ContainerStandardEngine的start方法，也是调用startInternal方法，实现在StandardEngine中： 1234protected synchronized void startInternal() throws LifecycleException &#123; &#x2F;&#x2F;标准容器启动，在父类中实现 super.startInternal();&#125; 继续看ContainerBase的startInternal方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&#x2F;&#x2F;暂未解析protected synchronized void startInternal() throws LifecycleException &#123; &#x2F;&#x2F; Start our subordinate components, if any if ((loader !&#x3D; null) &amp;&amp; (loader instanceof Lifecycle)) ((Lifecycle) loader).start(); logger &#x3D; null; getLogger(); if ((manager !&#x3D; null) &amp;&amp; (manager instanceof Lifecycle)) ((Lifecycle) manager).start(); if ((cluster !&#x3D; null) &amp;&amp; (cluster instanceof Lifecycle)) ((Lifecycle) cluster).start(); Realm realm &#x3D; getRealmInternal(); if ((realm !&#x3D; null) &amp;&amp; (realm instanceof Lifecycle)) ((Lifecycle) realm).start(); if ((resources !&#x3D; null) &amp;&amp; (resources instanceof Lifecycle)) ((Lifecycle) resources).start(); &#x2F;&#x2F;启动子容器 Container children[] &#x3D; findChildren(); List&lt;Future&lt;Void&gt;&gt; results &#x3D; new ArrayList&lt;Future&lt;Void&gt;&gt;(); for (int i &#x3D; 0; i &lt; children.length; i++) &#123; results.add(startStopExecutor.submit(new StartChild(children[i]))); &#125; boolean fail &#x3D; false; for (Future&lt;Void&gt; result : results) &#123; try &#123; result.get(); &#125; catch (Exception e) &#123; log.error(sm.getString(&quot;containerBase.threadedStartFailed&quot;), e); fail &#x3D; true; &#125; &#125; if (fail) &#123; throw new LifecycleException( sm.getString(&quot;containerBase.threadedStartFailed&quot;)); &#125; &#x2F;&#x2F; Start the Valves in our pipeline (including the basic), if any if (pipeline instanceof Lifecycle) ((Lifecycle) pipeline).start(); setState(LifecycleState.STARTING); &#x2F;&#x2F; Start our thread threadStart();&#125; 启动ConnectorConnector的start方法，Connector的startInternal方法： 123456789protected void startInternal() throws LifecycleException &#123; setState(LifecycleState.STARTING); try &#123; protocolHandler.start(); &#125; catch (Exception e) &#123;。。。&#125; mapperListener.start();&#125; Connector的启动跟初始化差不多，也是先启动protocolHandler，然后启动mapperListener。 启动protocolHandler代码实现在AbstractProtocol中： 12345public void start() throws Exception &#123; try &#123; endpoint.start(); &#125; catch (Exception ex) &#123;。。。&#125;&#125; 这里启动endpoint，代码实现在AbstractEndpoint中： 123456789public final void start() throws Exception &#123; &#x2F;&#x2F;没有绑定，先绑定 if (bindState &#x3D;&#x3D; BindState.UNBOUND) &#123; bind(); bindState &#x3D; BindState.BOUND_ON_START; &#125; &#x2F;&#x2F;启动 startInternal();&#125; startInternal方法用来启动endpoint，我们这里还是以JIoEndpoint来分析，代码如下： 1234567891011121314151617181920212223public void startInternal() throws Exception &#123; if (!running) &#123; running &#x3D; true; paused &#x3D; false; &#x2F;&#x2F;创建工作者线程 if (getExecutor() &#x3D;&#x3D; null) &#123; createExecutor(); &#125; &#x2F;&#x2F;实例化连接数栅栏 initializeConnectionLatch(); &#x2F;&#x2F;启动Acceptor线程 startAcceptorThreads(); &#x2F;&#x2F;启动异步超时线程 Thread timeoutThread &#x3D; new Thread(new AsyncTimeout(), getName() + &quot;-AsyncTimeout&quot;); timeoutThread.setPriority(threadPriority); timeoutThread.setDaemon(true); timeoutThread.start(); &#125;&#125; 启动mapperListenerMapperListener的startInternal方法： 123456789101112131415161718public void startInternal() throws LifecycleException &#123; setState(LifecycleState.STARTING); findDefaultHost(); Engine engine &#x3D; (Engine) connector.getService().getContainer(); addListeners(engine); Container[] conHosts &#x3D; engine.findChildren(); for (Container conHost : conHosts) &#123; Host host &#x3D; (Host) conHost; if (!LifecycleState.NEW.equals(host.getState())) &#123; &#x2F;&#x2F; Registering the host will register the context and wrappers registerHost(host); &#125; &#125;&#125; 到这里就启动完成，tomcat启动完毕，有关启动的还没有详细解释，待续～～～]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[tomcat7类加载器解析]]></title>
      <url>%2F2017%2F05%2F10%2Ftomcat7%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[tomcat中也有很多的自定义的类加载器，保证容器的不同部分，以及运行在容器中的web应用可以访问不同的保存着类和资源的仓库。tomcat的类加载器机制跟jdk的类加载器机制基本类似，但是web应用类加载器处理请求的时候会稍微有些不同，jdk的类加载机制不再重复。 tomcat类加载器结构tomcat的类加载器的结构大概如下： 1234567 Bootstrap | System | Common &#x2F; \Webapp1 Webapp2 ... Bootstrap，包含JVM的基本运行时类，以及系统扩展目录（$JAVA_HOME/jre/lib/ext）下的jar包。 System，通常是根据CLASSPATH环境变量内容进行初始化的。这些类对tomcat内部类以及web应用都是可见的。tomcat启动脚本$CATALINA_HOME/bin/catalina.sh忽略了CLASSPATH的内容，会从以下位置中构建类加载器： $CATALINA_HOME/bin/bootstrap.jar包含用来初始化tomcat服务器的main方法，以及它依赖的类加载器实现类。 $CATALINA_BASE/bin/tomcat-juli.jar或者$CATALINA_HOME/bin/tomcat-juli.jar是日志实现类，优先使用CATALINA_BASE下的tomcat-juli.jar。 $CATALINA_HOME/bin/commons-daemon.jar引用自bootstrap.jar的清单文件中。 Common，这种类加载器包含额外的类，对于tomcat内部以及所有web应用都是可见的。一般情况，应用类不会放在这里，Common类加载器会加载${catalina.base}/lib,${catalina.base}/lib/*.jar,${catalina.home}/lib,${catalina.home}/lib/*.jar这些目录下的资源或者jar包，该配置在$CATALINA_BASE/conf/catalina.properties的common.loader属性中。 Webapp1，Webapp2等，为每个部署在tomcat中的web应用创建的类加载器，每个web应用只能看到自己的/WEB-INF/classes和/WEB-INF/lib目录，其他应用则不可见。 web应用加载类顺序tomcat启动之后，在web应用类加载器处理请求的时候，Web应用类加载器和JVM的类加载器不太一样，不是双亲委派模型。当请求从Web应用的类加载器加载类时，首先查看自己的仓库，而不是委托给父类加载。类加载器会显式的忽略所有包含Servlert API类的Jar文件。tomcat其他的类加载器则使用双亲委派模型。 Web应用类加载器加载顺序为： JVM的BootStrap类 WEB应用的/WEB-INF/classes下的类 WEB应用的/WEB-INF/lib/*.jar下的jar System类加载器的类 Common类加载器的类 但是如果web应用类加载器有配置了&lt;Loader delegate=&quot;true&quot;/&gt;，这时候就会按照双亲委派模型，顺序变为： JVM的BootStrap类 System类加载器的类 Common类加载器的类 WEB应用的/WEB-INF/classes下的类 WEB应用的/WEB-INF/lib/*.jar下的jar tomcat启动时类加载器的创建顺序tomcat启动的时候，会创建如下的类加载器： Bootstrap类加载器，用来加载JVM启动所需要的类，也会加载JVM的标准扩展类 System类加载器，加载tomcat启动类，比如bootstrap.ja和tomcat-juli.jar。 Common类加载器，是tomcat的类加载器，加载tomcat自身使用的类，也加载web应用通用的类。 WebappClassLoader，web应用类加载器，每个应用都会有一个类加载器，会加载自己的/WEB-INF/classes和/WEB-INF/lib/*.jar下的class和jar文件。 其他的类加载器除了上面说的Common和Webapp类加载器之外，tomcat中还有Server类加载器和Shared类加载器。 Server类加载器负责加载位于$CATALINE_HOME/server目录下的tomcat的核心类，在启动时创建，其父类加载器是Common类加载器。 Shared类加载器负责加载webapp公用的类，其父类加载器是Common类加载器，也是在tomcat启动时创建。 有关更多的内容会在源码分析里面继续解析，这里解析的并不详细，最重要的是还不太熟悉和了解。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于UTF-8的BOM标识以及非法字符65279错误的一些记录]]></title>
      <url>%2F2017%2F05%2F09%2F%E5%85%B3%E4%BA%8EUTF-8%E7%9A%84BOM%E6%A0%87%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%9D%9E%E6%B3%95%E5%AD%97%E7%AC%A665279%E9%94%99%E8%AF%AF%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%B0%E5%BD%95%2F</url>
      <content type="text"><![CDATA[关于UTF-8的BOM标识和非法字符\65279的错误，已经遇到过好几次了，在这里记录一下。关于UTF-8带BOM和UTF-8不带BOM的区别，网上有很多解释。我遇到的最多的就是文件在Windows上被别人修改后，在我的电脑上会出错（我一直使用linux和macos），一般都是导入项目的时候，进行编译就会有问题。 IDEA导入项目出现\65279非法字符这个问题也是由于带BOM的UTF-8格式引起的，至少我遇到都是这样，一般在linux上和macos上导入项目会发生，可能是由于在windows上用一些软件编辑过文件导致的。解决办法也很简单，下面就说一下解决办法。 比如说我将一个项目导入到idea发现报错了，可以使用命令行，首先进入src目录的同级目录： 输入：vi 输入：:args ./src/** 这里的**表示循环src下的所有文件夹 输入：:ar 这一步可选，目的是查看当前添加了哪些目标文件 输入：:argdo set nobomb | update! 这句意思是对args列表中的文件分别执行 set nobomb 然后强制保存 以上就是步骤，这样就可以了。 UTF-8中BOM标志导致项目读取配置文件为空最近公司部署项目到刀片服务器上时候，发现项目可以正常运行，读取配置文件也可以在指定位置找到配置文件，但是就是读取配置文件内容的时候，一直是null。若干人各种调试无果。我想应该是配置文件被人在windows上编辑过或者windows上新建的文本文件，然后放进服务器上的。于是就将服务器配置文件拿下来和我本地的文件对比下，果然是由于UTF-8带有BOM的原因。 重新在服务器上新建配置文件，把内容重新复制进去，完成！ 一般properties和xml文件可能会遇到这个问题。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[tomcat7中对http请求的处理过程]]></title>
      <url>%2F2017%2F05%2F05%2Ftomcat7%E4%B8%AD%E5%AF%B9http%E8%AF%B7%E6%B1%82%E7%9A%84%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[每个Server可以代表Tomcat，每个Server下面有多个Service，每个Service中包含多个Connector和一个Container，Connector用来处理和客户端的通信，然后把请求交给Container进行处理。这里就简单看下处理http请求的流程。 Tomcat启动初始化之后，会有一个线程一直在等待连接的到来，接收到新的连接之后，把请求交给相关处理器进行处理，这里等待连接到来的那个角色是一个Acceptor，是JIoEndpoint的内部类，处理连接的角色是SocketProcessor，也是JIoEndpoint的内部类。 Acceptor初始化的过程这里不做说明，直接开始看Acceptor，这个内部类的注释如下：一个一直监听进来的TCP/IP连接的后台线程，并交给适当的processor去处理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&#x2F;&#x2F;AbstractEndpoint.Acceptor实现了Runnable接口protected class Acceptor extends AbstractEndpoint.Acceptor &#123; @Override public void run() &#123; int errorDelay &#x3D; 0; &#x2F;&#x2F; 一直循环，直到接到shutdown命令 while (running) &#123; &#x2F;&#x2F; Loop if endpoint is paused while (paused &amp;&amp; running) &#123; state &#x3D; AcceptorState.PAUSED; try &#123; Thread.sleep(50); &#125; catch (InterruptedException e) &#123; &#x2F;&#x2F; Ignore &#125; &#125; if (!running) &#123; break; &#125; state &#x3D; AcceptorState.RUNNING; try &#123; &#x2F;&#x2F;达到了最大连接数，等待 countUpOrAwaitConnection(); Socket socket &#x3D; null; try &#123; &#x2F;&#x2F;接受下一个进来的连接 socket &#x3D; serverSocketFactory.acceptSocket(serverSocket); &#125; catch (IOException ioe) &#123; &#x2F;&#x2F;异常，连接数减一个 countDownConnection(); &#x2F;&#x2F; Introduce delay if necessary errorDelay &#x3D; handleExceptionWithDelay(errorDelay); throw ioe; &#125; &#x2F;&#x2F; Successful accept, reset the error delay errorDelay &#x3D; 0; &#x2F;&#x2F; 配置socket if (running &amp;&amp; !paused &amp;&amp; setSocketOptions(socket)) &#123; &#x2F;&#x2F;交给合适的处理器处理Socket if (!processSocket(socket)) &#123; &#x2F;&#x2F;处理完之后，连接数减少 countDownConnection(); &#x2F;&#x2F;处理完之后，关闭Socket closeSocket(socket); &#125; &#125; else &#123; countDownConnection(); &#x2F;&#x2F; Close socket right away closeSocket(socket); &#125; &#125; catch (IOException x) &#123;。。。&#125; &#125; state &#x3D; AcceptorState.ENDED; &#125;&#125; processSocket可以看到，Acceptor中就是一直循环等待连接到来，连接到来之后，获取到Socket并交给处理器去处理，下面看看processSocket的处理过程。 123456789101112131415161718protected boolean processSocket(Socket socket) &#123; &#x2F;&#x2F;处理当前Socket中的request try &#123; &#x2F;&#x2F;将Socket封装成SocketWrapper SocketWrapper&lt;Socket&gt; wrapper &#x3D; new SocketWrapper&lt;Socket&gt;(socket); &#x2F;&#x2F;设置连接保持时间 wrapper.setKeepAliveLeft(getMaxKeepAliveRequests()); &#x2F;&#x2F;设置是否ssl可用 wrapper.setSecure(isSSLEnabled()); &#x2F;&#x2F; During shutdown, executor may be null - avoid NPE if (!running) &#123; return false; &#125; &#x2F;&#x2F;创建一个SocketProcessor实例，并提交到线程池执行 getExecutor().execute(new SocketProcessor(wrapper)); &#125; catch (RejectedExecutionException x) &#123;。。。 &#125; return true;&#125; processSocket是将Socket封装成一个SocketWrapper，然后设置其他属性，以wrapper新建一个SocketProcessor实例执行。 SocketProcessorSocketProcessor处理器进行处理包装后的Socket，SocketProcessor也是JIoEndpoint的内部类，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384&#x2F;&#x2F;实现了Runnable接口protected class SocketProcessor implements Runnable &#123; protected SocketWrapper&lt;Socket&gt; socket &#x3D; null; protected SocketStatus status &#x3D; null; public SocketProcessor(SocketWrapper&lt;Socket&gt; socket) &#123; if (socket&#x3D;&#x3D;null) throw new NullPointerException(); this.socket &#x3D; socket; &#125; public SocketProcessor(SocketWrapper&lt;Socket&gt; socket, SocketStatus status) &#123; this(socket); this.status &#x3D; status; &#125; @Override public void run() &#123; boolean launch &#x3D; false; synchronized (socket) &#123; try &#123; SocketState state &#x3D; SocketState.OPEN; try &#123; &#x2F;&#x2F; SSL 握手 serverSocketFactory.handshake(socket.getSocket()); &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); state &#x3D; SocketState.CLOSED; &#125; if ((state !&#x3D; SocketState.CLOSED)) &#123; if (status &#x3D;&#x3D; null) &#123; &#x2F;&#x2F;调用handler的process进行处理，实现是在AbstractProtocol中 state &#x3D; handler.process(socket, SocketStatus.OPEN_READ); &#125; else &#123; state &#x3D; handler.process(socket,status); &#125; &#125; if (state &#x3D;&#x3D; SocketState.CLOSED) &#123; &#x2F;&#x2F;关闭 countDownConnection(); try &#123; socket.getSocket().close(); &#125; catch (IOException e) &#123; &#x2F;&#x2F; Ignore &#125; &#125; else if (state &#x3D;&#x3D; SocketState.OPEN || state &#x3D;&#x3D; SocketState.UPGRADING || state &#x3D;&#x3D; SocketState.UPGRADING_TOMCAT || state &#x3D;&#x3D; SocketState.UPGRADED)&#123; &#x2F;&#x2F;保持连接设置为true socket.setKeptAlive(true); socket.access(); launch &#x3D; true; &#125; else if (state &#x3D;&#x3D; SocketState.LONG) &#123; &#x2F;&#x2F;作为长连接 socket.access(); waitingRequests.add(socket); &#125; &#125; finally &#123; &#x2F;&#x2F;launch为true表示上面状态为SocketState.OPEN &#x2F;&#x2F;保持连接，继续提交到线程池执行 if (launch) &#123; try &#123; getExecutor().execute(new SocketProcessor(socket, SocketStatus.OPEN_READ)); &#125; catch (RejectedExecutionException x) &#123; try &#123; &#x2F;&#x2F;unable to handle connection at this time handler.process(socket, SocketStatus.DISCONNECT); &#125; finally &#123; countDownConnection(); &#125; &#125; catch (NullPointerException npe) &#123;。。。&#125; &#125; &#125; &#125; socket &#x3D; null; &#x2F;&#x2F; Finish up this request &#125;&#125; process方法这里主要的是调用handler的process方法处理请求，实现是在AbstractProtocol的内部抽象类AbstractConnectionHandler中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114public SocketState process(SocketWrapper&lt;S&gt; wrapper, SocketStatus status) &#123; &#x2F;&#x2F;Socket已经被关闭 if (wrapper &#x3D;&#x3D; null) &#123; return SocketState.CLOSED; &#125; &#x2F;&#x2F;取得要处理的Socket S socket &#x3D; wrapper.getSocket(); if (socket &#x3D;&#x3D; null) &#123; return SocketState.CLOSED; &#125; &#x2F;&#x2F;从缓存中获取Socket对应的处理器 Processor&lt;S&gt; processor &#x3D; connections.get(socket); if (status &#x3D;&#x3D; SocketStatus.DISCONNECT &amp;&amp; processor &#x3D;&#x3D; null) &#123; return SocketState.CLOSED; &#125; wrapper.setAsync(false); ContainerThreadMarker.markAsContainerThread(); try &#123; if (processor &#x3D;&#x3D; null) &#123; &#x2F;&#x2F;从可循环使用的处理器中查找 processor &#x3D; recycledProcessors.poll(); &#125; if (processor &#x3D;&#x3D; null) &#123; &#x2F;&#x2F;创建处理器 &#x2F;&#x2F;该方法在子类中实现 &#x2F;&#x2F;我们这里是http请求，默认是在Http11Protocol的Http11ConnectionHandler中实现的 processor &#x3D; createProcessor(); &#125; &#x2F;&#x2F;初始化ssl的信息 &#x2F;&#x2F;也是在子类中实现的 &#x2F;&#x2F;默认是在Http11Protocol的Http11ConnectionHandler中实现的 initSsl(wrapper, processor); SocketState state &#x3D; SocketState.CLOSED; do &#123; if (status &#x3D;&#x3D; SocketStatus.DISCONNECT &amp;&amp;!processor.isComet()) &#123; &#125; else if (processor.isAsync() || state &#x3D;&#x3D; SocketState.ASYNC_END) &#123; &#x2F;&#x2F;异步 state &#x3D; processor.asyncDispatch(status); if (state &#x3D;&#x3D; SocketState.OPEN) &#123; getProtocol().endpoint.removeWaitingRequest(wrapper); state &#x3D; processor.process(wrapper); &#125; &#125; else if (processor.isComet()) &#123;&#x2F;&#x2F;往下是同步 state &#x3D; processor.event(status); &#125; else if (processor.getUpgradeInbound() !&#x3D; null) &#123; state &#x3D; processor.upgradeDispatch(); &#125; else if (processor.isUpgrade()) &#123; state &#x3D; processor.upgradeDispatch(status); &#125; else &#123; state &#x3D; processor.process(wrapper); &#125; if (state !&#x3D; SocketState.CLOSED &amp;&amp; processor.isAsync()) &#123; state &#x3D; processor.asyncPostProcess(); &#125; if (state &#x3D;&#x3D; SocketState.UPGRADING) &#123; HttpUpgradeHandler httpUpgradeHandler &#x3D; processor.getHttpUpgradeHandler(); release(wrapper, processor, false, false); processor &#x3D; createUpgradeProcessor( wrapper, httpUpgradeHandler); wrapper.setUpgraded(true); connections.put(socket, processor); httpUpgradeHandler.init((WebConnection) processor); &#125; else if (state &#x3D;&#x3D; SocketState.UPGRADING_TOMCAT) &#123; org.apache.coyote.http11.upgrade.UpgradeInbound inbound &#x3D; processor.getUpgradeInbound(); release(wrapper, processor, false, false); processor &#x3D; createUpgradeProcessor(wrapper, inbound); inbound.onUpgradeComplete(); &#125; &#125; while (state &#x3D;&#x3D; SocketState.ASYNC_END || state &#x3D;&#x3D; SocketState.UPGRADING || state &#x3D;&#x3D; SocketState.UPGRADING_TOMCAT); &#x2F;&#x2F;长连接 if (state &#x3D;&#x3D; SocketState.LONG) &#123; &#x2F;&#x2F;长连接放入connections中缓存 connections.put(socket, processor); longPoll(wrapper, processor); &#125; else if (state &#x3D;&#x3D; SocketState.OPEN) &#123; connections.remove(socket); release(wrapper, processor, false, true); &#125; else if (state &#x3D;&#x3D; SocketState.SENDFILE) &#123; connections.put(socket, processor); &#125; else if (state &#x3D;&#x3D; SocketState.UPGRADED) &#123; connections.put(socket, processor); if (status !&#x3D; SocketStatus.OPEN_WRITE) &#123; longPoll(wrapper, processor); &#125; &#125; else &#123; connections.remove(socket); if (processor.isUpgrade()) &#123; processor.getHttpUpgradeHandler().destroy(); &#125; else if (processor instanceof org.apache.coyote.http11.upgrade.UpgradeProcessor) &#123; &#x2F;&#x2F; NO-OP &#125; else &#123; release(wrapper, processor, true, false); &#125; &#125; return state; &#125; catch(java.net.SocketException e) &#123;。。。&#125; connections.remove(socket); if (!(processor instanceof org.apache.coyote.http11.upgrade.UpgradeProcessor) &amp;&amp; !processor.isUpgrade()) &#123; release(wrapper, processor, true, false); &#125; return SocketState.CLOSED;&#125; 同步的process方法createProcessor方法不列出，就是新建一个Http11Processor实例，设置属性。上面process进行处理分为异步和同步，这里我们没有配置，默认使用同步进行处理，process实现在AbstractHttp11Processor中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108public SocketState process(SocketWrapper&lt;S&gt; socketWrapper) throws IOException &#123; &#x2F;&#x2F;得到请求的信息 RequestInfo rp &#x3D; request.getRequestProcessor(); rp.setStage(org.apache.coyote.Constants.STAGE_PARSE); setSocketWrapper(socketWrapper); &#x2F;&#x2F;输入流 getInputBuffer().init(socketWrapper, endpoint); &#x2F;&#x2F;输出流 getOutputBuffer().init(socketWrapper, endpoint); keepAlive &#x3D; true; comet &#x3D; false; openSocket &#x3D; false; sendfileInProgress &#x3D; false; readComplete &#x3D; true; if (endpoint.getUsePolling()) &#123; keptAlive &#x3D; false; &#125; else &#123; keptAlive &#x3D; socketWrapper.isKeptAlive(); &#125; if (disableKeepAlive()) &#123; socketWrapper.setKeepAliveLeft(0); &#125; while (!getErrorState().isError() &amp;&amp; keepAlive &amp;&amp; !comet &amp;&amp; !isAsync() &amp;&amp; upgradeInbound &#x3D;&#x3D; null &amp;&amp; httpUpgradeHandler &#x3D;&#x3D; null &amp;&amp; !endpoint.isPaused()) &#123; &#x2F;&#x2F; Parsing the request header try &#123; setRequestLineReadTimeout(); &#x2F;&#x2F;解析请求行 if (!getInputBuffer().parseRequestLine(keptAlive)) &#123; if (handleIncompleteRequestLineRead()) &#123; break; &#125; &#125; if (endpoint.isPaused()) &#123; &#x2F;&#x2F; 503 - Service unavailable response.setStatus(503); setErrorState(ErrorState.CLOSE_CLEAN, null); &#125; else &#123; keptAlive &#x3D; true; request.getMimeHeaders().setLimit(endpoint.getMaxHeaderCount()); request.getCookies().setLimit(getMaxCookieCount()); &#x2F;&#x2F; 解析请求头 if (!getInputBuffer().parseHeaders()) &#123; openSocket &#x3D; true; readComplete &#x3D; false; break; &#125; if (!disableUploadTimeout) &#123; setSocketTimeout(connectionUploadTimeout); &#125; &#125; &#125; catch (IOException e) &#123; 。。。 &#x2F;&#x2F; 400 - Bad Request response.setStatus(400); setErrorState(ErrorState.CLOSE_CLEAN, t); getAdapter().log(request, response, 0); &#125; if (!getErrorState().isError()) &#123; rp.setStage(org.apache.coyote.Constants.STAGE_PREPARE); try &#123; &#x2F;&#x2F;读取完请求头之后，需要设置请求的过滤器 prepareRequest(); &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); &#x2F;&#x2F; 500 - Internal Server Error response.setStatus(500); setErrorState(ErrorState.CLOSE_CLEAN, t); getAdapter().log(request, response, 0); &#125; &#125; if (maxKeepAliveRequests &#x3D;&#x3D; 1) &#123; keepAlive &#x3D; false; &#125; else if (maxKeepAliveRequests &gt; 0 &amp;&amp; socketWrapper.decrementKeepAlive() &lt;&#x3D; 0) &#123; keepAlive &#x3D; false; &#125; &#x2F;&#x2F;在Adapter中处理请求 if (!getErrorState().isError()) &#123; try &#123; rp.setStage(org.apache.coyote.Constants.STAGE_SERVICE); &#x2F;&#x2F;CoyoteAdapter处理 adapter.service(request, response); setCometTimeouts(socketWrapper); &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); &#x2F;&#x2F; 500 - Internal Server Error response.setStatus(500); setErrorState(ErrorState.CLOSE_CLEAN, t); getAdapter().log(request, response, 0); &#125; &#125; &#125;&#125; 代码比较长，主要的步骤是： parseRequestLine解析请求行。 parseHeaders解析请求头。 prepareReques读取完请求头之后设置过滤器。 adapter.service交给Adapter进行真正的处理。 解析请求行parseRequestLine方法是用来解析请求行的方法，在InternalInputBuffer中，具体代码不做解析。 解析请求头parseHeaders方法是用来解析请求头的方法，在InternalInputBuffer中，具体代码不做解析。 设置过滤器也暂先不做解析。 Adapter真正的进行处理请求真正处理请求的地方在CoyoteAdapter的service方法中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public void service(org.apache.coyote.Request req, org.apache.coyote.Response res) throws Exception &#123; &#x2F;&#x2F;创建Request和Response对象，将requ和res转换 Request request &#x3D; (Request) req.getNote(ADAPTER_NOTES); Response response &#x3D; (Response) res.getNote(ADAPTER_NOTES); if (request &#x3D;&#x3D; null) &#123; &#x2F;&#x2F; Create objects request &#x3D; connector.createRequest(); request.setCoyoteRequest(req); response &#x3D; connector.createResponse(); response.setCoyoteResponse(res); &#x2F;&#x2F; Link objects request.setResponse(response); response.setRequest(request); &#x2F;&#x2F; Set as notes req.setNote(ADAPTER_NOTES, request); res.setNote(ADAPTER_NOTES, response); &#x2F;&#x2F; Set query string encoding req.getParameters().setQueryStringEncoding (connector.getURIEncoding()); &#125; if (connector.getXpoweredBy()) &#123; response.addHeader(&quot;X-Powered-By&quot;, POWERED_BY); &#125; boolean comet &#x3D; false; boolean async &#x3D; false; boolean postParseSuccess &#x3D; false; try &#123; req.getRequestProcessor().setWorkerThreadName(Thread.currentThread().getName()); &#x2F;&#x2F;解析请求，根据Request对象找到对应的Host，Context，Wrapper对象 postParseSuccess &#x3D; postParseRequest(req, request, res, response); if (postParseSuccess) &#123; request.setAsyncSupported(connector.getService().getContainer().getPipeline().isAsyncSupported()); &#x2F;&#x2F; 调用Container进行处理 &#x2F;&#x2F;这就交给了Engine去处理了 &#x2F;&#x2F;通过Pipeline链传递给最终的Servlet去处理 connector.getService().getContainer().getPipeline().getFirst().invoke(request, response); if (request.isComet()) &#123; if (!response.isClosed() &amp;&amp; !response.isError()) &#123; if (request.getAvailable() || (request.getContentLength() &gt; 0 &amp;&amp; (!request.isParametersParsed()))) &#123; &#x2F;&#x2F; Invoke a read event right away if there are available bytes if (event(req, res, SocketStatus.OPEN_READ)) &#123; comet &#x3D; true; res.action(ActionCode.COMET_BEGIN, null); &#125; else &#123; return; &#125; &#125; else &#123; comet &#x3D; true; res.action(ActionCode.COMET_BEGIN, null); &#125; &#125; else &#123; request.setFilterChain(null); &#125; &#125; &#125; &#x2F;&#x2F;异步 if (request.isAsync()) &#123; 。。。 &#125; else if (!comet) &#123; 。。。 &#125; &#125; catch (IOException e) &#123;。。。&#125; finally &#123;。。。 &#125;&#125; 这里主要做的事情是调用postParseRquest方法对请求进行处理，然后交给Engine去真正处理请求。 postParseRquest123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199protected boolean postParseRequest(org.apache.coyote.Request req, Request request, org.apache.coyote.Response res, Response response) throws Exception &#123; if (! req.scheme().isNull()) &#123; request.setSecure(req.scheme().equals(&quot;https&quot;)); &#125; else &#123; req.scheme().setString(connector.getScheme()); request.setSecure(connector.getSecure()); &#125; String proxyName &#x3D; connector.getProxyName(); int proxyPort &#x3D; connector.getProxyPort(); if (proxyPort !&#x3D; 0) &#123; req.setServerPort(proxyPort); &#125; if (proxyName !&#x3D; null) &#123; req.serverName().setString(proxyName); &#125; &#x2F;&#x2F; Copy the raw URI to the decodedURI MessageBytes decodedURI &#x3D; req.decodedURI(); decodedURI.duplicate(req.requestURI()); &#x2F;&#x2F; 解析url的参数 parsePathParameters(req, request); &#x2F;&#x2F; URI解码 try &#123; req.getURLDecoder().convert(decodedURI, false); &#125; catch (IOException ioe) &#123;。。。&#125; &#x2F;&#x2F;调用normalize方法判断请求路径是否正确 if (!normalize(req.decodedURI())) &#123; res.setStatus(400); res.setMessage(&quot;Invalid URI&quot;); connector.getService().getContainer().logAccess( request, response, 0, true); return false; &#125; &#x2F;&#x2F;字符解码 convertURI(decodedURI, request); &#x2F;&#x2F; 查看解码之后是否正常 if (!checkNormalize(req.decodedURI())) &#123; res.setStatus(400); res.setMessage(&quot;Invalid URI character encoding&quot;); connector.getService().getContainer().logAccess( request, response, 0, true); return false; &#125; &#x2F;&#x2F;请求映射 MessageBytes serverName; if (connector.getUseIPVHosts()) &#123; serverName &#x3D; req.localName(); if (serverName.isNull()) &#123; res.action(ActionCode.REQ_LOCAL_NAME_ATTRIBUTE, null); &#125; &#125; else &#123; serverName &#x3D; req.serverName(); &#125; if (request.isAsyncStarted()) &#123; &#x2F;&#x2F;TODO SERVLET3 - async &#x2F;&#x2F;reset mapping data, should prolly be done elsewhere request.getMappingData().recycle(); &#125; String version &#x3D; null; Context versionContext &#x3D; null; boolean mapRequired &#x3D; true; while (mapRequired) &#123; connector.getMapper().map(serverName, decodedURI, version, request.getMappingData()); request.setContext((Context) request.getMappingData().context); request.setWrapper((Wrapper) request.getMappingData().wrapper); if (request.getContext() &#x3D;&#x3D; null) &#123; res.setStatus(404); res.setMessage(&quot;Not found&quot;); &#x2F;&#x2F; No context, so use host Host host &#x3D; request.getHost(); &#x2F;&#x2F; Make sure there is a host (might not be during shutdown) if (host !&#x3D; null) &#123; host.logAccess(request, response, 0, true); &#125; return false; &#125; &#x2F;&#x2F;处理sessionId String sessionID; if (request.getServletContext().getEffectiveSessionTrackingModes() .contains(SessionTrackingMode.URL)) &#123; &#x2F;&#x2F; Get the session ID if there was one sessionID &#x3D; request.getPathParameter( SessionConfig.getSessionUriParamName( request.getContext())); if (sessionID !&#x3D; null) &#123; request.setRequestedSessionId(sessionID); request.setRequestedSessionURL(true); &#125; &#125; &#x2F;&#x2F; Look for session ID in cookies and SSL session parseSessionCookiesId(req, request); parseSessionSslId(request); sessionID &#x3D; request.getRequestedSessionId(); mapRequired &#x3D; false; if (version !&#x3D; null &amp;&amp; request.getContext() &#x3D;&#x3D; versionContext) &#123; &#x2F;&#x2F; We got the version that we asked for. That is it. &#125; else &#123; version &#x3D; null; versionContext &#x3D; null; Object[] contexts &#x3D; request.getMappingData().contexts; if (contexts !&#x3D; null &amp;&amp; sessionID !&#x3D; null) &#123; for (int i &#x3D; (contexts.length); i &gt; 0; i--) &#123; Context ctxt &#x3D; (Context) contexts[i - 1]; if (ctxt.getManager().findSession(sessionID) !&#x3D; null) &#123; if (!ctxt.equals(request.getMappingData().context)) &#123; version &#x3D; ctxt.getWebappVersion(); versionContext &#x3D; ctxt; request.getMappingData().recycle(); mapRequired &#x3D; true; request.recycleSessionInfo(); &#125; break; &#125; &#125; &#125; &#125; if (!mapRequired &amp;&amp; request.getContext().getPaused()) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; &#x2F;&#x2F; Should never happen &#125; &#x2F;&#x2F; Reset mapping request.getMappingData().recycle(); mapRequired &#x3D; true; &#125; &#125; &#x2F;&#x2F;重定向 MessageBytes redirectPathMB &#x3D; request.getMappingData().redirectPath; if (!redirectPathMB.isNull()) &#123; String redirectPath &#x3D; urlEncoder.encode(redirectPathMB.toString(), &quot;UTF-8&quot;); String query &#x3D; request.getQueryString(); if (request.isRequestedSessionIdFromURL()) &#123; redirectPath &#x3D; redirectPath + &quot;;&quot; + SessionConfig.getSessionUriParamName( request.getContext()) + &quot;&#x3D;&quot; + request.getRequestedSessionId(); &#125; if (query !&#x3D; null) &#123; redirectPath &#x3D; redirectPath + &quot;?&quot; + query; &#125; response.sendRedirect(redirectPath); request.getContext().logAccess(request, response, 0, true); return false; &#125; &#x2F;&#x2F;过滤trace方法 if (!connector.getAllowTrace() &amp;&amp; req.method().equalsIgnoreCase(&quot;TRACE&quot;)) &#123; Wrapper wrapper &#x3D; request.getWrapper(); String header &#x3D; null; if (wrapper !&#x3D; null) &#123; String[] methods &#x3D; wrapper.getServletMethods(); if (methods !&#x3D; null) &#123; for (int i&#x3D;0; i&lt;methods.length; i++) &#123; if (&quot;TRACE&quot;.equals(methods[i])) &#123; continue; &#125; if (header &#x3D;&#x3D; null) &#123; header &#x3D; methods[i]; &#125; else &#123; header +&#x3D; &quot;, &quot; + methods[i]; &#125; &#125; &#125; &#125; res.setStatus(405); res.addHeader(&quot;Allow&quot;, header); res.setMessage(&quot;TRACE method is not allowed&quot;); request.getContext().logAccess(request, response, 0, true); return false; &#125; doConnectorAuthenticationAuthorization(req, request); return true;&#125; Engine去真正处理请求connector.getService().getContainer().getPipeline().getFirst().invoke(request, response);这句代码是Engine处理请求的地方。这里面还有复杂的过程，最后会调用Servlet去处理。这里是责任链模式的使用。 在看一下处理过程之前，先看下这里使用的责任链模式，会更容易理解。 Container中责任链模式的使用在责任链模式中有两个角色：抽象处理者Handler和具体的处理者ConcreteHandler。在抽象处理者中一般会定义一个处理请求的接口，另外还会包含调用下一个或者上一个处理者的方法。 在tomcat中Container就是责任链模式中的抽象处理者，StandardEngine，StandardHost，StandardContext等等是具体的处理者。 请求过来时候，Engine首先接受请求，然后传递给Host容器，接着传递给Context容器，再传递给Wrapper容器，最后给Servlet处理。 而两个容器之间进行请求传递的时候涉及到另外两个概念：Pipeline和Value。Pipeline作为请求传递的管道，这个管道连接两个处理者，Value是管道上对请求加工的组件，就相当于管道上的一个口子，通过这个口子我们可以做一些其他事情。 容器间处理请求connector.getService().getContainer().getPipeline().getFirst().invoke(request, response);看这行代码，首先connector.getService().getContainer()获取到的是一个StandardEngine，然后调用getPipeline()，得到的是一个StandardPipeline标准的管道，接着调用getFirst()方法获取Value，这里没有设置first所以返回的是一个basic，类型是StandardEngineValve，然后调用的是StandardEngineValve的invoke方法，执行处理请求，看下StandardEngineValue的处理方法： 1234567891011121314151617181920public final void invoke(Request request, Response response) throws IOException, ServletException &#123; &#x2F;&#x2F;从request中获取Host Host host &#x3D; request.getHost(); if (host &#x3D;&#x3D; null) &#123; response.sendError (HttpServletResponse.SC_BAD_REQUEST, sm.getString(&quot;standardEngine.noHost&quot;, request.getServerName())); return; &#125; if (request.isAsyncSupported()) &#123; request.setAsyncSupported(host.getPipeline().isAsyncSupported()); &#125; &#x2F;&#x2F;获取到Host之后，交给Host进行处理，Host就是下一个处理者 host.getPipeline().getFirst().invoke(request, response);&#125; 得到Host之后，Engine就处理完了，该Host进行处理了，也是先获得Pipeline，得到的是StandardPipeline，然后调用getFirst获取到的是StandardHostValue，调用invoke方法： 12345678910public final void invoke(Request request, Response response) throws IOException, ServletException &#123; &#x2F;&#x2F;获取Context Context context &#x3D; request.getContext(); 。。。 context.getPipeline().getFirst().invoke(request, response); 。。。 可以看到在Host中处理也是如此，接着是调用Context进行请求处理，到了StandardContextValue的invoke方法进行处理，接着是Wrapper进行处理，调用StandardWrapperValve的invoke方法进行处理。 在StandardWrapperValue中还有构建Filter链的过程，对于Filter的处理也是责任链模式的应用，暂先不做解析。 在Filter链的最后，执行Servlet的service方法，往下就该是Servlet的执行了，有关Servlet的执行流程不再解析。到这里大概的流程就完成了，中间很多细节没有说明，等看完整个源码之后，再做详细说明。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[tomcat7架构简介]]></title>
      <url>%2F2017%2F05%2F05%2Ftomcat7%E6%9E%B6%E6%9E%84%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[这里仅仅是对Tomcat7中主要组件进行简单说明，详细的可以查看下tomcat的相关文档。 首先看下网上找来的一张架构图，还有其他的类似的图，可以自行谷歌一下。看图片也大概能了解tomcat整体的组成。 这里仅仅是对Tomcat7中主要组件进行简单说明，详细的可以查看下tomcat的相关文档。 首先看下网上找来的一张架构图，还有其他的类似的图，可以自行谷歌一下。看图片也大概能了解tomcat整体的组成。 ServerServer表示整个容器，Tomcat提供了一个默认的Server接口的实现，用户几乎很少自己实现Server接口。 ServiceService是一个中间组件，存活于Server中，绑定一个或者多个Connector到一个Engine上。用户很少自己实现Service接口，默认实现已经足够用。 Engine表示一个特定Service的请求处理流程。一个Service可能有多个Connector，Engine接受并处理这些来自Connector的所有请求，将响应传回给适当的Connector以传输到客户端。Engine也很少由用户自定义实现。 HostHost是一个网络名称同Tomcat服务器的关联。Engine可能存在多个Host。 ConnectorConnector处理和客户端的通信。Tomcat中有很多可用的Connector。 ContextContext表示一个web应用，一个Host可能包含多个Context，每个Context都有一个唯一的path。 总的架构Server可以表示是Tomcat，一个Tomcat中只有一个Server，一个Server下面可以有多个Service，每一个Service中包含多个Connector和一个Engine，每个Engine包含多个Host，每个Host包含多个Context。 Engine其实是一个Container，Container是Engine，Host，Context的父接口，这里把Engine称为Container，所以此时可以有如下表示：一个Server下面有多个Service，每个Service包含多个Connector和一个Container。 多个Connector和一个Container组成一个Service，这个Service就可以向外提供服务了。 ServerServer表示整个容器，Tomcat提供了一个默认的Server接口的实现，用户几乎很少自己实现Server接口。 ServiceService是一个中间组件，存活于Server中，绑定一个或者多个Connector到一个Engine上。用户很少自己实现Service接口，默认实现已经足够用。 Engine表示一个特定Service的请求处理流程。一个Service可能有多个Connector，Engine接受并处理这些来自Connector的所有请求，将响应传回给适当的Connector以传输到客户端。Engine也很少由用户自定义实现。 HostHost是一个网络名称同Tomcat服务器的关联。Engine可能存在多个Host。 ConnectorConnector处理和客户端的通信。Tomcat中有很多可用的Connector。 ContextContext表示一个web应用，一个Host可能包含多个Context，每个Context都有一个唯一的path。 总的架构Server可以表示是Tomcat，一个Tomcat中只有一个Server，一个Server下面可以有多个Service，每一个Service中包含多个Connector和一个Engine，每个Engine包含多个Host，每个Host包含多个Context。 Engine其实是一个Container，Container是Engine，Host，Context的父接口，这里把Engine称为Container，所以此时可以有如下表示：一个Server下面有多个Service，每个Service包含多个Connector和一个Container。 多个Connector和一个Container组成一个Service，这个Service就可以向外提供服务了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式中的责任链模式解析]]></title>
      <url>%2F2017%2F05%2F05%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B8%AD%E7%9A%84%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[这篇主要是在看Tomcat源码的时候，遇到了责任链模式相关的东西，做一下简单记录，可以和Tomcat源码中责任链的应用对比学习下，会更有效果。 责任链模式的定义 责任链模式（Chain of Responsibility）是一种对象的行为模式。在责任链模式里，很多对象由每一个对象对其下家的引用而连接起来形成一条链。请求在这个链上传递，直到链上的某一个对象决定处理此请求。发出这个请求的客户端并不知道链上的哪一个对象最终处理这个请求，这使得系统可以在不影响客户端的情况下动态地重新组织和分配责任。《JAVA与模式》-阎宏 责任链模式的结构责任链模式总共存在两个角色，抽象处理者（Handler）和具体处理者（ConcreteHandler）。 抽象处理者，定义处理请求的接口，通常也会有包含下一个和上一个处理者的方法，抽象处理者一般是一个接口或者抽象类。 具体处理者，是对抽象处理者的实现，不同的实现。当前如果能处理请求，就处理，如果不能处理请求就交给下家处理。 责任链模式的举例Handler： 123456789101112131415161718package me.cxis.test.gof.chainofresponsibility;&#x2F;** * Created by cheng.xi on 2017-05-05 17:46. *&#x2F;public abstract class Handler &#123; protected Handler successor; public abstract void handleRequest(String condition); public Handler getSuccessor() &#123; return successor; &#125; public void setSuccessor(Handler successor) &#123; this.successor &#x3D; successor; &#125;&#125; ConcreteHandler1： 1234567891011121314151617package me.cxis.test.gof.chainofresponsibility;&#x2F;** * Created by cheng.xi on 2017-05-05 17:49. *&#x2F;public class ConcreteHandler1 extends Handler &#123; @Override public void handleRequest(String condition) &#123; if(condition.equals(&quot;1&quot;))&#123; System.out.println(&quot;ConcreteHandler1处理&quot;); return; &#125;else &#123; System.out.println(&quot;ConcreteHandler1不处理，由其他的Handler处理&quot;); getSuccessor().handleRequest(condition); &#125; &#125;&#125; ConcreteHandler2： 1234567891011121314151617package me.cxis.test.gof.chainofresponsibility;&#x2F;** * Created by cheng.xi on 2017-05-05 17:49. *&#x2F;public class ConcreteHandler2 extends Handler &#123; @Override public void handleRequest(String condition) &#123; if(condition.equals(&quot;2&quot;))&#123; System.out.println(&quot;ConcreteHandler2处理&quot;); return; &#125;else &#123; System.out.println(&quot;ConcreteHandler2不处理，由其他的Handler处理&quot;); getSuccessor().handleRequest(condition); &#125; &#125;&#125; ConcreteHandlerX： 123456789101112package me.cxis.test.gof.chainofresponsibility;&#x2F;** * Created by cheng.xi on 2017-05-05 17:49. *&#x2F;public class ConcreteHandlerX extends Handler &#123; @Override public void handleRequest(String condition) &#123; &#x2F;&#x2F;一般是最后一个处理者 System.out.println(&quot;ConcreteHandlerX处理&quot;); &#125;&#125; Client： 1234567891011121314151617package me.cxis.test.gof.chainofresponsibility;&#x2F;** * Created by cheng.xi on 2017-05-05 17:53. *&#x2F;public class Client &#123; public static void main(String[] args) &#123; Handler handler1 &#x3D; new ConcreteHandler1(); Handler handler2 &#x3D; new ConcreteHandler2(); Handler handlerX &#x3D; new ConcreteHandlerX(); handler1.setSuccessor(handler2); handler2.setSuccessor(handlerX); handler1.handleRequest(&quot;2&quot;); &#125;&#125; 责任链模式的优点当然上面的例子我们可以直接在Client中写if-else，不过这样耦合度就太高了，而且如果顺序发生变化会很难弄，而责任链模式可以解耦，将发送者和接受者分开。 责任链模式的缺点责任链可能很长，即便某一个点不处理请求，也需要经过这个点，这样会有性能问题。 责任链模式的应用场景 Servlet中的过滤器 Tomcat中的Filter Tomcat中容器的设置]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[http协议简单解析]]></title>
      <url>%2F2017%2F05%2F04%2Fhttp%E5%8D%8F%E8%AE%AE%E7%AE%80%E5%8D%95%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[主要记录一下http协议的一些简单的知识，主要包括请求消息，响应消息的组成，以及get和post的‘对比’，对于更详细的信息可以看下http RFC。https也没有做说明。 http基于请求响应模式，无状态，应用层的协议，特点如下： 支持C/S模式。 无连接，每次连接只处理一个请求，服务器处理完请求，并返回给客户端之后，就会断开连接。 无状态，指的是协议对于事务处理没有记忆能力，如果需要前面的信息，需要重传。 http请求消息（Request）http请求由三部分组成：请求行，请求头，请求体。比如下面的例子： 12345678910GET &#x2F; HTTP&#x2F;1.1Host: cxis.meConnection: keep-alivePragma: no-cacheCache-Control: no-cacheUpgrade-Insecure-Requests: 1User-Agent: Mozilla&#x2F;5.0 (X11; Linux x86_64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;58.0.3029.81 Safari&#x2F;537.36Accept: text&#x2F;html,application&#x2F;xhtml+xml,application&#x2F;xml;q&#x3D;0.9,image&#x2F;webp,*&#x2F;*;q&#x3D;0.8Accept-Encoding: gzip, deflate, sdchAccept-Language: zh-CN,zh;q&#x3D;0.8,en-US;q&#x3D;0.6,en;q&#x3D;0.4,zh-TW;q&#x3D;0.2,nb;q&#x3D;0.2,da;q&#x3D;0.2 GET / HTTP/1.1是请求行，GET是请求方法，/是请求资源在服务器上的路径，HTTP/1.1是http协议版本号。 剩下的是请求头，格式为xxxx: value。 这里是get方法，所有没有请求体，请求体是向服务器提交的数据，在请求头和请求体中间会有一行空行。 http响应消息（Response）响应消息包括：响应行，响应头，响应体。一个响应消息如下： 123456789101112131415161718192021HTTP&#x2F;1.1 200 OKServer: GitHub.comContent-Type: text&#x2F;html; charset&#x3D;utf-8Last-Modified: Wed, 03 May 2017 08:32:57 GMTAccess-Control-Allow-Origin: *Expires: Wed, 03 May 2017 13:51:42 GMTCache-Control: max-age&#x3D;600Content-Encoding: gzipX-GitHub-Request-Id: AACA:40A3:65A338:8EB391:5909DE15Content-Length: 9905Accept-Ranges: bytesDate: Wed, 03 May 2017 14:41:45 GMTVia: 1.1 varnishAge: 0Connection: keep-aliveX-Served-By: cache-nrt6130-NRTX-Cache: HITX-Cache-Hits: 1X-Timer: S1493822505.031176,VS0,VE181Vary: Accept-EncodingX-Fastly-Request-ID: bc385cef3dbff07f200175fa461c920cb6ca4b3f HTTP/1.1 200 OK是响应行，HTTP/1.1是http协议版本号，200是状态码，OK是状态消息，和响应码对应。 剩下的是响应头，这里没有响应体。GET方法的响应体为空。 请求方法 GET，获取被Request-URI指定的信息。 POST，向服务器提交数据。 HEAD，获取响应消息报头。 PUT，请求服务器保存一个资源。 DELETE，请求服务器删除资源。 TRACE，请求服务器回应收到的请求消息。 OPTIONS，查询相关的资源和选项。 CONNECT，预留关键字，现在没有用。 GET和POST对比GET和POST我觉得不应该硬拿来对比，他们是http规范定义的两种不同的方法，各有各的用处，为什么要对比呢？ 关于定义GET是获取资源，是幂等的；POST是提交资源，是非幂等的。它们是http协议里面定义的两个不同的方法。 关于缓存GET请求的响应是可缓存的，但是需要响应满足HTTP缓存的要求。POST响应是不可缓存的，除非响应里面有Cache-Control或者Expires属性。 关于请求数据GET方法会把请求的数据附加到URL之后，也就是放到请求行中；POST则是把提交的数据放到请求体中。因此在地址栏可以直接看到GET请求提交的参数，而看不到POST请求的参数。 关于安全通常我们说的有关安全，只是相对的安全，比如说GET方法能直接在地址栏看到参数，而POST不能。这通常让人认为是安全和不安全的区别，其实如果抓包或者其他手段一样可以看到GET和POST提交的数据，两者并没有什么安全可言。 关于数据长度http协议并没有对传输的数据大小做限制，也没有对URL长度做限制，所以从http协议本身来说并没有长度的限制。而我们通常说的URL或者数据的长度限制其实是浏览器或者服务器的限制。 对于GET请求来说，提交的数据都会在URL中，各浏览器对URL的限制不太一样，所以没有什么标准可言；对于POST请求来说，数据存放在请求体中，并没有长度限制，但是服务器通常会有对POST提交数据的大小限制，因此也没有标准可言。 关于POST两次请求对于GET请求，浏览器会把请求头和请求体一起发送；而对于POST请求，浏览器会先发送请求头，服务器响应100 continue之后，浏览器再发送请求体。 状态码在响应消息的状态行中有一个状态码和状态消息，两者是对应的，状态码总共有五大类： 1xx，做指示信息，表示请求被接收到，继续处理。 2xx，成功，表示被成功接收，理解，接受。 3xx，重定向，为了完成请求必须采取进一步的动作。 4xx，客户端错误，请求有语法错误或者请求无法实现。 5xx，服务端错误，服务器未能实现请求。 而具体的状态码有很多，不在这里一一列举，下面是一些常用到的： 200 OK，表示请求成功 400 Bad Request 客户端错误，有语法错误 401 Unauthorized，请求未授权 403 Forbidden，服务器拒绝服务 404 Not Found，资源不存在 405 Method Not Allowed，方法不被允许 500 Internal Server Error，服务器内部错误 502 Bad Gateway，网关错误 503 Service Unavailable，服务不可用 消息报头在请求消息的第二部分是请求头，在响应消息的第二部分是响应头，请求头和响应头又叫做消息报头，这是可选的。其实消息报头不只是包括请求头和响应头，一个消息报头包括：普通报头、请求报头、响应报头、实体报头。 下面列出了各种报头，含义没有一一列出，如有需要可以查看http RFC 普通报头普通报头既适用于请求消息也适用于响应消息，这些头域不适用于实体传输，只适用于传输消息。 Cache-Control 控制缓存指令，缓存指令是单向，独立的。 Connection 允许发送指定连接的选项 Date 消息产生的日期和时间 Pragma Trailer Transfer-Encoding Upgrade Via Waring 请求报头 Accept 指定客户端接受哪些类型的信息 Accept-Charset 指定客户端接受的字符集 Accept-Encoding 指定客户端可接受的内容编码 Accept-Language 指定客户端可接受的语言 Authorization 客户端有权限查看某个资源 Expect From Host 指定被请求资源的主机和端口号 If-Match If-Modified-Since If-None-Match If-Range If-Unmodified-Since Max-Forwards Proxy-Authorization Range Referer TE User-Agent 响应报头 Accept-Ranges Age ETag Location Proxy-Authenticate Retry-After Server Vary WWW-Authenticate 实体报头 Allow Content-Encoding Content-Language Content-Length 指明实体正文的长度，以字节方式存储的十进制数字来表示 Content-Location Content-MD5 Content-Range Content-Type 指明发送给接收者的实体正文的媒体类型 Expires 响应过期的日期和时间 Last-Modified 用于指示资源的最后修改日期和时间 extension-header]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[跨域以及CORS相关知识简介]]></title>
      <url>%2F2017%2F05%2F03%2F%E8%B7%A8%E5%9F%9F%E4%BB%A5%E5%8F%8ACORS%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[html同源策略是不允许JavaScript的跨域请求的，而使用CORS（Cross-origin resource sharing）可以实现跨域请求，当然也有其他的办法，常用的有JSONP方式来实现跨域，这里就简单的列举一下实现跨域的几种办法，对于CROS和JSONP详细的了解一下。 CROSCROS可以实现跨域，是HTML5的标准，需要浏览器的支持，同时也需要服务器端的支持。使用CROS实现跨域，主要的工作是在后端实现，需要在服务器端做设置，一般都是设置http头中的Access-Control-Allow-Origin属性，用来指定哪些站点可以访问。 CROS常用属性 Access-Control-Allow-Origin，允许哪些站点访问。 Access-Control-Max-Age，表示多久之内不需要在发送预检请求，有关预检请求下面说明。 Access-Control-Allow-Methods，表示允许的请求方法，比如get、post、delete等。 Access-Control-Allow-Headers，表示允许的content-type。 Access-Control-Allow-Credentials，表示允许请求发送Cookie。 Access-Control-Expose-Headers，表示允许的Header。 CROS中简单请求和非简单请求CROS中简单请求规则： 请求方法是HEAD，GET或者POST。 HTTP头中只能包括以下几种：Accept，Content-Type，Content-Language，Accept-Language，Last-Event-ID 比如有一个get方法，请求头中包括的信息为以上列举的，当浏览器发送请求时发现这是一个简单请求，就会在发送的请求头中自动添加一个Origin表示请求发送的源地址。请求头如下： 123456GET &#x2F;test HTTP&#x2F;1.1Accept-Language: en-USConnection: keep-aliveUser-Agent: Mozilla&#x2F;5.0Host: www.aaa.comOrigin: http:&#x2F;&#x2F;www.bbb.com 服务端接受到请求之后，根据Origin字段判断是否允许该请求，如果服务端允许，则在Http的头信息中添加Access-Control-Allow-Origin以及服务端配置的其他属性，然后返回正确的结果；如果服务端不允许该请求，不会在头信息中添加Access-Control-Allow-Origin属性。 服务端返回结果后，浏览器接收到请求，根据Access-Control-Allow-Origin来决定是否拦截该请求。如果没有这个属性，就会出错，有这个属性就可以正常处理。 非简单请求就是除了上面的简单请求之外的，都是非简单请求。非简单请求的跨域操作，其实会有两次请求到服务端，一次是预检请求（Prelight request），另外一次才是真正的请求。 比如当发送一个DELETE请求时，浏览器会发现这是一个非简单请求，就会先发送一个预检请求，请求如下： 1234567OPTIONS &#x2F;test HTTP&#x2F;1.1Accept-Language: en-USConnection: keep-aliveUser-Agent: Mozilla&#x2F;5.0Host: www.aaa.comOrigin: http:&#x2F;&#x2F;www.bbb.comAccess-Control-Request-Method: DELETE 请注意预检请求使用的是OPTIONS，预检请求会询问服务器是否允许Origin的DELETE方法，允许的话就可以回应了。 浏览器接收到预检请求的回应之后，会根据返回的头信息判断，不允许的话就报错，允许的话就可以发送正常请求了，正在的CORS请求和简单请求一样。 过滤器的形式使用CROS通常可以使用过滤器的形式来实现CROS，只需要实现Filter接口，然后把自定义的过滤器配置到web.xml中即可。 1234567891011121314151617181920212223public class CorsFilter implements Filter &#123; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; &#125; @Override public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request &#x3D; (HttpServletRequest) req; HttpServletResponse response &#x3D; (HttpServletResponse) res; response.setHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;); response.setHeader(&quot;Access-Control-Allow-Methods&quot;, &quot;GET,POST,DELETE,PUT,OPTIONS&quot;); response.setHeader(&quot;Access-Control-Allow-Credentials&quot;, true); response.setHeader(&quot;Access-Control-Allow-Headers&quot;,&quot; Content-Type,X-Token&quot;); response.setHeader(&quot;Access-Control-Max-Age&quot;, &quot;3600&quot;); response.setHeader(&quot;Access-Control-Expose-Headers&quot;, &quot;X-My-Header&quot;); chain.doFilter(req, res); &#125; @Override public void destroy() &#123; &#125;&#125; 需要在web.xml中配置过滤器： 123456789&lt;!--支持跨域访问--&gt;&lt;filter&gt;&lt;filter-name&gt;corsFilter&lt;&#x2F;filter-name&gt;&lt;filter-class&gt;tb.admin.api.cors.CorsFilter&lt;&#x2F;filter-class&gt;&lt;&#x2F;filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;corsFilter&lt;&#x2F;filter-name&gt; &lt;url-pattern&gt;&#x2F;*&lt;&#x2F;url-pattern&gt;&lt;&#x2F;filter-mapping&gt; 服务器端设置好了CROS相关配置后，其他前端就可以跨域访问了。 SpringMVC中使用CROSSpringMVC中使用CROS需要到4.2版本之后，并且使用很方便，如果版本对应的话，可以优先考虑使用Spring的CORS配置。 使用@CrossOrigin注解Spring4.2中提供了@CrossOrigin注解，用来实现CROS，@CrossOrigin(origins = &quot;http://localhost:9000&quot;)直接用在Controller中的方法上，也可以用在类级别上。该注解默认允许所有的origins，所有的headers，所有在@RequestMapping中指定的方法，maxAge默认为30分钟。（具体的可以看下Spring相关源码。） 使用全局CORS配置还可以使用全局的CORS配置，继承WebMvcCOnfigurerAdapter来实现： 123456public class CorsConfigurerAdapter extends WebMvcConfigurerAdapter&#123; @Override public void addCorsMappings(CorsRegistry registry) &#123; registry.addMapping(&quot;&#x2F;*&quot;).allowedOrigins(&quot;http:&#x2F;&#x2F;localhost:9000&quot;); &#125;&#125; 其他的配置也可以依次添加，然后将该类注入到容器中即可。 nginx中配置CORS如果使用了nginx的话，也可以在nginx中配置CORS来实现跨域请求，在nginx.conf里找到server项,并添加如下配置： 1234567location &#x2F; &#123; add_header &#39;Access-Control-Allow-Origin&#39; &#39;*&#39;; add_header &#39;Access-Control-Allow-Credentials&#39; &#39;true&#39;; add_header &#39;Access-Control-Allow-Headers&#39; &#39;Authorization,Content-Type&#39;; add_header &#39;Access-Control-Allow-Methods&#39; &#39;GET,POST,PUT,DELETE,OPTIONS&#39;;...&#125; nginx具体的测试没有做，猜测原理应该跟上面类似，暂先不做过多解释。 JSONP方式实现跨域在CROS没有出现之前，JSONP方式实现跨域请求十分常见。JSONP原理实际上是对script标签的利用。需要服务端和前端都做处理，现在感觉耦合性有点大了，尤其是跟上面的CORS对比起来。 JSONP只支持get请求，但是它能够支持老的浏览器。 其他方法其他方法还有使用document.domain，src标签，navigation对象，以及html5中的window.postMessage，这里都不做讲解，条件允许，尽量使用新的CORS来解决跨域问题。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring定时器的配置从1.0到5.0的演进]]></title>
      <url>%2F2017%2F04%2F19%2FSpring%E5%AE%9A%E6%97%B6%E5%99%A8%E7%9A%84%E9%85%8D%E7%BD%AE%E4%BB%8E1.0%E5%88%B05.0%E7%9A%84%E6%BC%94%E8%BF%9B%2F</url>
      <content type="text"><![CDATA[这里主要是记录下从Spring1.0到现在的5.0中定时器的配置方式，关于源码，暂先不解释。主要用作自己记录用，如果有错误的还请指出一起改正学习，免得误导别人，谢谢。 Spring1中定时器的配置直接看Spring1.1.1的文档，里面都已经给出来了各种配置方式，更高版本的也都包含了这些，但是觉得看1.1.1的更纯粹一些。 Spring1中对定时器的支持有两种方式： jdk的Timer Quartz Scheduler Quartz SchedulerQuartz Scheduler使用Triggers，Jobs，JobDetail来实现定时器功能。Spring提供了对Quartz的支持。 使用的大概步骤是： 定义JobDetail，也就是定义具体的任务。 定义trigger，就是定义触发器，指定什么任务，在什么时间执行或者隔多久执行。 定义SchedulerFactoryBean，来执行任务。 下面我们以一个例子来说明，是一个定时的去获取信息和定时统计信息的示例。 定义JobDetail定义JobDetail有两种方式，一种是使用JobDetailBean，一种是使用MethodInvokingJobDetailFactoryBean，后者可以指定要执行的具体方法。 使用JobDetailBeanCountUserJob： 1234567891011121314151617181920212223242526package me.cxis.spring.scheduling.quartz;import org.quartz.JobExecutionContext;import org.quartz.JobExecutionException;import org.springframework.scheduling.quartz.QuartzJobBean;&#x2F;** * Created by cheng.xi on 2017-04-19 11:00. * 定时的统计信息的JOb * 比如这里是定时的统计系统中总的用户数，总的用户数是我查询到的数和我在xml指定的数的总和 *&#x2F;public class CountUserJob extends QuartzJobBean&#123; private int adminUser; public void setAdminUser(int adminUser) &#123; this.adminUser &#x3D; adminUser; &#125; protected void executeInternal(JobExecutionContext context) throws JobExecutionException &#123; &#x2F;&#x2F;执行真正的统计任务 System.out.println(&quot;开始统计系统中人数&quot;); System.out.println(&quot;统计完成，共有101人&quot;); System.out.println(&quot;加上系统管理员之后共有&quot; + (adminUser + 101) + &quot;人&quot;); &#125;&#125; xml中声明一个job： 12345678910111213&lt;!--定义一个JobDetailBean类型的Job，用来统计系统中总的人数，adminUser指的是系统中预先留的管理员数目--&gt;&lt;bean name&#x3D;&quot;countUserJob&quot; class&#x3D;&quot;org.springframework.scheduling.quartz.JobDetailBean&quot;&gt; &lt;property name&#x3D;&quot;jobClass&quot;&gt; &lt;value&gt;me.cxis.spring.scheduling.quartz.CountUserJob&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;jobDataAsMap&quot;&gt; &lt;map&gt; &lt;entry key&#x3D;&quot;adminUser&quot;&gt; &lt;value&gt;10&lt;&#x2F;value&gt; &lt;&#x2F;entry&gt; &lt;&#x2F;map&gt; &lt;&#x2F;property&gt;&lt;&#x2F;bean&gt; 使用MethodInvokingJobDetailFactoryBeanMethodInvokingJobDetailFactoryBean可以指定方法。直接看例子。 GetJob： 1234567891011package me.cxis.spring.scheduling.quartz;&#x2F;** * Created by cheng.xi on 2017-04-19 11:01. * 定时的获取信息的Job，定时从文件中获取数据 *&#x2F;public class GetJob &#123; public void getSomethingFromFile()&#123; System.out.println(&quot;从文件中获取数据。。。。&quot;); &#125;&#125; xml中配置： 12345678&lt;!--从文件中获取信息的bean--&gt;&lt;bean id&#x3D;&quot;getJob&quot; class&#x3D;&quot;me.cxis.spring.scheduling.quartz.GetJob&quot;&#x2F;&gt;&lt;!--定义一个MethodInvokingJobDetailFactoryBean，从文件中获取数据的Job--&gt;&lt;bean id&#x3D;&quot;getJobDetail&quot; class&#x3D;&quot;org.springframework.scheduling.quartz.MethodInvokingJobDetailFactoryBean&quot;&gt; &lt;property name&#x3D;&quot;targetObject&quot;&gt;&lt;ref bean&#x3D;&quot;getJob&quot;&#x2F;&gt;&lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;targetMethod&quot;&gt;&lt;value&gt;getSomethingFromFile&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;&#x2F;bean&gt; 定义Triggers上面我们把JobDetail都定义好了，也都配置好了，但是怎么去执行，多长时间执行一次都没有说明，这时候需要定义Triggers来描述任务什么时候执行等。只需要在xml中配置就可以了。 Triggers也有两种方式，一种是SimpleTriggerBean，一种是CronTriggerBean。我们的例子中，统计用户数使用SimpleTriggerBean，从文件中获取信息使用CronTriggerBean。 1234567891011121314151617181920212223242526&lt;!--定义Triggers，统计用户数--&gt;&lt;bean id&#x3D;&quot;countUserTrigger&quot; class&#x3D;&quot;org.springframework.scheduling.quartz.SimpleTriggerBean&quot;&gt; &lt;property name&#x3D;&quot;jobDetail&quot;&gt; &lt;ref bean&#x3D;&quot;countUserJob&quot;&#x2F;&gt; &lt;&#x2F;property&gt; &lt;!--第一次执行之前需要等待的时间--&gt; &lt;property name&#x3D;&quot;startDelay&quot;&gt; &lt;!--10秒--&gt; &lt;value&gt;10000&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;!--任务重复时间，每隔多少时间执行一次--&gt; &lt;property name&#x3D;&quot;repeatInterval&quot;&gt; &lt;value&gt;20000&lt;&#x2F;value&gt; &lt;&#x2F;property&gt;&lt;&#x2F;bean&gt;&lt;!--定义Triggers，定时从文件中获取数据--&gt;&lt;bean id&#x3D;&quot;getJobTrigger&quot; class&#x3D;&quot;org.springframework.scheduling.quartz.CronTriggerBean&quot;&gt; &lt;property name&#x3D;&quot;jobDetail&quot;&gt; &lt;ref bean&#x3D;&quot;getJobDetail&quot;&#x2F;&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;cronExpression&quot;&gt; &lt;!--cron表达式，这里是每隔两分钟执行一次--&gt; &lt;value&gt;0 0&#x2F;2 * * * ?&lt;&#x2F;value&gt; &lt;&#x2F;property&gt;&lt;&#x2F;bean&gt; 定义SchedulerFactoryBean123456789&lt;!--定义SchedulerFactoryBean--&gt;&lt;bean class&#x3D;&quot;org.springframework.scheduling.quartz.SchedulerFactoryBean&quot;&gt; &lt;property name&#x3D;&quot;triggers&quot;&gt; &lt;list&gt; &lt;ref local&#x3D;&quot;countUserTrigger&quot;&#x2F;&gt; &lt;ref local&#x3D;&quot;getJobTrigger&quot;&#x2F;&gt; &lt;&#x2F;list&gt; &lt;&#x2F;property&gt;&lt;&#x2F;bean&gt; 测试Main： 12345678910111213package me.cxis.spring.scheduling.quartz;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-04-19 11:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:scheduling-quartz.xml&quot;); &#125;&#125; JDK Timer使用JDK Timer，也跟上面类似，大概的步骤是： 创建一个TimerTask，里面是执行任务的逻辑。 创建ScheduledTimerTask，就是什么时候或者隔多久执行任务。 创建TimerFactoryBean，来执行任务。 创建TimerTask同样，创建一个Task也有两种方式，一种是继承TimerTask，另外一种是使用MethodInvokingTimerTaskFactoryBean，后者可以指定具体方法。 继承TimerTaskCountUserTask： 123456789101112131415161718192021222324package me.cxis.spring.scheduling.timer;import java.util.TimerTask;&#x2F;** * Created by cheng.xi on 2017-04-19 11:00. * 定时的统计信息的 task * 比如这里是定时的统计系统中总的用户数，总的用户数是我查询到的数和我在xml指定的数的总和 *&#x2F;public class CountUserTask extends TimerTask&#123; private int adminUser; public void setAdminUser(int adminUser) &#123; this.adminUser &#x3D; adminUser; &#125; public void run() &#123; &#x2F;&#x2F;执行真正的统计任务 System.out.println(&quot;开始统计系统中人数&quot;); System.out.println(&quot;统计完成，共有101人&quot;); System.out.println(&quot;加上系统管理员之后共有&quot; + (adminUser + 101) + &quot;人&quot;); &#125;&#125; 在xml中配置bean： 123456&lt;!--统计用户数的bean--&gt;&lt;bean id&#x3D;&quot;countUserTask&quot; class&#x3D;&quot;me.cxis.spring.scheduling.timer.CountUserTask&quot;&gt; &lt;property name&#x3D;&quot;adminUser&quot;&gt; &lt;value&gt;10&lt;&#x2F;value&gt; &lt;&#x2F;property&gt;&lt;&#x2F;bean&gt; 使用MethodInvokingTimerTaskFactoryBeanGetTask: 1234567891011package me.cxis.spring.scheduling.timer;&#x2F;** * Created by cheng.xi on 2017-04-19 11:01. * 定时的获取信息的task，定时从文件中获取数据 *&#x2F;public class GetTask &#123; public void getSomethingFromFile()&#123; System.out.println(&quot;从文件中获取数据。。。。&quot;); &#125;&#125; xml中配置： 12345678&lt;!--从文件中获取信息的bean--&gt;&lt;bean id&#x3D;&quot;getTaskBean&quot; class&#x3D;&quot;me.cxis.spring.scheduling.timer.GetTask&quot;&gt;&lt;&#x2F;bean&gt;&lt;!--使用MethodInvokingTimerTaskFactoryBean--&gt;&lt;bean id&#x3D;&quot;getTask&quot; class&#x3D;&quot;org.springframework.scheduling.timer.MethodInvokingTimerTaskFactoryBean&quot;&gt; &lt;property name&#x3D;&quot;targetObject&quot;&gt;&lt;ref bean&#x3D;&quot;getTaskBean&quot;&#x2F;&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;targetMethod&quot;&gt;&lt;value&gt;getSomethingFromFile&lt;&#x2F;value&gt;&lt;&#x2F;property&gt;&lt;&#x2F;bean&gt; 创建ScheduledTimerTask定义ScheduledTimerTask来描述任务什么时候执行等。只需要在xml中配置就可以了。 使用Timer的方式，就这么一种配置，没法使用cron的方式。 12345678910111213141516171819202122&lt;!--创建统计用户的ScheduledTimerTask，描述任务怎么运行--&gt;&lt;bean id&#x3D;&quot;countUserScheduledTimerTask&quot; class&#x3D;&quot;org.springframework.scheduling.timer.ScheduledTimerTask&quot;&gt; &lt;property name&#x3D;&quot;delay&quot;&gt; &lt;value&gt;10000&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;period&quot;&gt; &lt;value&gt;20000&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;timerTask&quot;&gt; &lt;ref local&#x3D;&quot;countUserTask&quot;&#x2F;&gt; &lt;&#x2F;property&gt;&lt;&#x2F;bean&gt;&lt;!--创建从文件获取信息的ScheduledTimerTask，描述任务怎么运行--&gt;&lt;bean id&#x3D;&quot;getScheduledTimerTask&quot; class&#x3D;&quot;org.springframework.scheduling.timer.ScheduledTimerTask&quot;&gt; &lt;property name&#x3D;&quot;period&quot;&gt; &lt;value&gt;60000&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;timerTask&quot;&gt; &lt;ref local&#x3D;&quot;getTask&quot;&#x2F;&gt; &lt;&#x2F;property&gt;&lt;&#x2F;bean&gt; 创建TimerFactoryBean任务执行的配置： 123456789&lt;!--创建TimerFactoryBean，执行任务--&gt;&lt;bean id&#x3D;&quot;timerFactory&quot; class&#x3D;&quot;org.springframework.scheduling.timer.TimerFactoryBean&quot;&gt; &lt;property name&#x3D;&quot;scheduledTimerTasks&quot;&gt; &lt;list&gt; &lt;ref local&#x3D;&quot;countUserScheduledTimerTask&quot;&#x2F;&gt; &lt;ref local&#x3D;&quot;getScheduledTimerTask&quot;&#x2F;&gt; &lt;&#x2F;list&gt; &lt;&#x2F;property&gt;&lt;&#x2F;bean&gt; 测试123456789101112131415161718192021package me.cxis.spring.scheduling.timer;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import java.io.IOException;import java.io.InputStream;&#x2F;** * Created by cheng.xi on 2017-04-19 11:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:scheduling-timer.xml&quot;); try &#123; System.in.read(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 上面就是Spring1.x中关于定时器的配置方式，配置清晰，易懂，但是任务多了之后，就会发现配置文件会迅速变得臃肿。 Spring2中定时器的配置What’s new in Spring 2.0? 增加对Executors的支持 上面就是AOP在2.0版本新增的特性，1.0的所有AOP配置方式在2.0中都支持，下面主要看看2.0中新增的一些方法。 Spring2.0中新定义了一个TaskExecutor接口，增加了对线程池的支持，这个接口的功能跟JDK1.5中的Executor接口一样。那么2.0中线程池的增加，对定时器有什么影响呢？其实就是可以在定时任务执行的时候，使用线程池来执行任务，我们不用关心其他的实现。 Spring2中配置示例直接看示例，我们定时，每隔5分钟，每次都从20个文件中同时获取数据。 首先写实际执行业务的类， 12345678910111213141516171819package me.cxis.spring.scheduling.executor;&#x2F;** * Created by cheng.xi on 2017-04-19 14:51. * 从文件中获取数据的Task *&#x2F;public class GetDataFromFileTask implements Runnable &#123; private int fileId; public GetDataFromFileTask(int fileId)&#123; this.fileId &#x3D; fileId; &#125; public void run() &#123; &#x2F;&#x2F;真正执行从文件中获取数据的逻辑 System.out.println(&quot;从文件&quot; + fileId + &quot;中获取数据&quot;); &#125;&#125; 然后是执行任务的定时器： 1234567891011121314151617181920212223242526package me.cxis.spring.scheduling.executor;import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;import java.util.TimerTask;&#x2F;** * Created by cheng.xi on 2017-04-19 14:54. * 批量从文件中获取数据的定时器 *&#x2F;public class GetDataFromFileScheduler extends TimerTask &#123; private ThreadPoolTaskExecutor executor; public void setExecutor(ThreadPoolTaskExecutor executor) &#123; this.executor &#x3D; executor; &#125; public void run() &#123; System.out.println(&quot;CorePoolSize:&quot; + taskExecutor.getCorePoolSize() + &quot;;MaxPoolSize:&quot; + taskExecutor.getMaxPoolSize()); &#x2F;&#x2F;每次都会同时执行从20个文件中获取数据 for(int i &#x3D; 0; i &lt; 20;i++)&#123; executor.execute(new GetDataFromFileTask(i)); &#125; &#125;&#125; 接着是xml的配置： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE beans PUBLIC &quot;-&#x2F;&#x2F;SPRING&#x2F;&#x2F;DTD BEAN&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;dtd&#x2F;spring-beans.dtd&quot;&gt;&lt;beans&gt; &lt;!--线程池taskExecutor--&gt; &lt;bean id&#x3D;&quot;taskExecutor&quot; class&#x3D;&quot;org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor&quot;&gt; &lt;!--核心线程数--&gt; &lt;property name&#x3D;&quot;corePoolSize&quot;&gt; &lt;value&gt;5&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;!--最大线程数--&gt; &lt;property name&#x3D;&quot;maxPoolSize&quot;&gt; &lt;value&gt;10&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;!--队列最大长度--&gt; &lt;property name&#x3D;&quot;queueCapacity&quot;&gt; &lt;value&gt;40&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;&#x2F;bean&gt; &lt;!--GetDataFromFileScheduler，获取数据的定时器--&gt; &lt;bean id&#x3D;&quot;getDataFromFileScheduler&quot; class&#x3D;&quot;me.cxis.spring.scheduling.executor.GetDataFromFileScheduler&quot;&gt; &lt;property name&#x3D;&quot;taskExecutor&quot;&gt; &lt;ref local&#x3D;&quot;taskExecutor&quot;&#x2F;&gt; &lt;&#x2F;property&gt; &lt;&#x2F;bean&gt; &lt;!--创建统计用户的ScheduledTimerTask，描述任务怎么运行--&gt; &lt;bean id&#x3D;&quot;getDataFromFileTimerTask&quot; class&#x3D;&quot;org.springframework.scheduling.timer.ScheduledTimerTask&quot;&gt; &lt;property name&#x3D;&quot;delay&quot;&gt; &lt;value&gt;10000&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;period&quot;&gt; &lt;value&gt;20000&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;timerTask&quot;&gt; &lt;ref local&#x3D;&quot;getDataFromFileScheduler&quot;&#x2F;&gt; &lt;&#x2F;property&gt; &lt;&#x2F;bean&gt; &lt;!--创建TimerFactoryBean，执行任务--&gt; &lt;bean id&#x3D;&quot;timerFactory&quot; class&#x3D;&quot;org.springframework.scheduling.timer.TimerFactoryBean&quot;&gt; &lt;property name&#x3D;&quot;scheduledTimerTasks&quot;&gt; &lt;list&gt; &lt;ref local&#x3D;&quot;getDataFromFileTimerTask&quot;&#x2F;&gt; &lt;&#x2F;list&gt; &lt;&#x2F;property&gt; &lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; 测试类： 12345678910111213package me.cxis.spring.scheduling.executor;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-04-19 15:11. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:scheduling-executor.xml&quot;); &#125;&#125; 上面就是结合线程池的示例。也就是在执行任务的时候多了线程池，基本的配置方式使用方法基本没变。 Spring3中定时器的配置 Spring3中TaskExecutor继承了JDK的Executor。使用方面还是跟原来2.0一样。 Spring3中还引入了新的接口TaskScheduler，Trigger，TriggerContext等。 Spring3中还引入了task的命名空间&lt;task:scheduler/&gt;，&lt;task:executor/&gt;，&lt;task:scheduled-tasks/&gt;等。 Spring3中还支持注解的方式@Scheduled，@Async，使配置更加简化。使用注解的方式，需要在配置文件中先开启注解支持&lt;task:annotation-driven/&gt; 注解方式的示例如下。 CountUserTask： 123456789101112131415161718192021package me.cxis.spring.scheduling.annotation;import org.springframework.scheduling.annotation.Scheduled;&#x2F;** * Created by cheng.xi on 2017-04-19 11:00. * 定时的统计信息的Task * *&#x2F;public class CountUserTask&#123; &#x2F;&#x2F;@Scheduled(cron&#x3D;&quot;*&#x2F;5 * * * * MON-FRI&quot;) cron的方式 &#x2F;&#x2F;下面是固定时间，每隔5秒执行一次 @Scheduled(fixedRate &#x3D; 5000) public void countUser()&#123; &#x2F;&#x2F;执行真正的统计任务 System.out.println(&quot;开始统计系统中人数&quot;); System.out.println(&quot;统计完成，共有101人&quot;); &#125;&#125; 配置文件： 1234567891011121314&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xmlns:task&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;task&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans-4.0.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;task http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;task&#x2F;spring-task.xsd&quot;&gt; &lt;!--开启task的注解支持--&gt; &lt;task:annotation-driven &#x2F;&gt; &lt;!--执行任务的bean--&gt; &lt;bean id&#x3D;&quot;countUserTask&quot; class&#x3D;&quot;me.cxis.spring.scheduling.annotation.CountUserTask&quot;&#x2F;&gt;&lt;&#x2F;beans&gt; 测试： 1234567891011121314151617181920package me.cxis.spring.scheduling.annotation;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import java.io.IOException;&#x2F;** * Created by cheng.xi on 2017-04-19 16:08. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:scheduling-annotation.xml&quot;); try &#123; System.in.read(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 可以看到，使用注解的方式简化了很多很多。 Spring4和Spring5中定时器的配置Spring4中增加了@EnableScheduling注解来启用对@Scheduled注解的支持。其他的基本没有什么变化，使用方式还是跟以前一样，现在使用注解更多。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java中SPI机制深入及源码解析]]></title>
      <url>%2F2017%2F04%2F17%2FJava%E4%B8%ADSPI%E6%9C%BA%E5%88%B6%E6%B7%B1%E5%85%A5%E5%8F%8A%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[SPI，Service Provider Interface，主要是被框架的开发人员使用，比如java.sql.Driver接口，其他不同厂商可以针对同一接口做出不同的实现，mysql和postgresql都有不同的实现提供给用户，而Java的SPI机制可以为某个接口寻找服务实现。 当服务的提供者提供了一种接口的实现之后，需要在classpath下的META-INF/services/目录里创建一个以服务接口命名的文件，这个文件里的内容就是这个接口的具体的实现类。当其他的程序需要这个服务的时候，就可以通过查找这个jar包（一般都是以jar包做依赖）的META-INF/services/中的配置文件，配置文件中有接口的具体实现类名，可以根据这个类名进行加载实例化，就可以使用该服务了。JDK中查找服务的实现的工具类是：java.util.ServiceLoader。 SPI实例有很多的SPI扩展机制应用的实例，比如common-logging，JDBC等等，我们这里以JDBC为例。 JDBC在JDBC4.0之前，我们开发有连接数据库的时候，通常会用Class.forName(&quot;com.mysql.jdbc.Driver&quot;)这句先加载数据库相关的驱动，然后再进行获取连接等的操作。而JDBC4.0之后不需要用Class.forName(&quot;com.mysql.jdbc.Driver&quot;)来加载驱动，直接获取连接就可以了，现在这种方式就是使用了Java的SPI扩展机制来实现。 JDBC接口定义首先在java中定义了接口java.sql.Driver，并没有具体的实现，具体的实现都是由不同厂商来提供的。 mysql实现在mysql的jar包mysql-connector-java-6.0.6.jar中，可以找到META-INF/services目录，该目录下会有一个名字为java.sql.Driver的文件，文件内容是com.mysql.cj.jdbc.Driver，这里面的内容就是针对Java中定义的接口的实现。 postgresql实现同样在postgresql的jar包postgresql-42.0.0.jar中，也可以找到同样的配置文件，文件内容是org.postgresql.Driver，这是postgresql对Java的java.sql.Driver的实现。 使用方法上面说了，现在使用SPI扩展来加载具体的驱动，我们在Java中写连接数据库的代码的时候，不需要再使用Class.forName(&quot;com.mysql.jdbc.Driver&quot;)来加载驱动了，而是直接使用如下代码： 123String url &#x3D; &quot;jdbc:xxxx:&#x2F;&#x2F;xxxx:xxxx&#x2F;xxxx&quot;;Connection conn &#x3D; DriverManager.getConnection(url,username,password);..... 这里并没有涉及到spi的使用，接着看下面的解析。 源码实现上面的使用方法，就是我们普通的连接数据库的代码，并没有涉及到SPI的东西，但是有一点我们可以确定的是，我们没有写有关具体驱动的硬编码Class.forName(&quot;com.mysql.jdbc.Driver&quot;)！ 上面的代码可以直接获取数据库连接进行操作，但是跟SPI有啥关系呢？上面代码没有了加载驱动的代码，我们怎么去确定使用哪个数据库连接的驱动呢？这里就涉及到使用Java的SPI扩展机制来查找相关驱动的东西了，关于驱动的查找其实都在DriverManager中，DriverManager是Java中的实现，用来获取数据库连接，在DriverManager中有一个静态代码块如下： 1234static &#123; loadInitialDrivers(); println(&quot;JDBC DriverManager initialized&quot;);&#125; 可以看到是加载实例化驱动的，接着看loadInitialDrivers方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445private static void loadInitialDrivers() &#123; String drivers; try &#123; drivers &#x3D; AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() &#123; public String run() &#123; return System.getProperty(&quot;jdbc.drivers&quot;); &#125; &#125;); &#125; catch (Exception ex) &#123; drivers &#x3D; null; &#125; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; &#x2F;&#x2F;使用SPI的ServiceLoader来加载接口的实现 ServiceLoader&lt;Driver&gt; loadedDrivers &#x3D; ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator &#x3D; loadedDrivers.iterator(); try&#123; while(driversIterator.hasNext()) &#123; driversIterator.next(); &#125; &#125; catch(Throwable t) &#123; &#x2F;&#x2F; Do nothing &#125; return null; &#125; &#125;); println(&quot;DriverManager.initialize: jdbc.drivers &#x3D; &quot; + drivers); if (drivers &#x3D;&#x3D; null || drivers.equals(&quot;&quot;)) &#123; return; &#125; String[] driversList &#x3D; drivers.split(&quot;:&quot;); println(&quot;number of Drivers:&quot; + driversList.length); for (String aDriver : driversList) &#123; try &#123; println(&quot;DriverManager.Initialize: loading &quot; + aDriver); Class.forName(aDriver, true, ClassLoader.getSystemClassLoader()); &#125; catch (Exception ex) &#123; println(&quot;DriverManager.Initialize: load failed: &quot; + ex); &#125; &#125;&#125; 上面的代码主要步骤是： 从系统变量中获取有关驱动的定义。 使用SPI来获取驱动的实现。 遍历使用SPI获取到的具体实现，实例化各个实现类。 根据第一步获取到的驱动列表来实例化具体实现类。 我们主要关注2,3步，这两步是SPI的用法，首先看第二步，使用SPI来获取驱动的实现，对应的代码是： 1ServiceLoader&lt;Driver&gt; loadedDrivers &#x3D; ServiceLoader.load(Driver.class); 这里没有去META-INF/services目录下查找配置文件，也没有加载具体实现类，做的事情就是封装了我们的接口类型和类加载器，并初始化了一个迭代器。 接着看第三步，遍历使用SPI获取到的具体实现，实例化各个实现类，对应的代码如下： 123456&#x2F;&#x2F;获取迭代器Iterator&lt;Driver&gt; driversIterator &#x3D; loadedDrivers.iterator();&#x2F;&#x2F;遍历所有的驱动实现while(driversIterator.hasNext()) &#123; driversIterator.next();&#125; 在遍历的时候，首先调用driversIterator.hasNext()方法，这里会搜索classpath下以及jar包中所有的META-INF/services目录下的java.sql.Driver文件，并找到文件中的实现类的名字，此时并没有实例化具体的实现类（ServiceLoader具体的源码实现在下面）。 然后是调用driversIterator.next();方法，此时就会根据驱动名字具体实例化各个实现类了。现在驱动就被找到并实例化了。 可以看下截图，我在测试项目中添加了两个jar包，mysql-connector-java-6.0.6.jar和postgresql-42.0.0.0.jar，跟踪到DriverManager中之后： SPI，Service Provider Interface，主要是被框架的开发人员使用，比如java.sql.Driver接口，其他不同厂商可以针对同一接口做出不同的实现，mysql和postgresql都有不同的实现提供给用户，而Java的SPI机制可以为某个接口寻找服务实现。 当服务的提供者提供了一种接口的实现之后，需要在classpath下的META-INF/services/目录里创建一个以服务接口命名的文件，这个文件里的内容就是这个接口的具体的实现类。当其他的程序需要这个服务的时候，就可以通过查找这个jar包（一般都是以jar包做依赖）的META-INF/services/中的配置文件，配置文件中有接口的具体实现类名，可以根据这个类名进行加载实例化，就可以使用该服务了。JDK中查找服务的实现的工具类是：java.util.ServiceLoader。 SPI实例有很多的SPI扩展机制应用的实例，比如common-logging，JDBC等等，我们这里以JDBC为例。 JDBC在JDBC4.0之前，我们开发有连接数据库的时候，通常会用Class.forName(&quot;com.mysql.jdbc.Driver&quot;)这句先加载数据库相关的驱动，然后再进行获取连接等的操作。而JDBC4.0之后不需要用Class.forName(&quot;com.mysql.jdbc.Driver&quot;)来加载驱动，直接获取连接就可以了，现在这种方式就是使用了Java的SPI扩展机制来实现。 JDBC接口定义首先在java中定义了接口java.sql.Driver，并没有具体的实现，具体的实现都是由不同厂商来提供的。 mysql实现在mysql的jar包mysql-connector-java-6.0.6.jar中，可以找到META-INF/services目录，该目录下会有一个名字为java.sql.Driver的文件，文件内容是com.mysql.cj.jdbc.Driver，这里面的内容就是针对Java中定义的接口的实现。 postgresql实现同样在postgresql的jar包postgresql-42.0.0.jar中，也可以找到同样的配置文件，文件内容是org.postgresql.Driver，这是postgresql对Java的java.sql.Driver的实现。 使用方法上面说了，现在使用SPI扩展来加载具体的驱动，我们在Java中写连接数据库的代码的时候，不需要再使用Class.forName(&quot;com.mysql.jdbc.Driver&quot;)来加载驱动了，而是直接使用如下代码： 123String url &#x3D; &quot;jdbc:xxxx:&#x2F;&#x2F;xxxx:xxxx&#x2F;xxxx&quot;;Connection conn &#x3D; DriverManager.getConnection(url,username,password);..... 这里并没有涉及到spi的使用，接着看下面的解析。 源码实现上面的使用方法，就是我们普通的连接数据库的代码，并没有涉及到SPI的东西，但是有一点我们可以确定的是，我们没有写有关具体驱动的硬编码Class.forName(&quot;com.mysql.jdbc.Driver&quot;)！ 上面的代码可以直接获取数据库连接进行操作，但是跟SPI有啥关系呢？上面代码没有了加载驱动的代码，我们怎么去确定使用哪个数据库连接的驱动呢？这里就涉及到使用Java的SPI扩展机制来查找相关驱动的东西了，关于驱动的查找其实都在DriverManager中，DriverManager是Java中的实现，用来获取数据库连接，在DriverManager中有一个静态代码块如下： 1234static &#123; loadInitialDrivers(); println(&quot;JDBC DriverManager initialized&quot;);&#125; 可以看到是加载实例化驱动的，接着看loadInitialDrivers方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445private static void loadInitialDrivers() &#123; String drivers; try &#123; drivers &#x3D; AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() &#123; public String run() &#123; return System.getProperty(&quot;jdbc.drivers&quot;); &#125; &#125;); &#125; catch (Exception ex) &#123; drivers &#x3D; null; &#125; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; &#x2F;&#x2F;使用SPI的ServiceLoader来加载接口的实现 ServiceLoader&lt;Driver&gt; loadedDrivers &#x3D; ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator &#x3D; loadedDrivers.iterator(); try&#123; while(driversIterator.hasNext()) &#123; driversIterator.next(); &#125; &#125; catch(Throwable t) &#123; &#x2F;&#x2F; Do nothing &#125; return null; &#125; &#125;); println(&quot;DriverManager.initialize: jdbc.drivers &#x3D; &quot; + drivers); if (drivers &#x3D;&#x3D; null || drivers.equals(&quot;&quot;)) &#123; return; &#125; String[] driversList &#x3D; drivers.split(&quot;:&quot;); println(&quot;number of Drivers:&quot; + driversList.length); for (String aDriver : driversList) &#123; try &#123; println(&quot;DriverManager.Initialize: loading &quot; + aDriver); Class.forName(aDriver, true, ClassLoader.getSystemClassLoader()); &#125; catch (Exception ex) &#123; println(&quot;DriverManager.Initialize: load failed: &quot; + ex); &#125; &#125;&#125; 上面的代码主要步骤是： 从系统变量中获取有关驱动的定义。 使用SPI来获取驱动的实现。 遍历使用SPI获取到的具体实现，实例化各个实现类。 根据第一步获取到的驱动列表来实例化具体实现类。 我们主要关注2,3步，这两步是SPI的用法，首先看第二步，使用SPI来获取驱动的实现，对应的代码是： 1ServiceLoader&lt;Driver&gt; loadedDrivers &#x3D; ServiceLoader.load(Driver.class); 这里没有去META-INF/services目录下查找配置文件，也没有加载具体实现类，做的事情就是封装了我们的接口类型和类加载器，并初始化了一个迭代器。 接着看第三步，遍历使用SPI获取到的具体实现，实例化各个实现类，对应的代码如下： 123456&#x2F;&#x2F;获取迭代器Iterator&lt;Driver&gt; driversIterator &#x3D; loadedDrivers.iterator();&#x2F;&#x2F;遍历所有的驱动实现while(driversIterator.hasNext()) &#123; driversIterator.next();&#125; 在遍历的时候，首先调用driversIterator.hasNext()方法，这里会搜索classpath下以及jar包中所有的META-INF/services目录下的java.sql.Driver文件，并找到文件中的实现类的名字，此时并没有实例化具体的实现类（ServiceLoader具体的源码实现在下面）。 然后是调用driversIterator.next();方法，此时就会根据驱动名字具体实例化各个实现类了。现在驱动就被找到并实例化了。 可以看下截图，我在测试项目中添加了两个jar包，mysql-connector-java-6.0.6.jar和postgresql-42.0.0.0.jar，跟踪到DriverManager中之后： 可以看到此时迭代器中有两个驱动，mysql和postgresql的都被加载了。有关两个驱动都加载了，具体使用哪个驱动，请自行深入jdbc的源码。这里不做过多解析。 SPI的使用步骤总结看完上面的数据库驱动的解析，应该都能知道大概的流程了： 有关组织或者公司定义标准。 具体厂商或者框架开发者实现。 程序猿使用。 定义标准定义标准，就是定义接口。比如接口java.sql.Driver 具体厂商或者框架开发者实现。厂商或者框架开发者开发具体的实现： 在META-INF/services目录下定义一个名字为接口全限定名的文件，比如java.sql.Driver文件，文件内容是具体的实现名字，比如me.cxis.sql.MyDriver。 写具体的实现me.cxis.sql.MyDriver，都是对接口Driver的实现。 程序猿使用我们会引用具体厂商的jar包来实现我们的功能： 12345678ServiceLoader&lt;Driver&gt; loadedDrivers &#x3D; ServiceLoader.load(Driver.class);&#x2F;&#x2F;获取迭代器Iterator&lt;Driver&gt; driversIterator &#x3D; loadedDrivers.iterator();&#x2F;&#x2F;遍历while(driversIterator.hasNext()) &#123; driversIterator.next(); &#x2F;&#x2F;可以做具体的业务逻辑&#125; SPI相关的源码解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259&#x2F;&#x2F;ServiceLoader实现了Iterable接口，可以遍历所有的服务实现者public final class ServiceLoader&lt;S&gt; implements Iterable&lt;S&gt;&#123; &#x2F;&#x2F;查找配置文件的目录 private static final String PREFIX &#x3D; &quot;META-INF&#x2F;services&#x2F;&quot;; &#x2F;&#x2F;表示要被加载的服务的类或接口 private final Class&lt;S&gt; service; &#x2F;&#x2F;这个ClassLoader用来定位，加载，实例化服务提供者 private final ClassLoader loader; &#x2F;&#x2F; 访问控制上下文 private final AccessControlContext acc; &#x2F;&#x2F; 缓存已经被实例化的服务提供者，按照实例化的顺序存储 private LinkedHashMap&lt;String,S&gt; providers &#x3D; new LinkedHashMap&lt;&gt;(); &#x2F;&#x2F; 迭代器 private LazyIterator lookupIterator; &#x2F;&#x2F;重新加载，就相当于重新创建ServiceLoader了，用于新的服务提供者安装到正在运行的Java虚拟机中的情况。 public void reload() &#123; &#x2F;&#x2F;清空缓存中所有已实例化的服务提供者 providers.clear(); &#x2F;&#x2F;新建一个迭代器，该迭代器会从头查找和实例化服务提供者 lookupIterator &#x3D; new LazyIterator(service, loader); &#125; &#x2F;&#x2F;私有构造器 &#x2F;&#x2F;使用指定的类加载器和服务创建服务加载器 &#x2F;&#x2F;如果没有指定类加载器，使用系统类加载器，就是应用类加载器。 private ServiceLoader(Class&lt;S&gt; svc, ClassLoader cl) &#123; service &#x3D; Objects.requireNonNull(svc, &quot;Service interface cannot be null&quot;); loader &#x3D; (cl &#x3D;&#x3D; null) ? ClassLoader.getSystemClassLoader() : cl; acc &#x3D; (System.getSecurityManager() !&#x3D; null) ? AccessController.getContext() : null; reload(); &#125; &#x2F;&#x2F;解析失败处理的方法 private static void fail(Class&lt;?&gt; service, String msg, Throwable cause) throws ServiceConfigurationError &#123; throw new ServiceConfigurationError(service.getName() + &quot;: &quot; + msg, cause); &#125; private static void fail(Class&lt;?&gt; service, String msg) throws ServiceConfigurationError &#123; throw new ServiceConfigurationError(service.getName() + &quot;: &quot; + msg); &#125; private static void fail(Class&lt;?&gt; service, URL u, int line, String msg) throws ServiceConfigurationError &#123; fail(service, u + &quot;:&quot; + line + &quot;: &quot; + msg); &#125; &#x2F;&#x2F;解析服务提供者配置文件中的一行 &#x2F;&#x2F;首先去掉注释校验，然后保存 &#x2F;&#x2F;返回下一行行号 &#x2F;&#x2F;重复的配置项和已经被实例化的配置项不会被保存 private int parseLine(Class&lt;?&gt; service, URL u, BufferedReader r, int lc, List&lt;String&gt; names) throws IOException, ServiceConfigurationError &#123; &#x2F;&#x2F;读取一行 String ln &#x3D; r.readLine(); if (ln &#x3D;&#x3D; null) &#123; return -1; &#125; &#x2F;&#x2F;#号代表注释行 int ci &#x3D; ln.indexOf(&#39;#&#39;); if (ci &gt;&#x3D; 0) ln &#x3D; ln.substring(0, ci); ln &#x3D; ln.trim(); int n &#x3D; ln.length(); if (n !&#x3D; 0) &#123; if ((ln.indexOf(&#39; &#39;) &gt;&#x3D; 0) || (ln.indexOf(&#39;\t&#39;) &gt;&#x3D; 0)) fail(service, u, lc, &quot;Illegal configuration-file syntax&quot;); int cp &#x3D; ln.codePointAt(0); if (!Character.isJavaIdentifierStart(cp)) fail(service, u, lc, &quot;Illegal provider-class name: &quot; + ln); for (int i &#x3D; Character.charCount(cp); i &lt; n; i +&#x3D; Character.charCount(cp)) &#123; cp &#x3D; ln.codePointAt(i); if (!Character.isJavaIdentifierPart(cp) &amp;&amp; (cp !&#x3D; &#39;.&#39;)) fail(service, u, lc, &quot;Illegal provider-class name: &quot; + ln); &#125; if (!providers.containsKey(ln) &amp;&amp; !names.contains(ln)) names.add(ln); &#125; return lc + 1; &#125; &#x2F;&#x2F;解析配置文件，解析指定的url配置文件 &#x2F;&#x2F;使用parseLine方法进行解析，未被实例化的服务提供者会被保存到缓存中去 private Iterator&lt;String&gt; parse(Class&lt;?&gt; service, URL u) throws ServiceConfigurationError &#123; InputStream in &#x3D; null; BufferedReader r &#x3D; null; ArrayList&lt;String&gt; names &#x3D; new ArrayList&lt;&gt;(); try &#123; in &#x3D; u.openStream(); r &#x3D; new BufferedReader(new InputStreamReader(in, &quot;utf-8&quot;)); int lc &#x3D; 1; while ((lc &#x3D; parseLine(service, u, r, lc, names)) &gt;&#x3D; 0); &#125; return names.iterator(); &#125; &#x2F;&#x2F;服务提供者查找的迭代器 private class LazyIterator implements Iterator&lt;S&gt; &#123; Class&lt;S&gt; service;&#x2F;&#x2F;服务提供者接口 ClassLoader loader;&#x2F;&#x2F;类加载器 Enumeration&lt;URL&gt; configs &#x3D; null;&#x2F;&#x2F;保存实现类的url Iterator&lt;String&gt; pending &#x3D; null;&#x2F;&#x2F;保存实现类的全名 String nextName &#x3D; null;&#x2F;&#x2F;迭代器中下一个实现类的全名 private LazyIterator(Class&lt;S&gt; service, ClassLoader loader) &#123; this.service &#x3D; service; this.loader &#x3D; loader; &#125; private boolean hasNextService() &#123; if (nextName !&#x3D; null) &#123; return true; &#125; if (configs &#x3D;&#x3D; null) &#123; try &#123; String fullName &#x3D; PREFIX + service.getName(); if (loader &#x3D;&#x3D; null) configs &#x3D; ClassLoader.getSystemResources(fullName); else configs &#x3D; loader.getResources(fullName); &#125; &#125; while ((pending &#x3D;&#x3D; null) || !pending.hasNext()) &#123; if (!configs.hasMoreElements()) &#123; return false; &#125; pending &#x3D; parse(service, configs.nextElement()); &#125; nextName &#x3D; pending.next(); return true; &#125; private S nextService() &#123; if (!hasNextService()) throw new NoSuchElementException(); String cn &#x3D; nextName; nextName &#x3D; null; Class&lt;?&gt; c &#x3D; null; try &#123; c &#x3D; Class.forName(cn, false, loader); &#125; if (!service.isAssignableFrom(c)) &#123; fail(service, &quot;Provider &quot; + cn + &quot; not a subtype&quot;); &#125; try &#123; S p &#x3D; service.cast(c.newInstance()); providers.put(cn, p); return p; &#125; &#125; public boolean hasNext() &#123; if (acc &#x3D;&#x3D; null) &#123; return hasNextService(); &#125; else &#123; PrivilegedAction&lt;Boolean&gt; action &#x3D; new PrivilegedAction&lt;Boolean&gt;() &#123; public Boolean run() &#123; return hasNextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125; &#125; public S next() &#123; if (acc &#x3D;&#x3D; null) &#123; return nextService(); &#125; else &#123; PrivilegedAction&lt;S&gt; action &#x3D; new PrivilegedAction&lt;S&gt;() &#123; public S run() &#123; return nextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125; &#125; public void remove() &#123; throw new UnsupportedOperationException(); &#125; &#125; &#x2F;&#x2F;获取迭代器 &#x2F;&#x2F;返回遍历服务提供者的迭代器 &#x2F;&#x2F;以懒加载的方式加载可用的服务提供者 &#x2F;&#x2F;懒加载的实现是：解析配置文件和实例化服务提供者的工作由迭代器本身完成 public Iterator&lt;S&gt; iterator() &#123; return new Iterator&lt;S&gt;() &#123; &#x2F;&#x2F;按照实例化顺序返回已经缓存的服务提供者实例 Iterator&lt;Map.Entry&lt;String,S&gt;&gt; knownProviders &#x3D; providers.entrySet().iterator(); public boolean hasNext() &#123; if (knownProviders.hasNext()) return true; return lookupIterator.hasNext(); &#125; public S next() &#123; if (knownProviders.hasNext()) return knownProviders.next().getValue(); return lookupIterator.next(); &#125; public void remove() &#123; throw new UnsupportedOperationException(); &#125; &#125;; &#125; &#x2F;&#x2F;为指定的服务使用指定的类加载器来创建一个ServiceLoader public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service, ClassLoader loader) &#123; return new ServiceLoader&lt;&gt;(service, loader); &#125; &#x2F;&#x2F;使用线程上下文的类加载器来创建ServiceLoader public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) &#123; ClassLoader cl &#x3D; Thread.currentThread().getContextClassLoader(); return ServiceLoader.load(service, cl); &#125; &#x2F;&#x2F;使用扩展类加载器为指定的服务创建ServiceLoader &#x2F;&#x2F;只能找到并加载已经安装到当前Java虚拟机中的服务提供者，应用程序类路径中的服务提供者将被忽略 public static &lt;S&gt; ServiceLoader&lt;S&gt; loadInstalled(Class&lt;S&gt; service) &#123; ClassLoader cl &#x3D; ClassLoader.getSystemClassLoader(); ClassLoader prev &#x3D; null; while (cl !&#x3D; null) &#123; prev &#x3D; cl; cl &#x3D; cl.getParent(); &#125; return ServiceLoader.load(service, prev); &#125; public String toString() &#123; return &quot;java.util.ServiceLoader[&quot; + service.getName() + &quot;]&quot;; &#125;&#125; ServiceLoader不是实例化以后，就去读取配置文件中的具体实现，并进行实例化。而是等到使用迭代器去遍历的时候，才会加载对应的配置文件去解析，调用hasNext方法的时候会去加载配置文件进行解析，调用next方法的时候进行实例化并缓存。 所有的配置文件只会加载一次，服务提供者也只会被实例化一次，重新加载配置文件可使用reload方法。 SPI缺点通过上面的解析，可以发现，我们使用SPI查找具体的实现的时候，需要遍历所有的实现，并实例化，然后我们在循环中才能找到我们需要实现。这应该也是最大的缺点，需要把所有的实现都实例化了，即便我们不需要，也都给实例化了。 有关SPI的东西暂先了解到这里，有深入的以后再添加。 可以看到此时迭代器中有两个驱动，mysql和postgresql的都被加载了。有关两个驱动都加载了，具体使用哪个驱动，请自行深入jdbc的源码。这里不做过多解析。 SPI的使用步骤总结看完上面的数据库驱动的解析，应该都能知道大概的流程了： 有关组织或者公司定义标准。 具体厂商或者框架开发者实现。 程序猿使用。 定义标准定义标准，就是定义接口。比如接口java.sql.Driver 具体厂商或者框架开发者实现。厂商或者框架开发者开发具体的实现： 在META-INF/services目录下定义一个名字为接口全限定名的文件，比如java.sql.Driver文件，文件内容是具体的实现名字，比如me.cxis.sql.MyDriver。 写具体的实现me.cxis.sql.MyDriver，都是对接口Driver的实现。 程序猿使用我们会引用具体厂商的jar包来实现我们的功能： 12345678ServiceLoader&lt;Driver&gt; loadedDrivers &#x3D; ServiceLoader.load(Driver.class);&#x2F;&#x2F;获取迭代器Iterator&lt;Driver&gt; driversIterator &#x3D; loadedDrivers.iterator();&#x2F;&#x2F;遍历while(driversIterator.hasNext()) &#123; driversIterator.next(); &#x2F;&#x2F;可以做具体的业务逻辑&#125; SPI相关的源码解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259&#x2F;&#x2F;ServiceLoader实现了Iterable接口，可以遍历所有的服务实现者public final class ServiceLoader&lt;S&gt; implements Iterable&lt;S&gt;&#123; &#x2F;&#x2F;查找配置文件的目录 private static final String PREFIX &#x3D; &quot;META-INF&#x2F;services&#x2F;&quot;; &#x2F;&#x2F;表示要被加载的服务的类或接口 private final Class&lt;S&gt; service; &#x2F;&#x2F;这个ClassLoader用来定位，加载，实例化服务提供者 private final ClassLoader loader; &#x2F;&#x2F; 访问控制上下文 private final AccessControlContext acc; &#x2F;&#x2F; 缓存已经被实例化的服务提供者，按照实例化的顺序存储 private LinkedHashMap&lt;String,S&gt; providers &#x3D; new LinkedHashMap&lt;&gt;(); &#x2F;&#x2F; 迭代器 private LazyIterator lookupIterator; &#x2F;&#x2F;重新加载，就相当于重新创建ServiceLoader了，用于新的服务提供者安装到正在运行的Java虚拟机中的情况。 public void reload() &#123; &#x2F;&#x2F;清空缓存中所有已实例化的服务提供者 providers.clear(); &#x2F;&#x2F;新建一个迭代器，该迭代器会从头查找和实例化服务提供者 lookupIterator &#x3D; new LazyIterator(service, loader); &#125; &#x2F;&#x2F;私有构造器 &#x2F;&#x2F;使用指定的类加载器和服务创建服务加载器 &#x2F;&#x2F;如果没有指定类加载器，使用系统类加载器，就是应用类加载器。 private ServiceLoader(Class&lt;S&gt; svc, ClassLoader cl) &#123; service &#x3D; Objects.requireNonNull(svc, &quot;Service interface cannot be null&quot;); loader &#x3D; (cl &#x3D;&#x3D; null) ? ClassLoader.getSystemClassLoader() : cl; acc &#x3D; (System.getSecurityManager() !&#x3D; null) ? AccessController.getContext() : null; reload(); &#125; &#x2F;&#x2F;解析失败处理的方法 private static void fail(Class&lt;?&gt; service, String msg, Throwable cause) throws ServiceConfigurationError &#123; throw new ServiceConfigurationError(service.getName() + &quot;: &quot; + msg, cause); &#125; private static void fail(Class&lt;?&gt; service, String msg) throws ServiceConfigurationError &#123; throw new ServiceConfigurationError(service.getName() + &quot;: &quot; + msg); &#125; private static void fail(Class&lt;?&gt; service, URL u, int line, String msg) throws ServiceConfigurationError &#123; fail(service, u + &quot;:&quot; + line + &quot;: &quot; + msg); &#125; &#x2F;&#x2F;解析服务提供者配置文件中的一行 &#x2F;&#x2F;首先去掉注释校验，然后保存 &#x2F;&#x2F;返回下一行行号 &#x2F;&#x2F;重复的配置项和已经被实例化的配置项不会被保存 private int parseLine(Class&lt;?&gt; service, URL u, BufferedReader r, int lc, List&lt;String&gt; names) throws IOException, ServiceConfigurationError &#123; &#x2F;&#x2F;读取一行 String ln &#x3D; r.readLine(); if (ln &#x3D;&#x3D; null) &#123; return -1; &#125; &#x2F;&#x2F;#号代表注释行 int ci &#x3D; ln.indexOf(&#39;#&#39;); if (ci &gt;&#x3D; 0) ln &#x3D; ln.substring(0, ci); ln &#x3D; ln.trim(); int n &#x3D; ln.length(); if (n !&#x3D; 0) &#123; if ((ln.indexOf(&#39; &#39;) &gt;&#x3D; 0) || (ln.indexOf(&#39;\t&#39;) &gt;&#x3D; 0)) fail(service, u, lc, &quot;Illegal configuration-file syntax&quot;); int cp &#x3D; ln.codePointAt(0); if (!Character.isJavaIdentifierStart(cp)) fail(service, u, lc, &quot;Illegal provider-class name: &quot; + ln); for (int i &#x3D; Character.charCount(cp); i &lt; n; i +&#x3D; Character.charCount(cp)) &#123; cp &#x3D; ln.codePointAt(i); if (!Character.isJavaIdentifierPart(cp) &amp;&amp; (cp !&#x3D; &#39;.&#39;)) fail(service, u, lc, &quot;Illegal provider-class name: &quot; + ln); &#125; if (!providers.containsKey(ln) &amp;&amp; !names.contains(ln)) names.add(ln); &#125; return lc + 1; &#125; &#x2F;&#x2F;解析配置文件，解析指定的url配置文件 &#x2F;&#x2F;使用parseLine方法进行解析，未被实例化的服务提供者会被保存到缓存中去 private Iterator&lt;String&gt; parse(Class&lt;?&gt; service, URL u) throws ServiceConfigurationError &#123; InputStream in &#x3D; null; BufferedReader r &#x3D; null; ArrayList&lt;String&gt; names &#x3D; new ArrayList&lt;&gt;(); try &#123; in &#x3D; u.openStream(); r &#x3D; new BufferedReader(new InputStreamReader(in, &quot;utf-8&quot;)); int lc &#x3D; 1; while ((lc &#x3D; parseLine(service, u, r, lc, names)) &gt;&#x3D; 0); &#125; return names.iterator(); &#125; &#x2F;&#x2F;服务提供者查找的迭代器 private class LazyIterator implements Iterator&lt;S&gt; &#123; Class&lt;S&gt; service;&#x2F;&#x2F;服务提供者接口 ClassLoader loader;&#x2F;&#x2F;类加载器 Enumeration&lt;URL&gt; configs &#x3D; null;&#x2F;&#x2F;保存实现类的url Iterator&lt;String&gt; pending &#x3D; null;&#x2F;&#x2F;保存实现类的全名 String nextName &#x3D; null;&#x2F;&#x2F;迭代器中下一个实现类的全名 private LazyIterator(Class&lt;S&gt; service, ClassLoader loader) &#123; this.service &#x3D; service; this.loader &#x3D; loader; &#125; private boolean hasNextService() &#123; if (nextName !&#x3D; null) &#123; return true; &#125; if (configs &#x3D;&#x3D; null) &#123; try &#123; String fullName &#x3D; PREFIX + service.getName(); if (loader &#x3D;&#x3D; null) configs &#x3D; ClassLoader.getSystemResources(fullName); else configs &#x3D; loader.getResources(fullName); &#125; &#125; while ((pending &#x3D;&#x3D; null) || !pending.hasNext()) &#123; if (!configs.hasMoreElements()) &#123; return false; &#125; pending &#x3D; parse(service, configs.nextElement()); &#125; nextName &#x3D; pending.next(); return true; &#125; private S nextService() &#123; if (!hasNextService()) throw new NoSuchElementException(); String cn &#x3D; nextName; nextName &#x3D; null; Class&lt;?&gt; c &#x3D; null; try &#123; c &#x3D; Class.forName(cn, false, loader); &#125; if (!service.isAssignableFrom(c)) &#123; fail(service, &quot;Provider &quot; + cn + &quot; not a subtype&quot;); &#125; try &#123; S p &#x3D; service.cast(c.newInstance()); providers.put(cn, p); return p; &#125; &#125; public boolean hasNext() &#123; if (acc &#x3D;&#x3D; null) &#123; return hasNextService(); &#125; else &#123; PrivilegedAction&lt;Boolean&gt; action &#x3D; new PrivilegedAction&lt;Boolean&gt;() &#123; public Boolean run() &#123; return hasNextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125; &#125; public S next() &#123; if (acc &#x3D;&#x3D; null) &#123; return nextService(); &#125; else &#123; PrivilegedAction&lt;S&gt; action &#x3D; new PrivilegedAction&lt;S&gt;() &#123; public S run() &#123; return nextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125; &#125; public void remove() &#123; throw new UnsupportedOperationException(); &#125; &#125; &#x2F;&#x2F;获取迭代器 &#x2F;&#x2F;返回遍历服务提供者的迭代器 &#x2F;&#x2F;以懒加载的方式加载可用的服务提供者 &#x2F;&#x2F;懒加载的实现是：解析配置文件和实例化服务提供者的工作由迭代器本身完成 public Iterator&lt;S&gt; iterator() &#123; return new Iterator&lt;S&gt;() &#123; &#x2F;&#x2F;按照实例化顺序返回已经缓存的服务提供者实例 Iterator&lt;Map.Entry&lt;String,S&gt;&gt; knownProviders &#x3D; providers.entrySet().iterator(); public boolean hasNext() &#123; if (knownProviders.hasNext()) return true; return lookupIterator.hasNext(); &#125; public S next() &#123; if (knownProviders.hasNext()) return knownProviders.next().getValue(); return lookupIterator.next(); &#125; public void remove() &#123; throw new UnsupportedOperationException(); &#125; &#125;; &#125; &#x2F;&#x2F;为指定的服务使用指定的类加载器来创建一个ServiceLoader public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service, ClassLoader loader) &#123; return new ServiceLoader&lt;&gt;(service, loader); &#125; &#x2F;&#x2F;使用线程上下文的类加载器来创建ServiceLoader public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) &#123; ClassLoader cl &#x3D; Thread.currentThread().getContextClassLoader(); return ServiceLoader.load(service, cl); &#125; &#x2F;&#x2F;使用扩展类加载器为指定的服务创建ServiceLoader &#x2F;&#x2F;只能找到并加载已经安装到当前Java虚拟机中的服务提供者，应用程序类路径中的服务提供者将被忽略 public static &lt;S&gt; ServiceLoader&lt;S&gt; loadInstalled(Class&lt;S&gt; service) &#123; ClassLoader cl &#x3D; ClassLoader.getSystemClassLoader(); ClassLoader prev &#x3D; null; while (cl !&#x3D; null) &#123; prev &#x3D; cl; cl &#x3D; cl.getParent(); &#125; return ServiceLoader.load(service, prev); &#125; public String toString() &#123; return &quot;java.util.ServiceLoader[&quot; + service.getName() + &quot;]&quot;; &#125;&#125; ServiceLoader不是实例化以后，就去读取配置文件中的具体实现，并进行实例化。而是等到使用迭代器去遍历的时候，才会加载对应的配置文件去解析，调用hasNext方法的时候会去加载配置文件进行解析，调用next方法的时候进行实例化并缓存。 所有的配置文件只会加载一次，服务提供者也只会被实例化一次，重新加载配置文件可使用reload方法。 SPI缺点通过上面的解析，可以发现，我们使用SPI查找具体的实现的时候，需要遍历所有的实现，并实例化，然后我们在循环中才能找到我们需要实现。这应该也是最大的缺点，需要把所有的实现都实例化了，即便我们不需要，也都给实例化了。 有关SPI的东西暂先了解到这里，有深入的以后再添加。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[从头开始写一个迷你dubbo]]></title>
      <url>%2F2017%2F04%2F14%2F%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E4%B8%80%E4%B8%AA%E8%BF%B7%E4%BD%A0dubbo%2F</url>
      <content type="text"><![CDATA[从头开始写一个迷你的dubbo，仅用作学习用，学习的过程中更深入的了解下dubbo，同时也补充下其他的知识。 工程说明mini-dubbo-provider服务提供者端，主要是暴露服务，处理消费者端请求等 mini-dubbo-consumer服务消费者端，主要作用是引用服务 mini-dubbo-common一些公用类 mini-dubbo-sample-*sample是示例项目 目标 可以使用API和Spring两种方式启动 提供完整暴露服务和服务引用功能 提供多协议支持 实现注册中心支持 提供自定义编解码 使用Netty和Mina 提供对多种序列化的支持 已有实现 可以使用API启动 简单的暴露和服务引用 现使用TCP协议 使用Netty 使用Netty的编解码 使用Java序列化方式 源码地址https://github.com/dachengxi/mini-dubbo 过程现在的版本就是一个简单的RPC调用功能。下面是大概的过程： 服务提供者端DubboProvider，这是API，用来启动服务暴露的功能，会调用Netty实现的服务端暴露服务，并监听处理。 编写Netty服务和Handler。 实现请求和相应分别对应的两个bean：Request和Response。 服务消费者端DubboConsumer，这是API，用来初始化消费者，和调用服务提供者。实际应该是先获取代理，在真正使用的时候采取调用服务提供者端，现在都在一步中完成了。 编写获取代理类DubboConsumerProxy。 编写Netty客户端和Handler。 测试都在sample的模块下。 还有很多要做的～加油！！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[关于Servlet线程安全性和DispatcherServlet的线程安全性的解析]]></title>
      <url>%2F2017%2F04%2F13%2F%E5%85%B3%E4%BA%8EServlet%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E6%80%A7%E5%92%8CDispatcherServlet%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E6%80%A7%E7%9A%84%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[我们知道在Servlet第一次被调用的时候，Servlet容器会根据web.xml中配置的信息去实例化Servlet，而且这个Servlet只会被实例化一次。当多个请求同时到来时，可能会使用同一个Servlet进行处理，这时候就会涉及到线程安全的问题。 纠结！！！ Servlet的线程安全性？不确定Servlet是单实例多线程的方式来处理请求，这应该就是造成线程安全的主要原因了。我们知道Servlet本身是无状态的，也就是说Servlet本身是线程安全的，但是为什么网上都说Servlet是线程不安全的呢？可能就是根据一句多个线程会同时访问一个Servlet实例来判断的把。 而Servlet是不是线程安全的，主要是由实现来决定的，如果一个Servlet实现有实例变量，并且会被多线程更改，这时候就不是线程安全的；而如果有实例变量，但是变量又是只读的，这时候不涉及变量的更改，就是线程安全的；而如果一个Servlet实现没有实例变量，都是局部变量，这时候也是线程安全的。 HttpServletHttpServlet是Servlet的一个实现，继承自GenericServlet，并且也是我们自定义Servlet所要继承的一个类，HttpServlet是不是线程安全的，也不好说，也得根据在使用过程中不同情况来确定。另外对于Servlet中的属性的使用也会对线程安全产生影响，见下面。 自定义的Servlet通常我们开发自己的Servlet都是继承HttpServlet，然后重写相关方法，这时候线程安全和不安全都是靠我们自己来决定了，没有实例变量的时候，就是线程安全的；而有实例变量的时候，并且会被改变，这时候就不是线程安全的了，需要使用其他手段保证线程安全。另外对于Servlet中的属性的使用也会对线程安全产生影响，见下面。 如何控制Servlet的线程安全性变量的线程安全我们知道当没有实例变量的时候，就基本不存在线程不安全的问题了，所以不使用实例变量是一种方法。 属性的线程安全 ServletContext，不是线程安全的，多线程可以同时读写。使用时要注意。 HttpSession，不是线程安全的，比如用户打开多个浏览器窗口时候就会产生多个请求针对同一个session的操作。使用时要注意。 ServletRequest，线程安全的，它对应着一个request请求，所以说是线程安全的。 SingleThreadModel我们还可以使用这个接口来创建自己的实现，可以保证线程安全，同一时刻只有一个线程可以执行Servlet实例的service方法，这就成了单线程了，该方式已经被废弃。 常用框架的线程安全性SpringMVC，我们知道Spring的IOC容器默认管理的bean是单实例的，对于SpringMVC的Controller来说也是单实例的，所以开发的时候需要保证线程安全。 Struts1中的action也是单实例的，使用的时候会有线程安全问题。 Struts2中Action会为每一个请求产生一个实例，所以不存在线程安全问题。 注意：当使用Spring管理Struts2的Action时，需要将Action的scope设置为prototype，因为Spring IOC容器中bean默认是单例的。 DispatcherServlet的线程安全性在应用启动的时候，就会根据web.xml中配置的有关Spring和SpringMVC的配置启动初始化，对于SpringMVC初始化的是DispatcherServlet，对于Servlet初始化只会进行一次，并且只有一个实例，所以DispatcherServlet只会存在一个。 但是当多线程同时访问DispatcherServlet的时候是线程安全的，因为DispatcherServlet中的内部属性都不会影响线程安全，所以DispatcherServlet可以忽略线程安全的问题。 虽然DispatcherServlet可以认为是线程安全的，但是SpringMVC中的Controller不是。Controller也是单例的，每个请求对应一个Controller中的方法，方法如果没有使用实例变量，可以认为是线程安全的，但是如果有实例变量就要考虑线程安全的问题了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java Servlet工作流程以及源码解析]]></title>
      <url>%2F2017%2F04%2F13%2FJava%20Servlet%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E4%BB%A5%E5%8F%8A%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[关于Servlet的学习还是在上学的时候，自学Java，也就是只是了解了Servlet是什么以及怎么使用，现在慢慢的明白很多很多的框架等等都是在Servlet上做的扩展，也开始明白自己的基础不好。现在回头来学习一下Servlet的相关知识。 Servlet的使用对于Servlet怎么写，以及在Servlet容器（这里特指Tomcat）中怎么配置几乎都忘记了，先回头了下一个最简单的Servlet的开发。 这里以一个最简单的自定义Servlet显示一个页面来作为例子。 首先写一个TestServlet，继承HttpServlet： 123456789101112131415161718192021222324252627282930313233343536373839package me.cxis.servlet;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.io.PrintWriter;&#x2F;** * Created by cheng.xi on 2017-04-12 23:42. *&#x2F;public class TestServlet extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; System.out.println(&quot;doGet...&quot;); resp.setContentType( &quot;text&#x2F;html;charset&#x3D;UTF-8&quot; ); PrintWriter out &#x3D; resp.getWriter(); try &#123; out.println( &quot;&lt;html&gt;&quot; ); out.println( &quot;&lt;head&gt;&quot; ); out.println( &quot;&lt;title&gt;TestServlet&lt;&#x2F;title&gt;&quot; ); out.println( &quot;&lt;&#x2F;head&gt;&quot; ); out.println( &quot;&lt;body&gt;&quot; ); out.println( &quot;&lt;h2&gt;testServlet&lt;&#x2F;h2&gt;&quot; ); out.println( &quot;&lt;&#x2F;body&gt;&quot; ); out.println( &quot;&lt;&#x2F;html&gt;&quot; ); &#125; finally &#123; out.close(); &#125; &#125; @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; System.out.println(&quot;doPost...&quot;); this.doGet(req,resp); &#125;&#125; 然后在web.xml中配置刚才写的servlet： 1234567891011121314&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;web-app xmlns&#x3D;&quot;http:&#x2F;&#x2F;xmlns.jcp.org&#x2F;xml&#x2F;ns&#x2F;javaee&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;xmlns.jcp.org&#x2F;xml&#x2F;ns&#x2F;javaee http:&#x2F;&#x2F;xmlns.jcp.org&#x2F;xml&#x2F;ns&#x2F;javaee&#x2F;web-app_3_1.xsd&quot; version&#x3D;&quot;3.1&quot;&gt; &lt;servlet&gt; &lt;servlet-name&gt;testServlet&lt;&#x2F;servlet-name&gt; &lt;servlet-class&gt;me.cxis.servlet.TestServlet&lt;&#x2F;servlet-class&gt; &lt;&#x2F;servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;testServlet&lt;&#x2F;servlet-name&gt; &lt;url-pattern&gt;&#x2F;testServlet&lt;&#x2F;url-pattern&gt; &lt;&#x2F;servlet-mapping&gt;&lt;&#x2F;web-app&gt; 这就可以了，启动Servlet容器，这里是tomcat，然后访问http://localhost:8080/testServlet就可以看到结果了。 写到这里感觉大学时光又回来了，那时候做项目的时候，可没少写了servlet，老师，学长，实验室，三年，几个人每天就写代码，太单纯！ Servlet的工作流程这里只看下一个请求到来时候Servlet是怎么处理的流程，不涉及容器的启动初始化之类的。 大概流程 客户端发起一个http请求，比如get类型。 Servlet容器接收到请求，根据请求信息调用相应的Servlet。 Servlet来处理具体的业务逻辑，也就是我们写的Servlet中的代码。 Servlet处理完成之后，返回给Servlet容器。 Servlet容器将最后结果返回给客户端。 具体流程 客户端发起一个http请求，比如get类型。 Servlet容器接收到请求，根据请求信息，封装成HttpServletRequest和HttpServletResponse对象。 Servlet容器调用HttpServlet的init()方法，init方法只在第一次请求的时候被调用。 Servlet容器调用service()方法。 service()方法根据请求类型，这里是get类型，分别调用doGet或者doPost方法，这里调用doGet方法。 doXXX方法中是我们自己写的业务逻辑。 业务逻辑处理完成之后，返回给Servlet容器，然后容器将结果返回给客户端。 容器关闭时候，会调用destory方法 这其中的2,3,4,5,6使我们要关注的，其他的步骤是容器实现的，先不了解具体信息。 注意： 同一个Servlet只会被初始化一次，也就是init方法只会被调用一次。 同一个Servlet只存在一个实例，而可能会有多个请求同时请求一个Servlet，所以存在线程安全问题。 Servlet生命周期Servlet生命周期由容器来管理，大致包含了四个阶段： 加载和实例化，由容器负责加载和实例化Servlet。 初始化，容器会调用init方法初始化Servlet对象，init方法只会被调用一次。 处理请求，容器会调用service方法进行请求的处理，service会调用相应的doXxx方法来处理。 服务销毁，即一个Servlet实例从服务中被移除的时候，会调用destory方法，这个方法也只会被执行一次。 下面我们解析的是从初始化开始，对于加载和实例化不做说明。 Servlet流程的源码分析初始化，init请求到来时候，会由容器先处理，然后调用Servlet的init方法进行初始化，init方法在GenericServlet中： 12345678@Overridepublic void init(ServletConfig config) throws ServletException &#123; &#x2F;&#x2F;config是由容器处理的，里面包含了请求和Servlet的相关配置信息 this.config &#x3D; config; &#x2F;&#x2F;由子类进行实现的init方法 &#x2F;&#x2F;我们可以重写init方法，进行一些资源的初始化等的操作 this.init();&#125; 有关init方法只会执行一次的问题，这里并没有体现到，这是具体的实现，而有关判断是在容器的StandardWrapper类中，会判断是否已经实例化，没有实例化就调用实例化方法实例Servlet，这就会调用init方法。 处理请求service当初始化完成之后，容器会进行处理，然后容器再去调用Servlet的service方法去进行请求的处理，首先进入HttpServlet的service方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; &#x2F;&#x2F;请求类型方法 String method &#x3D; req.getMethod(); &#x2F;&#x2F;对每种类型分别进行处理 if (method.equals(METHOD_GET)) &#123;&#x2F;&#x2F;get方法 &#x2F;&#x2F;get方法涉及到缓存的问题，会对最后修改时间进行判断 long lastModified &#x3D; getLastModified(req); &#x2F;&#x2F;不支持lastModified，直接调用doGet方法进行处理 if (lastModified &#x3D;&#x3D; -1) &#123; &#x2F;&#x2F; servlet doesn&#39;t support if-modified-since, no reason &#x2F;&#x2F; to go through further expensive logic doGet(req, resp); &#125; else &#123; &#x2F;&#x2F;支持lastModified long ifModifiedSince; try &#123; &#x2F;&#x2F;从请求头中获取If-Modified-Since属性的值 ifModifiedSince &#x3D; req.getDateHeader(HEADER_IFMODSINCE); &#125; catch (IllegalArgumentException iae) &#123; &#x2F;&#x2F; Invalid date header - proceed as if none was set ifModifiedSince &#x3D; -1; &#125; &#x2F;&#x2F;比较时间 if (ifModifiedSince &lt; (lastModified &#x2F; 1000 * 1000)) &#123; &#x2F;&#x2F;Servlet的修改时间晚，表示数据比客户端新 &#x2F;&#x2F;需要修改时间，并调用get方法处理 maybeSetLastModified(resp, lastModified); doGet(req, resp); &#125; else &#123; &#x2F;&#x2F;没有修改 直接返回状态给客户端 resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); &#125; &#125; &#125; else if (method.equals(METHOD_HEAD)) &#123;&#x2F;&#x2F;Head方法 long lastModified &#x3D; getLastModified(req); maybeSetLastModified(resp, lastModified); doHead(req, resp); &#125; else if (method.equals(METHOD_POST)) &#123;&#x2F;&#x2F;post方法 doPost(req, resp); &#125; else if (method.equals(METHOD_PUT)) &#123;&#x2F;&#x2F;put方法 doPut(req, resp); &#125; else if (method.equals(METHOD_DELETE)) &#123;&#x2F;&#x2F;delete方法 doDelete(req, resp); &#125; else if (method.equals(METHOD_OPTIONS)) &#123;&#x2F;&#x2F;options方法 doOptions(req,resp); &#125; else if (method.equals(METHOD_TRACE)) &#123;&#x2F;&#x2F;trace方法 doTrace(req,resp); &#125; else &#123; &#x2F;&#x2F;servlet不支持其他类型方法 String errMsg &#x3D; lStrings.getString(&quot;http.method_not_implemented&quot;); Object[] errArgs &#x3D; new Object[1]; errArgs[0] &#x3D; method; errMsg &#x3D; MessageFormat.format(errMsg, errArgs); resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg); &#125; &#125; 可以看到，service方法处理请求，会根据请求的类型分别进行处理，get会涉及到最后修改时间问题。这些doXxx方法都会有默认的实现，如果子类不做重写就会执行默认方法。 请求处理完成之后会回到容器中由容器进行其他的处理。 销毁方法destory如果我们重写了destory方法，在容器关闭或者Servlet实例移除的时候，会回调我们的destory方法，一般用来释放资源，这个方法也只会被调用一次。 上面只是最简单的一个Servlet流程，没有涉及到更多的内容，比如上下文，比如session，filter等等，还有一个就是线程安全问题，这个问题会在下面文章继续说明，流程的解析就到这里。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring中AOP源码深入解析]]></title>
      <url>%2F2017%2F04%2F12%2FSpring%E4%B8%ADAOP%E6%BA%90%E7%A0%81%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[有关AOP相关概念以及Spring AOP相关概念和Spring AOP的使用不再重复。关于AOP在Spring中的地位，不用说相信我们都知道，也都会用，但是对于更深入的东西，还未接触过，这里就对Spring AOP的相关源码进行说明一下，看看到底Spring中AOP是怎么实现的。 有关AOP的概念和Spring AOP相关配置，请参考其他两篇文章：AOP概念，原理，应用介绍 和 Spring中AOP的配置从1.0到5.0的演进 另外，本文使用的源码是Spring1.1.1版本的，之所以使用这么老的版本，是觉得相对来说简单一些，并且无关的东西更少，这样更容易去理解。对于后续版本新增功能可以在此基础上进行对比，理解的效果会更好。 示例程序首先我们还是先使用一个实例来看一下怎么使用，再从实例中一步一步跟进到源码中。 先定义业务接口和实现： LoginService： 12345678package me.cxis.spring.aop;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125; LoginServiceImpl： 123456789101112package me.cxis.spring.aop;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; public String login(String userName)&#123; System.out.println(&quot;正在登录&quot;); return &quot;success&quot;; &#125;&#125; 接着是三个通知类： 12345678910111213141516171819202122232425262728293031323334353637383940&#x2F;&#x2F;这里只是在登录方法调用之前打印一句话public class LogBeforeLogin implements MethodBeforeAdvice &#123; public void before(Method method, Object[] objects, Object o) throws Throwable &#123; System.out.println(&quot;有人要登录了。。。&quot;); &#125;&#125;package me.cxis.spring.aop.proxyfactory;import org.springframework.aop.AfterReturningAdvice;import org.springframework.aop.MethodBeforeAdvice;import java.lang.reflect.Method;&#x2F;** * Created by cheng.xi on 2017-03-29 10:56. *&#x2F;public class LogAfterLogin implements AfterReturningAdvice &#123; public void afterReturning(Object o, Method method, Object[] objects, Object o1) throws Throwable &#123; System.out.println(&quot;有人已经登录了。。。&quot;); &#125;&#125;package me.cxis.spring.aop.proxyfactory;import org.aopalliance.intercept.MethodInterceptor;import org.aopalliance.intercept.MethodInvocation;&#x2F;** * Created by cheng.xi on 2017-03-30 23:36. *&#x2F;public class LogAroundLogin implements MethodInterceptor &#123; public Object invoke(MethodInvocation invocation) throws Throwable &#123; System.out.println(&quot;有人要登录。。。&quot;); Object result &#x3D; invocation.proceed(); System.out.println(&quot;登录完了&quot;); return result; &#125;&#125; 测试方法： 1234567891011121314151617181920212223package me.cxis.spring.aop.proxyfactory;import org.springframework.aop.framework.ProxyFactory;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ProxyFactory proxyFactory &#x3D; new ProxyFactory();&#x2F;&#x2F;创建代理工厂 proxyFactory.setTarget(new LoginServiceImpl());&#x2F;&#x2F;设置目标对象 proxyFactory.addAdvice(new LogBeforeLogin());&#x2F;&#x2F;前置增强 proxyFactory.addAdvice(new LogAfterLogin());&#x2F;&#x2F;后置增强 &#x2F;&#x2F;proxyFactory.addAdvice(new LogAroundLogin());&#x2F;&#x2F;环绕增强 LoginService loginService &#x3D; (LoginService) proxyFactory.getProxy();&#x2F;&#x2F;从代理工厂中获取代理 loginService.login(&quot;x&quot;); &#125;&#125; 关于实例中要说明的：我们看到在使用的时候，直接获取的是一个代理，不是要使用的实现类，这也很好懂，之前文章都说过AOP其实就是代理模式，在编译期或者运行期，给我们原来的代码增加一些功能，变成一个代理。当我们调用的时候，实际就是调用的代理类。 源码解析对于源码的解析，我们这里使用的是代码的方式，没有选择xml配置文件的方式。关于xml配置的方式，后面再讲解。 创建AOP代理首先我们要明白，Spring中实现AOP，就是生成一个代理，然后在使用的时候调用代理。 创建代理工厂代码中首先创建一个代理工厂实例ProxyFactory proxyFactory = new ProxyFactory();代理工厂的作用就是使用编程的方式创建AOP代理。ProxyFactory继承自AdvisedSupport，AdvicedSupport是AOP代理的配置管理器。 设置目标对象然后是设置要代理的目标对象proxyFactory.setTarget(new LoginServiceImpl());，看下setTarget方法： 12345public void setTarget(Object target) &#123; &#x2F;&#x2F;先根据给定的目标实现类，创建一个单例的TargetSource &#x2F;&#x2F;然后设置TargetSource setTargetSource(new SingletonTargetSource(target));&#125; TargetSourceTargetSource用来获取当前的Target，也就是TargetSource中会保存着我们的的实现类。 12345678910111213141516public interface TargetSource &#123; &#x2F;&#x2F;返回目标类的类型 Class getTargetClass(); &#x2F;&#x2F;查看TargetSource是否是static的 &#x2F;&#x2F;静态的TargetSource每次都返回同一个Target boolean isStatic(); &#x2F;&#x2F;获取目标类的实例 Object getTarget() throws Exception; &#x2F;&#x2F;释放目标类 void releaseTarget(Object target) throws Exception;&#125; SingletonTargetSourceTargetSource的默认实现，是一个单例的TargetSource，isStatic方法直接返回true。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public final class SingletonTargetSource implements TargetSource, Serializable &#123; &#x2F;&#x2F;用来保存目标类 private final Object target; &#x2F;&#x2F;构造方法 public SingletonTargetSource(Object target) &#123; this.target &#x3D; target; &#125; &#x2F;&#x2F;直接返回目标类的类型 public Class getTargetClass() &#123; return target.getClass(); &#125; &#x2F;&#x2F;返回目标类 public Object getTarget() &#123; return this.target; &#125; &#x2F;&#x2F;释放目标类，这里啥也没做 public void releaseTarget(Object o) &#123; &#x2F;&#x2F; Nothing to do &#125; &#x2F;&#x2F;直接返回true public boolean isStatic() &#123; return true; &#125; &#x2F;&#x2F;equals方法 public boolean equals(Object other) &#123; &#x2F;&#x2F;相等，返回true if (this &#x3D;&#x3D; other) &#123; return true; &#125; &#x2F;&#x2F;不是SingletonTargetSource类型的返回false if (!(other instanceof SingletonTargetSource)) &#123; return false; &#125; SingletonTargetSource otherTargetSource &#x3D; (SingletonTargetSource) other; &#x2F;&#x2F;判断目标类是否相等 return ObjectUtils.nullSafeEquals(this.target, otherTargetSource.target); &#125; &#x2F;&#x2F;toString方法 public String toString() &#123; return &quot;SingletonTargetSource: target&#x3D;(&quot; + target + &quot;)&quot;; &#125;&#125; 上面是有关TargetSource和SingletonTargetSource的说明，接着往下一步就是设置目标类setTargetSource方法，在AdvisedSupport类中： 1234567public void setTargetSource(TargetSource targetSource) &#123; if (isActive() &amp;&amp; getOptimize()) &#123; throw new AopConfigException(&quot;Can&#39;t change target with an optimized CGLIB proxy: it has its own target&quot;); &#125; &#x2F;&#x2F;么有做什么处理，只是将我们构建的TargetSource缓存起来 this.targetSource &#x3D; targetSource;&#125; 添加通知上面设置了要代理的目标类之后，接着是添加通知，也就是添加增强类，proxyFactory.addAdvice()方法是添加增强类的方法。我们在例子中是这么使用的： 123proxyFactory.addAdvice(new LogBeforeLogin());&#x2F;&#x2F;前置增强proxyFactory.addAdvice(new LogAfterLogin());&#x2F;&#x2F;后置增强&#x2F;&#x2F;proxyFactory.addAdvice(new LogAroundLogin());&#x2F;&#x2F;环绕增强 addAdvice方法的参数是一个Advice类型的类，也就是通知或者叫增强，可以去我们的增强类中查看，我们都继承了各种Advice，比如MethodBeforeAdvice，AfterReturningAdvice，MethodInterceptor，这里先讲一下有关通知Advice的代码，然后再继续说明addAdvice方法。 Advice接口Advice不属于Spring，是AOP联盟定义的接口。Advice接口并没有定义任何方法，是一个空的接口，用来做标记，实现了此接口的的类是一个通知类。Advice有几个子接口： BeforeAdvice，前置增强，意思是在我们的目标类之前调用的增强。这个接口也没有定义任何方法。 AfterReturningAdvice，方法正常返回前的增强，该增强可以看到方法的返回值，但是不能更改返回值，该接口有一个方法afterReturning ThrowsAdvice，抛出异常时候的增强，也是一个标志接口，没有定义任何方法。 Interceptor，拦截器，也没有定义任何方法，表示一个通用的拦截器。不属于Spring，是AOP联盟定义的接口 DynamicIntroductionAdvice，动态引介增强，有一个方法implementsInterface。 MethodBeforeAdviceMethodBeforeAdvice接口，是BeforeAdvice的子接口，表示在方法前调用的增强，方法前置增强不能阻止方法的调用，但是能抛异常来使目标方法不继续执行。 12345678public interface MethodBeforeAdvice extends BeforeAdvice &#123; &#x2F;&#x2F;在给定的方法调用前，调用该方法 &#x2F;&#x2F;参数method是被代理的方法 &#x2F;&#x2F;参数args是被代理方法的参数 &#x2F;&#x2F;参数target是方法调用的目标，可能为null void before(Method m, Object[] args, Object target) throws Throwable;&#125; MethodInterceptorMethodInterceptor不属于Spring，是AOP联盟定义的接口，是Interceptor的子接口，我们通常叫做环绕增强。 123456public interface MethodInterceptor extends Interceptor &#123; &#x2F;&#x2F;在目标方法调用前后做一些事情 &#x2F;&#x2F;返回的是invocation.proceed()方法的返回值 Object invoke(MethodInvocation invocation) throws Throwable;&#125; 参数MethodInvocation是一个方法调用的连接点，接下来先看看MethodInvocation相关的代码。 Joinpoint连接点JointPoint接口，是一个通用的运行时连接点，运行时连接点是在一个静态连接点发生的事件。 123456789101112public interface Joinpoint &#123; &#x2F;&#x2F;开始调用拦截器链中的下一个拦截器 Object proceed() throws Throwable; &#x2F;&#x2F; Object getThis(); &#x2F;&#x2F; AccessibleObject getStaticPart(); &#125; Invocation接口Invocation接口是Joinpoint的子接口，表示程序的调用，一个Invocation就是一个连接点，可以被拦截器拦截。 123456public interface Invocation extends Joinpoint &#123; &#x2F;&#x2F;获取参数 Object[] getArguments();&#125; MethodInvocation接口MethodInvocation接口是Invocation的子接口，用来描述一个方法的调用。 1234567public interface MethodInvocation extends Invocation&#123; &#x2F;&#x2F;获取被调用的方法 Method getMethod();&#125; 另外还有一个ConstructorInvocation接口，也是Invocation的子接口，描述的是构造器的调用。 上面介绍完了Advice的相关定义，接着看往代理工厂中添加增强的addAdvice方法，addAdvice方法在AdvisedSupport类中： 12345678public void addAdvice(Advice advice) throws AopConfigException &#123; &#x2F;&#x2F;advisors是Advice列表，是一个LinkedList &#x2F;&#x2F;如果被添加进来的是一个Interceptor，会先被包装成一个Advice &#x2F;&#x2F;添加之前现获取advisor的大小，当做添加的Advice的位置 int pos &#x3D; (this.advisors !&#x3D; null) ? this.advisors.size() : 0; &#x2F;&#x2F;添加Advice addAdvice(pos, advice);&#125; 接着看addAdvice(pos, advice)方法： 1234567891011121314151617181920public void addAdvice(int pos, Advice advice) throws AopConfigException &#123; &#x2F;&#x2F;只能处理实现了AOP联盟的接口的拦截器 if (advice instanceof Interceptor &amp;&amp; !(advice instanceof MethodInterceptor)) &#123; throw new AopConfigException(getClass().getName() + &quot; only handles AOP Alliance MethodInterceptors&quot;); &#125; &#x2F;&#x2F;IntroductionInfo接口类型，表示引介信息 if (advice instanceof IntroductionInfo) &#123; &#x2F;&#x2F;不需要IntroductionAdvisor addAdvisor(pos, new DefaultIntroductionAdvisor(advice, (IntroductionInfo) advice)); &#125; &#x2F;&#x2F;动态引介增强的处理 else if (advice instanceof DynamicIntroductionAdvice) &#123; &#x2F;&#x2F;需要IntroductionAdvisor throw new AopConfigException(&quot;DynamicIntroductionAdvice may only be added as part of IntroductionAdvisor&quot;); &#125; else &#123; &#x2F;&#x2F;添加增强器，需要先把我们的增强包装成增强器，然后添加 addAdvisor(pos, new DefaultPointcutAdvisor(advice)); &#125;&#125; 我们看到添加增强的时候，实际调用添加增强器这个方法，首先需要把我们的Advice包装成一个PointCutAdvisor，然后在添加增强器。这里先了解一下有关PointCutAdvisor的相关信息。 Advisor接口Advisor，增强器，它持有一个增强Advice，还持有一个过滤器，来决定Advice可以用在哪里。 123456789public interface Advisor &#123; &#x2F;&#x2F;判断Advice是不是每个实例中都有 boolean isPerInstance(); &#x2F;&#x2F;返回持有的Advice Advice getAdvice();&#125; PointcutAdvisor是一个持有Pointcut切点的增强器，PointcutAdvisor现在就会持有一个Advice和一个Pointcut。 123456public interface PointcutAdvisor extends Advisor &#123; &#x2F;&#x2F;获取Pointcut Pointcut getPointcut();&#125; Pointcut接口切入点，定义了哪些连接点需要被织入横切逻辑。可以 12345678910public interface Pointcut &#123; &#x2F;&#x2F;类过滤器，可以知道哪些类需要拦截 ClassFilter getClassFilter(); &#x2F;&#x2F;方法匹配器，可以知道哪些方法需要拦截 MethodMatcher getMethodMatcher(); &#x2F;&#x2F; could add getFieldMatcher() without breaking most existing code Pointcut TRUE &#x3D; TruePointcut.INSTANCE; &#125; ClassFilter接口12345678public interface ClassFilter &#123; &#x2F;&#x2F;判断给定的类是不是要拦截 boolean matches(Class clazz); ClassFilter TRUE &#x3D; TrueClassFilter.INSTANCE;&#125; MethodMatcher接口1234567891011121314public interface MethodMatcher &#123; &#x2F; 静态方法匹配 boolean matches(Method m, Class targetClass); &#x2F;&#x2F;是否是运行时动态匹配 boolean isRuntime(); &#x2F;&#x2F;运行是动态匹配 boolean matches(Method m, Class targetClass, Object[] args); MethodMatcher TRUE &#x3D; TrueMethodMatcher.INSTANCE;&#125; 看完相关的定义之后，接着看方法new DefaultPointcutAdvisor(advice)，将Advice包装成一个DefaultPointcutAdvisor。其实就是将advice和默认的Pointcut包装进DefaultPointcutAdvisor。 DefaultPointcutAdvisor是Advisor的最常用的一个实现，可以使用任意类型的Pointcut和Advice，但是不能使用Introduction。 构造完成了DefaultPointcutAdvisor只有，接着就是添加增强器方法addAdvisor： 12345678910public void addAdvisor(int pos, Advisor advisor) throws AopConfigException &#123; &#x2F;&#x2F;引介增强器处理 if (advisor instanceof IntroductionAdvisor) &#123; addAdvisor(pos, (IntroductionAdvisor) advisor); &#125; else &#123; &#x2F;&#x2F;其他的增强器处理 addAdvisorInternal(pos, advisor); &#125;&#125; 首先看下非引介增强器的添加方法addAdvisorInternal： 1234567891011private void addAdvisorInternal(int pos, Advisor advice) throws AopConfigException &#123; if (isFrozen()) &#123; throw new AopConfigException(&quot;Cannot add advisor: config is frozen&quot;); &#125; &#x2F;&#x2F;把Advice添加到LinkedList中指定位置 this.advisors.add(pos, advice); &#x2F;&#x2F;同时更新一下Advisors数组 updateAdvisorArray(); &#x2F;&#x2F;通知监听器 adviceChanged();&#125; 然后看下关于引介增强器的添加addAdvisor，我们知道引介就是对目标类增加新的接口，所以引介增强，也就是对接口的处理： 123456789101112public void addAdvisor(int pos, IntroductionAdvisor advisor) throws AopConfigException &#123; &#x2F;&#x2F;对接口进行校验 advisor.validateInterfaces(); &#x2F;&#x2F; 遍历要添加的接口，添加 for (int i &#x3D; 0; i &lt; advisor.getInterfaces().length; i++) &#123; &#x2F;&#x2F;就是添加到interfaces集合中，interfaces是一个HashSet addInterface(advisor.getInterfaces()[i]); &#125; &#x2F;&#x2F;然后添加到advisors中 addAdvisorInternal(pos, advisor);&#125; 对于添加增强的步骤，就是把我们的增强器添加进代理工厂中，保存在一个LinkedList中，顺序是添加进来的顺序。 获取代理到目前为止，我们看到的都还是在组装代理工厂，并没有看到代理的生成，接下来proxyFactory.getProxy()这一步就是获取代理的过程，我们继续看ProxyFactory的getProxy方法： 123456public Object getProxy() &#123; &#x2F;&#x2F;创建一个AOP代理 AopProxy proxy &#x3D; createAopProxy(); &#x2F;&#x2F;返回代理 return proxy.getProxy();&#125; 我们知道一般创建代理会有两种方式，一种是JDK动态代理，另外一种是CGLIB动态代理，而这里的创建AOP代理就是生成这两种代理中的一种。先看createAopProxy()方法，在AdvisedSupport类中： 1234567protected synchronized AopProxy createAopProxy() &#123; if (!this.isActive) &#123; activate(); &#125; &#x2F;&#x2F;获取AOP代理工厂，然后创建代理 return getAopProxyFactory().createAopProxy(this);&#125; 获取代理工厂这一步，这里就是默认获取一个DefaultAopProxyFactory实例，然后调用createAopProxy创建AOP代理： 1234567891011public AopProxy createAopProxy(AdvisedSupport advisedSupport) throws AopConfigException &#123; &#x2F;&#x2F;对于指定了使用CGLIB方式，或者代理的是类，或者代理的不是接口，就使用CGLIB的方式来创建代理 boolean useCglib &#x3D; advisedSupport.getOptimize() || advisedSupport.getProxyTargetClass() || advisedSupport.getProxiedInterfaces().length &#x3D;&#x3D; 0; if (useCglib) &#123; return CglibProxyFactory.createCglibProxy(advisedSupport); &#125; else &#123; &#x2F;&#x2F;使用JDK动态代理来创建代理 return new JdkDynamicAopProxy(advisedSupport); &#125;&#125; 获取完AOP代理之后返回，然后就是调用getProxy方法获取代理，这里分为CGLIB的获取方式和JDK动态代理的获取方式两种。 JDK动态代理方式获取代理JDK动态代理方式获取代理，实现在JdkDynamicAopProxy中： 123public Object getProxy() &#123; return getProxy(Thread.currentThread().getContextClassLoader());&#125; 1234567public Object getProxy(ClassLoader cl) &#123; &#x2F;&#x2F;JDK动态代理只能代理接口类型，先获取接口 &#x2F;&#x2F;就是从AdvisedSupport中获取保存在interfaces中的接口 Class[] proxiedInterfaces &#x3D; AopProxyUtils.completeProxiedInterfaces(this.advisedSupport); &#x2F;&#x2F;使用Java的反射机制创建一个代理实例 return Proxy.newProxyInstance(cl, proxiedInterfaces, this);&#125; 关于JDK反射创建代理之类的，这里不做解析。 CGLIB方式获取代理CGLIB获取方式，实现在Cglib2AopProxy中： 1234public Object getProxy() &#123; &#x2F;&#x2F;使用CGLIB的方式来获取，CGLIB这里不做解析 return getProxy(Thread.currentThread().getContextClassLoader());&#125; 使用代理上面获取代理之后，就剩最后一步，使用，当我们调用业务方法的时候，实际上是调用代理中的方法，对于CGLIB生成的代理，调用的是DynamicAdvisedInterceptor的intercept方法；JDK动态代理生成的代理是调用invoke方法。 JDK动态代理看下JDK动态代理的方式，对于方法的调用，实际上调用的是代理类的invoke方法，在JdkDynamicAopProxy中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; MethodInvocation invocation &#x3D; null; Object oldProxy &#x3D; null; boolean setProxyContext &#x3D; false; &#x2F;&#x2F;代理的目标对象 TargetSource targetSource &#x3D; advisedSupport.targetSource; Class targetClass &#x3D; null; Object target &#x3D; null; try &#123; &#x2F;&#x2F;equals方法 if (method.getDeclaringClass() &#x3D;&#x3D; Object.class &amp;&amp; &quot;equals&quot;.equals(method.getName())) &#123; return equals(args[0]) ? Boolean.TRUE : Boolean.FALSE; &#125; else if (Advised.class &#x3D;&#x3D; method.getDeclaringClass()) &#123; &#x2F;&#x2F;？？？ return AopProxyUtils.invokeJoinpointUsingReflection(this.advisedSupport, method, args); &#125; Object retVal &#x3D; null; &#x2F;&#x2F;代理目标对象 target &#x3D; targetSource.getTarget(); if (target !&#x3D; null) &#123; targetClass &#x3D; target.getClass(); &#125; &#x2F;&#x2F;？？？ if (this.advisedSupport.exposeProxy) &#123; &#x2F;&#x2F; Make invocation available if necessary oldProxy &#x3D; AopContext.setCurrentProxy(proxy); setProxyContext &#x3D; true; &#125; &#x2F;&#x2F;获取配置的通知Advicelian List chain &#x3D; this.advisedSupport.advisorChainFactory.getInterceptorsAndDynamicInterceptionAdvice( this.advisedSupport, proxy, method, targetClass); &#x2F;&#x2F;没有配置通知 if (chain.isEmpty()) &#123; &#x2F;&#x2F;直接调用目标对象的方法 retVal &#x3D; AopProxyUtils.invokeJoinpointUsingReflection(target, method, args); &#125; else &#123; &#x2F;&#x2F;配置了通知，创建一个MethodInvocation invocation &#x3D; new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); &#x2F;&#x2F;执行通知链，沿着通知器链调用所有的通知 retVal &#x3D; invocation.proceed(); &#125; &#x2F;&#x2F;返回值 if (retVal !&#x3D; null &amp;&amp; retVal &#x3D;&#x3D; target) &#123; &#x2F;&#x2F;返回值为自己 retVal &#x3D; proxy; &#125; &#x2F;&#x2F;返回 return retVal; &#125; finally &#123; if (target !&#x3D; null &amp;&amp; !targetSource.isStatic()) &#123; targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; AopContext.setCurrentProxy(oldProxy); &#125; &#125;&#125; CGLIB动态代理CGLIB的是调用DynamicAdvisedInterceptor的intercept方法对目标对象进行处理，具体暂先不解析。 使用ProxyFactoryBean创建AOP代理ProxyFactoryBean对Pointcut和Advice提供了完全的控制，还包括应用的顺序。ProxyFactoryBean的getObject方法会返回一个AOP代理，包装了目标对象。 Spring在初始化的过程中，createBean的时候，如果是FactoryBean的话，会调用((BeanFactoryAware)bean).setBeanFactory(this);： 12345678910111213public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; this.beanFactory &#x3D; beanFactory; &#x2F;&#x2F;创建通知器链 this.createAdvisorChain(); if(this.singleton) &#123; &#x2F;&#x2F;刷新目标对象 this.targetSource &#x3D; this.freshTargetSource(); &#x2F;&#x2F;获取单例实例 this.getSingletonInstance(); this.addListener(this); &#125;&#125; 看下获取单例实例的方法： 1234567private Object getSingletonInstance() &#123; if(this.singletonInstance &#x3D;&#x3D; null) &#123; this.singletonInstance &#x3D; this.createAopProxy().getProxy(); &#125; return this.singletonInstance;&#125; createAopProxy方法在AdvisedSupport类中，下面创建的流程跟上面解析的都一样了。 到这里AOP的一个流程的源码算是走完了，这只是其中一小部分，还有很多的没有涉及到，包括AOP标签的解析，CGLIB生成代理以及调用代理等等。其中有些还没明白的已经画上了问号，慢慢的在研究下。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java动态代理机制解析]]></title>
      <url>%2F2017%2F04%2F12%2FJava%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E6%9C%BA%E5%88%B6%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[动态代理是指在运行时动态生成代理类。不需要我们像静态代理那个去手动写一个个的代理类。生成动态代理类有很多方式：Java动态代理，CGLIB，Javassist，ASM库等。这里主要说一下Java动态代理的实现。 Java动态代理InvocationHandler接口Java动态代理中，每一个动态代理类都必须要实现InvocationHandler接口，当我们通过代理对象调用一个方法的时候，这个方法就会被转发给代理类的invoke方法来调用，InvocationHandler接口只有一个方法： 1public Object invoke(Object proxy, Method method, Object[] args) throws Throwable; proxy，真实对象。method，我们调用的真实对象的方法。args，要调用真实对象的方法时接受的参数。 Proxy类实现了InvocationHandler的类是动态代理类，而Proxy就是用来动态创建代理类对象的工具，通常情况下我们只使用newProxyInstance这个方法，newProxyInstance定义： 1public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123;&#125; loader，对生成的代理类对象进行加载的ClassLoader。interfaces，代理对象会实现这些接口。h，动态代理对象调用方法的时候，要发送到哪个InvocationHandler上。 例子我们知道，在之前的静态代理中，每个代理类都实现了特定接口，针对每一个事情都需要去定义一个代理类，会迅速的使类变多，重复也会多。而使用动态代理可以避免这一点，还是使用之前的找人还钱的例子。 Subject： 1234567891011121314package me.cxis.test.gof.proxy.dynamicproxy;&#x2F;** * Created by cheng.xi on 2017-04-12 19:58. * 代理模式的主题类，这里代表的是欠钱的人 *&#x2F;public interface Subject &#123; &#x2F;** * 还给我的钱 * @param moneyCount 欠钱数 * @return 还给我的钱数 *&#x2F; int giveMeMyMoney(int moneyCount);&#125; RealSubject： 123456789101112package me.cxis.test.gof.proxy.dynamicproxy;&#x2F;** * Created by cheng.xi on 2017-04-12 19:58. * 真实主题，这里代表的是欠我钱的人 *&#x2F;public class RealSubject implements Subject &#123; @Override public int giveMeMyMoney(int moneyCount) &#123; return moneyCount; &#125;&#125; DynamicProxy： 1234567891011121314151617181920212223242526272829303132333435package me.cxis.test.gof.proxy.dynamicproxy;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;&#x2F;** * Created by cheng.xi on 2017-04-12 19:59. * 代理 *&#x2F;public class DynamicProxy implements InvocationHandler&#123; private Object target; public DynamicProxy(Object target)&#123; this.target &#x3D; target; &#125; public &lt;T&gt; T getProxy()&#123; return (T) Proxy.newProxyInstance( target.getClass().getClassLoader(), target.getClass().getInterfaces(), this); &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(&quot;办事之前先收取点费用&quot;); System.out.println(&quot;开始办事&quot;); Object result &#x3D; method.invoke(target,args); System.out.println(&quot;办完了&quot;); return result; &#125;&#125; 测试方法： 1234567891011121314package me.cxis.test.gof.proxy.dynamicproxy;&#x2F;** * Created by cheng.xi on 2017-04-12 20:06. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; Subject zhangsan &#x3D; new RealSubject(); Subject proxy &#x3D; new DynamicProxy(zhangsan).getProxy(); int money &#x3D; proxy.giveMeMyMoney(1000); System.out.println(money); &#125;&#125; 可以看到我们把之前的代理类，换成了现在的动态代理类，调用方法也有所改变，看起来没什么大的区别，但是当我们在需要一个类似的业务的时候，就有差别了，我们无需在定义第二个动态代理类，只需要有新的Subject1接口和RealSubject1实现即可，在我们测试方法中直接调用就可以了，动态代理类完全不需要改变。 Java动态代理的优缺点优点：Java动态代理可以避免静态代理带来的代码冗余的问题。 缺点：Java动态代理只能针对接口创建代理，不能针对类创建代理。 Java动态代理到底做了什么？其实动态代理是在运行时候为我们生成了一个代理类，大概如下： 12345678910111213public final class $Proxy1 extends Proxy implements Subject&#123; private InvocationHandler h; private $Proxy1()&#123;&#125; public $Proxy1(InvocationHandler h)&#123; this.h &#x3D; h; &#125; public int giveMeMyMoney(int i)&#123; &#x2F;&#x2F;&#x2F;&#x2F;创建method对象 Method method &#x3D; Subject.class.getMethod(&quot;giveMeMyMoney&quot;, new Class[]&#123;int.class&#125;); &#x2F;&#x2F;调用了invoke方法 return (Integer)h.invoke(this, method, new Object[]&#123;new Integer(i)&#125;); &#125;&#125; 从中可以看到，InvocationHandler是我们实现的那个类，我们实现了invoke方法，这里就是调用了invoke方法。 同时我们看到这个类实际上实现了我们的主题类Subject，看着和静态代理差不多了把。另外着重看下这个类继承了Proxy类，看到这里，对于JDK动态代理为什么不能代理类只能代理接口，就明了了，因为他已经继承了Proxy类。 动态代理的用处 Spring AOP就是使用的动态代理方式。 dubbo消费者初始化的时候生成代理，也是使用的动态代理。 hibernate的懒加载。 其他例子延迟加载代理举例： 接口类： 123public interface ILoadFile&#123; String load();&#125; 真实实现类： 12345678910111213141516171819public class LoadFile implements ILoadFile&#123; String fileContent &#x3D; &quot;&quot;; public LoadFile()&#123; try&#123; &#x2F;&#x2F;这里模拟加载一个大文件，需要时间很长 Thread.sleep(10000); &#x2F;&#x2F;加载完之后 fileContent &#x3D; &quot;file contents...&quot;; &#125;catch(Exception e)&#123; &#125; &#125; public String load()&#123; return fileContent; &#125; &#125; 代理类： 1234567891011public LoadFileHandler implements InvocationHandler&#123; ILoadFile loadFile &#x3D; null; public Object invoke(Object proxy,Method method,Object[] args) throws Throwable&#123; if( loadFile &#x3D;&#x3D; null)&#123; loadFile &#x3D; new LoadFile(); &#125; return loadFile.load(); &#125;&#125; 生成动态代理对象并使用： 1234public static void main(String[] args)&#123; ILoadFile loadFile &#x3D; (ILoadFile)Proxy.newProxyInstance(ClassLoader.getSystemClassLoader(),new Class[]&#123;ILoadFile.class&#125;,new LoadFileHandler()); loadFile.load();&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式中的代理模式解析]]></title>
      <url>%2F2017%2F04%2F12%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B8%AD%E7%9A%84%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[很多地方都用到了代理模式，比如AOP就是代理模式的一种应用，还有dubbo中消费者在初始化的时候，并没有真正的去调用服务提供者执行真正业务逻辑，而是返回一个代理，等到使用的时候，再去调用调用实际业务逻辑。代理模式还有很多其他的应用，比如资源懒加载等。 代理模式定义代理模式：为其他对象提供一种代理，用以控制对这个对象的访问。从字面意义来理解，代理，就是代替别人做事。比如我们需要找别人要账，要不回来，怎么办？找代理（专门要账的）去做这件事，不管他们是怎么样去要，最终会把要来的钱给我。 代理模式的结构通常代理模式包含三个角色： Subject，抽象的主题角色 RealSubject，真实的主题角色 Proxy，代理主题角色 Subject一般是一个接口，需要被真实主题和代理主题实现。 代理模式举例比如，张三欠我钱，张三不给我，我就找代理去帮我要，当我去找代理帮我的时候，这时候其实张三已经不是欠我钱了，而是代理欠我钱，张三欠的是代理的钱。所以当我找代理的时候，代理和张三都应该被标记成是欠钱的人。 所以此时： Subject，这里就是表示欠钱的人，欠钱的人应该要做的就是还钱。 RealSubject，这里就是张三 Proxy，这里就是代理 Subject： 1234567891011121314package me.cxis.test.gof.proxy;&#x2F;** * Created by cheng.xi on 2017-04-12 15:36. * 代理模式的主题类，这里代表的是欠钱的人 *&#x2F;public interface Subject &#123; &#x2F;** * 还给我的钱 * @param moneyCount 欠钱数 * @return 还给我的钱数 *&#x2F; int giveMeMyMoney(int moneyCount);&#125; RealSubject： 123456789101112package me.cxis.test.gof.proxy;&#x2F;** * Created by cheng.xi on 2017-04-12 15:38. * 真实主题，这里代表的是欠我钱的人 *&#x2F;public class RealSubject implements Subject &#123; @Override public int giveMeMyMoney(int moneyCount) &#123; return moneyCount; &#125;&#125; Proxy： 123456789101112131415161718192021222324252627282930package me.cxis.test.gof.proxy;&#x2F;** * Created by cheng.xi on 2017-04-12 15:40. * 代理，这里是专门要钱的机构 * 为什么他要实现Subject？我现在找代理帮我要钱，张三已经不欠我了， * 张三欠的是代理的，代理现在是欠我钱的人了 *&#x2F;public class Proxy implements Subject&#123; &#x2F;** * 欠钱的人，代理会接受消息，都是关于欠钱人的信息 *&#x2F; private Subject subject; public Proxy(Subject subject)&#123; this.subject &#x3D; subject; &#125; @Override public int giveMeMyMoney(int moneyCount) &#123; System.out.println(&quot;代理：放心，我们去找他要钱&quot;); &#x2F;&#x2F;要钱之前先跟张三做了一下交流，不知道他们做了什么 System.out.println(&quot;代理：张三，你欠钱不还，我们是xxx代理公司的。。。&quot;); &#x2F;&#x2F;代理找张三要钱 int money &#x3D; this.subject.giveMeMyMoney(moneyCount); System.out.println(&quot;代理：要到了，总共是：&quot; + money); return money; &#125;&#125; 测试方法： 12345678910111213141516171819package me.cxis.test.gof.proxy;&#x2F;** * Created by cheng.xi on 2017-04-12 15:47. * 这里是我，我去找代理要钱，代理帮我找张三要钱 *&#x2F;public class Main &#123; public static void main(String[] args) &#123; &#x2F;&#x2F;欠钱的人，张三 Subject zhangsan &#x3D; new RealSubject(); &#x2F;&#x2F;代理，招代理的时候，需要提供张三的信息 Proxy proxy &#x3D; new Proxy(zhangsan); &#x2F;&#x2F;代理去要钱，然后给我 int money &#x3D; proxy.giveMeMyMoney(1000); System.out.println(&quot;我：我的钱要回来了：&quot; + money); &#125;&#125; 上面的代码只是举一个例子，当然上面并没有体现出来代理模式的好处，而只是做了一个代理模式的定义的解析。下面稍微聊一下关于代理模式的好处。 代理模式的优点其实了解代理模式的优点也不难，需要通过对比，我们还是以上面的例子来说吧，比如我们去找张三要钱，他不给，怎么办？有人说可以揍一顿，这优点不好，都是朋友，万一揍出来毛病咋整，不还得赖我吗？其实这里可以对比一下，直接修改代码，这里揍他就是把原来要钱的逻辑给修改了，要钱的时候先揍一顿，明显不好，不可取。 第二种办法是继承，这个没办法类比上面的例子了，总不能继承张三去！在一些场景也可以使用继承，但是也不太好。 第三种办法就是我们现在这种代理模式，，也是使用面向对象设计原则中合成/聚合复用原则的体现。 代理模式可以对外部提供一个统一的接口方法，代理类是真正操作真实类的地方，我不管代理怎么做的，我要的就是结果，代理再自己调用各种底层的组件去找结果。 代理模式的缺点代理有可能会很复杂，因为他要做的事情非常多；也有可能会有请求的延迟，毕竟中间我加了一层代理；还有可能会有很多很多的代理类需要写。 代理模式的应用场景 AOP是一个代理模式的应用，aop可以帮我们把需要额外的代码切入到现在有的代码中去，然后生成一个代理类，我们调用的时候，实际上调用的是代理类，代理类中就有了我们需要的额外的功能。 dubbo中消费者初始化的时候，初始化bean的时候，并不会去调用远程的服务提供者的实际业务逻辑，而是会在初始化阶段生成一个代理，代理中包含了远程调用的所有东西，只有在使用的时候才回去使用代理中的方法去调用。 远程调用，其实上面dubbo就是远程调用。 另外上面我们介绍的代理模式，是静态代理模式，就是我们需要代理的时候，需要自己写一个代理类，还有另外一一种方式，叫做动态代理，Spring AOP就是使用的动态代理机制。再另外的文章中会再介绍。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring中AOP概念，原理，应用介绍]]></title>
      <url>%2F2017%2F04%2F12%2FSpring%E4%B8%ADAOP%E6%A6%82%E5%BF%B5%EF%BC%8C%E5%8E%9F%E7%90%86%EF%BC%8C%E5%BA%94%E7%94%A8%E4%BB%8B%E7%BB%8D%2F</url>
      <content type="text"><![CDATA[心情没法不沉重，被问到AOP是什么？AOP原理是什么？我竟然张大了嘴巴，说不出来！对于一个程序员的打击，还能有比这更大的吗？我没脸说我是个写代码的，我也没脸说我是程序员。 AOP是什么？定义AOP，面向切面编程，是对OOP的补充。从网上看到的一句话：这种在运行时，动态的将代码切入到类的指定方法或者指定位置上的编程思想，就是面向切面的编程。这是其中的一种方式，在运行时动态添加。还有另外一种是在编译代码的时候，将代码切入到指定的方法或者位置上去，这是静态添加的方式。 使用我们在实际的业务中都会有一些公共逻辑，比如日志的记录，事务的管理等等，而如果每次都把日志和事务的代码手动写到业务逻辑前后，重复代码就相当可怕，而如果这些额外代码有修改，必须要每个都修改，这是相当不明智的。AOP可以帮我们解决这些问题。 实现其实AOP本身并不能帮我们解决那些问题，AOP就是一种思想，而帮我们解决的是具体的AOP的实现，比如aspectj，jboss AOP，以及我们最熟悉的Spring AOP，Spring AOP在Spring1.0的时候是自己实现的AOP框架，在2.0之后就开始集成了aspectj。现在我们所说的Spring AOP就是Spring加Aspectj这种方式。 AOP的相关概念对于AOP中相关的概念，我们接触更多的还是Spring AOP，这里主要是以Spring AOP的概念来说明： Aspect，切面，一个关注点的模块化，这个关注点可能会横切多个对象。 JoinPoint，连接点，在程序执行过程中某个特定的点，比如某方法调用的时候或者处理异常的时候。在Spring AOP中，一个连接点总是表示一个方法的执行。 Advice，通知，在切面的某个特定的连接点上执行的动作。 Pointcut，切点，匹配连接点的断言。通知和一个切入点表达式关联，并在满足这个切入点的连接点上运行（例如，当执行某个特定名称的方法时）。切入点表达式如何和连接点匹配是AOP的核心：Spring缺省使用AspectJ切入点语法。 上面是关于AOP中几个基本概念的定义，下面看下有关我们使用时的一些概念： Target Object，目标对象，被一个或者多个切面所通知的对象。也就是我们业务中实际要进行增强的业务对象。 AOP Proxy，AOP代理，AOP框架创建的对象。也就是被增强之后的对象。 Weaving，织入，把切面连接到其它的应用程序类型或者对象上，并创建一个被通知的对象。就是把切面作用到目标对象，然后产生一个代理对象的过程。 还有另外一个概念，是给类声明额外方法的概念： Introduction，引介，用来给一个类型声明额外的方法或属性。就是我可以不用实现另外一个接口，就能使用那个接口的方法。 通知类型Advice是通知，也就是在切面的某个连接点上要执行的动作，也就是我们要编写的增强功能的代码。通知也分为好几种类型，分别有不同作用： 前置通知（Before advice）：在某连接点之前执行的通知，但这个通知不能阻止连接点之前的执行流程（除非它抛出一个异常）。 后置通知（After returning advice）：在某连接点正常完成后执行的通知：例如，一个方法没有抛出任何异常，正常返回。 异常通知（After throwing advice）：在方法抛出异常退出时执行的通知。 最终通知（After (finally) advice）：当某连接点退出的时候执行的通知（不论是正常返回还是异常退出）。 环绕通知（Around Advice）：包围一个连接点的通知，如方法调用。这是最强大的一种通知类型。环绕通知可以在方法调用前后完成自定义的行为。它也会选择是否继续执行连接点或直接返回它自己的返回值或抛出异常来结束执行。 AOP原理上面说到了AOP可以在编译时候将代码织入到指定的方法或者属性上，或者在运行的时候动态的将代码切入到指定的方法或者属性中，这描述了AOP应该要做的事情，其实也基本算是它的原理了，AOP实现的关键就是创建AOP代理，代理有静态代理和动态代理之分，其中aspectj为静态代理，Spring AOP是动态代理，这里把静态和运行时动态的分开说。 AspectJ编译时增强aspectj编译时增强，既是静态代理增强，也就是会在编译阶段生成代理，将代码织入到Java的字节码中去。 Spring AOP的运行时增强Spring AOP是基于代理机制的，并且Spring AOP使用的是动态代理增强，动态代理不会改变类的字节码，而是动态的生成代理对象。Spring AOP的动态代理机制有两种方式：JDK动态代理和CGLIB动态代理。 JDK动态代理JDK动态代理需要被代理的类必须实现一个接口，通过使用反射来接受被代理的类。 CGLIB动态代理CGLIB动态代理可以不用需要被代理类必须实现接口，被代理类可以是一个类。 Spring AOP上面说到了Spring AOP中使用的是动态代理机制，同时也分为两种代理机制：JDK动态代理和CGLIB动态代理，这可以在源码中看到，在DefaultAopProxyFactory的createAopProxy中可看到： 1234567891011public AopProxy createAopProxy(AdvisedSupport advisedSupport) throws AopConfigException &#123; &#x2F;&#x2F;可以看到这里有条件是没有实现接口 boolean useCglib &#x3D; advisedSupport.getOptimize() || advisedSupport.getProxyTargetClass() || advisedSupport.getProxiedInterfaces().length &#x3D;&#x3D; 0; if (useCglib) &#123; return CglibProxyFactory.createCglibProxy(advisedSupport); &#125; else &#123; &#x2F;&#x2F; Depends on whether we have expose proxy or frozen or static ts return new JdkDynamicAopProxy(advisedSupport); &#125;&#125; 对于接口的代理使用的JDK动态代理，而对于类的代理使用的是CGLIB动态代理。 AOP的使用场景AOP适用于具有横切逻辑的应用，比如性能监控，日志记录，缓存，事务管理，访问控制等。 有关Spring AOP的例子可以参考Spring中AOP的配置从1.0到5.0的演进，这里有具体的配置。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[自己写的，自己说不出来？]]></title>
      <url>%2F2017%2F04%2F11%2F%E8%87%AA%E5%B7%B1%E5%86%99%E7%9A%84%EF%BC%8C%E8%87%AA%E5%B7%B1%E8%AF%B4%E4%B8%8D%E5%87%BA%E6%9D%A5%EF%BC%9F%2F</url>
      <content type="text"><![CDATA[自己写的文章，被问到，自己却说不出来！一塌糊涂！真想抽大嘴巴子抽到不能停～开始怀疑，我是不是不适合做技术？经历一塌糊涂，技术一塌糊涂。还能做啥？ 不敢说我是做技术，做开发，做Java的了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring中AOP的配置从1.0到5.0的演进]]></title>
      <url>%2F2017%2F04%2F10%2FSpring%E4%B8%ADAOP%E7%9A%84%E9%85%8D%E7%BD%AE%E4%BB%8E1.0%E5%88%B05.0%E7%9A%84%E6%BC%94%E8%BF%9B%2F</url>
      <content type="text"><![CDATA[最近在学习Spring稍微深入一点的东西，在这过程中发现虽然有很多关于各种AOP，IOC原理配置等的文章，但是都只是针对某一版本或者压根儿就没有标明版本的解析配置等。或许是我理解力不够，为了方便自己以后快速找到这些东西去看，还是自己记录下。 这里主要是记录下从Spring1.0到现在的5.0中AOP的配置方式，关于AOP原理和源码，暂先不解释。主要用作自己记录用，如果有错误的还请指出一起改正学习，免得误导别人，谢谢。 Spring1中AOP的配置直接看Spring1.1.1的文档，里面都已经给出来了各种配置方式，更高版本的也都包含了这些，但是觉得看1.1.1的更纯粹一些。 使用ProxyFactoryBean创建AOP代理使用ProxyFactoryBean的方式来配置AOP，是最基础的方法。这里我们用的是代理接口的方式，步骤大概是： 定义我们的业务接口和业务实现类。 定义通知类，就是我们要对目标对象进行增强的类。 定义ProxyFactoryBean，这里封装了AOP的功能。 这就是Spring中AOP的配置，这种方式简单明了，往下接着看示例代码。 我们的业务接口，LoginService： 12345678package me.cxis.spring.aop;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125; 业务接口的实现类，LoginServiceImpl： 123456789101112package me.cxis.spring.aop;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; public String login(String userName)&#123; System.out.println(&quot;正在登录&quot;); return &quot;success&quot;; &#125;&#125; 在登录前做一些操作的通知类，LogBeforeLogin： 123456&#x2F;&#x2F;这里只是在登录方法调用之前打印一句话public class LogBeforeLogin implements MethodBeforeAdvice &#123; public void before(Method method, Object[] objects, Object o) throws Throwable &#123; System.out.println(&quot;有人要登录了。。。&quot;); &#125;&#125; 配置文件，在Spring1.x中主要还是用xml的方式来配置： 123456789101112131415161718192021222324252627&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE beans PUBLIC &quot;-&#x2F;&#x2F;SPRING&#x2F;&#x2F;DTD BEAN&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;dtd&#x2F;spring-beans.dtd&quot;&gt;&lt;beans&gt; &lt;!--业务处理类，也就是被代理的类--&gt; &lt;bean id&#x3D;&quot;loginServiceImpl&quot; class&#x3D;&quot;me.cxis.spring.aop.LoginServiceImpl&quot;&#x2F;&gt; &lt;!--通知类--&gt; &lt;bean id&#x3D;&quot;logBeforeLogin&quot; class&#x3D;&quot;me.cxis.spring.aop.LogBeforeLogin&quot;&#x2F;&gt; &lt;!--代理类--&gt; &lt;bean id&#x3D;&quot;loginProxy&quot; class&#x3D;&quot;org.springframework.aop.framework.ProxyFactoryBean&quot;&gt; &lt;!--要代理的接口--&gt; &lt;property name&#x3D;&quot;proxyInterfaces&quot;&gt; &lt;value&gt;me.cxis.spring.aop.LoginService&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;!--拦截器名字，也就是我们定义的通知类--&gt; &lt;property name&#x3D;&quot;interceptorNames&quot;&gt; &lt;list&gt; &lt;value&gt;logBeforeLogin&lt;&#x2F;value&gt; &lt;&#x2F;list&gt; &lt;&#x2F;property&gt; &lt;!--目标类，就是我们业务的实现类--&gt; &lt;property name&#x3D;&quot;target&quot;&gt; &lt;ref bean&#x3D;&quot;loginServiceImpl&quot;&#x2F;&gt; &lt;&#x2F;property&gt; &lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; 测试方法，Main： 1234567891011121314151617package me.cxis.spring.aop;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:aop.xml&quot;); LoginService loginService &#x3D; (LoginService) applicationContext.getBean(&quot;loginProxy&quot;); loginService.login(&quot;sdf&quot;); &#125;&#125; 上面的例子是用的是代理接口的方式，关于代理类的方式这里不做介绍，代理类的方式需要依赖CGLIB。从上面的代码可以看到，这种方式使用AOP简单直观，也是我们理解Spring AOP原理的很好的入口，但是在使用的时候，可能会发现业务增多了之后，ProxyFactoryBean的配置也会增多，导致xml迅速变多。 另外这种方式的使用会把LoginService接口中所有的方法都代理了，也就是说每个方法都会被增强，如果不想被增强，还可以使用另外一种方式，配置Advisor。 使用ProxyFactoryBean和Advisor的方式创建AOP代理使用Advisor配合，可以指定要增强的方法，不会把整个类中的所有方法都代理了。 这种方式跟上面的方式相比较，只是xml配置文件发生了变化，其他的代码都没有变，所以这里只列出了xml代码，其他的参照上面的代码。 xml配置： 12345678910111213141516171819202122232425262728293031&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE beans PUBLIC &quot;-&#x2F;&#x2F;SPRING&#x2F;&#x2F;DTD BEAN&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;dtd&#x2F;spring-beans.dtd&quot;&gt;&lt;beans&gt; &lt;!--业务处理类，也就是被代理的类--&gt; &lt;bean id&#x3D;&quot;loginServiceImpl&quot; class&#x3D;&quot;me.cxis.spring.aop.advisor.LoginServiceImpl&quot;&#x2F;&gt; &lt;!--通知类--&gt; &lt;bean id&#x3D;&quot;logBeforeLogin&quot; class&#x3D;&quot;me.cxis.spring.aop.advisor.LogBeforeLogin&quot;&#x2F;&gt; &lt;!--切面--&gt; &lt;bean id&#x3D;&quot;loginAdvisor&quot; class&#x3D;&quot;org.springframework.aop.support.RegexpMethodPointcutAdvisor&quot;&gt; &lt;property name&#x3D;&quot;advice&quot;&gt; &lt;ref bean&#x3D;&quot;logBeforeLogin&quot;&#x2F;&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;pattern&quot;&gt; &lt;value&gt;me.cxis.spring.aop.advisor.LoginServiceImpl.login*&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;&#x2F;bean&gt; &lt;!--代理类--&gt; &lt;bean id&#x3D;&quot;loginProxy&quot; class&#x3D;&quot;org.springframework.aop.framework.ProxyFactoryBean&quot;&gt; &lt;property name&#x3D;&quot;interceptorNames&quot;&gt; &lt;list&gt; &lt;value&gt;loginAdvisor&lt;&#x2F;value&gt; &lt;&#x2F;list&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;target&quot;&gt; &lt;ref bean&#x3D;&quot;loginServiceImpl&quot;&#x2F;&gt; &lt;&#x2F;property&gt; &lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; 可以看到这里我们多了Advisor，Advisor中可以使用正则表达式来匹配要增强的方法。 使用ProxyFactory编程的方式创建AOP代理也可以使用直接代码的方式，不依赖xml文件，来创建AOP代理，直接看示例代码。 业务接口，LoginService： 12345678package me.cxis.spring.aop.proxyfactory;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125; 业务接口实现类，LoginServiceImpl： 123456789101112package me.cxis.spring.aop.proxyfactory;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; public String login(String userName)&#123; System.out.println(&quot;正在登录&quot;); return &quot;success&quot;; &#125;&#125; 通知类，LogBeforeLogin： 1234567891011121314package me.cxis.spring.aop.proxyfactory;import org.springframework.aop.MethodBeforeAdvice;import java.lang.reflect.Method;&#x2F;** * Created by cheng.xi on 2017-03-29 10:56. *&#x2F;public class LogBeforeLogin implements MethodBeforeAdvice &#123; public void before(Method method, Object[] objects, Object o) throws Throwable &#123; System.out.println(&quot;有人要登录了。。。&quot;); &#125;&#125; 测试方法： 123456789101112131415161718192021package me.cxis.spring.aop.proxyfactory;import org.springframework.aop.framework.ProxyFactory;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ProxyFactory proxyFactory &#x3D; new ProxyFactory();&#x2F;&#x2F;创建代理工厂 proxyFactory.setTarget(new LoginServiceImpl());&#x2F;&#x2F;设置目标对象 proxyFactory.addAdvice(new LogBeforeLogin());&#x2F;&#x2F;前置增强 LoginService loginService &#x3D; (LoginService) proxyFactory.getProxy();&#x2F;&#x2F;从代理工厂中获取代理 loginService.login(&quot;x&quot;); &#125;&#125; 这种方式跟上面使用ProxyFactoryBean的方式差不多，步骤也基本相同，不做过多解释。Spring不推荐这种方式。 使用autoproxy方式创建AOP使用这种方式创建AOP代理，最主要的是可以使用一个配置来代理多个业务bean，也就是跟上面使用ProxyFactoryBean不同的地方，ProxyFactoryBean需要配置很多个ProxyFactoryBean配置，而autoproxy相对会很少。 使用autoproxy也有两种方式：BeanNameAutoProxyCreator和DefaultAdvisorAutoProxyCreator。两种方式的差别直接看代码。 BeanNameAutoProxyCreator方式业务接口，LoginService： 12345678package me.cxis.spring.aop.autoproxy;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125; 业务接口实现类，LoginServiceImpl： 123456789101112package me.cxis.spring.aop.autoproxy;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; public String login(String userName)&#123; System.out.println(&quot;autoproxy:正在登录&quot;); return &quot;success&quot;; &#125;&#125; 通知类，LogBeforeLogin： 1234567891011121314package me.cxis.spring.aop.autoproxy;import org.springframework.aop.MethodBeforeAdvice;import java.lang.reflect.Method;&#x2F;** * Created by cheng.xi on 2017-03-29 10:56. *&#x2F;public class LogBeforeLogin implements MethodBeforeAdvice &#123; public void before(Method method, Object[] objects, Object o) throws Throwable &#123; System.out.println(&quot;autoproxy:有人要登录了。。。&quot;); &#125;&#125; xml配置文件： 12345678910111213141516171819202122&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE beans PUBLIC &quot;-&#x2F;&#x2F;SPRING&#x2F;&#x2F;DTD BEAN&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;dtd&#x2F;spring-beans.dtd&quot;&gt;&lt;beans&gt; &lt;!--业务处理类，也就是被代理的类--&gt; &lt;bean id&#x3D;&quot;loginService&quot; class&#x3D;&quot;me.cxis.spring.aop.autoproxy.LoginServiceImpl&quot;&#x2F;&gt; &lt;!--通知类--&gt; &lt;bean id&#x3D;&quot;logBeforeLogin&quot; class&#x3D;&quot;me.cxis.spring.aop.autoproxy.LogBeforeLogin&quot;&#x2F;&gt; &lt;!--代理类--&gt; &lt;bean id&#x3D;&quot;loginServiceProxy&quot; class&#x3D;&quot;org.springframework.aop.framework.autoproxy.BeanNameAutoProxyCreator&quot;&gt; &lt;property name&#x3D;&quot;interceptorNames&quot;&gt; &lt;list&gt; &lt;value&gt;logBeforeLogin&lt;&#x2F;value&gt; &lt;&#x2F;list&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;beanNames&quot;&gt; &lt;value&gt;loginService*&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; 测试方法，Main： 12345678910111213141516package me.cxis.spring.aop.autoproxy;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:aop-auto-proxy.xml&quot;); LoginService loginService &#x3D; (LoginService) applicationContext.getBean(&quot;loginService&quot;); loginService.login(&quot;sdf&quot;); &#125;&#125; 在xml配置中beanNames的值我们使用了通配符，也就是我们可以使用这一个BeanNameAutoProxyCreator来匹配很多个接口，在ProxyFactoryBean的方式中，我们则需要配置很多ProxyFactoryBean的配置。 另外也需要注意下在测试方法中我们对bean的调用方式，之前我们是调用代理类，现在我们直接调用的Bean。这种方式中也还是把业务类中的所有的方法都增强了。 DefaultAdvisorAutoProxyCreator方式业务接口，LoginService： 12345678package me.cxis.spring.aop.advisorautoproxy;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125; 业务接口实现类，LoginServiceImpl： 123456789101112package me.cxis.spring.aop.advisorautoproxy;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; public String login(String userName)&#123; System.out.println(&quot;advisorautoproxy:正在登录&quot;); return &quot;success&quot;; &#125;&#125; 通知类，LogBeforeLogin： 1234567891011121314package me.cxis.spring.aop.advisorautoproxy;import org.springframework.aop.MethodBeforeAdvice;import java.lang.reflect.Method;&#x2F;** * Created by cheng.xi on 2017-03-29 10:56. *&#x2F;public class LogBeforeLogin implements MethodBeforeAdvice &#123; public void before(Method method, Object[] objects, Object o) throws Throwable &#123; System.out.println(&quot;advisorautoproxy:有人要登录了。。。&quot;); &#125;&#125; 配置文件xml： 12345678910111213141516171819202122&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE beans PUBLIC &quot;-&#x2F;&#x2F;SPRING&#x2F;&#x2F;DTD BEAN&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;dtd&#x2F;spring-beans.dtd&quot;&gt;&lt;beans&gt; &lt;!--业务处理类，也就是被代理的类--&gt; &lt;bean id&#x3D;&quot;loginService&quot; class&#x3D;&quot;me.cxis.spring.aop.advisorautoproxy.LoginServiceImpl&quot;&#x2F;&gt; &lt;!--通知类--&gt; &lt;bean id&#x3D;&quot;logBeforeLogin&quot; class&#x3D;&quot;me.cxis.spring.aop.advisorautoproxy.LogBeforeLogin&quot;&#x2F;&gt; &lt;bean id&#x3D;&quot;logBeforeAdvisor&quot; class&#x3D;&quot;org.springframework.aop.support.RegexpMethodPointcutAdvisor&quot;&gt; &lt;property name&#x3D;&quot;advice&quot;&gt; &lt;ref bean&#x3D;&quot;logBeforeLogin&quot;&#x2F;&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;pattern&quot;&gt; &lt;value&gt;me.cxis.spring.aop.advisorautoproxy.*&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;&#x2F;bean&gt; &lt;!--代理类--&gt; &lt;bean id&#x3D;&quot;advisorAutoProxy&quot; class&#x3D;&quot;org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator&quot;&gt; &lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; 测试方法： 1234567891011121314151617package me.cxis.spring.aop.advisorautoproxy;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:aop-advisor-auto-proxy.xml&quot;); LoginService loginService &#x3D; (LoginService) applicationContext.getBean(&quot;loginService&quot;); loginService.login(&quot;sdf&quot;); &#125;&#125; 在这里的配置文件中我们使用了正则的方式来配置Advisor，这种可以匹配指定的方法，不需要把类中的所有的方法都增强了。 引介增强Introduction上面所有AOP的代理都是对方法的增强，而引介增强则是对类的增强，所谓对类的增强就是，我是A类，实现了接口B，但是我没有实现接口C，那么通过引介增强的方式，我没有实现接口C，但是我可以调用C中的方法。 业务接口，LoginService： 12345678package me.cxis.spring.aop.introduction;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125; 业务接口实现类： 123456789101112package me.cxis.spring.aop.introduction;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; public String login(String userName)&#123; System.out.println(&quot;正在登录&quot;); return &quot;success&quot;; &#125;&#125; 另外一个业务接口，SendEmailService： 12345678package me.cxis.spring.aop.introduction;&#x2F;** * Created by cheng.xi on 2017-03-30 23:45. *&#x2F;public interface SendEmailService &#123; void sendEmail();&#125; 增强，LogAndSendEmailBeforeLogin： 123456789101112131415161718192021222324package me.cxis.spring.aop.introduction;import org.aopalliance.intercept.MethodInvocation;import org.springframework.aop.MethodBeforeAdvice;import org.springframework.aop.support.DelegatingIntroductionInterceptor;import java.lang.reflect.Method;&#x2F;** * Created by cheng.xi on 2017-03-29 10:56. *&#x2F;public class LogAndSendEmailBeforeLogin extends DelegatingIntroductionInterceptor implements SendEmailService &#123; @Override public Object invoke(MethodInvocation mi) throws Throwable &#123; System.out.println(&quot;有人要登录了。。。&quot;); return super.invoke(mi); &#125; public void sendEmail() &#123; System.out.println(&quot;发送邮件。。。。&quot;); &#125;&#125; xml配置文件： 123456789101112131415161718192021222324252627&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE beans PUBLIC &quot;-&#x2F;&#x2F;SPRING&#x2F;&#x2F;DTD BEAN&#x2F;&#x2F;EN&quot; &quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;dtd&#x2F;spring-beans.dtd&quot;&gt;&lt;beans&gt; &lt;!--业务处理类，也就是被代理的类--&gt; &lt;bean id&#x3D;&quot;loginServiceImpl&quot; class&#x3D;&quot;me.cxis.spring.aop.introduction.LoginServiceImpl&quot;&#x2F;&gt; &lt;!--通知类--&gt; &lt;bean id&#x3D;&quot;logAndSendEmailBeforeLogin&quot; class&#x3D;&quot;me.cxis.spring.aop.introduction.LogAndSendEmailBeforeLogin&quot;&#x2F;&gt; &lt;!--代理类--&gt; &lt;bean id&#x3D;&quot;loginProxy&quot; class&#x3D;&quot;org.springframework.aop.framework.ProxyFactoryBean&quot;&gt; &lt;property name&#x3D;&quot;interfaces&quot;&gt; &lt;value&gt;me.cxis.spring.aop.introduction.SendEmailService&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;interceptorNames&quot;&gt; &lt;list&gt; &lt;value&gt;logAndSendEmailBeforeLogin&lt;&#x2F;value&gt; &lt;&#x2F;list&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;target&quot;&gt; &lt;ref bean&#x3D;&quot;loginServiceImpl&quot;&#x2F;&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;proxyTargetClass&quot;&gt; &lt;value&gt;true&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; 测试方法： 12345678910111213141516171819package me.cxis.spring.aop.introduction;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:aop-introduction.xml&quot;); LoginServiceImpl loginService &#x3D; (LoginServiceImpl) applicationContext.getBean(&quot;loginProxy&quot;); loginService.login(&quot;sdf&quot;); SendEmailService sendEmailService &#x3D; (SendEmailService) loginService; sendEmailService.sendEmail(); &#125;&#125; 这样就可以了～ Spring2中AOP的配置What’s new in Spring 2.0? 添加了基于schema的AOP支持。 加入了AspectJ的支持，添加了@AspectJ注解。 上面就是AOP在2.0版本新增的特性，1.0的所有AOP配置方式在2.0中都支持，下面主要看看2.0中新增的一些方法。 使用@AspectJ的方式配置AOP代理步骤大概如下： 定义我们的业务接口和业务实现类。 定义通知类，就是我们要对目标对象进行增强的类。使用@AspectJ注解。 启用@AspectJ支持。 还是看代码。 业务接口，LoginService： 12345678package me.cxis.spring.aop;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125; 业务接口实现，LoginServiceImpl： 123456789101112package me.cxis.spring.aop;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; public String login(String userName)&#123; System.out.println(&quot;正在登录&quot;); return &quot;success&quot;; &#125;&#125; 增强类，LogBeforeLogin，请注意这里面使用了注解： 1234567891011121314151617181920package me.cxis.spring.aop;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;&#x2F;** * Created by cheng.xi on 2017-03-29 10:56. *&#x2F;@Aspectpublic class LogBeforeLogin &#123; @Pointcut(&quot;execution(* me.cxis.spring.aop.*.login(..))&quot;) public void loginMethod()&#123;&#125; @Before(&quot;loginMethod()&quot;) public void beforeLogin()&#123; System.out.println(&quot;有人要登录了。。。&quot;); &#125;&#125; xml配置文件： 12345678910111213141516&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xmlns:aop&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&#x2F;spring-aop.xsd&quot;&gt; &lt;!--@AspectJ支持--&gt; &lt;aop:aspectj-autoproxy&#x2F;&gt; &lt;!--业务实现--&gt; &lt;bean id&#x3D;&quot;loginService&quot; class&#x3D;&quot;me.cxis.spring.aop.LoginServiceImpl&quot;&#x2F;&gt; &lt;!--Aspect--&gt; &lt;bean id&#x3D;&quot;logBeforeLoginAspect&quot; class&#x3D;&quot;me.cxis.spring.aop.LogBeforeLogin&quot;&gt; &lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; 测试方法： 12345678910111213141516package me.cxis.spring.aop;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:aop.xml&quot;); LoginService loginService &#x3D; (LoginService) applicationContext.getBean(&quot;loginService&quot;); loginService.login(&quot;sdf&quot;); &#125;&#125; 可以看下上面的配置文件，首先开启@AspectJ注解的支持，然后只需要声明一下业务bean和增强bean，其余的都不用做了，是不是比以前方便多了。以前的那些配置，全部都在增强类中用注解处理了。 使用自定义注解作为execution的表达式上面使用普通的execution表达式来声明对那些方法进行增强，也可以使用注解的方式，其实就是把表达式换成了注解，只有添加了注解的方法才能被增强。 先定义一个注解UseAop： 123456789101112131415package me.cxis.spring.aop.customannotation;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;&#x2F;** * Created by cheng.xi on 2017-03-31 11:29. * 标注此注解的方法，需要使用AOP代理 *&#x2F;@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface UseAop &#123;&#125; 业务接口，LoginService： 12345678package me.cxis.spring.aop.customannotation;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125; 业务接口的实现，LoginServiceImpl： 12345678910111213package me.cxis.spring.aop.customannotation;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; @UseAop public String login(String userName)&#123; System.out.println(&quot;正在登录&quot;); return &quot;success&quot;; &#125;&#125; 这里业务实现类的方法使用了注解，表明这个方法需要使用AOP代理。 增强类，LogBeforeLogin： 1234567891011@Aspectpublic class LogBeforeLogin &#123; @Pointcut(&quot;@annotation(me.cxis.spring.aop.customannotation.UseAop)&quot;) public void loginMethod()&#123;&#125; @Before(&quot;loginMethod()&quot;) public void beforeLogin()&#123; System.out.println(&quot;有人要登录了。。。&quot;); &#125;&#125; 这里是把表达式换成了我们定义的注解。 xml配置： 12345678910111213141516&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xmlns:aop&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&#x2F;spring-aop.xsd&quot;&gt; &lt;!--@AspectJ支持--&gt; &lt;aop:aspectj-autoproxy&#x2F;&gt; &lt;!--业务实现--&gt; &lt;bean id&#x3D;&quot;loginService&quot; class&#x3D;&quot;me.cxis.spring.aop.customannotation.LoginServiceImpl&quot;&#x2F;&gt; &lt;!--Aspect--&gt; &lt;bean id&#x3D;&quot;logBeforeLoginAspect&quot; class&#x3D;&quot;me.cxis.spring.aop.customannotation.LogBeforeLogin&quot;&gt; &lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; xml配置文件并没有改变。同样下面的测试方法也没有变。 测试方法： 12345678910111213141516package me.cxis.spring.aop.customannotation;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:aop-annotation.xml&quot;); LoginService loginService &#x3D; (LoginService) applicationContext.getBean(&quot;loginService&quot;); loginService.login(&quot;sdf&quot;); &#125;&#125; 使用基于schema的方式配置AOP代理基于schema的方式配置，可以不使用注解，而是完全基于xml配置。 业务接口，实现类，增强如下： 123456789101112131415161718192021222324252627282930313233package me.cxis.spring.aop.config;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125;package me.cxis.spring.aop.config;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; public String login(String userName)&#123; System.out.println(&quot;正在登录&quot;); return &quot;success&quot;; &#125;&#125;package me.cxis.spring.aop.config;&#x2F;** * Created by cheng.xi on 2017-03-29 10:56. *&#x2F;public class LogBeforeLogin &#123; public void beforeLogin()&#123; System.out.println(&quot;有人要登录了。。。&quot;); &#125;&#125; 可以看到上面三个类中，增强类只是一个普通的bean而已，所有的配置都在xml中。 xml配置： 12345678910111213141516171819&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xmlns:aop&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&#x2F;spring-aop.xsd&quot;&gt; &lt;!--业务实现类--&gt; &lt;bean id&#x3D;&quot;loginService&quot; class&#x3D;&quot;me.cxis.spring.aop.config.LoginServiceImpl&quot;&gt;&lt;&#x2F;bean&gt; &lt;!--增强类--&gt; &lt;bean id&#x3D;&quot;logBeforeLogin&quot; class&#x3D;&quot;me.cxis.spring.aop.config.LogBeforeLogin&quot;&gt;&lt;&#x2F;bean&gt; &lt;aop:config&gt; &lt;aop:aspect id&#x3D;&quot;loginAspect&quot; ref&#x3D;&quot;logBeforeLogin&quot;&gt; &lt;aop:pointcut expression&#x3D;&quot;execution(* me.cxis.spring.aop.config.*.*(..))&quot; id&#x3D;&quot;beforeLoginPointCut&quot;&#x2F;&gt; &lt;aop:before method&#x3D;&quot;beforeLogin&quot; pointcut-ref&#x3D;&quot;beforeLoginPointCut&quot;&#x2F;&gt; &lt;&#x2F;aop:aspect&gt; &lt;&#x2F;aop:config&gt;&lt;&#x2F;beans&gt; 可以类比下上面@AspectJ的方式，其实是一样的，只不过把注解的东西都放到了xml中。 测试方法： 12345678910111213141516package me.cxis.spring.aop.config;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:aop-config.xml&quot;); LoginService loginService &#x3D; (LoginService) applicationContext.getBean(&quot;loginService&quot;); loginService.login(&quot;sdf&quot;); &#125;&#125; 使用dtd方式我们上面看到使用&lt;aop:aspectj-autoproxy/&gt;来启用@AspectJ的支持，这种方式使用的基于schema扩展的，如果想用原来的DTD模式也是可以的，使用AnnotationAwareAspectJAutoProxyCreator即可。 业务接口，业务实现类，增强类的代码都跟使用@AspectJ的方式配置AOP代理这一步的一样，除了xml里面有点不一样，代码如下： 123456789101112131415&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans.xsd &quot;&gt; &lt;bean class&#x3D;&quot;org.springframework.aop.aspectj.annotation.AnnotationAwareAspectJAutoProxyCreator&quot;&#x2F;&gt; &lt;!--业务实现--&gt; &lt;bean id&#x3D;&quot;loginService&quot; class&#x3D;&quot;me.cxis.spring.aop.dtd.LoginServiceImpl&quot;&#x2F;&gt; &lt;!--Aspect--&gt; &lt;bean id&#x3D;&quot;logBeforeLoginAspect&quot; class&#x3D;&quot;me.cxis.spring.aop.dtd.LogBeforeLogin&quot;&gt; &lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; 就是将&lt;aop:aspectj-autoproxy/&gt;替换成&lt;bean class=&quot;org.springframework.aop.aspectj.annotation.AnnotationAwareAspectJAutoProxyCreator&quot;/&gt;，Spring文档上也有说明。 编程的方式使用@AspectJ业务接口LoginService： 12345678package me.cxis.spring.aop.programmatic;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125; 业务实现类： 123456789101112package me.cxis.spring.aop.programmatic;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; public String login(String userName)&#123; System.out.println(&quot;正在登录&quot;); return &quot;success&quot;; &#125;&#125; 增强类： 123456789101112131415161718192021package me.cxis.spring.aop.programmatic;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;&#x2F;** * Created by cheng.xi on 2017-03-29 10:56. *&#x2F;@Aspectpublic class LogBeforeLogin &#123; @Pointcut(&quot;execution(* me.cxis.spring.aop.programmatic.*.login(..))&quot;) public void loginMethod()&#123;&#125; @Before(&quot;loginMethod()&quot;) public void beforeLogin()&#123; System.out.println(&quot;有人要登录了。。。&quot;); &#125;&#125; 测试方法： 12345678910111213141516171819package me.cxis.spring.aop.programmatic;import org.springframework.aop.aspectj.annotation.AspectJProxyFactory;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; AspectJProxyFactory factory &#x3D; new AspectJProxyFactory();&#x2F;&#x2F;创建代理工厂 factory.setTarget(new LoginServiceImpl());&#x2F;&#x2F;设置目标类 factory.addAspect(LogBeforeLogin.class);&#x2F;&#x2F;设置增强 LoginService loginService &#x3D; factory.getProxy();&#x2F;&#x2F;获取代理 loginService.login(&quot;xsd&quot;); &#125;&#125; 基本跟使用xml方式的@Aspect的步骤差不多。 引介增强Introduction感觉引介增强比1.0更强大了点，直接看代码，对比1.0的引介就知道了。 业务接口： 12345678package me.cxis.spring.aop.introduction;&#x2F;** * Created by cheng.xi on 2017-03-29 12:02. *&#x2F;public interface LoginService &#123; String login(String userName);&#125; 接口实现： 123456789101112package me.cxis.spring.aop.introduction;&#x2F;** * Created by cheng.xi on 2017-03-29 10:36. *&#x2F;public class LoginServiceImpl implements LoginService &#123; public String login(String userName)&#123; System.out.println(&quot;正在登录&quot;); return &quot;success&quot;; &#125;&#125; 另外一个业务接口： 12345678package me.cxis.spring.aop.introduction;&#x2F;** * Created by cheng.xi on 2017-03-30 23:45. *&#x2F;public interface SendEmailService &#123; void sendEmail();&#125; 接口实现： 12345678910package me.cxis.spring.aop.introduction;&#x2F;** * Created by cheng.xi on 2017-03-31 13:46. *&#x2F;public class SendMailServiceImpl implements SendEmailService &#123; public void sendEmail() &#123; System.out.println(&quot;发送邮件。。。。&quot;); &#125;&#125; 增强，也就是把上面两个接口关联起来的地方： 1234567891011121314package me.cxis.spring.aop.introduction;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.DeclareParents;&#x2F;** * Created by cheng.xi on 2017-03-29 10:56. *&#x2F;@Aspectpublic class LogAndSendEmailBeforeLogin &#123; @DeclareParents(value &#x3D; &quot;me.cxis.spring.aop.introduction.LoginServiceImpl&quot;,defaultImpl &#x3D; SendMailServiceImpl.class) private SendEmailService sendEmailService;&#125; xml配置： 12345678910111213141516&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xmlns:aop&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans.xsd http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;aop&#x2F;spring-aop.xsd&quot;&gt; &lt;!--@AspectJ支持--&gt; &lt;aop:aspectj-autoproxy&#x2F;&gt; &lt;!--业务实现--&gt; &lt;bean id&#x3D;&quot;loginService&quot; class&#x3D;&quot;me.cxis.spring.aop.introduction.LoginServiceImpl&quot;&#x2F;&gt; &lt;!--Aspect--&gt; &lt;bean id&#x3D;&quot;logBeforeLoginAspect&quot; class&#x3D;&quot;me.cxis.spring.aop.introduction.LogAndSendEmailBeforeLogin&quot;&gt; &lt;&#x2F;bean&gt;&lt;&#x2F;beans&gt; 测试方法： 12345678910111213141516171819package me.cxis.spring.aop.introduction;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;&#x2F;** * Created by cheng.xi on 2017-03-29 10:34. *&#x2F;public class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:aop-introduction.xml&quot;); LoginService loginService &#x3D; (LoginService) applicationContext.getBean(&quot;loginService&quot;); loginService.login(&quot;sdf&quot;); SendEmailService sendEmailService &#x3D; (SendEmailService) loginService; sendEmailService.sendEmail(); &#125;&#125; 具体的Introduction不做过多解释。另外上面也都是基于接口进行的代理，关于基于类的，这里不做说明。 上面是Spring2.0新增的关于AOP的配置的东西，1.0的方式在2.0中仍然适用。另外在Spring2.5中还增加了AspectJ的load-time织入的支持，也就是在类加载的时候织入。 Spring3,4,5中AOP的配置Spring3,4,5基本就没在增加新的配置方式了，使用的方式基本都还是1.0和2.0中的方式，但是还会有很多的细节以及小特性添加，这里不能过多深入理解。暂先到这里。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JUC中Lock和ReentrantLock介绍及源码解析]]></title>
      <url>%2F2017%2F04%2F08%2FJUC%E4%B8%ADLock%E5%92%8CReentrantLock%E4%BB%8B%E7%BB%8D%E5%8F%8A%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[Lock框架是jdk1.5新增的，作用和synchronized的作用一样，所以学习的时候可以和synchronized做对比。在这里先和synchronized做一下简单对比，然后分析下Lock接口以及ReentrantLock的源码和说明。具体的其他的Lock实现的分析在后面会慢慢介绍。 Lock框架和synchronized有关synchronized的作用和用法不在具体说明，应该都很熟悉了。而Lock有着和synchronized一样的语意，但是比synchronized多了一些功能，单单就从Lock接口定义来看，比synchronized多出来的功能有： 可中断的获取锁，就是获取锁的线程可以响应中断。 可以尝试获取锁，也就是非阻塞获取锁，一个线程可以尝试去获取锁，获取成功就持有锁并返回true，否则返回false。 带超时的尝试获取锁，就是在尝试获取锁的时候，会有超时时间，当到达了指定的时间后，还未获取到锁，就返回false。 除了定义之外，Lock框架还和synchronized有不一样的是： Lock需要显示的加锁和释放锁，而且一定要在finally中去释放锁。而synchronized则不需要我们去关心锁的释放。 锁的公平性，Lock接口并没有定义有关公平性的方法，而是在具体的实现类中使用AQS来实现锁的公平性。 Lock接口源码1234567891011121314151617181920212223242526public interface Lock &#123; &#x2F;&#x2F;获取锁，获取到锁后返回 &#x2F;&#x2F;注意一定要记得释放锁 void lock(); &#x2F;&#x2F;可中断的获取锁 &#x2F;&#x2F;获取锁的时候，如果线程正在等待获取锁，则该线程能响应中断 void lockInterruptibly() throws InterruptedException; &#x2F;&#x2F;尝试获取锁，当线程获取锁的时候，获取成功与否都会立即返回 &#x2F;&#x2F;不会一直等着去获取锁 boolean tryLock(); &#x2F;&#x2F;带有超时时间的尝试获取锁 &#x2F;&#x2F;在一定的时间内获取到锁会返回true &#x2F;&#x2F;在这段时间内被中断了，会返回 &#x2F;&#x2F;在这段时间内，没有获取到锁，会返回false boolean tryLock(long time, TimeUnit unit) throws InterruptedException; &#x2F;&#x2F;释放锁 void unlock(); &#x2F;&#x2F;获取一个Condition对象。 Condition newCondition();&#125; Lock接口的定义并不复杂，获取锁释放锁以及非阻塞式的获取锁等方法的定义。其实想象一下日常使用的时候，也大概是如此，获取锁，释放锁，获取锁的时候没有得到锁，我就转一圈回来再试试，等到一定时间之后，我就不要了，走了。接口的定义没有太多要说的，接下来看Lock接口的实现。 Lock接口的实现Lock接口主要的实现是ReentrantLock重入锁，另外还有ConcurrentHashMap中的Segment继承了ReentrantLock，在ReentrantReadWriteLock中的WriteLock和ReadLock也实现了Lock接口。 ReentrantLockReentrantLock是一个可重入的互斥锁，等同于synchronized，但是比synchronized更强大灵活，减少死锁发生的概率。我们上面说Lock框架提供了公平锁的机制，就是在ReentrantLock中有提供公平锁机制的实现，默认为非公平锁。 在继续看ReentrantLock的各个方法实现之前，首先需要了解下内部是怎么实现公平锁和非公平锁的，其实想一下也简单，比如我就是一可重入锁ReentrantLock，你想从我这获得到公平的还是不公平的，但是不能我说什么就是什么，我这里有一个天平（AQS），这个是大家公认的可以实现公平和不公平的机器，你找我要，我就给天平说一声，他来操作，然后我再把结果给你。（越描述越复杂！）。几乎ReentrantLock中所有的操作都会交给Sync去实现。 有关AQS这里不做介绍，在AQS专门的文章有介绍，请自行查阅把。接下来就看看我拿着的两把锁，公平和不公平。 SyncSync是公平和非公平两种的基类，直接看代码，看不明白的话，可以先看下面公平和非公平的解析，然后再返回来： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677&#x2F;&#x2F;继承自AQSabstract static class Sync extends AbstractQueuedSynchronizer &#123; &#x2F;&#x2F;由具体的子类实现，即公平和非公平的有不同实现 abstract void lock(); &#x2F;&#x2F;非公平的尝试获取 final boolean nonfairTryAcquire(int acquires) &#123; &#x2F;&#x2F;当前线程 final Thread current &#x3D; Thread.currentThread(); &#x2F;&#x2F;当前AQS同步器的状态 int c &#x3D; getState(); &#x2F;&#x2F;状态为0，说明没有人获取锁 if (c &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F;尝试获取，获取成功设为独占模式 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; &#x2F;&#x2F;这里解释跟公平的一样，参照下面的 else if (current &#x3D;&#x3D; getExclusiveOwnerThread()) &#123; int nextc &#x3D; c + acquires; if (nextc &lt; 0) &#x2F;&#x2F; overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; &#x2F;&#x2F;尝试释放 protected final boolean tryRelease(int releases) &#123; int c &#x3D; getState() - releases; if (Thread.currentThread() !&#x3D; getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free &#x3D; false; if (c &#x3D;&#x3D; 0) &#123; free &#x3D; true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125; &#x2F;&#x2F;是否是独占 protected final boolean isHeldExclusively() &#123; &#x2F;&#x2F; While we must in general read state before owner, &#x2F;&#x2F; we don&#39;t need to do so to check if current thread is owner return getExclusiveOwnerThread() &#x3D;&#x3D; Thread.currentThread(); &#125; final ConditionObject newCondition() &#123; return new ConditionObject(); &#125; &#x2F;&#x2F; Methods relayed from outer class &#x2F;&#x2F;获取持有者线程 final Thread getOwner() &#123; return getState() &#x3D;&#x3D; 0 ? null : getExclusiveOwnerThread(); &#125; &#x2F;&#x2F;获取重入数 final int getHoldCount() &#123; return isHeldExclusively() ? getState() : 0; &#125; &#x2F;&#x2F;是否锁了 final boolean isLocked() &#123; return getState() !&#x3D; 0; &#125; &#x2F;&#x2F; private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; s.defaultReadObject(); setState(0); &#x2F;&#x2F; reset to unlocked state &#125;&#125; FairSync公平锁的实现，有关公平的实现，是此类进行处理的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&#x2F;&#x2F;继承自Syncstatic final class FairSync extends Sync &#123; &#x2F;&#x2F;获取锁 &#x2F;&#x2F;公平的lock方法交给了AQS的acquire方法去处理 &#x2F;&#x2F;acquire方法采用独占模式，并且忽略中断 &#x2F;&#x2F;而AQS获取锁的实现是先使用tryAcquire方法获取，获取不到就加入到队列中，一直尝试获取，直到成功返回， &#x2F;&#x2F;tryAcquire的实现又是具体的子类实现的，下面的tryAcquire方法就是公平的tryAcquire实现 &#x2F;&#x2F; final void lock() &#123; &#x2F;&#x2F;参数1是AQS的同步状态 &#x2F;&#x2F;首先了解下AQS中同步状态的定义，state &#x2F;&#x2F;0表示未被获取到锁，1表示已经被获取到锁了，大于1表示重入数 &#x2F;&#x2F;我们要获取锁，肯定是想要现在的同步状态为0，然后我们把状态变成1，这样锁就是我们的了 acquire(1); &#125; &#x2F;&#x2F;公平的tryAcquire方法实现 protected final boolean tryAcquire(int acquires) &#123; &#x2F;&#x2F;当前线程 final Thread current &#x3D; Thread.currentThread(); &#x2F;&#x2F;获取AQS的同步状态 int c &#x3D; getState(); &#x2F;&#x2F;状态为0的话，说明没有其他人获取到锁 if (c &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F;hasQueuedPredecessors查询是否还有其他线程比当前线程等待获取锁的时间更长 &#x2F;&#x2F;compareAndSetState使用cas来设置状态，预期为0，我们想要设置的值为1 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; &#x2F;&#x2F;如果我们是等待获取时间最长的（这就是公平，我等的时间长，就该我第一个被服务） &#x2F;&#x2F;并且cas设置成功了，表示我们获取到锁了 &#x2F;&#x2F;设置当前线程为独占访问 setExclusiveOwnerThread(current); return true; &#125; &#125; &#x2F;&#x2F;往下是state不为0的情况，也就是1，或者大于1 &#x2F;&#x2F;如果当前线程和独占线程是同一个 else if (current &#x3D;&#x3D; getExclusiveOwnerThread()) &#123; &#x2F;&#x2F;当前状态加上我们要获取的参数1 &#x2F;&#x2F;现在表示的是重入数 int nextc &#x3D; c + acquires; &#x2F;&#x2F;state是一个32位整型，小于0，表示重入数超过了最大数 if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); &#x2F;&#x2F;设置当前状态 setState(nextc); return true; &#125; return false; &#125;&#125; 可以看到公平的tryAcquire在获取锁的开始只调用一次，获取到就获取到了，或者已经获取到增加重入数，没有获取到就返回false，如果返回false的话，AQS就会将其加入到队列中一直尝试获取。 NonfairSync123456789101112131415161718&#x2F;&#x2F;也是继承自Syncstatic final class NonfairSync extends Sync &#123; &#x2F;&#x2F;非公平的获取锁 final void lock() &#123; &#x2F;&#x2F;先尝试直接获取锁 &#x2F;&#x2F;如果能获取到锁，就设置为独占模式 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else &#x2F;&#x2F;直接获取不到的话，就会跟公平锁一样的流程去获取 &#x2F;&#x2F;tryAcquire在下面 acquire(1); &#125; &#x2F;&#x2F;这里是非公平的tryAcquire，直接调用Sync中的nofairTryAcquire方法 protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125; 公平和非公平的区别上面看完了代码，有点模糊，感觉代码都差不多，到底公平和非公平差别在哪里。首先看下公平的锁获取，公平锁获取会直接调用acquire方法，acquire方法并不是直接去获取锁，而是调用公平的tryAcquire方法，公平的tryAcquire方法首先获取到当前同步器状态，如果没有人用同步器，也就是状态为0，会先去判断有没有人比我等的时间更长，有的话我就不能获取锁，而是让别人先去；如果我是等待最长的那个，我就去使用CAS更改状态，获取锁。 而非公平的实现是，我上来就直接使用CAS获取锁，不问别人是不是等着很长时间了，我获取到了就是我的了，我获取不到，再调用acquire方法，然后acquire方法中调用非公平的tryAcquire方法，非公平的tryAcquire方法也是很直接，如果当前锁没有人用，也就是state为0，我不管有没有人比我等的时间长，我就去获取，然后设置独占。 公平锁，获取锁首先去尝试，没有的话就排队，轮到我之后，还要去问一下有没有等的时间更长的。非公平锁则是不排队，直接上，没有获取到，我也尝试获取，尝试获取的时候我还是直接上，不管其他人。 了解完公平和非公平锁，再去看其他方法就没那么难了。 ReentrantLock构造函数1234&#x2F;&#x2F;可以看到，默认是非公平的public ReentrantLock() &#123; sync &#x3D; new NonfairSync();&#125; 还可以指定公平性 123public ReentrantLock(boolean fair) &#123; sync &#x3D; fair ? new FairSync() : new NonfairSync();&#125; lock方法1234&#x2F;&#x2F;直接调用公平或者非公平的同步器的lock方法public void lock() &#123; sync.lock();&#125; lock方法有三种情况： 如果锁没有被其他线程持有，当前线程立即获得锁并返回，同步器状态设为1。 如果当前线程已经持有锁，则状态加1，并立即返回。 如果锁被其他线程持有，当前线程挂起直到获取到锁，然后返回，同步器设为1。 lockInterruptibly方法12345&#x2F;&#x2F;可中断的获取锁public void lockInterruptibly() throws InterruptedException &#123; &#x2F;&#x2F;调用AQS的方法 sync.acquireInterruptibly(1);&#125; 获取锁，可以被Thread.interrupt打断。也有三种情况： 如果锁没有被其他线程持有，当前线程立即获得锁并返回，同步器状态设为1。 如果当前线程已经持有锁，则状态加1，并立即返回。 如果锁被其他线程持有，当前线程会挂起去获取锁，在这个过程会有两种情况： 当前线程获取到了锁，返回，同步器状态设置1。 当前线程被中断了，会抛出InterruptedException异常，并清除中断状态。 tryLock方法12345&#x2F;&#x2F;尝试获取锁，不会阻塞，成功与否都会直接返回public boolean tryLock() &#123; &#x2F;&#x2F;使用的是非公平锁的获取 return sync.nonfairTryAcquire(1);&#125; 使用非公平的锁获取，如果使用了公平的，获取的时候还要判断别人是不是了好久，而非公平的nonfairTryAcquire，能获取就直接获取到，获取不到就返回false，比较直接。 如果不想破坏公平性，可以使用带有超时时间的tryLock方法。 带超时的tryLock方法12345&#x2F;&#x2F;在超时间内，并且没有被打断，锁没有被其他线程持有，就立即获取到锁并返回public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout));&#125; 如果使用的是公平锁，如果有其他等的时间更长的线程，即便现在锁没有人持有，当前线程也不会获取到锁，给等的时间更长的去获取。 unlock方法12345&#x2F;&#x2F;释放锁&#x2F;&#x2F;直接调用AQS来释放锁public void unlock() &#123; sync.release(1);&#125; newCondition方法1234&#x2F;&#x2F;返回一个新的Condition实例public Condition newCondition() &#123; return sync.newCondition();&#125; 返回的Condition实例的方法，其实和Object的wait，notify，notifyAll方法的作用一样。 其他方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&#x2F;&#x2F;重入次数 public int getHoldCount() &#123; return sync.getHoldCount();&#125;&#x2F;&#x2F;锁是否被当前线程持有public boolean isHeldByCurrentThread() &#123; return sync.isHeldExclusively();&#125;&#x2F;&#x2F;查询锁是否被任何线程持有public boolean isLocked() &#123; return sync.isLocked();&#125;&#x2F;&#x2F;是否是公平锁public final boolean isFair() &#123; return sync instanceof FairSync;&#125;&#x2F;&#x2F;返回当前拥有锁的线程protected Thread getOwner() &#123; return sync.getOwner();&#125;&#x2F;&#x2F;查询是否有线程在排队获取锁public final boolean hasQueuedThreads() &#123; return sync.hasQueuedThreads();&#125;&#x2F;&#x2F;查询给定的线程是否在等待获取锁public final boolean hasQueuedThread(Thread thread) &#123; return sync.isQueued(thread);&#125;&#x2F;&#x2F;得到正在等待获取锁的队列的长度public final int getQueueLength() &#123; return sync.getQueueLength();&#125;&#x2F;&#x2F;获取正在等待获取锁的所有线程protected Collection&lt;Thread&gt; getQueuedThreads() &#123; return sync.getQueuedThreads();&#125;&#x2F;&#x2F;查询是否有线程正在等待给定的Conditionpublic boolean hasWaiters(Condition condition) &#123; if (condition &#x3D;&#x3D; null) throw new NullPointerException(); if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject)) throw new IllegalArgumentException(&quot;not owner&quot;); return sync.hasWaiters((AbstractQueuedSynchronizer.ConditionObject)condition);&#125;&#x2F;&#x2F;得到正在等待一个Condition的队列的长度public int getWaitQueueLength(Condition condition) &#123; if (condition &#x3D;&#x3D; null) throw new NullPointerException(); if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject)) throw new IllegalArgumentException(&quot;not owner&quot;); return sync.getWaitQueueLength((AbstractQueuedSynchronizer.ConditionObject)condition);&#125;&#x2F;&#x2F;获取所有的等待某个Condition的线程集合protected Collection&lt;Thread&gt; getWaitingThreads(Condition condition) &#123; if (condition &#x3D;&#x3D; null) throw new NullPointerException(); if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject)) throw new IllegalArgumentException(&quot;not owner&quot;); return sync.getWaitingThreads((AbstractQueuedSynchronizer.ConditionObject)condition);&#125; ReentrantLock和synchronized的区别ReentrantLock和synchronized很类似，但是比synchronized多了更多功能，比如可中断锁，锁可以带超时时间，可以尝试非阻塞获取锁等。ReentrantLock还提供了条件Condition，跟Object的wait/notify类似，但是在多个条件变量和高度竞争锁的地方，ReentrantLock更加合适。 另外AQS是重点，一定要多学几遍，学会了，才能掌握锁（我还不太明白！）。 有关其他实现，比如ReentrantReadWriteLock的ReadLock和WriteLock以及ConcurrentHashMap中的Segment会另行介绍。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringMVC执行流程及源码解析]]></title>
      <url>%2F2017%2F04%2F06%2FSpringMVC%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E5%8F%8A%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[在SpringMVC中主要是围绕着DispatcherServlet来设计，可以把它当做指挥中心。这里先说明一下SpringMVC文档给出的执行流程，然后是我们稍微具体的执行流程，最后是流程大致的源码跟踪。关于很很很详细的源码解析，这里暂先不做。 官方文档中的流程首先看下SpringMVC文档上给的流程图： 在SpringMVC中主要是围绕着DispatcherServlet来设计，可以把它当做指挥中心。这里先说明一下SpringMVC文档给出的执行流程，然后是我们稍微具体的执行流程，最后是流程大致的源码跟踪。关于很很很详细的源码解析，这里暂先不做。 官方文档中的流程首先看下SpringMVC文档上给的流程图： 这张图片给了我们大概的执行流程： 用户请求首先发送到前端控制器DispatcherServlet，DispatcherServlet根据请求的信息来决定使用哪个页面控制器Controller（也就是我们通常编写的Controller）来处理该请求。找到控制器之后，DispatcherServlet将请求委托给控制器去处理。 接下来页面控制器开始处理用户请求，页面控制器会根据请求信息进行处理，调用业务层等等，处理完成之后，会把结果封装成一个ModelAndView返回给DispatcherServlet。 前端控制器DispatcherServlet接到页面控制器的返回结果后，根据返回的视图名选择相应的试图模板，并根据返回的数据进行渲染。 最后前端控制器DispatcherServlet将结果返回给用户。 更具体的流程上面只是总体流程，接下来我们稍微深入一点，看下更具体的流程，这里没有图，只有步骤解析： 用户请求发送到前端控制器DispatcherServlet。 前端控制器DispatcherServlet接收到请求后，DispatcherServlet会使用HandlerMapping来处理，HandlerMapping会查找到具体进行处理请求的Handler对象。 HandlerMapping找到对应的Handler之后，并不是返回一个Handler原始对象，而是一个Handler执行链，在这个执行链中包括了拦截器和处理请求的Handler。HandlerMapping返回一个执行链给DispatcherServlet。 DispatcherServlet接收到执行链之后，会调用Handler适配器去执行Handler。 Handler适配器执行完成Handler（也就是我们写的Controller）之后会得到一个ModelAndView，并返回给DispatcherServlet。 DispatcherServlet接收到Handler适配器返回的ModelAndView之后，会根据其中的视图名调用视图解析器。 视图解析器根据逻辑视图名解析成一个真正的View视图，并返回给DispatcherServlet。 DispatcherServlet接收到视图之后，会根据上面的ModelAndView中的model来进行视图中数据的填充，也就是所谓的视图渲染。 渲染完成之后，DispatcherServlet就可以将结果返回给用户了。 源码DispatcherServlet是一个Servlet，我们知道在Servlet在处理一个请求的时候会交给service方法进行处理，这里也不例外，DispatcherServlet继承了FrameworkServlet，首先进入FrameworkServlet的service方法： 123456789101112protected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; &#x2F;&#x2F;请求方法 String method &#x3D; request.getMethod(); &#x2F;&#x2F;PATCH方法单独处理 if (method.equalsIgnoreCase(RequestMethod.PATCH.name())) &#123; processRequest(request, response); &#125; else &#123;&#x2F;&#x2F;其他的请求类型的方法经由父类，也就是HttpServlet处理 super.service(request, response); &#125;&#125; HttpServlet中会根据请求类型的不同分别调用doGet或者doPost等方法，FrameworkServlet中已经重写了这些方法，在这些方法中会调用processRequest进行处理，在processRequest中会调用doService方法，这个doService方法就是在DispatcherServlet中实现的。下面就看下DispatcherServlet中的doService方法的实现。 请求到达DispatcherServletdoService方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; &#x2F;&#x2F;给request中的属性做一份快照 Map&lt;String, Object&gt; attributesSnapshot &#x3D; null; if (WebUtils.isIncludeRequest(request)) &#123; logger.debug(&quot;Taking snapshot of request attributes before include&quot;); attributesSnapshot &#x3D; new HashMap&lt;String, Object&gt;(); Enumeration&lt;?&gt; attrNames &#x3D; request.getAttributeNames(); while (attrNames.hasMoreElements()) &#123; String attrName &#x3D; (String) attrNames.nextElement(); if (this.cleanupAfterInclude || attrName.startsWith(&quot;org.springframework.web.servlet&quot;)) &#123; attributesSnapshot.put(attrName, request.getAttribute(attrName)); &#125; &#125; &#125; &#x2F;&#x2F;如果我们没有配置类似本地化或者主题的处理器之类的 &#x2F;&#x2F;SpringMVC会使用默认的值 &#x2F;&#x2F;默认配置文件是DispatcherServlet.properties request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); FlashMap inputFlashMap &#x3D; this.flashMapManager.retrieveAndUpdate(request, response); if (inputFlashMap !&#x3D; null) &#123; request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap)); &#125; request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); try &#123; &#x2F;&#x2F;开始处理 doDispatch(request, response); &#125; finally &#123; if (WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123; return; &#125; &#x2F;&#x2F; Restore the original attribute snapshot, in case of an include. if (attributesSnapshot !&#x3D; null) &#123; restoreAttributesAfterInclude(request, attributesSnapshot); &#125; &#125;&#125; DispatcherServlet开始真正的处理，doDispatch方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest &#x3D; request; HandlerExecutionChain mappedHandler &#x3D; null; boolean multipartRequestParsed &#x3D; false; &#x2F;&#x2F;SpringMVC中异步请求的相关知识，暂先不解释 WebAsyncManager asyncManager &#x3D; WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv &#x3D; null; Exception dispatchException &#x3D; null; try &#123; &#x2F;&#x2F;先检查是不是Multipart类型的，比如上传等 &#x2F;&#x2F;如果是Multipart类型的，则转换为MultipartHttpServletRequest类型 processedRequest &#x3D; checkMultipart(request); multipartRequestParsed &#x3D; processedRequest !&#x3D; request; &#x2F;&#x2F;获取当前请求的Handler mappedHandler &#x3D; getHandler(processedRequest, false); if (mappedHandler &#x3D;&#x3D; null || mappedHandler.getHandler() &#x3D;&#x3D; null) &#123; noHandlerFound(processedRequest, response); return; &#125; &#x2F;&#x2F;获取当前请求的Handler适配器 HandlerAdapter ha &#x3D; getHandlerAdapter(mappedHandler.getHandler()); &#x2F;&#x2F; 对于header中last-modified的处理 String method &#x3D; request.getMethod(); boolean isGet &#x3D; &quot;GET&quot;.equals(method); if (isGet || &quot;HEAD&quot;.equals(method)) &#123; long lastModified &#x3D; ha.getLastModified(request, mappedHandler.getHandler()); if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; &#x2F;&#x2F;拦截器的preHandle方法进行处理 if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; try &#123; &#x2F;&#x2F;真正调用Handler的地方 mv &#x3D; ha.handle(processedRequest, response, mappedHandler.getHandler()); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; &#125; &#x2F;&#x2F;处理成默认视图名，就是添加前缀和后缀等 applyDefaultViewName(request, mv); &#x2F;&#x2F;拦截器postHandle方法进行处理 mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException &#x3D; ex; &#125; &#x2F;&#x2F;处理最后的结果，渲染之类的都在这里 processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Error err) &#123; triggerAfterCompletionWithError(processedRequest, response, mappedHandler, err); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; &#x2F;&#x2F; Instead of postHandle and afterCompletion mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); return; &#125; &#x2F;&#x2F; Clean up any resources used by a multipart request. if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); &#125; &#125;&#125; 可以看到大概的步骤还是按照我们上面分析的走的。 查找请求对应的Handler对象对应着这句代码mappedHandler = getHandler(processedRequest, false);，看下具体的getHandler方法： 123protected HandlerExecutionChain getHandler(HttpServletRequest request, boolean cache) throws Exception &#123; return getHandler(request);&#125; 继续往下看getHandler： 1234567891011protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; &#x2F;&#x2F;遍历所有的handlerMappings进行处理 &#x2F;&#x2F;handlerMappings是在启动的时候预先注册好的 for (HandlerMapping hm : this.handlerMappings) &#123; HandlerExecutionChain handler &#x3D; hm.getHandler(request); if (handler !&#x3D; null) &#123; return handler; &#125; &#125; return null;&#125; 继续往下看getHandler，在AbstractHandlerMapping类中： 12345678910111213141516171819public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; &#x2F;&#x2F;根据request获取handler Object handler &#x3D; getHandlerInternal(request); if (handler &#x3D;&#x3D; null) &#123; &#x2F;&#x2F;如果没有找到就使用默认的handler handler &#x3D; getDefaultHandler(); &#125; if (handler &#x3D;&#x3D; null) &#123; return null; &#125; &#x2F;&#x2F;如果Handler是String，表明是一个bean名称 &#x2F;&#x2F;需要超照对应bean if (handler instanceof String) &#123; String handlerName &#x3D; (String) handler; handler &#x3D; getApplicationContext().getBean(handlerName); &#125; &#x2F;&#x2F;封装Handler执行链 return getHandlerExecutionChain(handler, request);&#125; 根据requrst获取handler首先看下根据requrst获取handler步骤getHandlerInternal方法，在AbstractHandlerMethodMapping中： 12345678protected HandlerMethod getHandlerInternal(HttpServletRequest request) throws Exception &#123; &#x2F;&#x2F;获取request中的url，用来匹配handler String lookupPath &#x3D; getUrlPathHelper().getLookupPathForRequest(request); &#x2F;&#x2F;根据路径寻找Handler HandlerMethod handlerMethod &#x3D; lookupHandlerMethod(lookupPath, request); &#x2F;&#x2F;根据handlerMethod中的bean来实例化Handler并添加进HandlerMethod return (handlerMethod !&#x3D; null) ? handlerMethod.createWithResolvedBean() : null;&#125; 看下根据路径寻找handler的方法lookupHandlerMethod： 123456789101112131415161718192021222324252627282930313233343536373839protected HandlerMethod lookupHandlerMethod(String lookupPath, HttpServletRequest request) throws Exception &#123; List&lt;Match&gt; matches &#x3D; new ArrayList&lt;Match&gt;(); &#x2F;&#x2F;直接匹配 List&lt;T&gt; directPathMatches &#x3D; this.urlMap.get(lookupPath); &#x2F;&#x2F;如果有匹配的，就添加进匹配列表中 if (directPathMatches !&#x3D; null) &#123; addMatchingMappings(directPathMatches, matches, request); &#125; &#x2F;&#x2F;还没有匹配的，就遍历所有的处理方法查找 if (matches.isEmpty()) &#123; &#x2F;&#x2F; No choice but to go through all mappings addMatchingMappings(this.handlerMethods.keySet(), matches, request); &#125; &#x2F;&#x2F;找到了匹配的 if (!matches.isEmpty()) &#123; Comparator&lt;Match&gt; comparator &#x3D; new MatchComparator(getMappingComparator(request)); Collections.sort(matches, comparator); &#x2F;&#x2F;排序之后，获取第一个 Match bestMatch &#x3D; matches.get(0); &#x2F;&#x2F;如果有多个匹配的，会找到第二个最合适的进行比较一下 if (matches.size() &gt; 1) &#123; Match secondBestMatch &#x3D; matches.get(1); if (comparator.compare(bestMatch, secondBestMatch) &#x3D;&#x3D; 0) &#123; Method m1 &#x3D; bestMatch.handlerMethod.getMethod(); Method m2 &#x3D; secondBestMatch.handlerMethod.getMethod(); throw new IllegalStateException( &quot;Ambiguous handler methods mapped for HTTP path &#39;&quot; + request.getRequestURL() + &quot;&#39;: &#123;&quot; + m1 + &quot;, &quot; + m2 + &quot;&#125;&quot;); &#125; &#125; &#x2F;&#x2F;设置request参数 handleMatch(bestMatch.mapping, lookupPath, request); &#x2F;&#x2F;返回匹配的url的处理的方法 return bestMatch.handlerMethod; &#125; else &#123;&#x2F;&#x2F;最后还没有找到，返回null return handleNoMatch(handlerMethods.keySet(), lookupPath, request); &#125;&#125; 获取默认Handler如果上面没有获取到Handler，就会获取默认的Handler。如果还获取不到就返回null。 处理String类型的Handler如果上面处理完的Handler是String类型的，就会根据这个handlerName获取bean。 封装Handler执行链上面获取完Handler，就开始封装执行链了，就是将我们配置的拦截器加入到执行链中去，getHandlerExecutionChain： 123456789101112131415161718protected HandlerExecutionChain getHandlerExecutionChain(Object handler, HttpServletRequest request) &#123; &#x2F;&#x2F;如果当前Handler不是执行链类型，就使用一个新的执行链实例封装起来 HandlerExecutionChain chain &#x3D; (handler instanceof HandlerExecutionChain) ? (HandlerExecutionChain) handler : new HandlerExecutionChain(handler); &#x2F;&#x2F;先获取适配类型的拦截器添加进去拦截器链 chain.addInterceptors(getAdaptedInterceptors()); &#x2F;&#x2F;当前的url String lookupPath &#x3D; urlPathHelper.getLookupPathForRequest(request); &#x2F;&#x2F;遍历拦截器，找到跟当前url对应的，添加进执行链中去 for (MappedInterceptor mappedInterceptor : mappedInterceptors) &#123; if (mappedInterceptor.matches(lookupPath, pathMatcher)) &#123; chain.addInterceptor(mappedInterceptor.getInterceptor()); &#125; &#125; return chain;&#125; 获取对应请求的Handler适配器getHandlerAdapter： 123456789protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException &#123; &#x2F;&#x2F;遍历所有的HandlerAdapter，找到和当前Handler匹配的就返回 &#x2F;&#x2F;我们这里会匹配到RequestMappingHandlerAdapter for (HandlerAdapter ha : this.handlerAdapters) &#123; if (ha.supports(handler)) &#123; return ha; &#125; &#125;&#125; 缓存的处理也就是对last-modified的处理 执行拦截器的preHandle方法就是遍历所有的我们定义的interceptor，执行preHandle方法 使用Handler适配器执行当前的Handlerha.handle执行当前Handler，我们这里使用的是RequestMappingHandlerAdapter，首先会进入AbstractHandlerMethodAdapter的handle方法： 1234public final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return handleInternal(request, response, (HandlerMethod) handler);&#125; handleInternal方法，在RequestMappingHandlerAdapter中： 12345678910111213141516171819202122232425protected final ModelAndView handleInternal(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; if (getSessionAttributesHandler(handlerMethod).hasSessionAttributes()) &#123; &#x2F;&#x2F; Always prevent caching in case of session attribute management. checkAndPrepare(request, response, this.cacheSecondsForSessionAttributeHandlers, true); &#125; else &#123; &#x2F;&#x2F; Uses configured default cacheSeconds setting. checkAndPrepare(request, response, true); &#125; &#x2F;&#x2F; Execute invokeHandlerMethod in synchronized block if required. if (this.synchronizeOnSession) &#123; HttpSession session &#x3D; request.getSession(false); if (session !&#x3D; null) &#123; Object mutex &#x3D; WebUtils.getSessionMutex(session); synchronized (mutex) &#123; return invokeHandleMethod(request, response, handlerMethod); &#125; &#125; &#125; &#x2F;&#x2F;执行方法，封装ModelAndView return invokeHandleMethod(request, response, handlerMethod);&#125; 组装默认视图名称前缀和后缀名都加上 执行拦截器的postHandle方法遍历intercepter的postHandle方法。 处理最后的结果，渲染之类的processDispatchResult方法： 123456789101112131415161718192021222324252627282930313233343536private void processDispatchResult(HttpServletRequest request, HttpServletResponse response, HandlerExecutionChain mappedHandler, ModelAndView mv, Exception exception) throws Exception &#123; boolean errorView &#x3D; false; if (exception !&#x3D; null) &#123; if (exception instanceof ModelAndViewDefiningException) &#123; mv &#x3D; ((ModelAndViewDefiningException) exception).getModelAndView(); &#125; else &#123; Object handler &#x3D; (mappedHandler !&#x3D; null ? mappedHandler.getHandler() : null); mv &#x3D; processHandlerException(request, response, handler, exception); errorView &#x3D; (mv !&#x3D; null); &#125; &#125; &#x2F;&#x2F; Did the handler return a view to render? if (mv !&#x3D; null &amp;&amp; !mv.wasCleared()) &#123; &#x2F;&#x2F;渲染 render(mv, request, response); if (errorView) &#123; WebUtils.clearErrorRequestAttributes(request); &#125; &#125; else &#123; &#125; if (WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123; &#x2F;&#x2F; Concurrent handling started during a forward return; &#125; if (mappedHandler !&#x3D; null) &#123; mappedHandler.triggerAfterCompletion(request, response, null); &#125;&#125; 重点看下render方法，进行渲染： 12345678910111213141516171819202122protected void render(ModelAndView mv, HttpServletRequest request, HttpServletResponse response) throws Exception &#123; &#x2F;&#x2F;设置本地化 Locale locale &#x3D; this.localeResolver.resolveLocale(request); response.setLocale(locale); View view; if (mv.isReference()) &#123; &#x2F;&#x2F;解析视图名，得到视图 view &#x3D; resolveViewName(mv.getViewName(), mv.getModelInternal(), locale, request); &#125; else &#123; &#x2F;&#x2F; No need to lookup: the ModelAndView object contains the actual View object. view &#x3D; mv.getView(); if (view &#x3D;&#x3D; null) &#123; throw new ServletException(&quot;ModelAndView [&quot; + mv + &quot;] neither contains a view name nor a &quot; + &quot;View object in servlet with name &#39;&quot; + getServletName() + &quot;&#39;&quot;); &#125; &#125; &#x2F;&#x2F;委托给视图进行渲染 view.render(mv.getModelInternal(), request, response);&#125; view.render就是进行视图的渲染，然后跳转页面等处理。 到这里大概的流程就走完了。其中涉及到的东西还有很多，暂先不做详细处理。 这张图片给了我们大概的执行流程： 用户请求首先发送到前端控制器DispatcherServlet，DispatcherServlet根据请求的信息来决定使用哪个页面控制器Controller（也就是我们通常编写的Controller）来处理该请求。找到控制器之后，DispatcherServlet将请求委托给控制器去处理。 接下来页面控制器开始处理用户请求，页面控制器会根据请求信息进行处理，调用业务层等等，处理完成之后，会把结果封装成一个ModelAndView返回给DispatcherServlet。 前端控制器DispatcherServlet接到页面控制器的返回结果后，根据返回的视图名选择相应的试图模板，并根据返回的数据进行渲染。 最后前端控制器DispatcherServlet将结果返回给用户。 更具体的流程上面只是总体流程，接下来我们稍微深入一点，看下更具体的流程，这里没有图，只有步骤解析： 用户请求发送到前端控制器DispatcherServlet。 前端控制器DispatcherServlet接收到请求后，DispatcherServlet会使用HandlerMapping来处理，HandlerMapping会查找到具体进行处理请求的Handler对象。 HandlerMapping找到对应的Handler之后，并不是返回一个Handler原始对象，而是一个Handler执行链，在这个执行链中包括了拦截器和处理请求的Handler。HandlerMapping返回一个执行链给DispatcherServlet。 DispatcherServlet接收到执行链之后，会调用Handler适配器去执行Handler。 Handler适配器执行完成Handler（也就是我们写的Controller）之后会得到一个ModelAndView，并返回给DispatcherServlet。 DispatcherServlet接收到Handler适配器返回的ModelAndView之后，会根据其中的视图名调用视图解析器。 视图解析器根据逻辑视图名解析成一个真正的View视图，并返回给DispatcherServlet。 DispatcherServlet接收到视图之后，会根据上面的ModelAndView中的model来进行视图中数据的填充，也就是所谓的视图渲染。 渲染完成之后，DispatcherServlet就可以将结果返回给用户了。 源码DispatcherServlet是一个Servlet，我们知道在Servlet在处理一个请求的时候会交给service方法进行处理，这里也不例外，DispatcherServlet继承了FrameworkServlet，首先进入FrameworkServlet的service方法： 123456789101112protected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; &#x2F;&#x2F;请求方法 String method &#x3D; request.getMethod(); &#x2F;&#x2F;PATCH方法单独处理 if (method.equalsIgnoreCase(RequestMethod.PATCH.name())) &#123; processRequest(request, response); &#125; else &#123;&#x2F;&#x2F;其他的请求类型的方法经由父类，也就是HttpServlet处理 super.service(request, response); &#125;&#125; HttpServlet中会根据请求类型的不同分别调用doGet或者doPost等方法，FrameworkServlet中已经重写了这些方法，在这些方法中会调用processRequest进行处理，在processRequest中会调用doService方法，这个doService方法就是在DispatcherServlet中实现的。下面就看下DispatcherServlet中的doService方法的实现。 请求到达DispatcherServletdoService方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; &#x2F;&#x2F;给request中的属性做一份快照 Map&lt;String, Object&gt; attributesSnapshot &#x3D; null; if (WebUtils.isIncludeRequest(request)) &#123; logger.debug(&quot;Taking snapshot of request attributes before include&quot;); attributesSnapshot &#x3D; new HashMap&lt;String, Object&gt;(); Enumeration&lt;?&gt; attrNames &#x3D; request.getAttributeNames(); while (attrNames.hasMoreElements()) &#123; String attrName &#x3D; (String) attrNames.nextElement(); if (this.cleanupAfterInclude || attrName.startsWith(&quot;org.springframework.web.servlet&quot;)) &#123; attributesSnapshot.put(attrName, request.getAttribute(attrName)); &#125; &#125; &#125; &#x2F;&#x2F;如果我们没有配置类似本地化或者主题的处理器之类的 &#x2F;&#x2F;SpringMVC会使用默认的值 &#x2F;&#x2F;默认配置文件是DispatcherServlet.properties request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); FlashMap inputFlashMap &#x3D; this.flashMapManager.retrieveAndUpdate(request, response); if (inputFlashMap !&#x3D; null) &#123; request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap)); &#125; request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); try &#123; &#x2F;&#x2F;开始处理 doDispatch(request, response); &#125; finally &#123; if (WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123; return; &#125; &#x2F;&#x2F; Restore the original attribute snapshot, in case of an include. if (attributesSnapshot !&#x3D; null) &#123; restoreAttributesAfterInclude(request, attributesSnapshot); &#125; &#125;&#125; DispatcherServlet开始真正的处理，doDispatch方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest &#x3D; request; HandlerExecutionChain mappedHandler &#x3D; null; boolean multipartRequestParsed &#x3D; false; &#x2F;&#x2F;SpringMVC中异步请求的相关知识，暂先不解释 WebAsyncManager asyncManager &#x3D; WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv &#x3D; null; Exception dispatchException &#x3D; null; try &#123; &#x2F;&#x2F;先检查是不是Multipart类型的，比如上传等 &#x2F;&#x2F;如果是Multipart类型的，则转换为MultipartHttpServletRequest类型 processedRequest &#x3D; checkMultipart(request); multipartRequestParsed &#x3D; processedRequest !&#x3D; request; &#x2F;&#x2F;获取当前请求的Handler mappedHandler &#x3D; getHandler(processedRequest, false); if (mappedHandler &#x3D;&#x3D; null || mappedHandler.getHandler() &#x3D;&#x3D; null) &#123; noHandlerFound(processedRequest, response); return; &#125; &#x2F;&#x2F;获取当前请求的Handler适配器 HandlerAdapter ha &#x3D; getHandlerAdapter(mappedHandler.getHandler()); &#x2F;&#x2F; 对于header中last-modified的处理 String method &#x3D; request.getMethod(); boolean isGet &#x3D; &quot;GET&quot;.equals(method); if (isGet || &quot;HEAD&quot;.equals(method)) &#123; long lastModified &#x3D; ha.getLastModified(request, mappedHandler.getHandler()); if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; &#x2F;&#x2F;拦截器的preHandle方法进行处理 if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; try &#123; &#x2F;&#x2F;真正调用Handler的地方 mv &#x3D; ha.handle(processedRequest, response, mappedHandler.getHandler()); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; &#125; &#x2F;&#x2F;处理成默认视图名，就是添加前缀和后缀等 applyDefaultViewName(request, mv); &#x2F;&#x2F;拦截器postHandle方法进行处理 mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException &#x3D; ex; &#125; &#x2F;&#x2F;处理最后的结果，渲染之类的都在这里 processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Error err) &#123; triggerAfterCompletionWithError(processedRequest, response, mappedHandler, err); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; &#x2F;&#x2F; Instead of postHandle and afterCompletion mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); return; &#125; &#x2F;&#x2F; Clean up any resources used by a multipart request. if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); &#125; &#125;&#125; 可以看到大概的步骤还是按照我们上面分析的走的。 查找请求对应的Handler对象对应着这句代码mappedHandler = getHandler(processedRequest, false);，看下具体的getHandler方法： 123protected HandlerExecutionChain getHandler(HttpServletRequest request, boolean cache) throws Exception &#123; return getHandler(request);&#125; 继续往下看getHandler： 1234567891011protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; &#x2F;&#x2F;遍历所有的handlerMappings进行处理 &#x2F;&#x2F;handlerMappings是在启动的时候预先注册好的 for (HandlerMapping hm : this.handlerMappings) &#123; HandlerExecutionChain handler &#x3D; hm.getHandler(request); if (handler !&#x3D; null) &#123; return handler; &#125; &#125; return null;&#125; 继续往下看getHandler，在AbstractHandlerMapping类中： 12345678910111213141516171819public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; &#x2F;&#x2F;根据request获取handler Object handler &#x3D; getHandlerInternal(request); if (handler &#x3D;&#x3D; null) &#123; &#x2F;&#x2F;如果没有找到就使用默认的handler handler &#x3D; getDefaultHandler(); &#125; if (handler &#x3D;&#x3D; null) &#123; return null; &#125; &#x2F;&#x2F;如果Handler是String，表明是一个bean名称 &#x2F;&#x2F;需要超照对应bean if (handler instanceof String) &#123; String handlerName &#x3D; (String) handler; handler &#x3D; getApplicationContext().getBean(handlerName); &#125; &#x2F;&#x2F;封装Handler执行链 return getHandlerExecutionChain(handler, request);&#125; 根据requrst获取handler首先看下根据requrst获取handler步骤getHandlerInternal方法，在AbstractHandlerMethodMapping中： 12345678protected HandlerMethod getHandlerInternal(HttpServletRequest request) throws Exception &#123; &#x2F;&#x2F;获取request中的url，用来匹配handler String lookupPath &#x3D; getUrlPathHelper().getLookupPathForRequest(request); &#x2F;&#x2F;根据路径寻找Handler HandlerMethod handlerMethod &#x3D; lookupHandlerMethod(lookupPath, request); &#x2F;&#x2F;根据handlerMethod中的bean来实例化Handler并添加进HandlerMethod return (handlerMethod !&#x3D; null) ? handlerMethod.createWithResolvedBean() : null;&#125; 看下根据路径寻找handler的方法lookupHandlerMethod： 123456789101112131415161718192021222324252627282930313233343536373839protected HandlerMethod lookupHandlerMethod(String lookupPath, HttpServletRequest request) throws Exception &#123; List&lt;Match&gt; matches &#x3D; new ArrayList&lt;Match&gt;(); &#x2F;&#x2F;直接匹配 List&lt;T&gt; directPathMatches &#x3D; this.urlMap.get(lookupPath); &#x2F;&#x2F;如果有匹配的，就添加进匹配列表中 if (directPathMatches !&#x3D; null) &#123; addMatchingMappings(directPathMatches, matches, request); &#125; &#x2F;&#x2F;还没有匹配的，就遍历所有的处理方法查找 if (matches.isEmpty()) &#123; &#x2F;&#x2F; No choice but to go through all mappings addMatchingMappings(this.handlerMethods.keySet(), matches, request); &#125; &#x2F;&#x2F;找到了匹配的 if (!matches.isEmpty()) &#123; Comparator&lt;Match&gt; comparator &#x3D; new MatchComparator(getMappingComparator(request)); Collections.sort(matches, comparator); &#x2F;&#x2F;排序之后，获取第一个 Match bestMatch &#x3D; matches.get(0); &#x2F;&#x2F;如果有多个匹配的，会找到第二个最合适的进行比较一下 if (matches.size() &gt; 1) &#123; Match secondBestMatch &#x3D; matches.get(1); if (comparator.compare(bestMatch, secondBestMatch) &#x3D;&#x3D; 0) &#123; Method m1 &#x3D; bestMatch.handlerMethod.getMethod(); Method m2 &#x3D; secondBestMatch.handlerMethod.getMethod(); throw new IllegalStateException( &quot;Ambiguous handler methods mapped for HTTP path &#39;&quot; + request.getRequestURL() + &quot;&#39;: &#123;&quot; + m1 + &quot;, &quot; + m2 + &quot;&#125;&quot;); &#125; &#125; &#x2F;&#x2F;设置request参数 handleMatch(bestMatch.mapping, lookupPath, request); &#x2F;&#x2F;返回匹配的url的处理的方法 return bestMatch.handlerMethod; &#125; else &#123;&#x2F;&#x2F;最后还没有找到，返回null return handleNoMatch(handlerMethods.keySet(), lookupPath, request); &#125;&#125; 获取默认Handler如果上面没有获取到Handler，就会获取默认的Handler。如果还获取不到就返回null。 处理String类型的Handler如果上面处理完的Handler是String类型的，就会根据这个handlerName获取bean。 封装Handler执行链上面获取完Handler，就开始封装执行链了，就是将我们配置的拦截器加入到执行链中去，getHandlerExecutionChain： 123456789101112131415161718protected HandlerExecutionChain getHandlerExecutionChain(Object handler, HttpServletRequest request) &#123; &#x2F;&#x2F;如果当前Handler不是执行链类型，就使用一个新的执行链实例封装起来 HandlerExecutionChain chain &#x3D; (handler instanceof HandlerExecutionChain) ? (HandlerExecutionChain) handler : new HandlerExecutionChain(handler); &#x2F;&#x2F;先获取适配类型的拦截器添加进去拦截器链 chain.addInterceptors(getAdaptedInterceptors()); &#x2F;&#x2F;当前的url String lookupPath &#x3D; urlPathHelper.getLookupPathForRequest(request); &#x2F;&#x2F;遍历拦截器，找到跟当前url对应的，添加进执行链中去 for (MappedInterceptor mappedInterceptor : mappedInterceptors) &#123; if (mappedInterceptor.matches(lookupPath, pathMatcher)) &#123; chain.addInterceptor(mappedInterceptor.getInterceptor()); &#125; &#125; return chain;&#125; 获取对应请求的Handler适配器getHandlerAdapter： 123456789protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException &#123; &#x2F;&#x2F;遍历所有的HandlerAdapter，找到和当前Handler匹配的就返回 &#x2F;&#x2F;我们这里会匹配到RequestMappingHandlerAdapter for (HandlerAdapter ha : this.handlerAdapters) &#123; if (ha.supports(handler)) &#123; return ha; &#125; &#125;&#125; 缓存的处理也就是对last-modified的处理 执行拦截器的preHandle方法就是遍历所有的我们定义的interceptor，执行preHandle方法 使用Handler适配器执行当前的Handlerha.handle执行当前Handler，我们这里使用的是RequestMappingHandlerAdapter，首先会进入AbstractHandlerMethodAdapter的handle方法： 1234public final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return handleInternal(request, response, (HandlerMethod) handler);&#125; handleInternal方法，在RequestMappingHandlerAdapter中： 12345678910111213141516171819202122232425protected final ModelAndView handleInternal(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; if (getSessionAttributesHandler(handlerMethod).hasSessionAttributes()) &#123; &#x2F;&#x2F; Always prevent caching in case of session attribute management. checkAndPrepare(request, response, this.cacheSecondsForSessionAttributeHandlers, true); &#125; else &#123; &#x2F;&#x2F; Uses configured default cacheSeconds setting. checkAndPrepare(request, response, true); &#125; &#x2F;&#x2F; Execute invokeHandlerMethod in synchronized block if required. if (this.synchronizeOnSession) &#123; HttpSession session &#x3D; request.getSession(false); if (session !&#x3D; null) &#123; Object mutex &#x3D; WebUtils.getSessionMutex(session); synchronized (mutex) &#123; return invokeHandleMethod(request, response, handlerMethod); &#125; &#125; &#125; &#x2F;&#x2F;执行方法，封装ModelAndView return invokeHandleMethod(request, response, handlerMethod);&#125; 组装默认视图名称前缀和后缀名都加上 执行拦截器的postHandle方法遍历intercepter的postHandle方法。 处理最后的结果，渲染之类的processDispatchResult方法： 123456789101112131415161718192021222324252627282930313233343536private void processDispatchResult(HttpServletRequest request, HttpServletResponse response, HandlerExecutionChain mappedHandler, ModelAndView mv, Exception exception) throws Exception &#123; boolean errorView &#x3D; false; if (exception !&#x3D; null) &#123; if (exception instanceof ModelAndViewDefiningException) &#123; mv &#x3D; ((ModelAndViewDefiningException) exception).getModelAndView(); &#125; else &#123; Object handler &#x3D; (mappedHandler !&#x3D; null ? mappedHandler.getHandler() : null); mv &#x3D; processHandlerException(request, response, handler, exception); errorView &#x3D; (mv !&#x3D; null); &#125; &#125; &#x2F;&#x2F; Did the handler return a view to render? if (mv !&#x3D; null &amp;&amp; !mv.wasCleared()) &#123; &#x2F;&#x2F;渲染 render(mv, request, response); if (errorView) &#123; WebUtils.clearErrorRequestAttributes(request); &#125; &#125; else &#123; &#125; if (WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123; &#x2F;&#x2F; Concurrent handling started during a forward return; &#125; if (mappedHandler !&#x3D; null) &#123; mappedHandler.triggerAfterCompletion(request, response, null); &#125;&#125; 重点看下render方法，进行渲染： 12345678910111213141516171819202122protected void render(ModelAndView mv, HttpServletRequest request, HttpServletResponse response) throws Exception &#123; &#x2F;&#x2F;设置本地化 Locale locale &#x3D; this.localeResolver.resolveLocale(request); response.setLocale(locale); View view; if (mv.isReference()) &#123; &#x2F;&#x2F;解析视图名，得到视图 view &#x3D; resolveViewName(mv.getViewName(), mv.getModelInternal(), locale, request); &#125; else &#123; &#x2F;&#x2F; No need to lookup: the ModelAndView object contains the actual View object. view &#x3D; mv.getView(); if (view &#x3D;&#x3D; null) &#123; throw new ServletException(&quot;ModelAndView [&quot; + mv + &quot;] neither contains a view name nor a &quot; + &quot;View object in servlet with name &#39;&quot; + getServletName() + &quot;&#39;&quot;); &#125; &#125; &#x2F;&#x2F;委托给视图进行渲染 view.render(mv.getModelInternal(), request, response);&#125; view.render就是进行视图的渲染，然后跳转页面等处理。 到这里大概的流程就走完了。其中涉及到的东西还有很多，暂先不做详细处理。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Ubuntu，请告诉我这不是真的！]]></title>
      <url>%2F2017%2F04%2F06%2FUbuntu%EF%BC%8C%E8%AF%B7%E5%91%8A%E8%AF%89%E6%88%91%E8%BF%99%E4%B8%8D%E6%98%AF%E7%9C%9F%E7%9A%84%EF%BC%81%2F</url>
      <content type="text"><![CDATA[Ubuntu别闹，请告诉我这是愚人节的过期玩笑。 We are wrapping up an excellent quarter and an excellent year for the company, with performance in many teams and products that we can be proud of. As we head into the new fiscal year, it’s appropriate to reassess each of our initiatives. I’m writing to let you know that we will end our investment in Unity8, the phone and convergence shell. We will shift our default Ubuntu desktop back to GNOME for Ubuntu 18.04 LTS. 详情见： https://insights.ubuntu.com/2017/04/05/growing-ubuntu-for-cloud-and-iot-rather-than-phone-and-convergence/ Unity8，Phone放弃，可以原谅，但是Unity也要放弃吗？要用Gnome！！我就当没看到～没看到～我不听～我不听！ 又要换回mac了～]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用gogs搭建git服务器记录]]></title>
      <url>%2F2017%2F04%2F03%2F%E4%BD%BF%E7%94%A8gogs%E6%90%AD%E5%BB%BAgit%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%B0%E5%BD%95%2F</url>
      <content type="text"><![CDATA[昨晚半夜网上一个朋友找到我，说是使用gogs搭建git服务器，使用ssh操作要免密啥啥啥的～也没描述清楚。就是要ssh的方式，提交时候不要账号密码，心想这不就三下的事情吗？结果折腾到晚上一点，没好～敢肯定的是他按照网上的毒教程，被坑了！还是自己本地虚拟机配置一下吧～ 环境说明 本机Ubuntu16.10 virtualbox上运行的是Centos7 虚拟机中mysql已经安装好 虚拟机中firewall已禁用，安装了iptables 虚拟机中已经安装git 步骤 去gogs网站下载，这里下载的是0.10.18版本，文件名是linux_amd64.zip mysql建立gogs数据库 新建用户名字为git的用户（用户目录/home/git） 解压下载的文件，然后运行程序 配置，安装 现在已经可以访问了，也可以使用http方式进行clone和提交了 配置ssh方式 下载gogs去gogs网站下载，https://dl.gogs.io/ ，我下载的是0.10.18，linux 64位版本。 建立gogs数据库在mysql中建立gogs数据库。 新建git用户在虚拟机Centos中新建一个git用户。 创建git组：sudo groupadd git。 创建git用户，分到git组中：sudo useradd -g git git 设置git用户的密码：sudo passwd git 接下来切换到刚才新建的git用户，一定要切换到这个git用户！！！！ 切换用户：su git 解压文件，运行现在已经切换到git这个用户了，切记一定要切换到git这个用户才能执行以下步骤。 首先进入/home/git目录下，将下载的文件解压到/home/git目录下并重新命名，我这里是命名为gogs。然后进入gogs文件夹下，运行./gogs web，应该没啥错。 配置，安装上面运行完成之后，打开浏览器输入：http://localhost:3000/install ，就可以看到安装配置页面了，里面配置根据自己需要配置（请先阅读文档了解清楚了，再自定义配置。）我这里填了mysql的密码，其他基本都是默认值。点击保存，有可能会提示git的path问题，请安装git！ 测试http方式现在已经可以访问了，访问：http://localhost:3000 不出意外，可以看到页面了。接下来需要注册一个用户，然后登录，添加一个仓库，在局域网中使用http的方式clone，我猜应该没啥意外情况。我这里是http://192.168.1.104:3000/dachengxi/gogs-test.git，你的根据情况来。 使用ssh方式首先需要在你的机器上生成ssh公钥：ssh-keygen -t rsa -C &quot;your_email@example.com&quot;，各种回车之后完成，生成的文件在你的用户主目录下的.ssh文件夹下，其中id_rsa.pub文件中的内容是我们需要的。打开此文件，复制所有内容。 然后打开gogs页面，点击右上角头像，找到用户设置，然后选择管理SSH密钥，在这里添加一个密钥，名字随便输，下面内容是你刚才复制的那个id_rsa.pub文件中的内容，添加进去保存，就好了。（其实这一步就是在你git用户主目录下的.ssh文件夹下生成一个叫做authorized_keys的文件，里面内容就是上面你添加的内容）。 测试ssh方式上面的步骤没出啥错，现在已经可以使用，我这里是git@192.168.1.104:dachengxi/gogs-test.git，你的根据自己情况来定。 其他其他各种高级功能不做讨论，请自己找文档找文章找自己！ 请确认虚拟机防火墙开放了3000端口，22端口。 请确认git已经安装。 请确认你运行gogs的时候，是你新建的git用户。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo中Directory解析]]></title>
      <url>%2F2017%2F04%2F02%2FDubbo%E4%B8%ADDirectory%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[Directory代表多个Invoker，可以把它看成List，但与List不同的是，它的值可能是动态变化的，比如注册中心推送变更。Cluster将Directory中的多个Invoker伪装成一个Invoker，对上层透明，伪装过程包含了容错逻辑，调用失败后，重试另一个。 上面是文档上对Directory的解释。 Directory接口Directory接口继承了Node接口： 1234567public interface Directory&lt;T&gt; extends Node &#123; &#x2F;&#x2F;获取服务类型 Class&lt;T&gt; getInterface(); &#x2F;&#x2F;invoker列表，服务的列表 List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException;&#125; AbstractDirectory默认实现为AbstractDirectory： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public abstract class AbstractDirectory&lt;T&gt; implements Directory&lt;T&gt; &#123; &#x2F;&#x2F; 日志输出 private static final Logger logger &#x3D; LoggerFactory.getLogger(AbstractDirectory.class); &#x2F;&#x2F;服务url private final URL url ; private volatile boolean destroyed &#x3D; false; &#x2F;&#x2F;消费者url private volatile URL consumerUrl ; &#x2F;&#x2F;路由 private volatile List&lt;Router&gt; routers; public AbstractDirectory(URL url) &#123; this(url, null); &#125; public AbstractDirectory(URL url, List&lt;Router&gt; routers) &#123; this(url, url, routers); &#125; public AbstractDirectory(URL url, URL consumerUrl, List&lt;Router&gt; routers) &#123; if (url &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;url &#x3D;&#x3D; null&quot;); this.url &#x3D; url; this.consumerUrl &#x3D; consumerUrl; setRouters(routers); &#125; &#x2F;&#x2F;对list方法的默认实现 public List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException &#123; if (destroyed)&#123; throw new RpcException(&quot;Directory already destroyed .url: &quot;+ getUrl()); &#125; &#x2F;&#x2F;获取Invoker列表的具体实现由具体子类实现 List&lt;Invoker&lt;T&gt;&gt; invokers &#x3D; doList(invocation); &#x2F;&#x2F;路由 List&lt;Router&gt; localRouters &#x3D; this.routers; &#x2F;&#x2F; local reference if (localRouters !&#x3D; null &amp;&amp; localRouters.size() &gt; 0) &#123; for (Router router: localRouters)&#123; try &#123; if (router.getUrl() &#x3D;&#x3D; null || router.getUrl().getParameter(Constants.RUNTIME_KEY, true)) &#123; &#x2F;&#x2F;路由 invokers &#x3D; router.route(invokers, getConsumerUrl(), invocation); &#125; &#125; catch (Throwable t) &#123; logger.error(&quot;Failed to execute router: &quot; + getUrl() + &quot;, cause: &quot; + t.getMessage(), t); &#125; &#125; &#125; return invokers; &#125; public URL getUrl() &#123; return url; &#125; public List&lt;Router&gt; getRouters()&#123; return routers; &#125; public URL getConsumerUrl() &#123; return consumerUrl; &#125; public void setConsumerUrl(URL consumerUrl) &#123; this.consumerUrl &#x3D; consumerUrl; &#125; &#x2F;&#x2F;构造中调用的设置路由的方法 protected void setRouters(List&lt;Router&gt; routers)&#123; &#x2F;&#x2F; copy list routers &#x3D; routers &#x3D;&#x3D; null ? new ArrayList&lt;Router&gt;() : new ArrayList&lt;Router&gt;(routers); &#x2F;&#x2F; append url router String routerkey &#x3D; url.getParameter(Constants.ROUTER_KEY); &#x2F;&#x2F;指定了router，就使用制定的router来获取扩展实现 if (routerkey !&#x3D; null &amp;&amp; routerkey.length() &gt; 0) &#123; RouterFactory routerFactory &#x3D; ExtensionLoader.getExtensionLoader(RouterFactory.class).getExtension(routerkey); routers.add(routerFactory.getRouter(url)); &#125; &#x2F;&#x2F; append mock invoker selector routers.add(new MockInvokersSelector()); Collections.sort(routers); this.routers &#x3D; routers; &#125; public boolean isDestroyed() &#123; return destroyed; &#125; public void destroy()&#123; destroyed &#x3D; true; &#125; &#x2F;&#x2F;子类实现具体的获取invoker列表 protected abstract List&lt;Invoker&lt;T&gt;&gt; doList(Invocation invocation) throws RpcException ;&#125; Directory具体的实现有两个RegistryDirectory注册目录服务和StaticDirectory静态目录服务。 RegistryDirectoryRegistryDirectory实现了NotifyListener接口，因此他本身也是一个监听器，可以在服务变更时接受通知，消费方要调用远程服务，会向注册中心订阅这个服务的所有的服务提供方，订阅的时候会调用notify方法，进行invoker实例的重新生成，也就是服务的重新引用。在服务提供方有变动时，也会调用notify方法，有关notify方法在Dubbo中订阅和通知解析那篇文章中已经解释，不做重复。subscribe方法也不做重复解释。 StaticDirectory静态目录服务。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo中订阅和通知解析]]></title>
      <url>%2F2017%2F04%2F02%2FDubbo%E4%B8%AD%E8%AE%A2%E9%98%85%E5%92%8C%E9%80%9A%E7%9F%A5%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[Dubbo中关于服务的订阅和通知主要发生在服务提供方暴露服务的过程和服务消费方初始化时候引用服务的过程中。 服务引用过程中的订阅和通知在服务消费者初始化的过程中，会有一步是进行服务的引用，具体的代码是在RegistryProtocol的refer方法： 12345678910111213141516171819public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; url &#x3D; url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY); &#x2F;&#x2F;在这一步获取注册中心实例的过程中，也会有notify的操作。（这里省略） Registry registry &#x3D; registryFactory.getRegistry(url); if (RegistryService.class.equals(type)) &#123; return proxyFactory.getInvoker((T) registry, type, url); &#125; &#x2F;&#x2F; group&#x3D;&quot;a,b&quot; or group&#x3D;&quot;*&quot; Map&lt;String, String&gt; qs &#x3D; StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY)); String group &#x3D; qs.get(Constants.GROUP_KEY); if (group !&#x3D; null &amp;&amp; group.length() &gt; 0 ) &#123; if ( ( Constants.COMMA_SPLIT_PATTERN.split( group ) ).length &gt; 1 || &quot;*&quot;.equals( group ) ) &#123; return doRefer( getMergeableCluster(), registry, type, url ); &#125; &#125; return doRefer(cluster, registry, type, url);&#125; 在refer方法中有一步是获取注册中心实例，这一步中也会有一个notify操作，先暂时不解释。接着就是doRefer方法： 1234567891011121314151617181920private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) &#123; RegistryDirectory&lt;T&gt; directory &#x3D; new RegistryDirectory&lt;T&gt;(type, url); directory.setRegistry(registry); directory.setProtocol(protocol); &#x2F;&#x2F;订阅的url URL subscribeUrl &#x3D; new URL(Constants.CONSUMER_PROTOCOL, NetUtils.getLocalHost(), 0, type.getName(), directory.getUrl().getParameters()); if (! Constants.ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) &#123; &#x2F;&#x2F;服务消费方向注册中心注册自己，供其他层使用，比如服务治理 registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY, Constants.CHECK_KEY, String.valueOf(false))); &#125; &#x2F;&#x2F;订阅服务提供方 &#x2F;&#x2F;同时订阅了三种类型providers，routers，configurators。 directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, Constants.PROVIDERS_CATEGORY + &quot;,&quot; + Constants.CONFIGURATORS_CATEGORY + &quot;,&quot; + Constants.ROUTERS_CATEGORY)); return cluster.join(directory);&#125; 在doRefer方法中服务消费者会订阅服务，同时订阅了三种类型：providers，routers，configurators。 接续看directory.subscribe订阅方法，这里directory是RegistryDirectory： 12345678public void subscribe(URL url) &#123; &#x2F;&#x2F;设置消费者url setConsumerUrl(url); &#x2F;&#x2F;订阅 &#x2F;&#x2F;url为订阅条件，不能为空 &#x2F;&#x2F;第二个参数this，是变更事件监听器，不允许为空，RegistryDirectory实现了NotifyListener接口，因此是一个事件监听器 registry.subscribe(url, this);&#125; 这里registry是ZookeeperRegistry，在ZookeeperRegistry调用subscribe处理之前会先经过AbstractRegistry的处理，然后经过FailbackRegistry处理，在FailbackRegistry中会调用ZookeeperRegistry的doSubscribe方法。 首先看下AbstractRegistry中subscribe方法： 12345678910111213141516public void subscribe(URL url, NotifyListener listener) &#123; if (url &#x3D;&#x3D; null) &#123; throw new IllegalArgumentException(&quot;subscribe url &#x3D;&#x3D; null&quot;); &#125; if (listener &#x3D;&#x3D; null) &#123; throw new IllegalArgumentException(&quot;subscribe listener &#x3D;&#x3D; null&quot;); &#125; &#x2F;&#x2F;从缓存中获取已经订阅的url的监听器 Set&lt;NotifyListener&gt; listeners &#x3D; subscribed.get(url); if (listeners &#x3D;&#x3D; null) &#123; subscribed.putIfAbsent(url, new ConcurrentHashSet&lt;NotifyListener&gt;()); listeners &#x3D; subscribed.get(url); &#125; &#x2F;&#x2F;将当前监听器添加到监听器的set中 listeners.add(listener);&#125; 然后是FailbackRegistry的subscribe方法： 123456789101112131415161718192021222324252627282930313233public void subscribe(URL url, NotifyListener listener) &#123; &#x2F;&#x2F;上面AbstractRegistry的处理 super.subscribe(url, listener); &#x2F;&#x2F;移除订阅失败的 removeFailedSubscribed(url, listener); try &#123; &#x2F;&#x2F; 向服务器端发送订阅请求 &#x2F;&#x2F;子类实现，我们这里使用的是ZookeeperRegistry doSubscribe(url, listener); &#125; catch (Exception e) &#123; Throwable t &#x3D; e; List&lt;URL&gt; urls &#x3D; getCacheUrls(url); if (urls !&#x3D; null &amp;&amp; urls.size() &gt; 0) &#123; &#x2F;&#x2F;订阅失败，进行通知，重试 notify(url, listener, urls); &#125; else &#123; &#x2F;&#x2F; 如果开启了启动时检测，则直接抛出异常 boolean check &#x3D; getUrl().getParameter(Constants.CHECK_KEY, true) &amp;&amp; url.getParameter(Constants.CHECK_KEY, true); boolean skipFailback &#x3D; t instanceof SkipFailbackWrapperException; if (check || skipFailback) &#123; if(skipFailback) &#123; t &#x3D; t.getCause(); &#125; throw new IllegalStateException(&quot;Failed to subscribe &quot; + url + &quot;, cause: &quot; + t.getMessage(), t); &#125; &#125; &#x2F;&#x2F; 将失败的订阅请求记录到失败列表，定时重试 addFailedSubscribed(url, listener); &#125;&#125; 这里总共进行了一下几件事情： AbstractRegistry的处理 移除订阅失败的 由具体的子类向服务器端发送订阅请求 如果订阅发生失败了，尝试获取缓存url，然后进行失败通知或者如果开启了启动时检测，则直接抛出异常 将失败的订阅请求记录到失败列表，定时重试 主要看下子类向服务器段发送订阅请求的步骤，在ZookeeperRegistry的doSubscribe方法中： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071protected void doSubscribe(final URL url, final NotifyListener listener) &#123; try &#123; if (Constants.ANY_VALUE.equals(url.getServiceInterface())) &#123;&#x2F;&#x2F;这里暂时没用到先不解释 String root &#x3D; toRootPath(); ConcurrentMap&lt;NotifyListener, ChildListener&gt; listeners &#x3D; zkListeners.get(url); if (listeners &#x3D;&#x3D; null) &#123; zkListeners.putIfAbsent(url, new ConcurrentHashMap&lt;NotifyListener, ChildListener&gt;()); listeners &#x3D; zkListeners.get(url); &#125; ChildListener zkListener &#x3D; listeners.get(listener); if (zkListener &#x3D;&#x3D; null) &#123; listeners.putIfAbsent(listener, new ChildListener() &#123; public void childChanged(String parentPath, List&lt;String&gt; currentChilds) &#123; for (String child : currentChilds) &#123; child &#x3D; URL.decode(child); if (! anyServices.contains(child)) &#123; anyServices.add(child); subscribe(url.setPath(child).addParameters(Constants.INTERFACE_KEY, child, Constants.CHECK_KEY, String.valueOf(false)), listener); &#125; &#125; &#125; &#125;); zkListener &#x3D; listeners.get(listener); &#125; zkClient.create(root, false); List&lt;String&gt; services &#x3D; zkClient.addChildListener(root, zkListener); if (services !&#x3D; null &amp;&amp; services.size() &gt; 0) &#123; for (String service : services) &#123; service &#x3D; URL.decode(service); anyServices.add(service); subscribe(url.setPath(service).addParameters(Constants.INTERFACE_KEY, service, Constants.CHECK_KEY, String.valueOf(false)), listener); &#125; &#125; &#125; else &#123; List&lt;URL&gt; urls &#x3D; new ArrayList&lt;URL&gt;(); &#x2F;&#x2F;这里的path分别为providers，routers，configurators三种 for (String path : toCategoriesPath(url)) &#123; &#x2F;&#x2F;根据url获取对应的监听器map ConcurrentMap&lt;NotifyListener, ChildListener&gt; listeners &#x3D; zkListeners.get(url); if (listeners &#x3D;&#x3D; null) &#123; zkListeners.putIfAbsent(url, new ConcurrentHashMap&lt;NotifyListener, ChildListener&gt;()); listeners &#x3D; zkListeners.get(url); &#125; &#x2F;&#x2F;根据我们的listener获取一个ChildListener实例 ChildListener zkListener &#x3D; listeners.get(listener); &#x2F;&#x2F;没有的话就创建一个ChildListener实例。 if (zkListener &#x3D;&#x3D; null) &#123; listeners.putIfAbsent(listener, new ChildListener() &#123; public void childChanged(String parentPath, List&lt;String&gt; currentChilds) &#123; ZookeeperRegistry.this.notify(url, listener, toUrlsWithEmpty(url, parentPath, currentChilds)); &#125; &#125;); zkListener &#x3D; listeners.get(listener); &#125; &#x2F;&#x2F;根据path在Zookeeper中创建节点，这里就是订阅服务 zkClient.create(path, false); &#x2F;&#x2F;这里zkClient是dubbo的ZookeeperClient，在addChildListener中会转化为ZkClient的Listener List&lt;String&gt; children &#x3D; zkClient.addChildListener(path, zkListener); if (children !&#x3D; null) &#123; urls.addAll(toUrlsWithEmpty(url, path, children)); &#125; &#125; &#x2F;&#x2F;订阅完成之后，进行通知 notify(url, listener, urls); &#125; &#125; catch (Throwable e) &#123; throw new RpcException(&quot;Failed to subscribe &quot; + url + &quot; to zookeeper &quot; + getUrl() + &quot;, cause: &quot; + e.getMessage(), e); &#125;&#125; 上面主要是分别对providers，routers，configurators三种不同类型的进行订阅，也就是往zookeeper中注册节点，注册之前先给url添加监听器。最后是订阅完之后进行通知。 notify方法，这里notify方法实现是在ZookeeperRegistry的父类FailbackRegistry中： 1234567891011121314151617181920protected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; if (url &#x3D;&#x3D; null) &#123; throw new IllegalArgumentException(&quot;notify url &#x3D;&#x3D; null&quot;); &#125; if (listener &#x3D;&#x3D; null) &#123; throw new IllegalArgumentException(&quot;notify listener &#x3D;&#x3D; null&quot;); &#125; try &#123; &#x2F;&#x2F;doNotify方法中没做处理，直接调用父类的notify方法 doNotify(url, listener, urls); &#125; catch (Exception t) &#123; &#x2F;&#x2F; 将失败的通知请求记录到失败列表，定时重试 Map&lt;NotifyListener, List&lt;URL&gt;&gt; listeners &#x3D; failedNotified.get(url); if (listeners &#x3D;&#x3D; null) &#123; failedNotified.putIfAbsent(url, new ConcurrentHashMap&lt;NotifyListener, List&lt;URL&gt;&gt;()); listeners &#x3D; failedNotified.get(url); &#125; listeners.put(listener, urls); &#125;&#125; 看下AbstractRegistry的notify方法： 123456789101112131415161718192021222324252627282930313233protected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; Map&lt;String, List&lt;URL&gt;&gt; result &#x3D; new HashMap&lt;String, List&lt;URL&gt;&gt;(); &#x2F;&#x2F;获取catagory列表，providers，routers，configurators for (URL u : urls) &#123; if (UrlUtils.isMatch(url, u)) &#123; String category &#x3D; u.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); List&lt;URL&gt; categoryList &#x3D; result.get(category); if (categoryList &#x3D;&#x3D; null) &#123; categoryList &#x3D; new ArrayList&lt;URL&gt;(); result.put(category, categoryList); &#125; categoryList.add(u); &#125; &#125; if (result.size() &#x3D;&#x3D; 0) &#123; return; &#125; &#x2F;&#x2F;已经通知过 Map&lt;String, List&lt;URL&gt;&gt; categoryNotified &#x3D; notified.get(url); if (categoryNotified &#x3D;&#x3D; null) &#123; notified.putIfAbsent(url, new ConcurrentHashMap&lt;String, List&lt;URL&gt;&gt;()); categoryNotified &#x3D; notified.get(url); &#125; for (Map.Entry&lt;String, List&lt;URL&gt;&gt; entry : result.entrySet()) &#123; &#x2F;&#x2F;providers，routers，configurators中的一个 String category &#x3D; entry.getKey(); List&lt;URL&gt; categoryList &#x3D; entry.getValue(); categoryNotified.put(category, categoryList); saveProperties(url); &#x2F;&#x2F;还记得刚开始的时候，listener参数么，这里listener是RegistryDirectory listener.notify(categoryList); &#125;&#125; 继续看RegistryDirectory的notify方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public synchronized void notify(List&lt;URL&gt; urls) &#123; &#x2F;&#x2F;三种类型分开 List&lt;URL&gt; invokerUrls &#x3D; new ArrayList&lt;URL&gt;(); List&lt;URL&gt; routerUrls &#x3D; new ArrayList&lt;URL&gt;(); List&lt;URL&gt; configuratorUrls &#x3D; new ArrayList&lt;URL&gt;(); for (URL url : urls) &#123; String protocol &#x3D; url.getProtocol(); String category &#x3D; url.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); if (Constants.ROUTERS_CATEGORY.equals(category) || Constants.ROUTE_PROTOCOL.equals(protocol)) &#123; routerUrls.add(url); &#125; else if (Constants.CONFIGURATORS_CATEGORY.equals(category) || Constants.OVERRIDE_PROTOCOL.equals(protocol)) &#123; configuratorUrls.add(url); &#125; else if (Constants.PROVIDERS_CATEGORY.equals(category)) &#123; invokerUrls.add(url); &#125; else &#123; &#125; &#125; &#x2F;&#x2F; configurators &#x2F;&#x2F;更新缓存的服务提供方配置规则 if (configuratorUrls !&#x3D; null &amp;&amp; configuratorUrls.size() &gt;0 )&#123; this.configurators &#x3D; toConfigurators(configuratorUrls); &#125; &#x2F;&#x2F; routers &#x2F;&#x2F;更新缓存的路由配置规则 if (routerUrls !&#x3D; null &amp;&amp; routerUrls.size() &gt;0 )&#123; List&lt;Router&gt; routers &#x3D; toRouters(routerUrls); if(routers !&#x3D; null)&#123; &#x2F;&#x2F; null - do nothing setRouters(routers); &#125; &#125; List&lt;Configurator&gt; localConfigurators &#x3D; this.configurators; &#x2F;&#x2F; local reference &#x2F;&#x2F; 合并override参数 this.overrideDirectoryUrl &#x3D; directoryUrl; if (localConfigurators !&#x3D; null &amp;&amp; localConfigurators.size() &gt; 0) &#123; for (Configurator configurator : localConfigurators) &#123; this.overrideDirectoryUrl &#x3D; configurator.configure(overrideDirectoryUrl); &#125; &#125; &#x2F;&#x2F; providers &#x2F;&#x2F;重建invoker实例 refreshInvoker(invokerUrls);&#125; 最重要的重建invoker实例，在服务引用的文章中已经介绍过，不再重复，还有上面说省略的获取注册中心实例的过程中，也会有notify的操作。（这里省略）这里也是进行了invoker实例的重建。 暴露服务过程中的订阅和通知服务暴露过程中的订阅在RegistryProtocol的export方法中： 12345678910111213141516171819202122232425262728293031323334353637383940public &lt;T&gt; Exporter&lt;T&gt; export(final Invoker&lt;T&gt; originInvoker) throws RpcException &#123; &#x2F;&#x2F;export invoker final ExporterChangeableWrapper&lt;T&gt; exporter &#x3D; doLocalExport(originInvoker); &#x2F;&#x2F;registry provider final Registry registry &#x3D; getRegistry(originInvoker); final URL registedProviderUrl &#x3D; getRegistedProviderUrl(originInvoker); registry.register(registedProviderUrl); &#x2F;&#x2F; 订阅override数据 &#x2F;&#x2F; FIXME 提供者订阅时，会影响同一JVM即暴露服务，又引用同一服务的的场景，因为subscribed以服务名为缓存的key，导致订阅信息覆盖。 final URL overrideSubscribeUrl &#x3D; getSubscribedOverrideUrl(registedProviderUrl); &#x2F;&#x2F;OverrideListener是RegistryProtocol的内部类 final OverrideListener overrideSubscribeListener &#x3D; new OverrideListener(overrideSubscribeUrl); overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener); &#x2F;&#x2F;订阅override数据 registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener); &#x2F;&#x2F;保证每次export都返回一个新的exporter实例 return new Exporter&lt;T&gt;() &#123; public Invoker&lt;T&gt; getInvoker() &#123; return exporter.getInvoker(); &#125; public void unexport() &#123; try &#123; exporter.unexport(); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; try &#123; registry.unregister(registedProviderUrl); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; try &#123; overrideListeners.remove(overrideSubscribeUrl); registry.unsubscribe(overrideSubscribeUrl, overrideSubscribeListener); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; &#125;;&#125; registry.subscribe订阅override数据，会首先经过AbstractRegistry处理，然后经过FailbackRegistry处理。处理方法在上面消费者发布订阅的讲解中都已经介绍。往下的步骤基本相同，不同之处在于AbstractRegistry的notify方法： 12345678910111213141516171819202122232425262728293031323334protected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; Map&lt;String, List&lt;URL&gt;&gt; result &#x3D; new HashMap&lt;String, List&lt;URL&gt;&gt;(); &#x2F;&#x2F;获取catagory列表，providers，routers，configurators for (URL u : urls) &#123; if (UrlUtils.isMatch(url, u)) &#123; String category &#x3D; u.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); List&lt;URL&gt; categoryList &#x3D; result.get(category); if (categoryList &#x3D;&#x3D; null) &#123; categoryList &#x3D; new ArrayList&lt;URL&gt;(); result.put(category, categoryList); &#125; categoryList.add(u); &#125; &#125; if (result.size() &#x3D;&#x3D; 0) &#123; return; &#125; &#x2F;&#x2F;已经通知过 Map&lt;String, List&lt;URL&gt;&gt; categoryNotified &#x3D; notified.get(url); if (categoryNotified &#x3D;&#x3D; null) &#123; notified.putIfAbsent(url, new ConcurrentHashMap&lt;String, List&lt;URL&gt;&gt;()); categoryNotified &#x3D; notified.get(url); &#125; for (Map.Entry&lt;String, List&lt;URL&gt;&gt; entry : result.entrySet()) &#123; &#x2F;&#x2F;providers，routers，configurators中的一个 String category &#x3D; entry.getKey(); List&lt;URL&gt; categoryList &#x3D; entry.getValue(); categoryNotified.put(category, categoryList); saveProperties(url); &#x2F;&#x2F;对于消费者来说这里listener是RegistryDirectory &#x2F;&#x2F;而对于服务提供者来说这里是OverrideListener，是RegistryProtocol的内部类 listener.notify(categoryList); &#125;&#125; 接下来看OverrideListener的notify方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445&#x2F;* * provider 端可识别的override url只有这两种. * override:&#x2F;&#x2F;0.0.0.0&#x2F;serviceName?timeout&#x3D;10 * override:&#x2F;&#x2F;0.0.0.0&#x2F;?timeout&#x3D;10 *&#x2F;public void notify(List&lt;URL&gt; urls) &#123; List&lt;URL&gt; result &#x3D; null; for (URL url : urls) &#123; URL overrideUrl &#x3D; url; if (url.getParameter(Constants.CATEGORY_KEY) &#x3D;&#x3D; null &amp;&amp; Constants.OVERRIDE_PROTOCOL.equals(url.getProtocol())) &#123; &#x2F;&#x2F; 兼容旧版本 overrideUrl &#x3D; url.addParameter(Constants.CATEGORY_KEY, Constants.CONFIGURATORS_CATEGORY); &#125; if (! UrlUtils.isMatch(subscribeUrl, overrideUrl)) &#123; if (result &#x3D;&#x3D; null) &#123; result &#x3D; new ArrayList&lt;URL&gt;(urls); &#125; result.remove(url); logger.warn(&quot;Subsribe category&#x3D;configurator, but notifed non-configurator urls. may be registry bug. unexcepted url: &quot; + url); &#125; &#125; if (result !&#x3D; null) &#123; urls &#x3D; result; &#125; this.configurators &#x3D; RegistryDirectory.toConfigurators(urls); List&lt;ExporterChangeableWrapper&lt;?&gt;&gt; exporters &#x3D; new ArrayList&lt;ExporterChangeableWrapper&lt;?&gt;&gt;(bounds.values()); for (ExporterChangeableWrapper&lt;?&gt; exporter : exporters)&#123; Invoker&lt;?&gt; invoker &#x3D; exporter.getOriginInvoker(); final Invoker&lt;?&gt; originInvoker ; if (invoker instanceof InvokerDelegete)&#123; originInvoker &#x3D; ((InvokerDelegete&lt;?&gt;)invoker).getInvoker(); &#125;else &#123; originInvoker &#x3D; invoker; &#125; URL originUrl &#x3D; RegistryProtocol.this.getProviderUrl(originInvoker); URL newUrl &#x3D; getNewInvokerUrl(originUrl, urls); if (! originUrl.equals(newUrl))&#123; &#x2F;&#x2F;对修改了url的invoker重新export RegistryProtocol.this.doChangeLocalExport(originInvoker, newUrl); &#125; &#125;&#125; 这里也是对Invoker重新进行了引用。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo中集群Cluster，负载均衡，容错，路由解析]]></title>
      <url>%2F2017%2F03%2F26%2FDubbo%E4%B8%AD%E9%9B%86%E7%BE%A4Cluster%EF%BC%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%EF%BC%8C%E5%AE%B9%E9%94%99%EF%BC%8C%E8%B7%AF%E7%94%B1%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[Dubbo中的Cluster可以将多个服务提供方伪装成一个提供方，具体也就是将Directory中的多个Invoker伪装成一个Invoker，在伪装的过程中包含了容错的处理，负载均衡的处理和路由的处理。这篇文章介绍下集群相关的东西，开始先对着文档解释下容错模式，负载均衡，路由等概念，然后解析下源码的处理。（稍微有点乱，心情不太好，不适合分析源码。） 集群的容错模式Failover Cluster这是dubbo中默认的集群容错模式 失败自动切换，当出现失败，重试其它服务器。 通常用于读操作，但重试会带来更长延迟。 可通过retries=”2”来设置重试次数(不含第一次)。 Failfast Cluster 快速失败，只发起一次调用，失败立即报错。 通常用于非幂等性的写操作，比如新增记录。 Failsafe Cluster 失败安全，出现异常时，直接忽略。 通常用于写入审计日志等操作。 Failback Cluster 失败自动恢复，后台记录失败请求，定时重发。 通常用于消息通知操作。 Forking Cluster 并行调用多个服务器，只要一个成功即返回。 通常用于实时性要求较高的读操作，但需要浪费更多服务资源。 可通过forks=”2”来设置最大并行数。 Broadcast Cluster 广播调用所有提供者，逐个调用，任意一台报错则报错。(2.1.0开始支持) 通常用于通知所有提供者更新缓存或日志等本地资源信息。 负载均衡dubbo默认的负载均衡策略是random，随机调用。 Random LoadBalance 随机，按权重设置随机概率。 在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。 RoundRobin LoadBalance 轮循，按公约后的权重设置轮循比率。 存在慢的提供者累积请求问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。 LeastActive LoadBalance 最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。 使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。 ConsistentHash LoadBalance 一致性Hash，相同参数的请求总是发到同一提供者。 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。 缺省只对第一个参数Hash。 缺省用160份虚拟节点。 集群相关源码解析回想一下在服务消费者初始化的过程中，在引用远程服务的那一步，也就是RegistryProtocol的refer方法中，调用了doRefer方法，doRefer方法中第一个参数就是cluster，我们就从这里开始解析。RegistryProtocol的refer方法： 1234567891011121314151617181920212223public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; url &#x3D; url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY); &#x2F;&#x2F;根据url获取注册中心实例 &#x2F;&#x2F;这一步连接注册中心，并把消费者注册到注册中心 Registry registry &#x3D; registryFactory.getRegistry(url); &#x2F;&#x2F;对注册中心服务的处理 if (RegistryService.class.equals(type)) &#123; return proxyFactory.getInvoker((T) registry, type, url); &#125; &#x2F;&#x2F;以下是我们自己定义的业务的服务处理 &#x2F;&#x2F; group&#x3D;&quot;a,b&quot; or group&#x3D;&quot;*&quot; Map&lt;String, String&gt; qs &#x3D; StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY)); String group &#x3D; qs.get(Constants.GROUP_KEY); &#x2F;&#x2F;服务需要合并不同实现 if (group !&#x3D; null &amp;&amp; group.length() &gt; 0 ) &#123; if ( ( Constants.COMMA_SPLIT_PATTERN.split( group ) ).length &gt; 1 || &quot;*&quot;.equals( group ) ) &#123; return doRefer( getMergeableCluster(), registry, type, url ); &#125; &#125; &#x2F;&#x2F;这里参数cluster是集群的适配类，代码在下面 return doRefer(cluster, registry, type, url);&#125; 接着看doRefer，真正去做服务引用的方法： 12345678910111213141516171819202122232425private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) &#123; &#x2F;&#x2F;Directory中是Invoker的集合，相当于一个List &#x2F;&#x2F;也就是说这里面存放了多个Invoker，那么我们该调用哪一个呢？ &#x2F;&#x2F;该调用哪一个Invoker的工作就是Cluster来处理的 RegistryDirectory&lt;T&gt; directory &#x3D; new RegistryDirectory&lt;T&gt;(type, url); directory.setRegistry(registry); directory.setProtocol(protocol); URL subscribeUrl &#x3D; new URL(Constants.CONSUMER_PROTOCOL, NetUtils.getLocalHost(), 0, type.getName(), directory.getUrl().getParameters()); if (! Constants.ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) &#123; &#x2F;&#x2F;到注册中心注册服务 registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY, Constants.CHECK_KEY, String.valueOf(false))); &#125; &#x2F;&#x2F;订阅服务，注册中心会推送服务消息给消费者，消费者会再次进行服务的引用。 directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, Constants.PROVIDERS_CATEGORY + &quot;,&quot; + Constants.CONFIGURATORS_CATEGORY + &quot;,&quot; + Constants.ROUTERS_CATEGORY)); &#x2F;&#x2F;服务的引用和变更全部由Directory异步完成 &#x2F;&#x2F;Directory中可能存在多个Invoker &#x2F;&#x2F;而Cluster会把多个Invoker伪装成一个Invoker &#x2F;&#x2F;这一步就是做这个事情的 return cluster.join(directory);&#125; 集群处理的入口入口就是在doRefer的时候最后一步：cluster.join(directory);。 首先解释下cluster，这个是根据dubbo的扩展机制生成的，在RegistryProtocol中有一个setCluster方法，根据扩展机制可以知道，这是注入Cluster的地方，代码如下： 12345678910111213141516import com.alibaba.dubbo.common.extension.ExtensionLoader;public class Cluster$Adpative implements com.alibaba.dubbo.rpc.cluster.Cluster &#123; public com.alibaba.dubbo.rpc.Invoker join(com.alibaba.dubbo.rpc.cluster.Directory arg0) throws com.alibaba.dubbo.rpc.cluster.Directory &#123; if (arg0 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.cluster.Directory argument &#x3D;&#x3D; null&quot;); if (arg0.getUrl() &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.cluster.Directory argument getUrl() &#x3D;&#x3D; null&quot;);com.alibaba.dubbo.common.URL url &#x3D; arg0.getUrl(); String extName &#x3D; url.getParameter(&quot;cluster&quot;, &quot;failover&quot;); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.cluster.Cluster) name from url(&quot; + url.toString() + &quot;) use keys([cluster])&quot;); com.alibaba.dubbo.rpc.cluster.Cluster extension &#x3D; (com.alibaba.dubbo.rpc.cluster.Cluster)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.cluster.Cluster.class).getExtension(extName); return extension.join(arg0); &#125;&#125; 可以看到，如果我们没有配置集群策略的话，默认是用failover模式，在Cluster接口的注解上@SPI(FailoverCluster.NAME)也可以看到默认是failover。 继续执行cluster.join方法，会首先进入MockClusterWrapper的join方法： 123456public &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException &#123; &#x2F;&#x2F;先执行FailoverCluster的join方法处理 &#x2F;&#x2F;然后将Directory和返回的Invoker封装成一个MockCluster return new MockClusterInvoker&lt;T&gt;(directory, this.cluster.join(directory));&#125; 看下Failover的join方法： 1234public &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException &#123; &#x2F;&#x2F;直接返回一个FailoverClusterInvoker的实例 return new FailoverClusterInvoker&lt;T&gt;(directory);&#125; 到这里就算把Invoker都封装好了，返回的Invoker是一个MockClusterInvoker，MockClusterInvoker内部包含一个Directory和一个FailoverClusterInvoker。 Invoker都封装好了之后，就是创建代理，然后使用代理调用我们的要调用的方法。 调用方法时集群的处理在进行具体方法调用的时候，代理中会invoker.invoke()，这里Invoker就是我们上面封装好的MockClusterInvoker，所以首先进入MockClusterInvoker的invoke方法： 1234567891011121314151617181920212223242526272829303132public Result invoke(Invocation invocation) throws RpcException &#123; Result result &#x3D; null; &#x2F;&#x2F;我们没配置mock，所以这里为false &#x2F;&#x2F;Mock通常用于服务降级 String value &#x3D; directory.getUrl().getMethodParameter(invocation.getMethodName(), Constants.MOCK_KEY, Boolean.FALSE.toString()).trim(); &#x2F;&#x2F;没有使用mock if (value.length() &#x3D;&#x3D; 0 || value.equalsIgnoreCase(&quot;false&quot;))&#123; &#x2F;&#x2F;这里的invoker是FailoverClusterInvoker result &#x3D; this.invoker.invoke(invocation); &#125; else if (value.startsWith(&quot;force&quot;)) &#123; &#x2F;&#x2F;mock&#x3D;force:return+null &#x2F;&#x2F;表示消费方对方法的调用都直接返回null，不发起远程调用 &#x2F;&#x2F;可用于屏蔽不重要服务不可用的时候，对调用方的影响 &#x2F;&#x2F;force:direct mock result &#x3D; doMockInvoke(invocation, null); &#125; else &#123; &#x2F;&#x2F;mock&#x3D;fail:return+null &#x2F;&#x2F;表示消费方对该服务的方法调用失败后，再返回null，不抛异常 &#x2F;&#x2F;可用于对不重要服务不稳定的时候，忽略对调用方的影响 &#x2F;&#x2F;fail-mock try &#123; result &#x3D; this.invoker.invoke(invocation); &#125;catch (RpcException e) &#123; if (e.isBiz()) &#123; throw e; &#125; else &#123; result &#x3D; doMockInvoke(invocation, e); &#125; &#125; &#125; return result;&#125; 我们这里么有配置mock属性。首先进入的是AbstractClusterInvoker的incoke方法： 123456789101112131415161718192021public Result invoke(final Invocation invocation) throws RpcException &#123; &#x2F;&#x2F;检查是否已经被销毁 checkWheatherDestoried(); &#x2F;&#x2F;可以看到这里该处理负载均衡的问题了 LoadBalance loadbalance; &#x2F;&#x2F;根据invocation中的信息从Directory中获取Invoker列表 &#x2F;&#x2F;这一步中会进行路由的处理 List&lt;Invoker&lt;T&gt;&gt; invokers &#x3D; list(invocation); if (invokers !&#x3D; null &amp;&amp; invokers.size() &gt; 0) &#123; &#x2F;&#x2F;使用扩展机制，加载LoadBalance的实现类，默认使用的是random &#x2F;&#x2F;我们这里得到的就是RandomLoadBalance loadbalance &#x3D; ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(invokers.get(0).getUrl() .getMethodParameter(invocation.getMethodName(),Constants.LOADBALANCE_KEY, Constants.DEFAULT_LOADBALANCE)); &#125; else &#123; loadbalance &#x3D; ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(Constants.DEFAULT_LOADBALANCE); &#125; &#x2F;&#x2F;异步操作默认添加invocation id RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation); &#x2F;&#x2F;调用具体的实现类的doInvoke方法，这里是FailoverClusterInvoker return doInvoke(invocation, invokers, loadbalance);&#125; 看下FailoverClusterInvoker的invoke方法： 12345678910111213141516171819202122232425262728293031323334353637public Result doInvoke(Invocation invocation, final List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; &#x2F;&#x2F;Invoker列表 List&lt;Invoker&lt;T&gt;&gt; copyinvokers &#x3D; invokers; &#x2F;&#x2F;确认下Invoker列表不为空 checkInvokers(copyinvokers, invocation); &#x2F;&#x2F;重试次数 int len &#x3D; getUrl().getMethodParameter(invocation.getMethodName(), Constants.RETRIES_KEY, Constants.DEFAULT_RETRIES) + 1; if (len &lt;&#x3D; 0) &#123; len &#x3D; 1; &#125; &#x2F;&#x2F; retry loop. RpcException le &#x3D; null; &#x2F;&#x2F; last exception. List&lt;Invoker&lt;T&gt;&gt; invoked &#x3D; new ArrayList&lt;Invoker&lt;T&gt;&gt;(copyinvokers.size()); &#x2F;&#x2F; invoked invokers. Set&lt;String&gt; providers &#x3D; new HashSet&lt;String&gt;(len); for (int i &#x3D; 0; i &lt; len; i++) &#123; &#x2F;&#x2F;重试时，进行重新选择，避免重试时invoker列表已发生变化. &#x2F;&#x2F;注意：如果列表发生了变化，那么invoked判断会失效，因为invoker示例已经改变 if (i &gt; 0) &#123; checkWheatherDestoried(); copyinvokers &#x3D; list(invocation); &#x2F;&#x2F;重新检查一下 checkInvokers(copyinvokers, invocation); &#125; &#x2F;&#x2F;使用loadBalance选择一个Invoker返回 Invoker&lt;T&gt; invoker &#x3D; select(loadbalance, invocation, copyinvokers, invoked); invoked.add(invoker); RpcContext.getContext().setInvokers((List)invoked); try &#123; &#x2F;&#x2F;使用选择的结果Invoker进行调用，返回结果 Result result &#x3D; invoker.invoke(invocation); return result; &#125; catch (RpcException e) &#123;。。。&#125; finally &#123; providers.add(invoker.getUrl().getAddress()); &#125; &#125; throw new RpcException(。。。);&#125; 先看下使用loadbalance选择invoker的select方法： 1234567891011121314151617181920212223242526protected Invoker&lt;T&gt; select(LoadBalance loadbalance, Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, List&lt;Invoker&lt;T&gt;&gt; selected) throws RpcException &#123; if (invokers &#x3D;&#x3D; null || invokers.size() &#x3D;&#x3D; 0) return null; String methodName &#x3D; invocation &#x3D;&#x3D; null ? &quot;&quot; : invocation.getMethodName(); &#x2F;&#x2F;sticky，滞连接用于有状态服务，尽可能让客户端总是向同一提供者发起调用，除非该提供者挂了，再连另一台。 boolean sticky &#x3D; invokers.get(0).getUrl().getMethodParameter(methodName,Constants.CLUSTER_STICKY_KEY, Constants.DEFAULT_CLUSTER_STICKY) ; &#123; &#x2F;&#x2F;ignore overloaded method if ( stickyInvoker !&#x3D; null &amp;&amp; !invokers.contains(stickyInvoker) )&#123; stickyInvoker &#x3D; null; &#125; &#x2F;&#x2F;ignore cucurrent problem if (sticky &amp;&amp; stickyInvoker !&#x3D; null &amp;&amp; (selected &#x3D;&#x3D; null || !selected.contains(stickyInvoker)))&#123; if (availablecheck &amp;&amp; stickyInvoker.isAvailable())&#123; return stickyInvoker; &#125; &#125; &#125; Invoker&lt;T&gt; invoker &#x3D; doselect(loadbalance, invocation, invokers, selected); if (sticky)&#123; stickyInvoker &#x3D; invoker; &#125; return invoker;&#125; doselect方法： 123456789101112131415161718192021222324252627282930313233private Invoker&lt;T&gt; doselect(LoadBalance loadbalance, Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, List&lt;Invoker&lt;T&gt;&gt; selected) throws RpcException &#123; if (invokers &#x3D;&#x3D; null || invokers.size() &#x3D;&#x3D; 0) return null; &#x2F;&#x2F;只有一个invoker，直接返回，不需要处理 if (invokers.size() &#x3D;&#x3D; 1) return invokers.get(0); &#x2F;&#x2F; 如果只有两个invoker，退化成轮循 if (invokers.size() &#x3D;&#x3D; 2 &amp;&amp; selected !&#x3D; null &amp;&amp; selected.size() &gt; 0) &#123; return selected.get(0) &#x3D;&#x3D; invokers.get(0) ? invokers.get(1) : invokers.get(0); &#125; &#x2F;&#x2F;使用loadBalance进行选择 Invoker&lt;T&gt; invoker &#x3D; loadbalance.select(invokers, getUrl(), invocation); &#x2F;&#x2F;如果 selected中包含（优先判断） 或者 不可用&amp;&amp;availablecheck&#x3D;true 则重试. if( (selected !&#x3D; null &amp;&amp; selected.contains(invoker)) ||(!invoker.isAvailable() &amp;&amp; getUrl()!&#x3D;null &amp;&amp; availablecheck))&#123; try&#123; &#x2F;&#x2F;重新选择 Invoker&lt;T&gt; rinvoker &#x3D; reselect(loadbalance, invocation, invokers, selected, availablecheck); if(rinvoker !&#x3D; null)&#123; invoker &#x3D; rinvoker; &#125;else&#123; &#x2F;&#x2F;看下第一次选的位置，如果不是最后，选+1位置. int index &#x3D; invokers.indexOf(invoker); try&#123; &#x2F;&#x2F;最后在避免碰撞 invoker &#x3D; index &lt;invokers.size()-1?invokers.get(index+1) :invoker; &#125;catch (Exception e) &#123;。。。 &#125; &#125; &#125;catch (Throwable t)&#123;。。。&#125; &#125; return invoker;&#125; 接着看使用loadBalance进行选择，首先进入AbstractLoadBalance的select方法： 12345678 public &lt;T&gt; Invoker&lt;T&gt; select(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123; if (invokers &#x3D;&#x3D; null || invokers.size() &#x3D;&#x3D; 0) return null; if (invokers.size() &#x3D;&#x3D; 1) return invokers.get(0); &#x2F;&#x2F; 进行选择，具体的子类实现，我们这里是RandomLoadBalance return doSelect(invokers, url, invocation);&#125; 接着去RandomLoadBalance中查看： 1234567891011121314151617181920212223242526protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123; int length &#x3D; invokers.size(); &#x2F;&#x2F; 总个数 int totalWeight &#x3D; 0; &#x2F;&#x2F; 总权重 boolean sameWeight &#x3D; true; &#x2F;&#x2F; 权重是否都一样 for (int i &#x3D; 0; i &lt; length; i++) &#123; int weight &#x3D; getWeight(invokers.get(i), invocation); totalWeight +&#x3D; weight; &#x2F;&#x2F; 累计总权重 if (sameWeight &amp;&amp; i &gt; 0 &amp;&amp; weight !&#x3D; getWeight(invokers.get(i - 1), invocation)) &#123; sameWeight &#x3D; false; &#x2F;&#x2F; 计算所有权重是否一样 &#125; &#125; if (totalWeight &gt; 0 &amp;&amp; ! sameWeight) &#123; &#x2F;&#x2F; 如果权重不相同且权重大于0则按总权重数随机 int offset &#x3D; random.nextInt(totalWeight); &#x2F;&#x2F; 并确定随机值落在哪个片断上 for (int i &#x3D; 0; i &lt; length; i++) &#123; offset -&#x3D; getWeight(invokers.get(i), invocation); if (offset &lt; 0) &#123; return invokers.get(i); &#125; &#125; &#125; &#x2F;&#x2F; 如果权重相同或权重为0则均等随机 return invokers.get(random.nextInt(length));&#125; 上面根据权重之类的来进行选择一个Invoker返回。接下来reselect的方法不在说明，是先从非selected的列表中选择，没有在从selected列表中选择。 选择好了Invoker之后，就回去FailoverClusterInvoker的doInvoke方法，接着就是根据选中的Invoker调用invoke方法进行返回结果，接着就是到具体的Invoker进行调用的过程了。这部分的解析在消费者和提供者请求响应过程已经解析过了，不再重复。 路由回到AbstractClusterInvoker的invoke方法中，这里有一步是List&lt;Invoker&lt;T&gt;&gt; invokers = list(invocation);获取Invoker列表，这里同时也进行了路由的操作，看下list方法： 1234protected List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException &#123; List&lt;Invoker&lt;T&gt;&gt; invokers &#x3D; directory.list(invocation); return invokers;&#125; 接着看AbstractDirectory的list方法： 1234567891011121314151617181920public List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException &#123; if (destroyed)&#123; throw new RpcException(&quot;Directory already destroyed .url: &quot;+ getUrl()); &#125; &#x2F;&#x2F;RegistryDirectory中的doList实现 List&lt;Invoker&lt;T&gt;&gt; invokers &#x3D; doList(invocation); List&lt;Router&gt; localRouters &#x3D; this.routers; &#x2F;&#x2F; local reference if (localRouters !&#x3D; null &amp;&amp; localRouters.size() &gt; 0) &#123; for (Router router: localRouters)&#123; try &#123; if (router.getUrl() &#x3D;&#x3D; null || router.getUrl().getParameter(Constants.RUNTIME_KEY, true)) &#123; &#x2F;&#x2F;路由选择 &#x2F;&#x2F;MockInvokersSelector中 invokers &#x3D; router.route(invokers, getConsumerUrl(), invocation); &#125; &#125; catch (Throwable t) &#123;。。。&#125; &#125; &#125; return invokers;&#125; 路由来过滤之后，进行负载均衡的处理。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JUC中AQS简介]]></title>
      <url>%2F2017%2F03%2F23%2FJUC%E4%B8%ADAQS%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[AQS，在java.util.concurrent.locks包中，AbstractQueuedSynchronizer这个类是并发包中的核心，了解其他类之前，需要先弄清楚AQS。在JUC的很多类中都会存在一个内部类Sync，Sync都是继承自AbstractQueuedSynchronizer，相信不用说就能明白AQS有多重要。 AQS原理AQS就是一个同步器，要做的事情就相当于一个锁，所以就会有两个动作：一个是获取，一个是释放。获取释放的时候该有一个东西来记住他是被用还是没被用，这个东西就是一个状态。如果锁被获取了，也就是被用了，还有很多其他的要来获取锁，总不能给全部拒绝了，这时候就需要他们排队，这里就需要一个队列。这大概就清楚了AQS的主要构成了： 获取和释放两个动作 同步状态（原子操作） 阻塞队列 stateAQS用32位整形来表示同步状态。 1private volatile int state; 在互斥锁中表示线程是否已经获取了锁，0未获取，1已经获取，大于1表示重入数。 AQS提供了getState(),setState(),compareAndSetState()来获取和修改state的值，这些操作需要atomic包的支持，采用CAS操作，保证其原子性和可见性。 AQS的CLH锁队列CLH其实就是一个FIFO的队列，只不过稍微做了点改进。AQS中内部使用内部类Node来实现，是一个链表队列，原始CLH使用自旋锁，AQS的CLH则在每个node里使用一个状态字段来控制阻塞，不是自旋。直接看代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&#x2F;** +------+ prev +-----+ +-----+ head | | &lt;---- | | &lt;---- | | tail +------+ +-----+ +-----+&#x2F;**static final class Node &#123; &#x2F;&#x2F;作为共享模式 static final Node SHARED &#x3D; new Node(); &#x2F;&#x2F;作为独占模式 static final Node EXCLUSIVE &#x3D; null; &#x2F;&#x2F;等待状态：表示节点中线程是已被取消的 static final int CANCELLED &#x3D; 1; &#x2F;&#x2F;等待状态：表示当前节点的后继节点的线程需要被唤醒 static final int SIGNAL &#x3D; -1; &#x2F;&#x2F;等待状态：表示线程正在等待条件 static final int CONDITION &#x3D; -2; &#x2F;&#x2F;等待状态：表示下一个共享模式的节点应该无条件的传播下去 static final int PROPAGATE &#x3D; -3; &#x2F;&#x2F;等待状态，初始化为0，剩下的状态就是上面列出的 volatile int waitStatus; &#x2F;&#x2F;当前节点的前驱节点 volatile Node prev; &#x2F;&#x2F;后继节点 volatile Node next; &#x2F;&#x2F;当前节点的线程 volatile Thread thread; &#x2F;&#x2F; Node nextWaiter; &#x2F;&#x2F;是否是共享节点 final boolean isShared() &#123; return nextWaiter &#x3D;&#x3D; SHARED; &#125; &#x2F;&#x2F;当前节点的前驱节点 final Node predecessor() throws NullPointerException &#123; Node p &#x3D; prev; if (p &#x3D;&#x3D; null) throw new NullPointerException(); else return p; &#125; Node() &#123; &#x2F;&#x2F; Used to establish initial head or SHARED marker &#125; Node(Thread thread, Node mode) &#123; &#x2F;&#x2F; Used by addWaiter this.nextWaiter &#x3D; mode; this.thread &#x3D; thread; &#125; Node(Thread thread, int waitStatus) &#123; &#x2F;&#x2F; Used by Condition this.waitStatus &#x3D; waitStatus; this.thread &#x3D; thread; &#125;&#125; 共享锁和互斥锁AQS的CLH队列锁中，每个节点代表着一个需要获取锁的线程，该node中有两个常量SHARED共享模式，EXCLUSIVE独占模式。 1234&#x2F;** Marker to indicate a node is waiting in shared mode *&#x2F;static final Node SHARED &#x3D; new Node();&#x2F;** Marker to indicate a node is waiting in exclusive mode *&#x2F;static final Node EXCLUSIVE &#x3D; null; 共享模式允许多个线程可以获取同一个锁，独占模式则一个锁只能被一个线程持有，其他线程必须要等待。 AQS源码1234567891011121314151617181920&#x2F;&#x2F;阻塞队列的队列头private transient volatile Node head;&#x2F;&#x2F;队列尾private transient volatile Node tail;&#x2F;&#x2F;同步状态，这就是上面提到的需要原子操作的状态private volatile int state;&#x2F;&#x2F;返回当前同步器的状态protected final int getState() &#123; return state;&#125;&#x2F;&#x2F;设置同步器的状态protected final void setState(int newState) &#123; state &#x3D; newState;&#125;&#x2F;&#x2F;原子的设置当前同步器的状态protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125;&#x2F;&#x2F;static final long spinForTimeoutThreshold &#x3D; 1000L; 独占模式的获取acquire，独占，忽略中断12345678910&#x2F;&#x2F;独占模式的获取方法，会忽略中断&#x2F;&#x2F;tryAcquire方法会被至少调用一次，由子类实现&#x2F;&#x2F;如果tryAcquire不能成功，当前线程就会进入队列排队public final void acquire(int arg) &#123; &#x2F;&#x2F;首先调用tryAcquire尝试获取 &#x2F;&#x2F;获取不成功，就使用acquireQueued使线程进入等待队列 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; tryAcquire方法： 12345&#x2F;&#x2F;由子类来实现&#x2F;&#x2F;尝试在独占模式下获取，会查询该对象的状态是否允许在独占模式下获取protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125; 使用指定的模式创建一个节点，添加到AQS链表队列中： 12345678910111213141516private Node addWaiter(Node mode) &#123; &#x2F;&#x2F;当前线程，指定的mode，共享或者独占 Node node &#x3D; new Node(Thread.currentThread(), mode); &#x2F;&#x2F;先尝试使用直接添加进队列 Node pred &#x3D; tail; if (pred !&#x3D; null) &#123; node.prev &#x3D; pred; if (compareAndSetTail(pred, node)) &#123; pred.next &#x3D; node; return node; &#125; &#125; &#x2F;&#x2F;使用添加节点的方法 enq(node); return node;&#125; 向队列中插入节点： 12345678910111213141516171819&#x2F;&#x2F;会插入节点到对列中private Node enq(final Node node) &#123; for (;;) &#123; &#x2F;&#x2F;尾节点 Node t &#x3D; tail; &#x2F;&#x2F;需要实例化一个队列 if (t &#x3D;&#x3D; null) &#123; &#x2F;&#x2F; Must initialize &#x2F;&#x2F;使用cas创建头节点 if (compareAndSetHead(new Node())) tail &#x3D; head; &#125; else &#123; node.prev &#x3D; t; if (compareAndSetTail(t, node)) &#123; t.next &#x3D; node; return t; &#125; &#125; &#125;&#125; tryAcquire没有获取到，就会先使用addWaiter添加进队列，然后使用acquireQueued从队列获取，如果这时候获取成功，则替换当前节点为队列头，然后返回： 123456789101112131415161718192021222324252627282930313233343536&#x2F;&#x2F;独占模式处理正在排队等待的线程。&#x2F;&#x2F;自旋，直至获取成功才返回final boolean acquireQueued(final Node node, int arg) &#123; &#x2F;&#x2F;当前获取是否失败 boolean failed &#x3D; true; try &#123; &#x2F;&#x2F;获取是否被中断 boolean interrupted &#x3D; false; for (;;) &#123; &#x2F;&#x2F;获取当前节点的前驱节点 final Node p &#x3D; node.predecessor(); &#x2F;&#x2F;head节点要么是刚才初始化的节点 &#x2F;&#x2F;要么就是成功获取锁的节点 &#x2F;&#x2F;如果当前节点的前驱节点是head，当前节点就应该去尝试获取锁了 &#x2F;&#x2F;当前节点的前驱节点是头节点，就尝试获取 if (p &#x3D;&#x3D; head &amp;&amp; tryAcquire(arg)) &#123; &#x2F;&#x2F;获取成功的话，就把当前节点设置为头节点 setHead(node); &#x2F;&#x2F;之前的head节点的next引用设为null p.next &#x3D; null; &#x2F;&#x2F; help GC failed &#x3D; false; return interrupted; &#125; &#x2F;&#x2F;查看当前节点是否应该被park &#x2F;&#x2F;如果应该，就park当前线程 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted &#x3D; true; &#125; &#125; finally &#123; &#x2F;&#x2F;失败了，取消当前线程 if (failed) cancelAcquire(node); &#125;&#125; 设置头节点，只能被获取方法调用： 12345private void setHead(Node node) &#123; head &#x3D; node; node.thread &#x3D; null; node.prev &#x3D; null;&#125; shouldParkAfterFailedAcquire方法，查看是否应该被park： 123456789101112131415161718192021private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; &#x2F;&#x2F;前驱节点中保存的等待状态 int ws &#x3D; pred.waitStatus; &#x2F;&#x2F;等待状态是signal，也就是当前节点在等着被唤醒 &#x2F;&#x2F;此时当前节点应该park if (ws &#x3D;&#x3D; Node.SIGNAL) return true; &#x2F;&#x2F;等待状态大于0表示前驱节点已经取消 &#x2F;&#x2F;会向前找到一个非取消状态的节点 if (ws &gt; 0) &#123; do &#123; node.prev &#x3D; pred &#x3D; pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next &#x3D; node; &#125; else &#123; &#x2F;&#x2F;将前驱节点的waitStatus设置为signal，表示当前需要被park compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 看下parkAndCheckInterrupt方法： 123456&#x2F;&#x2F;挂起当前线程，并返回当前中断状态private final boolean parkAndCheckInterrupt() &#123; &#x2F;&#x2F;挂起当前线程 LockSupport.park(this); return Thread.interrupted();&#125; cancelAcquire取消当前节点： 1234567891011121314151617181920212223242526272829303132333435363738private void cancelAcquire(Node node) &#123; &#x2F;&#x2F;节点不存在 if (node &#x3D;&#x3D; null) return; &#x2F;&#x2F;节点的线程引用设为null node.thread &#x3D; null; &#x2F;&#x2F;前驱节点 Node pred &#x3D; node.prev; &#x2F;&#x2F;大于0表示前驱节点被取消 while (pred.waitStatus &gt; 0) node.prev &#x3D; pred &#x3D; pred.prev; &#x2F;&#x2F;前驱节点的下一个是需要移除的节点 Node predNext &#x3D; pred.next; &#x2F;&#x2F;设置节点状态为取消 node.waitStatus &#x3D; Node.CANCELLED; &#x2F;&#x2F;如果是尾节点，直接取消，将前一个节点设置为尾节点 if (node &#x3D;&#x3D; tail &amp;&amp; compareAndSetTail(node, pred)) &#123; compareAndSetNext(pred, predNext, null); &#125; else &#123;&#x2F;&#x2F;不是尾节点，说明有后继节点，将前驱节点的next纸箱后继节点 int ws; if (pred !&#x3D; head &amp;&amp; ((ws &#x3D; pred.waitStatus) &#x3D;&#x3D; Node.SIGNAL || (ws &lt;&#x3D; 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread !&#x3D; null) &#123; Node next &#x3D; node.next; if (next !&#x3D; null &amp;&amp; next.waitStatus &lt;&#x3D; 0) compareAndSetNext(pred, predNext, next); &#125; else &#123; unparkSuccessor(node); &#125; node.next &#x3D; node; &#x2F;&#x2F; help GC &#125;&#125; acquireInterruptibly 独占，可中断跟独占忽略中断类似，不再解释。 tryAcquireNanos，独占，可超时，可中断跟上面类似，但是在doAcquireNanos中会获取当前时间，并获取LockSupport.parkNanos之后的时间在做超时时间的重新计算，到了超时时间，就返回false。 独占模式的释放release，独占，忽略中断12345678910111213public final boolean release(int arg) &#123; &#x2F;&#x2F;尝试释放，修改状态 if (tryRelease(arg)) &#123; &#x2F;&#x2F;成功释放 &#x2F;&#x2F;head代表初始化的节点，或者是当前占有锁的节点 &#x2F;&#x2F;需要unpark后继节点 Node h &#x3D; head; if (h !&#x3D; null &amp;&amp; h.waitStatus !&#x3D; 0) unparkSuccessor(h); return true; &#125; return false;&#125; unparkSuccessor： 1234567891011121314151617181920private void unparkSuccessor(Node node) &#123; &#x2F;&#x2F;头节点中保存的waitStatus int ws &#x3D; node.waitStatus; &#x2F;&#x2F;重置头节点状态为0 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); &#x2F;&#x2F;后继节点 Node s &#x3D; node.next; &#x2F;&#x2F;后继节点为null或者已经取消 if (s &#x3D;&#x3D; null || s.waitStatus &gt; 0) &#123; s &#x3D; null; &#x2F;&#x2F;从最后往前找有效的节点 for (Node t &#x3D; tail; t !&#x3D; null &amp;&amp; t !&#x3D; node; t &#x3D; t.prev) if (t.waitStatus &lt;&#x3D; 0) s &#x3D; t; &#125; &#x2F;&#x2F;unpark if (s !&#x3D; null) LockSupport.unpark(s.thread);&#125; 共享模式的获取acquireShared，共享，忽略中断acquireSharedInterruptibly，共享，可中断tryAcquireSharedNanos，共享，可设置超时，可中断共享模式的释放releaseShared共享模式的和独占模式基本差不多，和独占式的acquireQueued方法区别就是在获取成功的节点后会继续unpark后继节点，将共享状态向后传播。 LockSupport用来创建锁和其他同步类的基本线程阻塞原语。每个使用LockSupport的线程都会与一个许可关联，如果该许可可用并且可在进程中使用，则调用park()将会立即返回，否则可能阻塞。如果许可不可用，可调用unpark使其可用。 许可不可重入，只能调用一次park()方法，否则会一直阻塞。 park()和unpark()作用分别是阻塞线程和解除阻塞线程，且park和unpark不会遇到suspend和resume可能引发的死锁问题。 park，如果许可可用，使用该许可，并且该调用立即返回；否则为线程调度禁用当前线程，并在发生以下三种情况之一之前，使其处于休眠状态： * 其他某个线程将当前线程作为目标调用unpark * 其他某个线程中断当前线程 * 该调用不合逻辑的返回 unpark，如果给定的线程尚不可用，则使其可用。如果线程在park上受阻塞，则它将解除其阻塞状态。否则，保证下一次调用park不受阻塞。如果给定线程尚未启动，则无法保证此操作有任何效果。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo中服务消费者和服务提供者之间的请求和响应过程]]></title>
      <url>%2F2017%2F03%2F21%2FDubbo%E4%B8%AD%E6%9C%8D%E5%8A%A1%E6%B6%88%E8%B4%B9%E8%80%85%E5%92%8C%E6%9C%8D%E5%8A%A1%E6%8F%90%E4%BE%9B%E8%80%85%E4%B9%8B%E9%97%B4%E7%9A%84%E8%AF%B7%E6%B1%82%E5%92%8C%E5%93%8D%E5%BA%94%E8%BF%87%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[服务提供者初始化完成之后，对外暴露Exporter。服务消费者初始化完成之后，得到的是Proxy代理，方法调用的时候就是调用代理。 服务消费者经过初始化之后，得到的是一个动态代理类，InvokerInvocationHandler，包含MockClusterInvoker，MockClusterInvoker包含一个RegistryDirectory和FailoverClusterInvoker。 Java动态代理，每一个动态代理类都必须要实现InvocationHandler这个接口，并且每一个代理类的实例都关联到了一个handler，当我们通过代理对象调用一个方法的时候，这个方法就会被转发为由实现了InvocationHandler这个接口的类的invoke方法来进行调用。 服务消费者发起调用请求InvokerInvocationHandler实现了InvocationHandler接口，当我们调用helloService.sayHello();的时候，实际上会调用invoke()方法： 123456789101112131415161718192021222324252627&#x2F;&#x2F;proxy是代理的真实对象&#x2F;&#x2F;method调用真实对象的方法&#x2F;&#x2F;args调用真实对象的方法的参数public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; &#x2F;&#x2F;方法名sayHello String methodName &#x3D; method.getName(); &#x2F;&#x2F;参数类型 Class&lt;?&gt;[] parameterTypes &#x3D; method.getParameterTypes(); if (method.getDeclaringClass() &#x3D;&#x3D; Object.class) &#123; return method.invoke(invoker, args); &#125; if (&quot;toString&quot;.equals(methodName) &amp;&amp; parameterTypes.length &#x3D;&#x3D; 0) &#123; return invoker.toString(); &#125; if (&quot;hashCode&quot;.equals(methodName) &amp;&amp; parameterTypes.length &#x3D;&#x3D; 0) &#123; return invoker.hashCode(); &#125; if (&quot;equals&quot;.equals(methodName) &amp;&amp; parameterTypes.length &#x3D;&#x3D; 1) &#123; return invoker.equals(args[0]); &#125; &#x2F;&#x2F;invoker是MockClusterInvoker &#x2F;&#x2F;首先new RpcInvocation &#x2F;&#x2F;然后invoker.invoke &#x2F;&#x2F;最后recreate &#x2F;&#x2F;返回结果 return invoker.invoke(new RpcInvocation(method, args)).recreate();&#125; 先看下new RpcInvocation，Invocation是会话域，它持有调用过程中的变量，比如方法名，参数类型等。 接着是invoker.invoke()，这里invoker是MockClusterInvoker，进入MockClusterInvoker.invoker()： 123456789101112131415161718192021222324public Result invoke(Invocation invocation) throws RpcException &#123; Result result &#x3D; null; &#x2F;&#x2F;获取mock属性的值，我们没有配置，默认false String value &#x3D; directory.getUrl().getMethodParameter(invocation.getMethodName(), Constants.MOCK_KEY, Boolean.FALSE.toString()).trim(); if (value.length() &#x3D;&#x3D; 0 || value.equalsIgnoreCase(&quot;false&quot;))&#123; &#x2F;&#x2F;这里invoker是FailoverClusterInvoker result &#x3D; this.invoker.invoke(invocation); &#125; else if (value.startsWith(&quot;force&quot;)) &#123; &#x2F;&#x2F;force:direct mock result &#x3D; doMockInvoke(invocation, null); &#125; else &#123; &#x2F;&#x2F;fail-mock try &#123; result &#x3D; this.invoker.invoke(invocation); &#125;catch (RpcException e) &#123; if (e.isBiz()) &#123; throw e; &#125; else &#123; result &#x3D; doMockInvoke(invocation, e); &#125; &#125; &#125; return result;&#125; result = this.invoker.invoke(invocation);这里invoker是FailoverClusterInvoker，会首先进入AbstractClusterInvoker的invoke方法： 12345678910111213141516171819public Result invoke(final Invocation invocation) throws RpcException &#123; &#x2F;&#x2F;检查是否被销毁 checkWheatherDestoried(); LoadBalance loadbalance; &#x2F;&#x2F;根据invocation中的参数来获取所有的invoker列表 List&lt;Invoker&lt;T&gt;&gt; invokers &#x3D; list(invocation); if (invokers !&#x3D; null &amp;&amp; invokers.size() &gt; 0) &#123; &#x2F;&#x2F;我们没有配置负载均衡的参数，默认使用random &#x2F;&#x2F;这里得到的是RandomLoadBalance loadbalance &#x3D; ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(invokers.get(0).getUrl() .getMethodParameter(invocation.getMethodName(),Constants.LOADBALANCE_KEY, Constants.DEFAULT_LOADBALANCE)); &#125; else &#123; loadbalance &#x3D; ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(Constants.DEFAULT_LOADBALANCE); &#125; &#x2F;&#x2F;如果是异步操作默认添加invocation id RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation); &#x2F;&#x2F;这里是子类实现，FailoverClusterInvoker中，执行调用 return doInvoke(invocation, invokers, loadbalance);&#125; FailoverClusterInvoker.doInvoke()： 1234567891011121314151617181920212223242526272829303132333435363738public Result doInvoke(Invocation invocation, final List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException &#123; List&lt;Invoker&lt;T&gt;&gt; copyinvokers &#x3D; invokers; &#x2F;&#x2F;检查invokers是否为空 checkInvokers(copyinvokers, invocation); &#x2F;&#x2F;重试次数 int len &#x3D; getUrl().getMethodParameter(invocation.getMethodName(), Constants.RETRIES_KEY, Constants.DEFAULT_RETRIES) + 1; if (len &lt;&#x3D; 0) &#123; len &#x3D; 1; &#125; &#x2F;&#x2F; retry loop. RpcException le &#x3D; null; &#x2F;&#x2F; last exception. &#x2F;&#x2F;已经调用过的invoker List&lt;Invoker&lt;T&gt;&gt; invoked &#x3D; new ArrayList&lt;Invoker&lt;T&gt;&gt;(copyinvokers.size()); &#x2F;&#x2F; invoked invokers. Set&lt;String&gt; providers &#x3D; new HashSet&lt;String&gt;(len); for (int i &#x3D; 0; i &lt; len; i++) &#123; &#x2F;&#x2F;重试时，进行重新选择，避免重试时invoker列表已发生变化. &#x2F;&#x2F;注意：如果列表发生了变化，那么invoked判断会失效，因为invoker示例已经改变 if (i &gt; 0) &#123; checkWheatherDestoried(); copyinvokers &#x3D; list(invocation); &#x2F;&#x2F;重新检查一下 checkInvokers(copyinvokers, invocation); &#125; &#x2F;&#x2F;使用负载均衡选择invoker.（负载均衡咱先不做解释） Invoker&lt;T&gt; invoker &#x3D; select(loadbalance, invocation, copyinvokers, invoked); invoked.add(invoker); &#x2F;&#x2F;添加到以调用过的列表中 RpcContext.getContext().setInvokers((List)invoked); try &#123; &#x2F;&#x2F;开始调用，返回结果 Result result &#x3D; invoker.invoke(invocation); return result; &#125; catch (RpcException e) &#123;。。。 &#125; finally &#123; providers.add(invoker.getUrl().getAddress()); &#125; &#125; throw new RpcException(。。。);&#125; Result result = invoker.invoke(invocation);调用并返回结果，会首先进入InvokerWrapper，然后进入ListenerInvokerWrapper的invoke方法，接着进入AbstractInvoker的invoke： 123456789101112131415161718192021222324public Result invoke(Invocation inv) throws RpcException &#123; if(destroyed) &#123; throw new RpcException(。。。); &#125; &#x2F;&#x2F;转成RpcInvocation RpcInvocation invocation &#x3D; (RpcInvocation) inv; invocation.setInvoker(this); if (attachment !&#x3D; null &amp;&amp; attachment.size() &gt; 0) &#123; invocation.addAttachmentsIfAbsent(attachment); &#125; Map&lt;String, String&gt; context &#x3D; RpcContext.getContext().getAttachments(); if (context !&#x3D; null) &#123; invocation.addAttachmentsIfAbsent(context); &#125; if (getUrl().getMethodParameter(invocation.getMethodName(), Constants.ASYNC_KEY, false))&#123; invocation.setAttachment(Constants.ASYNC_KEY, Boolean.TRUE.toString()); &#125; &#x2F;&#x2F;异步的话，需要添加id RpcUtils.attachInvocationIdIfAsync(getUrl(), invocation); try &#123; &#x2F;&#x2F;这里是DubboInvoker return doInvoke(invocation); &#125; catch (InvocationTargetException e) &#123; &#125; &#125; DubboInvoker.doInvoke()： 123456789101112131415161718192021222324252627282930313233343536protected Result doInvoke(final Invocation invocation) throws Throwable &#123; RpcInvocation inv &#x3D; (RpcInvocation) invocation; final String methodName &#x3D; RpcUtils.getMethodName(invocation); inv.setAttachment(Constants.PATH_KEY, getUrl().getPath()); inv.setAttachment(Constants.VERSION_KEY, version); ExchangeClient currentClient; &#x2F;&#x2F;在初始化的时候，引用服务的过程中会保存一个连接到服务端的Client if (clients.length &#x3D;&#x3D; 1) &#123; currentClient &#x3D; clients[0]; &#125; else &#123; currentClient &#x3D; clients[index.getAndIncrement() % clients.length]; &#125; try &#123; &#x2F;&#x2F;异步标志 boolean isAsync &#x3D; RpcUtils.isAsync(getUrl(), invocation); &#x2F;&#x2F;单向标志 boolean isOneway &#x3D; RpcUtils.isOneway(getUrl(), invocation); int timeout &#x3D; getUrl().getMethodParameter(methodName, Constants.TIMEOUT_KEY,Constants.DEFAULT_TIMEOUT); &#x2F;&#x2F;单向的，反送完不管结果 if (isOneway) &#123; boolean isSent &#x3D; getUrl().getMethodParameter(methodName, Constants.SENT_KEY, false); currentClient.send(inv, isSent); RpcContext.getContext().setFuture(null); return new RpcResult(); &#125; else if (isAsync) &#123;&#x2F;&#x2F;异步的，发送完需要得到Future ResponseFuture future &#x3D; currentClient.request(inv, timeout) ; RpcContext.getContext().setFuture(new FutureAdapter&lt;Object&gt;(future)); return new RpcResult(); &#125; else &#123;&#x2F;&#x2F;同步调用，我们这里使用的这种方式 RpcContext.getContext().setFuture(null); &#x2F;&#x2F;HeaderExchangeClient return (Result) currentClient.request(inv, timeout).get(); &#125; &#125; catch (TimeoutException e) &#123;。。。&#125;&#125; 我们这里使用的是同步调用，看(Result) currentClient.request(inv, timeout).get();方法，这里的client是ReferenceCountExchangeClient，直接调用HeaderExchangeClient的request方法： 1234public ResponseFuture request(Object request, int timeout) throws RemotingException &#123; &#x2F;&#x2F;这里的Channel是HeaderExchangeChannel return channel.request(request, timeout);&#125; 进入HeaderExchangeChannel的request方法： 1234567891011121314151617181920212223242526public ResponseFuture request(Object request, int timeout) throws RemotingException &#123; if (closed) &#123; throw new RemotingException(。。。); &#125; &#x2F;&#x2F;创建一个请求头 Request req &#x3D; new Request(); req.setVersion(&quot;2.0.0&quot;); req.setTwoWay(true); &#x2F;&#x2F;这里request参数里面保存着 &#x2F;&#x2F;methodName &#x3D; &quot;sayHello&quot; &#x2F;&#x2F;parameterTypes &#x3D; &#123;Class[0]@2814&#125; &#x2F;&#x2F;arguments &#x3D; &#123;Object[0]@2768&#125; &#x2F;&#x2F;attachments &#x3D; &#123;HashMap@2822&#125; size &#x3D; 4 &#x2F;&#x2F;invoker &#x3D; &#123;DubboInvoker@2658&#125; req.setData(request); DefaultFuture future &#x3D; new DefaultFuture(channel, req, timeout); try&#123; &#x2F;&#x2F;这里的channel是NettyClient &#x2F;&#x2F;发送请求 channel.send(req); &#125;catch (RemotingException e) &#123; future.cancel(); throw e; &#125; return future;&#125; channel.send(req)，首先会调用AbstractPeer的send方法： 1234&#x2F;&#x2F;子类处理，接着是AbstractClient执行发送public void send(Object message) throws RemotingException &#123; send(message, url.getParameter(Constants.SENT_KEY, false));&#125; AbstractClient执行发送： 1234567891011121314public void send(Object message, boolean sent) throws RemotingException &#123; &#x2F;&#x2F;重连 if (send_reconnect &amp;&amp; !isConnected())&#123; connect(); &#125; &#x2F;&#x2F;先获取Channel，是在NettyClient中实现的 Channel channel &#x3D; getChannel(); &#x2F;&#x2F;TODO getChannel返回的状态是否包含null需要改进 if (channel &#x3D;&#x3D; null || ! channel.isConnected()) &#123; throw new RemotingException(this, &quot;message can not send, because channel is closed . url:&quot; + getUrl()); &#125; channel是NettyChannel channel.send(message, sent);&#125; channel.send(message, sent);首先经过AbstractChannel的send方法处理，只是判断是否关闭了，然后是NettyChannel的send来继续处理，这里就把消息发送到服务端了： 12345678910111213141516171819202122232425public void send(Object message, boolean sent) throws RemotingException &#123; super.send(message, sent); boolean success &#x3D; true; int timeout &#x3D; 0; try &#123; &#x2F;&#x2F;交给netty处理 ChannelFuture future &#x3D; channel.write(message); if (sent) &#123; timeout &#x3D; getUrl().getPositiveParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); success &#x3D; future.await(timeout); &#125; Throwable cause &#x3D; future.getCause(); if (cause !&#x3D; null) &#123; throw cause; &#125; &#125; catch (Throwable e) &#123; throw new RemotingException(this, &quot;Failed to send message &quot; + message + &quot; to &quot; + getRemoteAddress() + &quot;, cause: &quot; + e.getMessage(), e); &#125; if(! success) &#123; throw new RemotingException(this, &quot;Failed to send message &quot; + message + &quot; to &quot; + getRemoteAddress() + &quot;in timeout(&quot; + timeout + &quot;ms) limit&quot;); &#125;&#125; 服务提供者处理并响应请求服务端已经打开端口并监听请求的到来，当服务消费者发送调用请求的时候，经过Netty的处理后会到dubbo中的codec相关方法中先进行解码，入口是NettyCodecAdapter.messageReceived()，关于这个方法的代码在dubbo编解码的那篇文章中已经分析过，不再重复。经过解码之后，会进入到NettyHandler.messageReceived()方法： 12345678910public void messageReceived(ChannelHandlerContext ctx, MessageEvent e) throws Exception &#123; &#x2F;&#x2F;获取channel NettyChannel channel &#x3D; NettyChannel.getOrAddChannel(ctx.getChannel(), url, handler); try &#123; &#x2F;&#x2F;这里handler是NettyServer handler.received(channel, e.getMessage()); &#125; finally &#123; NettyChannel.removeChannelIfDisconnected(ctx.getChannel()); &#125;&#125; 接着会进入AbstractPeer的received方法： 1234567public void received(Channel ch, Object msg) throws RemotingException &#123; if (closed) &#123; return; &#125; &#x2F;&#x2F;这里是MultiMessageHandler handler.received(ch, msg);&#125; 进入MultiMessageHandler的received方法： 123456789101112public void received(Channel channel, Object message) throws RemotingException &#123; &#x2F;&#x2F;是多消息的话，使用多消息处理器处理 if (message instanceof MultiMessage) &#123; MultiMessage list &#x3D; (MultiMessage)message; for(Object obj : list) &#123; handler.received(channel, obj); &#125; &#125; else &#123; &#x2F;&#x2F;这里是HeartbeatHandler handler.received(channel, message); &#125;&#125; 进入HeartbeatHandler的received方法： 12345678910111213141516171819public void received(Channel channel, Object message) throws RemotingException &#123; setReadTimestamp(channel); &#x2F;&#x2F;心跳请求处理 if (isHeartbeatRequest(message)) &#123; Request req &#x3D; (Request) message; if (req.isTwoWay()) &#123; Response res &#x3D; new Response(req.getId(), req.getVersion()); res.setEvent(Response.HEARTBEAT_EVENT); channel.send(res); &#125; return; &#125; &#x2F;&#x2F;心跳回应消息处理 if (isHeartbeatResponse(message)) &#123; return; &#125; &#x2F;&#x2F;这里是AllChannelHandler handler.received(channel, message);&#125; 继续进入AllChannelHandler的received方法： 12345678public void received(Channel channel, Object message) throws RemotingException &#123; &#x2F;&#x2F;获取线程池执行 ExecutorService cexecutor &#x3D; getExecutorService(); try &#123; &#x2F;&#x2F;handler是DecodeHandler cexecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message)); &#125; catch (Throwable t) &#123; &#125;&#125; 这里会去启动新线程执行ChannelEventRunnable的run方法，接着去调用DecodeHandler的received方法： 12345678910111213141516public void received(Channel channel, Object message) throws RemotingException &#123; &#x2F;&#x2F;不清楚啥意思 if (message instanceof Decodeable) &#123; decode(message); &#125; &#x2F;&#x2F;解码请求类型 if (message instanceof Request) &#123; decode(((Request)message).getData()); &#125; &#x2F;&#x2F;解码响应类型 if (message instanceof Response) &#123; decode( ((Response)message).getResult()); &#125; &#x2F;&#x2F;解码之后到HeaderExchangeHandler中处理 handler.received(channel, message);&#125; 解码之后到HeaderExchangeHandler的received方法： 123456789101112131415161718192021222324252627282930313233343536373839public void received(Channel channel, Object message) throws RemotingException &#123; channel.setAttribute(KEY_READ_TIMESTAMP, System.currentTimeMillis()); ExchangeChannel exchangeChannel &#x3D; HeaderExchangeChannel.getOrAddChannel(channel); try &#123; &#x2F;&#x2F;request类型的消息 if (message instanceof Request) &#123; Request request &#x3D; (Request) message; if (request.isEvent()) &#123;&#x2F;&#x2F;判断心跳还是正常请求 &#x2F;&#x2F; 处理心跳 handlerEvent(channel, request); &#125; else &#123;&#x2F;&#x2F;正常的请求 &#x2F;&#x2F;需要返回 if (request.isTwoWay()) &#123; &#x2F;&#x2F;处理请求，并构造响应信息 Response response &#x3D; handleRequest(exchangeChannel, request); &#x2F;&#x2F;NettyChannel，发送响应信息 channel.send(response); &#125; else &#123;&#x2F;&#x2F;不需要返回的处理 handler.received(exchangeChannel, request.getData()); &#125; &#125; &#125; else if (message instanceof Response) &#123;&#x2F;&#x2F;response类型的消息 handleResponse(channel, (Response) message); &#125; else if (message instanceof String) &#123; if (isClientSide(channel)) &#123; Exception e &#x3D; new Exception(&quot;Dubbo client can not supported string message: &quot; + message + &quot; in channel: &quot; + channel + &quot;, url: &quot; + channel.getUrl()); &#125; else &#123;&#x2F;&#x2F;telnet类型 String echo &#x3D; handler.telnet(channel, (String) message); if (echo !&#x3D; null &amp;&amp; echo.length() &gt; 0) &#123; channel.send(echo); &#125; &#125; &#125; else &#123; handler.received(exchangeChannel, message); &#125; &#125; finally &#123; HeaderExchangeChannel.removeChannelIfDisconnected(channel); &#125;&#125; 先看下处理请求，并构造响应信息： 123456789101112131415161718192021222324Response handleRequest(ExchangeChannel channel, Request req) throws RemotingException &#123; Response res &#x3D; new Response(req.getId(), req.getVersion()); if (req.isBroken()) &#123; Object data &#x3D; req.getData(); String msg; if (data &#x3D;&#x3D; null) msg &#x3D; null; else if (data instanceof Throwable) msg &#x3D; StringUtils.toString((Throwable) data); else msg &#x3D; data.toString(); res.setErrorMessage(&quot;Fail to decode request due to: &quot; + msg); res.setStatus(Response.BAD_REQUEST); return res; &#125; &#x2F;&#x2F; find handler by message class. Object msg &#x3D; req.getData(); try &#123; &#x2F;&#x2F;处理请求数据，handler是DubboProtocol中的new的一个ExchangeHandlerAdapter Object result &#x3D; handler.reply(channel, msg); res.setStatus(Response.OK); res.setResult(result); &#125; catch (Throwable e) &#123; &#125; return res;&#125; 进入DubboProtocol中的ExchangeHandlerAdapter的replay方法： 12345678910111213141516171819202122232425262728293031public Object reply(ExchangeChannel channel, Object message) throws RemotingException &#123; if (message instanceof Invocation) &#123; &#x2F;&#x2F;Invocation中保存着方法名等 Invocation inv &#x3D; (Invocation) message; &#x2F;&#x2F;获取Invoker Invoker&lt;?&gt; invoker &#x3D; getInvoker(channel, inv); &#x2F;&#x2F;如果是callback 需要处理高版本调用低版本的问题 if (Boolean.TRUE.toString().equals(inv.getAttachments().get(IS_CALLBACK_SERVICE_INVOKE)))&#123; String methodsStr &#x3D; invoker.getUrl().getParameters().get(&quot;methods&quot;); boolean hasMethod &#x3D; false; if (methodsStr &#x3D;&#x3D; null || methodsStr.indexOf(&quot;,&quot;) &#x3D;&#x3D; -1)&#123; hasMethod &#x3D; inv.getMethodName().equals(methodsStr); &#125; else &#123; String[] methods &#x3D; methodsStr.split(&quot;,&quot;); for (String method : methods)&#123; if (inv.getMethodName().equals(method))&#123; hasMethod &#x3D; true; break; &#125; &#125; &#125; if (!hasMethod)&#123; return null; &#125; &#125; RpcContext.getContext().setRemoteAddress(channel.getRemoteAddress()); &#x2F;&#x2F;执行调用，然后返回结果 return invoker.invoke(inv); &#125; throw new RemotingException(。。。); &#125; 先看下getInvoker获取Invoker： 1234567891011121314151617181920212223242526Invoker&lt;?&gt; getInvoker(Channel channel, Invocation inv) throws RemotingException&#123; boolean isCallBackServiceInvoke &#x3D; false; boolean isStubServiceInvoke &#x3D; false; int port &#x3D; channel.getLocalAddress().getPort(); String path &#x3D; inv.getAttachments().get(Constants.PATH_KEY); &#x2F;&#x2F;如果是客户端的回调服务. isStubServiceInvoke &#x3D; Boolean.TRUE.toString().equals(inv.getAttachments().get(Constants.STUB_EVENT_KEY)); if (isStubServiceInvoke)&#123; port &#x3D; channel.getRemoteAddress().getPort(); &#125; &#x2F;&#x2F;callback isCallBackServiceInvoke &#x3D; isClientSide(channel) &amp;&amp; !isStubServiceInvoke; if(isCallBackServiceInvoke)&#123; path &#x3D; inv.getAttachments().get(Constants.PATH_KEY)+&quot;.&quot;+inv.getAttachments().get(Constants.CALLBACK_SERVICE_KEY); inv.getAttachments().put(IS_CALLBACK_SERVICE_INVOKE, Boolean.TRUE.toString()); &#125; String serviceKey &#x3D; serviceKey(port, path, inv.getAttachments().get(Constants.VERSION_KEY), inv.getAttachments().get(Constants.GROUP_KEY)); &#x2F;&#x2F;从之前缓存的exporterMap中查找Exporter &#x2F;&#x2F;key：dubbo.common.hello.service.HelloService:20880 DubboExporter&lt;?&gt; exporter &#x3D; (DubboExporter&lt;?&gt;) exporterMap.get(serviceKey); if (exporter &#x3D;&#x3D; null) throw new RemotingException(。。。）; &#x2F;&#x2F;得到Invoker，返回 return exporter.getInvoker();&#125; 再看执行调用invoker.invoke(inv);，会先进入InvokerWrapper： 123public Result invoke(Invocation invocation) throws RpcException &#123; return invoker.invoke(invocation);&#125; 接着进入AbstractProxyInvoker： 1234567public Result invoke(Invocation invocation) throws RpcException &#123; try &#123; &#x2F;&#x2F;先doInvoke &#x2F;&#x2F;然后封装成结果返回 return new RpcResult(doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments())); &#125; catch (InvocationTargetException e) &#123;。。。&#125;&#125; 这里的doInvoke是在JavassistProxyFactory中的AbstractProxyInvoker实例： 12345678910111213public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; &#x2F;&#x2F; TODO Wrapper类不能正确处理带$的类名 final Wrapper wrapper &#x3D; Wrapper.getWrapper(proxy.getClass().getName().indexOf(&#39;$&#39;) &lt; 0 ? proxy.getClass() : type); return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; &#x2F;&#x2F;这里就调用了具体的方法 return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &#125; &#125;;&#125; 消息处理完后返回到HeaderExchangeHandler的received方法： 123456789101112131415161718192021222324252627282930313233343536373839public void received(Channel channel, Object message) throws RemotingException &#123; channel.setAttribute(KEY_READ_TIMESTAMP, System.currentTimeMillis()); ExchangeChannel exchangeChannel &#x3D; HeaderExchangeChannel.getOrAddChannel(channel); try &#123; &#x2F;&#x2F;request类型的消息 if (message instanceof Request) &#123; Request request &#x3D; (Request) message; if (request.isEvent()) &#123;&#x2F;&#x2F;判断心跳还是正常请求 &#x2F;&#x2F; 处理心跳 handlerEvent(channel, request); &#125; else &#123;&#x2F;&#x2F;正常的请求 &#x2F;&#x2F;需要返回 if (request.isTwoWay()) &#123; &#x2F;&#x2F;处理请求，并构造响应信息，这在上面已经解析过了 Response response &#x3D; handleRequest(exchangeChannel, request); &#x2F;&#x2F;NettyChannel，发送响应信息 channel.send(response); &#125; else &#123;&#x2F;&#x2F;不需要返回的处理 handler.received(exchangeChannel, request.getData()); &#125; &#125; &#125; else if (message instanceof Response) &#123;&#x2F;&#x2F;response类型的消息 handleResponse(channel, (Response) message); &#125; else if (message instanceof String) &#123; if (isClientSide(channel)) &#123; Exception e &#x3D; new Exception(&quot;Dubbo client can not supported string message: &quot; + message + &quot; in channel: &quot; + channel + &quot;, url: &quot; + channel.getUrl()); &#125; else &#123;&#x2F;&#x2F;telnet类型 String echo &#x3D; handler.telnet(channel, (String) message); if (echo !&#x3D; null &amp;&amp; echo.length() &gt; 0) &#123; channel.send(echo); &#125; &#125; &#125; else &#123; handler.received(exchangeChannel, message); &#125; &#125; finally &#123; HeaderExchangeChannel.removeChannelIfDisconnected(channel); &#125;&#125; 解析完请求，构造完响应消息，就开始发送响应了,channel.send(response);，先经过AbstractPeer: 1234public void send(Object message) throws RemotingException &#123; &#x2F;&#x2F;NettyChannel send(message, url.getParameter(Constants.SENT_KEY, false));&#125; 进入NettyChannel中，进行响应消息的发送： 12345678910111213141516171819202122232425public void send(Object message, boolean sent) throws RemotingException &#123; &#x2F;&#x2F;AbstractChannel的处理 super.send(message, sent); boolean success &#x3D; true; int timeout &#x3D; 0; try &#123; ChannelFuture future &#x3D; channel.write(message); if (sent) &#123; timeout &#x3D; getUrl().getPositiveParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); success &#x3D; future.await(timeout); &#125; Throwable cause &#x3D; future.getCause(); if (cause !&#x3D; null) &#123; throw cause; &#125; &#125; catch (Throwable e) &#123; throw new RemotingException(this, &quot;Failed to send message &quot; + message + &quot; to &quot; + getRemoteAddress() + &quot;, cause: &quot; + e.getMessage(), e); &#125; if(! success) &#123; throw new RemotingException(this, &quot;Failed to send message &quot; + message + &quot; to &quot; + getRemoteAddress() + &quot;in timeout(&quot; + timeout + &quot;ms) limit&quot;); &#125;&#125; 消费者接受到服务端返回的响应后的处理服务提供者端接收到消费者端的请求并处理之后，返回给消费者端，消费者这边接受响应的入口跟提供者差不多，也是NettyCodecAdapter.messageReceived()，经过解码，到NettyHandler.messageReceived()处理： 123456789public void messageReceived(ChannelHandlerContext ctx, MessageEvent e) throws Exception &#123; NettyChannel channel &#x3D; NettyChannel.getOrAddChannel(ctx.getChannel(), url, handler); try &#123; &#x2F;&#x2F;NettyClient handler.received(channel, e.getMessage()); &#125; finally &#123; NettyChannel.removeChannelIfDisconnected(ctx.getChannel()); &#125;&#125; 先经过AbstractPeer的received方法： 1234567public void received(Channel ch, Object msg) throws RemotingException &#123; if (closed) &#123; return; &#125; &#x2F;&#x2F;MultiMessageHandler handler.received(ch, msg);&#125; 进入MultiMessageHandler： 1234567891011public void received(Channel channel, Object message) throws RemotingException &#123; if (message instanceof MultiMessage) &#123; MultiMessage list &#x3D; (MultiMessage)message; for(Object obj : list) &#123; handler.received(channel, obj); &#125; &#125; else &#123; &#x2F;&#x2F;HeartbeatHandler handler.received(channel, message); &#125;&#125; 进入HeartbeatHandler，根据不同类型进行处理： 1234567891011121314151617181920212223242526272829303132public void received(Channel channel, Object message) throws RemotingException &#123; setReadTimestamp(channel); if (isHeartbeatRequest(message)) &#123; Request req &#x3D; (Request) message; if (req.isTwoWay()) &#123; Response res &#x3D; new Response(req.getId(), req.getVersion()); res.setEvent(Response.HEARTBEAT_EVENT); channel.send(res); if (logger.isInfoEnabled()) &#123; int heartbeat &#x3D; channel.getUrl().getParameter(Constants.HEARTBEAT_KEY, 0); if(logger.isDebugEnabled()) &#123; logger.debug(&quot;Received heartbeat from remote channel &quot; + channel.getRemoteAddress() + &quot;, cause: The channel has no data-transmission exceeds a heartbeat period&quot; + (heartbeat &gt; 0 ? &quot;: &quot; + heartbeat + &quot;ms&quot; : &quot;&quot;)); &#125; &#125; &#125; return; &#125; if (isHeartbeatResponse(message)) &#123; if (logger.isDebugEnabled()) &#123; logger.debug( new StringBuilder(32) .append(&quot;Receive heartbeat response in thread &quot;) .append(Thread.currentThread().getName()) .toString()); &#125; return; &#125; &#x2F;&#x2F;AllChannelHandler handler.received(channel, message);&#125; 进入AllChannelHandler： 12345678public void received(Channel channel, Object message) throws RemotingException &#123; ExecutorService cexecutor &#x3D; getExecutorService(); try &#123; cexecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message)); &#125; catch (Throwable t) &#123; throw new ExecutionException(message, channel, getClass() + &quot; error when process received event .&quot;, t); &#125;&#125; 然后在新线程，ChannelEventRunnable的run方法中进入DecodeHandler： 123456789101112131415public void received(Channel channel, Object message) throws RemotingException &#123; if (message instanceof Decodeable) &#123; decode(message); &#125; if (message instanceof Request) &#123; decode(((Request)message).getData()); &#125; &#x2F;&#x2F;这里进行response类型的处理 if (message instanceof Response) &#123; decode( ((Response)message).getResult()); &#125; handler.received(channel, message);&#125; 进入处理response的decode方法，进行解码response： 1234567private void decode(Object message) &#123; if (message !&#x3D; null &amp;&amp; message instanceof Decodeable) &#123; try &#123; ((Decodeable)message).decode(); &#125; catch (Throwable e) &#123;。。。&#125; &#x2F;&#x2F; ~ end of catch &#125; &#x2F;&#x2F; ~ end of if&#125; 接着会进入HeaderExchangerHandler.received () 方法： 123456789101112131415161718192021222324252627282930313233public void received(Channel channel, Object message) throws RemotingException &#123; channel.setAttribute(KEY_READ_TIMESTAMP, System.currentTimeMillis()); ExchangeChannel exchangeChannel &#x3D; HeaderExchangeChannel.getOrAddChannel(channel); try &#123; if (message instanceof Request) &#123; Request request &#x3D; (Request) message; if (request.isEvent()) &#123; handlerEvent(channel, request); &#125; else &#123; if (request.isTwoWay()) &#123; Response response &#x3D; handleRequest(exchangeChannel, request); channel.send(response); &#125; else &#123; handler.received(exchangeChannel, request.getData()); &#125; &#125; &#125; else if (message instanceof Response) &#123; &#x2F;&#x2F;这里处理response消息 handleResponse(channel, (Response) message); &#125; else if (message instanceof String) &#123; if (isClientSide(channel)) &#123; Exception &#125; else &#123; String echo &#x3D; handler.telnet(channel, (String) message); if (echo !&#x3D; null &amp;&amp; echo.length() &gt; 0) &#123; channel.send(echo); &#125; &#125; &#125; else &#123; handler.received(exchangeChannel, message); &#125; &#125; finally &#123; HeaderExchangeChannel.removeChannelIfDisconnected(channel); &#125;&#125; handleResponse方法： 12345static void handleResponse(Channel channel, Response response) throws RemotingException &#123; if (response !&#x3D; null &amp;&amp; !response.isHeartbeat()) &#123; DefaultFuture.received(channel, response); &#125;&#125; 这一步设置response到消费者请求的Future中，以供消费者通过DefaultFuture.get()取得提供者的响应，此为同步转异步重要一步，且请求超时也由DefaultFuture控制。 然后就是return (Result) currentClient.request(inv, timeout).get();在DubboInvoker中，这里继续执行，然后执行Filter，最后返回到InvokerInvocationHandler.invoker()方法中，方法得到调用结果，结束！ 注意： 消费者端的DubboInvoker发起请求后，后续的逻辑是异步的或是指定超时时间内阻塞的，直到得到响应结果后，继续执行DubboInvoker中逻辑。 对于异步请求时，消费者得到Future，其余逻辑均是异步的。 消费者还可以通过设置async、sent、return来调整处理逻辑，async指异步还是同步请求，sent指是否等待请求消息发出即阻塞等待是否成功发出请求、return指是否忽略返回值即但方向通信，一般异步时使用以减少Future对象的创建和管理成本。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo中消费者初始化的过程解析]]></title>
      <url>%2F2017%2F03%2F21%2FDubbo%E4%B8%AD%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%9D%E5%A7%8B%E5%8C%96%E7%9A%84%E8%BF%87%E7%A8%8B%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[首先还是Spring碰到dubbo的标签之后，会使用parseCustomElement解析dubbo标签，使用的解析器是dubbo的DubboBeanDefinitionParser，解析完成之后返回BeanDefinition给Spring管理。 服务消费者端对应的是ReferenceBean，实现了ApplicationContextAware接口，Spring会在Bean的实例化那一步回调setApplicationContext方法。也实现了InitializingBean接口，接着会回调afterPropertySet方法。还实现了FactoryBean接口，实现FactoryBean可以在后期获取bean的时候做一些操作，dubbo在这个时候做初始化。另外ReferenceBean还实现了DisposableBean，会在bean销毁的时候调用destory方法。 消费者的初始化是在ReferenceBean的init方法中执行，分为两种情况： reference标签中没有配置init属性，此时是延迟初始化的，也就是只有等到bean引用被注入到其他Bean中，或者调用getBean获取这个Bean的时候，才会初始化。比如在这里的例子里reference没有配置init属性，只有等到HelloService helloService = (HelloService) applicationContext.getBean(&quot;helloService&quot;);这句getBean的时候，才会开始调用init方法进行初始化。 另外一种情况是立即初始化，即是如果reference标签中init属性配置为true，会立即进行初始化（也就是上面说到的实现了FactoryBean接口）。 初始化开始这里以没有配置init的reference为例，只要不注入bean或者不调用getBean获取bean的时候，就不会被初始化。HelloService helloService = (HelloService) applicationContext.getBean(&quot;helloService&quot;); 另外在ReferenceBean这个类在Spring中初始化的时候，有几个静态变量会被初始化： 12345private static final Protocol refprotocol &#x3D; ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();private static final Cluster cluster &#x3D; ExtensionLoader.getExtensionLoader(Cluster.class).getAdaptiveExtension();private static final ProxyFactory proxyFactory &#x3D; ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension(); 这几个变量的初始化是根据dubbo的SPI扩展机制动态生成的代码： refprotocol： 12345678910111213141516171819202122232425262728293031323334353637import com.alibaba.dubbo.common.extension.ExtensionLoader;public class Protocol$Adpative implements com.alibaba.dubbo.rpc.Protocol &#123; public com.alibaba.dubbo.rpc.Invoker refer(java.lang.Class arg0, com.alibaba.dubbo.common.URL arg1) throws java.lang.Class &#123; if (arg1 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;url &#x3D;&#x3D; null&quot;); com.alibaba.dubbo.common.URL url &#x3D; arg1; String extName &#x3D; ( url.getProtocol() &#x3D;&#x3D; null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); com.alibaba.dubbo.rpc.Protocol extension &#x3D; (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); &#125; public com.alibaba.dubbo.rpc.Exporter export(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker &#123; if (arg0 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument &#x3D;&#x3D; null&quot;); if (arg0.getUrl() &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument getUrl() &#x3D;&#x3D; null&quot;);com.alibaba.dubbo.common.URL url &#x3D; arg0.getUrl(); String extName &#x3D; ( url.getProtocol() &#x3D;&#x3D; null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); com.alibaba.dubbo.rpc.Protocol extension &#x3D; (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName); return extension.export(arg0); &#125; public void destroy() &#123; throw new UnsupportedOperationException(&quot;method public abstract void com.alibaba.dubbo.rpc.Protocol.destroy() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!&quot;); &#125; public int getDefaultPort() &#123; throw new UnsupportedOperationException(&quot;method public abstract int com.alibaba.dubbo.rpc.Protocol.getDefaultPort() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!&quot;); &#125;&#125; cluster： 12345678910111213141516import com.alibaba.dubbo.common.extension.ExtensionLoader;public class Cluster$Adpative implements com.alibaba.dubbo.rpc.cluster.Cluster &#123; public com.alibaba.dubbo.rpc.Invoker join(com.alibaba.dubbo.rpc.cluster.Directory arg0) throws com.alibaba.dubbo.rpc.cluster.Directory &#123; if (arg0 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.cluster.Directory argument &#x3D;&#x3D; null&quot;); if (arg0.getUrl() &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.cluster.Directory argument getUrl() &#x3D;&#x3D; null&quot;);com.alibaba.dubbo.common.URL url &#x3D; arg0.getUrl(); String extName &#x3D; url.getParameter(&quot;cluster&quot;, &quot;failover&quot;); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.cluster.Cluster) name from url(&quot; + url.toString() + &quot;) use keys([cluster])&quot;); com.alibaba.dubbo.rpc.cluster.Cluster extension &#x3D; (com.alibaba.dubbo.rpc.cluster.Cluster)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.cluster.Cluster.class).getExtension(extName); return extension.join(arg0); &#125;&#125; proxyFactory： 1234567891011121314151617181920212223242526272829import com.alibaba.dubbo.common.extension.ExtensionLoader;public class ProxyFactory$Adpative implements com.alibaba.dubbo.rpc.ProxyFactory &#123; public java.lang.Object getProxy(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker &#123; if (arg0 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument &#x3D;&#x3D; null&quot;); if (arg0.getUrl() &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument getUrl() &#x3D;&#x3D; null&quot;);com.alibaba.dubbo.common.URL url &#x3D; arg0.getUrl(); String extName &#x3D; url.getParameter(&quot;proxy&quot;, &quot;javassist&quot;); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.ProxyFactory) name from url(&quot; + url.toString() + &quot;) use keys([proxy])&quot;); com.alibaba.dubbo.rpc.ProxyFactory extension &#x3D; (com.alibaba.dubbo.rpc.ProxyFactory)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getProxy(arg0); &#125; public com.alibaba.dubbo.rpc.Invoker getInvoker(java.lang.Object arg0, java.lang.Class arg1, com.alibaba.dubbo.common.URL arg2) throws java.lang.Object &#123; if (arg2 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;url &#x3D;&#x3D; null&quot;); com.alibaba.dubbo.common.URL url &#x3D; arg2; String extName &#x3D; url.getParameter(&quot;proxy&quot;, &quot;javassist&quot;); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.ProxyFactory) name from url(&quot; + url.toString() + &quot;) use keys([proxy])&quot;); com.alibaba.dubbo.rpc.ProxyFactory extension &#x3D; (com.alibaba.dubbo.rpc.ProxyFactory)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getInvoker(arg0, arg1, arg2); &#125;&#125; 初始化入口初始化的入口在ReferenceConfig的get()方法： 123456789public synchronized T get() &#123; if (destroyed)&#123; throw new IllegalStateException(&quot;Already destroyed!&quot;); &#125; if (ref &#x3D;&#x3D; null) &#123; init(); &#125; return ref;&#125; init()方法会先检查初始化所有的配置信息，然后调用ref = createProxy(map);创建代理，消费者最终得到的是服务的代理。初始化主要做的事情就是引用对应的远程服务，大概的步骤： 监听注册中心 连接服务提供者端进行服务引用 创建服务代理并返回 文档上关于Zookeeper作为注册中心时，服务消费者启动时要做的事情有： 订阅/dubbo/com.foo.BarService/providers目录下的提供者URL地址。并向/dubbo/com.foo.BarService/consumers目录下写入自己的URL地址。 创建代理 引用远程服务 创建代理 init()中createProxy方法： 123456789101112131415161718private T createProxy(Map&lt;String, String&gt; map) &#123; &#x2F;&#x2F;先判断是否是本地服务引用injvm &#x2F;&#x2F;判断是否是点对点直连 &#x2F;&#x2F;判断是否是通过注册中心连接 &#x2F;&#x2F;然后是服务的引用 &#x2F;&#x2F;这里url为 &#x2F;&#x2F;registry:&#x2F;&#x2F;127.0.0.1:2181&#x2F;com.alibaba.dubbo.registry.RegistryService? &#x2F;&#x2F;application&#x3D;dubbo-consumer&amp;dubbo&#x3D;2.5.3&amp;pid&#x3D;12272&amp; &#x2F;&#x2F;refer&#x3D;application%3Ddubbo-consumer%26dubbo%3D2.5.3%26 &#x2F;&#x2F;interface%3Ddubbo.common.hello.service.HelloService%26 &#x2F;&#x2F;methods%3DsayHello%26pid%3D12272%26side%3D &#x2F;&#x2F;consumer%26timeout%3D100000%26timestamp%3D1489318676447&amp; &#x2F;&#x2F;registry&#x3D;zookeeper&amp;timestamp&#x3D;1489318676641 &#x2F;&#x2F;引用远程服务由Protocol的实现来处理 refprotocol.refer(interfaceClass, url); &#x2F;&#x2F;最后返回服务代理 return (T) proxyFactory.getProxy(invoker);&#125; 这里refprotocol是上面生成的代码，会根据协议不同选择不同的Protocol协议。 引用远程服务对于服务引用refprotocol.refer(interfaceClass, url)会首先进入ProtocolListenerWrapper的refer方法，然后在进入ProtocolFilterWrapper的refer方法，然后再进入RegistryProtocol的refer方法，这里的url协议是registry，所以上面两个Wrapper中不做处理，直接进入了RegistryProtocol，看下RegistryProtocol中： 12345678910111213141516171819202122232425262728293031323334public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; &#x2F;&#x2F;这里获得的url是 &#x2F;&#x2F;zookeeper:&#x2F;&#x2F;127.0.0.1:2181&#x2F;com.alibaba.dubbo.registry.RegistryService? &#x2F;&#x2F;application&#x3D;dubbo-consumer&amp;dubbo&#x3D;2.5.3&amp;pid&#x3D;12272&amp; &#x2F;&#x2F;refer&#x3D;application%3Ddubbo-consumer%26dubbo%3D2.5.3%26 &#x2F;&#x2F;interface%3Ddubbo.common.hello.service.HelloService%26 &#x2F;&#x2F;methods%3DsayHello%26pid%3D12272%26side%3D &#x2F;&#x2F;consumer%26timeout%3D100000%26 &#x2F;&#x2F;timestamp%3D1489318676447&amp;timestamp&#x3D;1489318676641 url &#x3D; url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY); &#x2F;&#x2F;根据url获取Registry对象 &#x2F;&#x2F;先连接注册中心，把消费者注册到注册中心 Registry registry &#x3D; registryFactory.getRegistry(url); &#x2F;&#x2F;判断引用是否是注册中心RegistryService，如果是直接返回刚得到的注册中心服务 if (RegistryService.class.equals(type)) &#123; return proxyFactory.getInvoker((T) registry, type, url); &#125; &#x2F;&#x2F;以下是普通服务，需要进入注册中心和集群下面的逻辑 &#x2F;&#x2F; group&#x3D;&quot;a,b&quot; or group&#x3D;&quot;*&quot; &#x2F;&#x2F;获取ref的各种属性 Map&lt;String, String&gt; qs &#x3D; StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY)); &#x2F;&#x2F;获取分组属性 String group &#x3D; qs.get(Constants.GROUP_KEY); &#x2F;&#x2F;先判断引用服务是否需要合并不同实现的返回结果 if (group !&#x3D; null &amp;&amp; group.length() &gt; 0 ) &#123; if ( ( Constants.COMMA_SPLIT_PATTERN.split( group ) ).length &gt; 1 || &quot;*&quot;.equals( group ) ) &#123; &#x2F;&#x2F;使用默认的分组聚合集群策略 return doRefer( getMergeableCluster(), registry, type, url ); &#125; &#125; &#x2F;&#x2F;选择配置的集群策略（cluster&#x3D;&quot;failback&quot;）或者默认策略 return doRefer(cluster, registry, type, url);&#125; 获取注册中心连接注册中心Registry registry = registryFactory.getRegistry(url);首先会到AbstractRegistryFactory的getRegistry方法： 123456789101112131415161718192021222324252627282930313233public Registry getRegistry(URL url) &#123; &#x2F;&#x2F;这里url是 &#x2F;&#x2F;zookeeper:&#x2F;&#x2F;127.0.0.1:2181&#x2F;com.alibaba.dubbo.registry.RegistryService? &#x2F;&#x2F;application&#x3D;dubbo-consumer&amp;dubbo&#x3D;2.5.3&amp; &#x2F;&#x2F;interface&#x3D;com.alibaba.dubbo.registry.RegistryService&amp; &#x2F;&#x2F;pid&#x3D;12272&amp;timestamp&#x3D;1489318676641 url &#x3D; url.setPath(RegistryService.class.getName()) .addParameter(Constants.INTERFACE_KEY, RegistryService.class.getName()) .removeParameters(Constants.EXPORT_KEY, Constants.REFER_KEY); &#x2F;&#x2F;这里key是 &#x2F;&#x2F;zookeeper:&#x2F;&#x2F;127.0.0.1:2181&#x2F;com.alibaba.dubbo.registry.RegistryService String key &#x3D; url.toServiceString(); &#x2F;&#x2F; 锁定注册中心获取过程，保证注册中心单一实例 LOCK.lock(); try &#123; Registry registry &#x3D; REGISTRIES.get(key); if (registry !&#x3D; null) &#123; return registry; &#125; &#x2F;&#x2F;这里用的是ZookeeperRegistryFactory &#x2F;&#x2F;返回的Registry中封装了已经连接到Zookeeper的zkClient实例 registry &#x3D; createRegistry(url); if (registry &#x3D;&#x3D; null) &#123; throw new IllegalStateException(&quot;Can not create registry &quot; + url); &#125; &#x2F;&#x2F;放到缓存中 REGISTRIES.put(key, registry); return registry; &#125; finally &#123; &#x2F;&#x2F; 释放锁 LOCK.unlock(); &#125;&#125; ZookeeperRegistryFactory的createRegistry方法： 12345public Registry createRegistry(URL url) &#123; &#x2F;&#x2F;直接返回一个新的ZookeeperRegistry实例 &#x2F;&#x2F;这里的zookeeperTransporter代码在下面，动态生成的适配类 return new ZookeeperRegistry(url, zookeeperTransporter);&#125; zookeeperTransporter代码： 12345678910111213141516package com.alibaba.dubbo.remoting.zookeeper;import com.alibaba.dubbo.common.extension.ExtensionLoader;public class ZookeeperTransporter$Adpative implements com.alibaba.dubbo.remoting.zookeeper.ZookeeperTransporter &#123; public com.alibaba.dubbo.remoting.zookeeper.ZookeeperClient connect(com.alibaba.dubbo.common.URL arg0) &#123; if (arg0 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;url &#x3D;&#x3D; null&quot;); com.alibaba.dubbo.common.URL url &#x3D; arg0; String extName &#x3D; url.getParameter(&quot;client&quot;, url.getParameter(&quot;transporter&quot;, &quot;zkclient&quot;)); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.remoting.zookeeper.ZookeeperTransporter) name from url(&quot; + url.toString() + &quot;) use keys([client, transporter])&quot;); com.alibaba.dubbo.remoting.zookeeper.ZookeeperTransporter extension &#x3D; (com.alibaba.dubbo.remoting.zookeeper.ZookeeperTransporter)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.remoting.zookeeper.ZookeeperTransporter.class).getExtension(extName); return extension.connect(arg0); &#125;&#125; 上面代码中可以看到，如果我们没有指定Zookeeper的client属性，默认使用zkClient，所以上面的zookeeperTransporter是ZkclientZookeeperTransporter。 继续看new ZookeeperRegistry(url, zookeeperTransporter);： 123456789101112131415161718192021222324252627282930public ZookeeperRegistry(URL url, ZookeeperTransporter zookeeperTransporter) &#123; &#x2F;&#x2F;这里会先经过AbstractRegistry的处理，然后经过FailbackRegistry的处理（解释在下面） super(url); if (url.isAnyHost()) &#123; throw new IllegalStateException(&quot;registry address &#x3D;&#x3D; null&quot;); &#125; &#x2F;&#x2F;服务分组，默认dubbo String group &#x3D; url.getParameter(Constants.GROUP_KEY, DEFAULT_ROOT); if (! group.startsWith(Constants.PATH_SEPARATOR)) &#123; group &#x3D; Constants.PATH_SEPARATOR + group; &#125; &#x2F;&#x2F;注册中心的节点 this.root &#x3D; group; &#x2F;&#x2F;ZkclientZookeeperTransporter的connect方法 &#x2F;&#x2F;直接返回一个ZkclientZookeeperClient实例 &#x2F;&#x2F;具体的步骤是，new一个ZkClient实例，然后订阅了一个状态变化的监听器 zkClient &#x3D; zookeeperTransporter.connect(url); &#x2F;&#x2F;添加一个状态改变的监听器 zkClient.addStateListener(new StateListener() &#123; public void stateChanged(int state) &#123; if (state &#x3D;&#x3D; RECONNECTED) &#123; try &#123; recover(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; &#125; &#125; &#125;);&#125; AbstractRegistry的处理： 1234567891011121314151617181920212223public AbstractRegistry(URL url) &#123; &#x2F;&#x2F;设置registryUrl setUrl(url); &#x2F;&#x2F; 启动文件保存定时器 syncSaveFile &#x3D; url.getParameter(Constants.REGISTRY_FILESAVE_SYNC_KEY, false); &#x2F;&#x2F;会先去用户主目录下的.dubbo目录下加载缓存注册中心的缓存文件比如：dubbo-registry-127.0.0.1.cache String filename &#x3D; url.getParameter(Constants.FILE_KEY, System.getProperty(&quot;user.home&quot;) + &quot;&#x2F;.dubbo&#x2F;dubbo-registry-&quot; + url.getHost() + &quot;.cache&quot;); File file &#x3D; null; if (ConfigUtils.isNotEmpty(filename)) &#123; file &#x3D; new File(filename); if(! file.exists() &amp;&amp; file.getParentFile() !&#x3D; null &amp;&amp; ! file.getParentFile().exists())&#123; if(! file.getParentFile().mkdirs())&#123; throw new IllegalArgumentException(&quot;Invalid registry store file &quot; + file + &quot;, cause: Failed to create directory &quot; + file.getParentFile() + &quot;!&quot;); &#125; &#125; &#125; this.file &#x3D; file; &#x2F;&#x2F;缓存文件存在的话就把文件读进内存中 loadProperties(); &#x2F;&#x2F;先获取backup url &#x2F;&#x2F;然后通知订阅 notify(url.getBackupUrls());&#125; 获取注册中心时的通知方法notify方法： 123456789101112131415161718192021protected void notify(List&lt;URL&gt; urls) &#123; if(urls &#x3D;&#x3D; null || urls.isEmpty()) return; &#x2F;&#x2F;getSubscribed()方法获取订阅者列表 for (Map.Entry&lt;URL, Set&lt;NotifyListener&gt;&gt; entry : getSubscribed().entrySet()) &#123; URL url &#x3D; entry.getKey(); if(! UrlUtils.isMatch(url, urls.get(0))) &#123; continue; &#125; Set&lt;NotifyListener&gt; listeners &#x3D; entry.getValue(); if (listeners !&#x3D; null) &#123; for (NotifyListener listener : listeners) &#123; try &#123; &#x2F;&#x2F;通知每个监听器 notify(url, listener, filterEmpty(url, urls)); &#125; catch (Throwable t) &#123; &#125; &#125; &#125; &#125;&#125; notify(url, listener, filterEmpty(url, urls));代码： 12345678910111213141516171819202122232425262728293031protected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; Map&lt;String, List&lt;URL&gt;&gt; result &#x3D; new HashMap&lt;String, List&lt;URL&gt;&gt;(); for (URL u : urls) &#123; if (UrlUtils.isMatch(url, u)) &#123; &#x2F;&#x2F;分类 String category &#x3D; u.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); List&lt;URL&gt; categoryList &#x3D; result.get(category); if (categoryList &#x3D;&#x3D; null) &#123; categoryList &#x3D; new ArrayList&lt;URL&gt;(); result.put(category, categoryList); &#125; categoryList.add(u); &#125; &#125; if (result.size() &#x3D;&#x3D; 0) &#123; return; &#125; Map&lt;String, List&lt;URL&gt;&gt; categoryNotified &#x3D; notified.get(url); if (categoryNotified &#x3D;&#x3D; null) &#123; notified.putIfAbsent(url, new ConcurrentHashMap&lt;String, List&lt;URL&gt;&gt;()); categoryNotified &#x3D; notified.get(url); &#125; for (Map.Entry&lt;String, List&lt;URL&gt;&gt; entry : result.entrySet()) &#123; String category &#x3D; entry.getKey(); List&lt;URL&gt; categoryList &#x3D; entry.getValue(); categoryNotified.put(category, categoryList); saveProperties(url); &#x2F;&#x2F;通知 listener.notify(categoryList); &#125;&#125; AbstractRegistry构造完，接着是FailbackRegistry的处理： 123456789101112131415public FailbackRegistry(URL url) &#123; super(url); int retryPeriod &#x3D; url.getParameter(Constants.REGISTRY_RETRY_PERIOD_KEY, Constants.DEFAULT_REGISTRY_RETRY_PERIOD); &#x2F;&#x2F;启动失败重试定时器 this.retryFuture &#x3D; retryExecutor.scheduleWithFixedDelay(new Runnable() &#123; public void run() &#123; &#x2F;&#x2F; 检测并连接注册中心 try &#123; &#x2F;&#x2F;重试方法由每个具体子类实现 &#x2F;&#x2F;获取到注册失败的，然后尝试注册 retry(); &#125; catch (Throwable t) &#123; &#x2F;&#x2F; 防御性容错 &#125; &#125; &#125;, retryPeriod, retryPeriod, TimeUnit.MILLISECONDS);&#125; 这里会启动一个新的定时线程，主要是有连接失败的话，会进行重试连接retry()，启动完之后返回ZookeeperRegistry中继续处理。接下来下一步是服务的引用。 引用远程服务继续看ref方法中最后一步，服务的引用，返回的是一个Invoker，return doRefer(cluster, registry, type, url)； 1234567891011121314151617181920212223242526272829303132333435private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) &#123; &#x2F;&#x2F;初始化Directory &#x2F;&#x2F;组装Directory，可以看成一个消费端的List，可以随着注册中心的消息推送而动态的变化服务的Invoker &#x2F;&#x2F;封装了所有服务真正引用逻辑，覆盖配置，路由规则等逻辑 &#x2F;&#x2F;初始化时只需要向注册中心发起订阅请求，其他逻辑均是异步处理，包括服务的引用等 &#x2F;&#x2F;缓存接口所有的提供者端Invoker以及注册中心接口相关的配置等 RegistryDirectory&lt;T&gt; directory &#x3D; new RegistryDirectory&lt;T&gt;(type, url); directory.setRegistry(registry); directory.setProtocol(protocol); &#x2F;&#x2F;此处的subscribeUrl为 &#x2F;&#x2F;consumer:&#x2F;&#x2F;192.168.1.100&#x2F;dubbo.common.hello.service.HelloService? &#x2F;&#x2F;application&#x3D;dubbo-consumer&amp;dubbo&#x3D;2.5.3&amp; &#x2F;&#x2F;interface&#x3D;dubbo.common.hello.service.HelloService&amp; &#x2F;&#x2F;methods&#x3D;sayHello&amp;pid&#x3D;16409&amp; &#x2F;&#x2F;side&#x3D;consumer&amp;timeout&#x3D;100000&amp;timestamp&#x3D;1489322133987 URL subscribeUrl &#x3D; new URL(Constants.CONSUMER_PROTOCOL, NetUtils.getLocalHost(), 0, type.getName(), directory.getUrl().getParameters()); if (! Constants.ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) &#123; &#x2F;&#x2F;到注册中心注册服务 &#x2F;&#x2F;此处regist是上面一步获得的registry，即是ZookeeperRegistry，包含zkClient的实例 &#x2F;&#x2F;会先经过AbstractRegistry的处理，然后经过FailbackRegistry的处理（解析在下面） registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY, Constants.CHECK_KEY, String.valueOf(false))); &#125; &#x2F;&#x2F;订阅服务 &#x2F;&#x2F;有服务提供的时候，注册中心会推送服务消息给消费者，消费者再进行服务的引用。 directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, Constants.PROVIDERS_CATEGORY + &quot;,&quot; + Constants.CONFIGURATORS_CATEGORY + &quot;,&quot; + Constants.ROUTERS_CATEGORY)); &#x2F;&#x2F;服务的引用与变更全部由Directory异步完成 &#x2F;&#x2F;集群策略会将Directory伪装成一个Invoker返回 &#x2F;&#x2F;合并所有相同的invoker return cluster.join(directory);&#125; 注册中心接收到消费者发送的订阅请求后，会根据提供者注册服务的列表，推送服务消息给消费者。消费者端接收到注册中心发来的提供者列表后，进行服务的引用。触发Directory监听器的可以是订阅请求，覆盖策略消息，路由策略消息。 注册到注册中心AbstractRegistry的register方法： 123456789101112131415public void register(URL url) &#123; &#x2F;&#x2F;此时url是 &#x2F;&#x2F;consumer:&#x2F;&#x2F;192.168.1.100&#x2F;dubbo.common.hello.service.HelloService? &#x2F;&#x2F;application&#x3D;dubbo-consumer&amp; &#x2F;&#x2F;category&#x3D;consumers&amp;check&#x3D;false&amp;dubbo&#x3D;2.5.3&amp; &#x2F;&#x2F;interface&#x3D;dubbo.common.hello.service.HelloService&amp;methods&#x3D;sayHello &#x2F;&#x2F;&amp;pid&#x3D;16409&amp;side&#x3D;consumer&amp;timeout&#x3D;100000&amp;timestamp&#x3D;1489322133987 if (url &#x3D;&#x3D; null) &#123; throw new IllegalArgumentException(&quot;register url &#x3D;&#x3D; null&quot;); &#125; if (logger.isInfoEnabled())&#123; logger.info(&quot;Register: &quot; + url); &#125; registered.add(url);&#125; 上面只是把url添加到registered这个set中。 接着看FailbackRegistry的register方法： 1234567891011121314151617181920212223242526272829public void register(URL url) &#123; super.register(url); failedRegistered.remove(url); failedUnregistered.remove(url); try &#123; &#x2F;&#x2F; 向服务器端发送注册请求 &#x2F;&#x2F;这里调用的是ZookeeperRegistry中的doRegister方法 doRegister(url); &#125; catch (Exception e) &#123; Throwable t &#x3D; e; &#x2F;&#x2F; 如果开启了启动时检测，则直接抛出异常 boolean check &#x3D; getUrl().getParameter(Constants.CHECK_KEY, true) &amp;&amp; url.getParameter(Constants.CHECK_KEY, true) &amp;&amp; ! Constants.CONSUMER_PROTOCOL.equals(url.getProtocol()); boolean skipFailback &#x3D; t instanceof SkipFailbackWrapperException; if (check || skipFailback) &#123; if(skipFailback) &#123; t &#x3D; t.getCause(); &#125; throw new IllegalStateException(&quot;Failed to register &quot; + url + &quot; to registry &quot; + getUrl().getAddress() + &quot;, cause: &quot; + t.getMessage(), t); &#125; else &#123; logger.error(&quot;Failed to register &quot; + url + &quot;, waiting for retry, cause: &quot; + t.getMessage(), t); &#125; &#x2F;&#x2F; 将失败的注册请求记录到失败列表，定时重试 failedRegistered.add(url); &#125;&#125; 接着看下doRegister(url);方法，向服务器端发送注册请求，在ZookeeperRegistry中： 12345678protected void doRegister(URL url) &#123; try &#123; &#x2F;&#x2F;直接调用create，在AbstractZookeeperClient类中 zkClient.create(toUrlPath(url), url.getParameter(Constants.DYNAMIC_KEY, true)); &#125; catch (Throwable e) &#123; throw new RpcException(&quot;Failed to register &quot; + url + &quot; to zookeeper &quot; + getUrl() + &quot;, cause: &quot; + e.getMessage(), e); &#125;&#125; zkClient.create()方法： 12345678910111213141516171819202122232425262728293031&#x2F;&#x2F;path为&#x2F;&#x2F;&#x2F;dubbo&#x2F;dubbo.common.hello.service.HelloService&#x2F;consumers&#x2F;&#x2F;&#x2F;consumer%3A%2F%2F192.168.1.100%2F&#x2F;&#x2F;dubbo.common.hello.service.HelloService%3Fapplication%3D&#x2F;&#x2F;dubbo-consumer%26category%3Dconsumers%26check%3Dfalse%26&#x2F;&#x2F;dubbo%3D2.5.3%26interface%3D&#x2F;&#x2F;dubbo.common.hello.service.HelloService%26&#x2F;&#x2F;methods%3DsayHello%26pid%3D28819%26&#x2F;&#x2F;side%3Dconsumer%26timeout%3D100000%26timestamp%3D1489332839677public void create(String path, boolean ephemeral) &#123; int i &#x3D; path.lastIndexOf(&#39;&#x2F;&#39;); if (i &gt; 0) &#123; create(path.substring(0, i), false); &#125; &#x2F;&#x2F;循环完得到的path为&#x2F;dubbo &#x2F;&#x2F;dynamic&#x3D;false 表示该数据为持久数据，当注册方退出时，数据依然保存在注册中心 if (ephemeral) &#123; &#x2F;&#x2F;创建临时的节点 createEphemeral(path); &#125; else &#123; &#x2F;&#x2F;创建持久的节点，&#x2F;dubbo&#x2F;dubbo.common.hello.service.HelloService&#x2F;consumers&#x2F; &#x2F;&#x2F;consumer%3A%2F%2F192.168.110.197%2F &#x2F;&#x2F;dubbo.common.hello.service.HelloService%3Fapplication%3Ddubbo-consumer%26 &#x2F;&#x2F;category%3Dconsumers%26check%3Dfalse%26 &#x2F;&#x2F;dubbo%3D2.5.3%26interface%3D &#x2F;&#x2F;dubbo.common.hello.service.HelloService%26 &#x2F;&#x2F;methods%3DsayHello%26pid%3D6370%26side%3D &#x2F;&#x2F;consumer%26timeout%3D100000%26timestamp%3D1489367959659 createPersistent(path); &#125;&#125; 经过上面create之后，Zookeeper中就存在了消费者需要订阅的服务的节点： 12345678910111213&#x2F;dubbo &#x2F;dubbo.common.hello.service.HelloService &#x2F;consumers &#x2F;http:&#x2F;&#x2F;0.0.0.0:4550&#x2F;?path&#x3D;dubbo%2F dubbo.common.hello.service.HelloService%2F consumers%2Fconsumer%253A%252F%252F192.168.110.197%252F dubbo.common.hello.service.HelloService%253F application%253Ddubbo-consumer%2526category%253D consumers%2526check%253Dfalse%2526 dubbo%253D2.5.3%2526interface%253D dubbo.common.hello.service.HelloService%2526 methods%253DsayHello%2526pid%253D22392%2526side%253D consumer%2526timeout%253D100000%2526timestamp%253D1490063394184 订阅服务提供者消费者自己注册到注册中心之后，接着是订阅服务提供者，directory.subscribe()： 123456public void subscribe(URL url) &#123; &#x2F;&#x2F;设置消费者url setConsumerUrl(url); &#x2F;&#x2F;这里的registry是ZookeeperRegistry registry.subscribe(url, this);&#125; 看下registry.subscribe(url, this);，这里registry是ZookeeperRegistry，会先经过AbstractRegistry的处理，然后是FailbackRegistry的处理。 在AbstractRegistry中： 1234567891011121314&#x2F;&#x2F;此时url为consumer:&#x2F;&#x2F;192.168.1.100&#x2F;dubbo.common.hello.service.HelloService?application&#x3D;dubbo-consumer&amp;&#x2F;&#x2F;category&#x3D;providers,configurators,routers&amp;dubbo&#x3D;2.5.3&amp;interface&#x3D;dubbo.common.hello.service.HelloService&amp;methods&#x3D;&#x2F;&#x2F;sayHello&amp;pid&#x3D;28819&amp;side&#x3D;consumer&amp;timeout&#x3D;100000&amp;timestamp&#x3D;1489332839677public void subscribe(URL url, NotifyListener listener) &#123; &#x2F;&#x2F;先根据url获取已注册的监听器 Set&lt;NotifyListener&gt; listeners &#x3D; subscribed.get(url); &#x2F;&#x2F;没有监听器，就创建，并添加进去 if (listeners &#x3D;&#x3D; null) &#123; subscribed.putIfAbsent(url, new ConcurrentHashSet&lt;NotifyListener&gt;()); listeners &#x3D; subscribed.get(url); &#125; &#x2F;&#x2F;有监听器，直接把当前RegistryDirectory添加进去 listeners.add(listener);&#125; 然后是FailbackRegistry中： 12345678public void subscribe(URL url, NotifyListener listener) &#123; super.subscribe(url, listener); removeFailedSubscribed(url, listener); try &#123; &#x2F;&#x2F; 向服务器端发送订阅请求 doSubscribe(url, listener); &#125; catch (Exception e) &#123;...&#125;&#125; 继续看doSubscribe(url, listener);向服务端发送订阅请求，在ZookeeperRegistry中： 1234567891011121314151617181920212223242526272829303132333435363738protected void doSubscribe(final URL url, final NotifyListener listener) &#123; try &#123; if (Constants.ANY_VALUE.equals(url.getServiceInterface())) &#123;... &#125; else &#123; List&lt;URL&gt; urls &#x3D; new ArrayList&lt;URL&gt;(); for (String path : toCategoriesPath(url)) &#123; ConcurrentMap&lt;NotifyListener, ChildListener&gt; listeners &#x3D; zkListeners.get(url); if (listeners &#x3D;&#x3D; null) &#123; zkListeners.putIfAbsent(url, new ConcurrentHashMap&lt;NotifyListener, ChildListener&gt;()); listeners &#x3D; zkListeners.get(url); &#125; &#x2F;&#x2F;将zkClient的事件IZkChildListener转换到registry事件NotifyListener ChildListener zkListener &#x3D; listeners.get(listener); if (zkListener &#x3D;&#x3D; null) &#123; listeners.putIfAbsent(listener, new ChildListener() &#123; public void childChanged(String parentPath, List&lt;String&gt; currentChilds) &#123; ZookeeperRegistry.this.notify(url, listener, toUrlsWithEmpty(url, parentPath, currentChilds)); &#125; &#125;); zkListener &#x3D; listeners.get(listener); &#125; &#x2F;&#x2F;创建三个节点 &#x2F;&#x2F; &#x2F;dubbo&#x2F;dubbo.common.hello.service.HelloService&#x2F;providers&#x2F; &#x2F;&#x2F; &#x2F;dubbo&#x2F;dubbo.common.hello.service.HelloService&#x2F;configurators&#x2F; &#x2F;&#x2F; &#x2F;dubbo&#x2F;dubbo.common.hello.service.HelloService&#x2F;routers&#x2F; &#x2F;&#x2F;上面三个路径会被消费者端监听，当提供者，配置，路由发生变化之后， &#x2F;&#x2F;注册中心会通知消费者刷新本地缓存。 zkClient.create(path, false); List&lt;String&gt; children &#x3D; zkClient.addChildListener(path, zkListener); if (children !&#x3D; null) &#123; urls.addAll(toUrlsWithEmpty(url, path, children)); &#125; &#125; notify(url, listener, urls); &#125; &#125; catch (Throwable e) &#123; throw new RpcException(&quot;Failed to subscribe &quot; + url + &quot; to zookeeper &quot; + getUrl() + &quot;, cause: &quot; + e.getMessage(), e); &#125;&#125; 服务订阅完之后的通知服务订阅完成之后，接着就是notify(url, listener, urls);： 会先经过FailbackRegistry将失败的通知请求记录到失败列表，定时重试。 1234567891011121314protected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; try &#123; doNotify(url, listener, urls); &#125; catch (Exception t) &#123; &#x2F;&#x2F; 将失败的通知请求记录到失败列表，定时重试 Map&lt;NotifyListener, List&lt;URL&gt;&gt; listeners &#x3D; failedNotified.get(url); if (listeners &#x3D;&#x3D; null) &#123; failedNotified.putIfAbsent(url, new ConcurrentHashMap&lt;NotifyListener, List&lt;URL&gt;&gt;()); listeners &#x3D; failedNotified.get(url); &#125; listeners.put(listener, urls); logger.error(&quot;Failed to notify for subscribe &quot; + url + &quot;, waiting for retry, cause: &quot; + t.getMessage(), t); &#125;&#125; doNotify(url, listener, urls);： 1234protected void doNotify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; &#x2F;&#x2F;父类实现 super.notify(url, listener, urls);&#125; AbstractRegistry中的doNotify实现： 123456789101112131415161718192021222324252627282930313233protected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; Map&lt;String, List&lt;URL&gt;&gt; result &#x3D; new HashMap&lt;String, List&lt;URL&gt;&gt;(); for (URL u : urls) &#123; if (UrlUtils.isMatch(url, u)) &#123; &#x2F;&#x2F;不同类型的数据分开通知，providers，consumers，routers，overrides &#x2F;&#x2F;允许只通知其中一种类型，但该类型的数据必须是全量的，不是增量的。 String category &#x3D; u.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); List&lt;URL&gt; categoryList &#x3D; result.get(category); if (categoryList &#x3D;&#x3D; null) &#123; categoryList &#x3D; new ArrayList&lt;URL&gt;(); result.put(category, categoryList); &#125; categoryList.add(u); &#125; &#125; if (result.size() &#x3D;&#x3D; 0) &#123; return; &#125; Map&lt;String, List&lt;URL&gt;&gt; categoryNotified &#x3D; notified.get(url); if (categoryNotified &#x3D;&#x3D; null) &#123; notified.putIfAbsent(url, new ConcurrentHashMap&lt;String, List&lt;URL&gt;&gt;()); categoryNotified &#x3D; notified.get(url); &#125; &#x2F;&#x2F;对这里得到的providers，configurators，routers分别进行通知 for (Map.Entry&lt;String, List&lt;URL&gt;&gt; entry : result.entrySet()) &#123; String category &#x3D; entry.getKey(); List&lt;URL&gt; categoryList &#x3D; entry.getValue(); categoryNotified.put(category, categoryList); saveProperties(url); &#x2F;&#x2F;这里的listener是RegistryDirectory listener.notify(categoryList); &#125;&#125; 到RegistryDirectory中查看notify方法： 123456789101112131415161718192021222324252627282930313233343536373839404142public synchronized void notify(List&lt;URL&gt; urls) &#123; List&lt;URL&gt; invokerUrls &#x3D; new ArrayList&lt;URL&gt;(); List&lt;URL&gt; routerUrls &#x3D; new ArrayList&lt;URL&gt;(); List&lt;URL&gt; configuratorUrls &#x3D; new ArrayList&lt;URL&gt;(); for (URL url : urls) &#123; String protocol &#x3D; url.getProtocol(); String category &#x3D; url.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); if (Constants.ROUTERS_CATEGORY.equals(category) || Constants.ROUTE_PROTOCOL.equals(protocol)) &#123; routerUrls.add(url); &#125; else if (Constants.CONFIGURATORS_CATEGORY.equals(category) || Constants.OVERRIDE_PROTOCOL.equals(protocol)) &#123; configuratorUrls.add(url); &#125; else if (Constants.PROVIDERS_CATEGORY.equals(category)) &#123; invokerUrls.add(url); &#125; else &#123; logger.warn(&quot;Unsupported category &quot; + category + &quot; in notified url: &quot; + url + &quot; from registry &quot; + getUrl().getAddress() + &quot; to consumer &quot; + NetUtils.getLocalHost()); &#125; &#125; &#x2F;&#x2F; configurators 更新缓存的服务提供方配置 if (configuratorUrls !&#x3D; null &amp;&amp; configuratorUrls.size() &gt;0 )&#123; this.configurators &#x3D; toConfigurators(configuratorUrls); &#125; &#x2F;&#x2F; routers&#x2F;&#x2F;更新缓存的路由规则配置 if (routerUrls !&#x3D; null &amp;&amp; routerUrls.size() &gt;0 )&#123; List&lt;Router&gt; routers &#x3D; toRouters(routerUrls); if(routers !&#x3D; null)&#123; &#x2F;&#x2F; null - do nothing setRouters(routers); &#125; &#125; List&lt;Configurator&gt; localConfigurators &#x3D; this.configurators; &#x2F;&#x2F; local reference &#x2F;&#x2F; 合并override参数 this.overrideDirectoryUrl &#x3D; directoryUrl; if (localConfigurators !&#x3D; null &amp;&amp; localConfigurators.size() &gt; 0) &#123; for (Configurator configurator : localConfigurators) &#123; this.overrideDirectoryUrl &#x3D; configurator.configure(overrideDirectoryUrl); &#125; &#125; &#x2F;&#x2F; providers &#x2F;&#x2F;重建invoker实例 refreshInvoker(invokerUrls);&#125; 重建invoker实例refreshInvoker(invokerUrls);： 123456789101112131415161718192021222324252627282930313233343536373839404142434445&#x2F;** * 根据invokerURL列表转换为invoker列表。转换规则如下： * 1.如果url已经被转换为invoker，则不在重新引用，直接从缓存中获取，注意如果url中任何一个参数变更也会重新引用 * 2.如果传入的invoker列表不为空，则表示最新的invoker列表 * 3.如果传入的invokerUrl列表是空，则表示只是下发的override规则或route规则，需要重新交叉对比，决定是否需要重新引用。 * @param invokerUrls 传入的参数不能为null *&#x2F;private void refreshInvoker(List&lt;URL&gt; invokerUrls)&#123; if (invokerUrls !&#x3D; null &amp;&amp; invokerUrls.size() &#x3D;&#x3D; 1 &amp;&amp; invokerUrls.get(0) !&#x3D; null &amp;&amp; Constants.EMPTY_PROTOCOL.equals(invokerUrls.get(0).getProtocol())) &#123; this.forbidden &#x3D; true; &#x2F;&#x2F; 禁止访问 this.methodInvokerMap &#x3D; null; &#x2F;&#x2F; 置空列表 destroyAllInvokers(); &#x2F;&#x2F; 关闭所有Invoker &#125; else &#123; this.forbidden &#x3D; false; &#x2F;&#x2F; 允许访问 Map&lt;String, Invoker&lt;T&gt;&gt; oldUrlInvokerMap &#x3D; this.urlInvokerMap; &#x2F;&#x2F; local reference if (invokerUrls.size() &#x3D;&#x3D; 0 &amp;&amp; this.cachedInvokerUrls !&#x3D; null)&#123; invokerUrls.addAll(this.cachedInvokerUrls); &#125; else &#123; this.cachedInvokerUrls &#x3D; new HashSet&lt;URL&gt;(); this.cachedInvokerUrls.addAll(invokerUrls);&#x2F;&#x2F;缓存invokerUrls列表，便于交叉对比 &#125; if (invokerUrls.size() &#x3D;&#x3D;0 )&#123; return; &#125; &#x2F;&#x2F;会重新走一遍服务的引用过程 &#x2F;&#x2F;给每个提供者创建一个Invoker Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap &#x3D; toInvokers(invokerUrls) ;&#x2F;&#x2F; 将URL列表转成Invoker列表 Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; newMethodInvokerMap &#x3D; toMethodInvokers(newUrlInvokerMap); &#x2F;&#x2F; 换方法名映射Invoker列表 &#x2F;&#x2F; state change &#x2F;&#x2F;如果计算错误，则不进行处理. if (newUrlInvokerMap &#x3D;&#x3D; null || newUrlInvokerMap.size() &#x3D;&#x3D; 0 )&#123; logger.error(new IllegalStateException(&quot;urls to invokers error .invokerUrls.size :&quot;+invokerUrls.size() + &quot;, invoker.size :0. urls :&quot;+invokerUrls.toString())); return ; &#125; &#x2F;&#x2F;服务提供者Invoker保存在这个map中 this.methodInvokerMap &#x3D; multiGroup ? toMergeMethodInvokerMap(newMethodInvokerMap) : newMethodInvokerMap; this.urlInvokerMap &#x3D; newUrlInvokerMap; try&#123; destroyUnusedInvokers(oldUrlInvokerMap,newUrlInvokerMap); &#x2F;&#x2F; 关闭未使用的Invoker &#125;catch (Exception e) &#123; logger.warn(&quot;destroyUnusedInvokers error. &quot;, e); &#125; &#125;&#125; toInvokers(invokerUrls) 方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970private Map&lt;String, Invoker&lt;T&gt;&gt; toInvokers(List&lt;URL&gt; urls) &#123; Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap &#x3D; new HashMap&lt;String, Invoker&lt;T&gt;&gt;(); if(urls &#x3D;&#x3D; null || urls.size() &#x3D;&#x3D; 0)&#123; return newUrlInvokerMap; &#125; Set&lt;String&gt; keys &#x3D; new HashSet&lt;String&gt;(); String queryProtocols &#x3D; this.queryMap.get(Constants.PROTOCOL_KEY); for (URL providerUrl : urls) &#123; &#x2F;&#x2F;此时url是dubbo:&#x2F;&#x2F;192.168.110.197:20880&#x2F;dubbo.common.hello.service.HelloService?anyhost&#x3D;true&amp; &#x2F;&#x2F;application&#x3D;dubbo-provider&amp;application.version&#x3D;1.0&amp;dubbo&#x3D;2.5.3&amp;environment&#x3D;product&amp; &#x2F;&#x2F;interface&#x3D;dubbo.common.hello.service.HelloService&amp;methods&#x3D;sayHello&amp;organization&#x3D;china&amp; &#x2F;&#x2F;owner&#x3D;cheng.xi&amp;pid&#x3D;5631&amp;side&#x3D;provider&amp;timestamp&#x3D;1489367571986 &#x2F;&#x2F;从注册中心获取到的携带提供者信息的url &#x2F;&#x2F;如果reference端配置了protocol，则只选择匹配的protocol if (queryProtocols !&#x3D; null &amp;&amp; queryProtocols.length() &gt;0) &#123; boolean accept &#x3D; false; String[] acceptProtocols &#x3D; queryProtocols.split(&quot;,&quot;); for (String acceptProtocol : acceptProtocols) &#123; if (providerUrl.getProtocol().equals(acceptProtocol)) &#123; accept &#x3D; true; break; &#125; &#125; if (!accept) &#123; continue; &#125; &#125; if (Constants.EMPTY_PROTOCOL.equals(providerUrl.getProtocol())) &#123; continue; &#125; if (! ExtensionLoader.getExtensionLoader(Protocol.class).hasExtension(providerUrl.getProtocol())) &#123; logger.error(new IllegalStateException(&quot;Unsupported protocol &quot; + providerUrl.getProtocol() + &quot; in notified url: &quot; + providerUrl + &quot; from registry &quot; + getUrl().getAddress() + &quot; to consumer &quot; + NetUtils.getLocalHost() + &quot;, supported protocol: &quot;+ExtensionLoader.getExtensionLoader(Protocol.class).getSupportedExtensions())); continue; &#125; URL url &#x3D; mergeUrl(providerUrl); String key &#x3D; url.toFullString(); &#x2F;&#x2F; URL参数是排序的 if (keys.contains(key)) &#123; &#x2F;&#x2F; 重复URL continue; &#125; keys.add(key); &#x2F;&#x2F; 缓存key为没有合并消费端参数的URL，不管消费端如何合并参数，如果服务端URL发生变化，则重新refer Map&lt;String, Invoker&lt;T&gt;&gt; localUrlInvokerMap &#x3D; this.urlInvokerMap; &#x2F;&#x2F; local reference Invoker&lt;T&gt; invoker &#x3D; localUrlInvokerMap &#x3D;&#x3D; null ? null : localUrlInvokerMap.get(key); if (invoker &#x3D;&#x3D; null) &#123; &#x2F;&#x2F; 缓存中没有，重新refer try &#123; boolean enabled &#x3D; true; if (url.hasParameter(Constants.DISABLED_KEY)) &#123; enabled &#x3D; ! url.getParameter(Constants.DISABLED_KEY, false); &#125; else &#123; enabled &#x3D; url.getParameter(Constants.ENABLED_KEY, true); &#125; if (enabled) &#123; &#x2F;&#x2F;根据扩展点加载机制，这里使用的protocol是DubboProtocol invoker &#x3D; new InvokerDelegete&lt;T&gt;(protocol.refer(serviceType, url), url, providerUrl); &#125; &#125; catch (Throwable t) &#123; logger.error(&quot;Failed to refer invoker for interface:&quot;+serviceType+&quot;,url:(&quot;+url+&quot;)&quot; + t.getMessage(), t); &#125; if (invoker !&#x3D; null) &#123; &#x2F;&#x2F; 将新的引用放入缓存 newUrlInvokerMap.put(key, invoker); &#125; &#125;else &#123; newUrlInvokerMap.put(key, invoker); &#125; &#125; keys.clear(); return newUrlInvokerMap;&#125; 创建invoker invoker = new InvokerDelegete&lt;T&gt;(protocol.refer(serviceType, url), url, providerUrl);： 先使用DubboProtocol的refer方法，这一步会依次调用ProtocolFIlterListenerWrapper，ProtocolFilterWrapper，DubboProtocol中的refer方法。经过两个Wrapper中，会添加对应的InvokerListener并构建Invoker Filter链，在DubboProtocol中会创建一个DubboInvoker对象，该Invoker对象持有服务Class，providerUrl，负责和服务提供端通信的ExchangeClient。 接着使用得到的Invoker创建一个InvokerDelegete 创建invoker在DubboProtocol中创建DubboInvoker的时候代码如下： 1234567public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; serviceType, URL url) throws RpcException &#123; &#x2F;&#x2F; create rpc invoker. &#x2F;&#x2F;这里有一个getClients方法 DubboInvoker&lt;T&gt; invoker &#x3D; new DubboInvoker&lt;T&gt;(serviceType, url, getClients(url), invokers); invokers.add(invoker); return invoker;&#125; 查看getClients方法： 12345678910111213141516171819202122private ExchangeClient[] getClients(URL url)&#123; &#x2F;&#x2F;是否共享连接 boolean service_share_connect &#x3D; false; int connections &#x3D; url.getParameter(Constants.CONNECTIONS_KEY, 0); &#x2F;&#x2F;如果connections不配置，则共享连接，否则每服务每连接 if (connections &#x3D;&#x3D; 0)&#123; service_share_connect &#x3D; true; connections &#x3D; 1; &#125; ExchangeClient[] clients &#x3D; new ExchangeClient[connections]; for (int i &#x3D; 0; i &lt; clients.length; i++) &#123; if (service_share_connect)&#123; &#x2F;&#x2F;这里没有配置connections，就使用getSharedClient &#x2F;&#x2F;getSharedClient中先去缓存中查找，没有的话就会新建，也是调用initClient方法 clients[i] &#x3D; getSharedClient(url); &#125; else &#123; clients[i] &#x3D; initClient(url); &#125; &#125; return clients;&#125; 直接看initClient方法： 12345678910111213141516171819202122232425262728293031323334&#x2F;&#x2F;创建新连接private ExchangeClient initClient(URL url) &#123; &#x2F;&#x2F; client type setting. String str &#x3D; url.getParameter(Constants.CLIENT_KEY, url.getParameter(Constants.SERVER_KEY, Constants.DEFAULT_REMOTING_CLIENT)); String version &#x3D; url.getParameter(Constants.DUBBO_VERSION_KEY); boolean compatible &#x3D; (version !&#x3D; null &amp;&amp; version.startsWith(&quot;1.0.&quot;)); url &#x3D; url.addParameter(Constants.CODEC_KEY, Version.isCompatibleVersion() &amp;&amp; compatible ? COMPATIBLE_CODEC_NAME : DubboCodec.NAME); &#x2F;&#x2F;默认开启heartbeat url &#x3D; url.addParameterIfAbsent(Constants.HEARTBEAT_KEY, String.valueOf(Constants.DEFAULT_HEARTBEAT)); &#x2F;&#x2F; BIO存在严重性能问题，暂时不允许使用 if (str !&#x3D; null &amp;&amp; str.length() &gt; 0 &amp;&amp; ! ExtensionLoader.getExtensionLoader(Transporter.class).hasExtension(str)) &#123; throw new RpcException(&quot;Unsupported client type: &quot; + str + &quot;,&quot; + &quot; supported client type is &quot; + StringUtils.join(ExtensionLoader.getExtensionLoader(Transporter.class).getSupportedExtensions(), &quot; &quot;)); &#125; ExchangeClient client ; try &#123; &#x2F;&#x2F;如果lazy属性没有配置为true（我们没有配置，默认为false）ExchangeClient会马上和服务端建立连接 &#x2F;&#x2F;设置连接应该是lazy的 if (url.getParameter(Constants.LAZY_CONNECT_KEY, false))&#123; client &#x3D; new LazyConnectExchangeClient(url ,requestHandler); &#125; else &#123; &#x2F;&#x2F;立即和服务端建立连接 client &#x3D; Exchangers.connect(url ,requestHandler); &#125; &#125; catch (RemotingException e) &#123; throw new RpcException(&quot;Fail to create remoting client for service(&quot; + url + &quot;): &quot; + e.getMessage(), e); &#125; return client;&#125; 和服务端建立连接，Exchangers.connect(url ,requestHandler);，其实最后使用的是HeaderExchanger，Exchanger目前只有这一个实现： 1234567public ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException &#123; &#x2F;&#x2F;先经过HeaderExchangeHandler包装 &#x2F;&#x2F;然后是DecodeHandler &#x2F;&#x2F;然后是Transporters.connect &#x2F;&#x2F;返回一个HeaderExchangerClient，这里封装了client，channel，启动心跳的定时器等 return new HeaderExchangeClient(Transporters.connect(url, new DecodeHandler(new HeaderExchangeHandler(handler))));&#125; Transporters.connect中也是根据SPI扩展获取Transport的具体实现，这里默认使用NettyTransporter.connect()，在NettyTransporter的connect方法中直接返回一个NettyClient(url, listener);，下面看下具体的NettyClient初始化细节，会先初始化AbstractPeer这里只是吧url和handler赋值；然后是AbstractEndpoint初始化： 1234567public AbstractEndpoint(URL url, ChannelHandler handler) &#123; super(url, handler); &#x2F;&#x2F;获取编解码器，这里是DubboCountCodec this.codec &#x3D; getChannelCodec(url); this.timeout &#x3D; url.getPositiveParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); this.connectTimeout &#x3D; url.getPositiveParameter(Constants.CONNECT_TIMEOUT_KEY, Constants.DEFAULT_CONNECT_TIMEOUT);&#125; 接着是AbstractClient的初始化： 123456789101112131415161718192021public AbstractClient(URL url, ChannelHandler handler) throws RemotingException &#123; super(url, handler); send_reconnect &#x3D; url.getParameter(Constants.SEND_RECONNECT_KEY, false); shutdown_timeout &#x3D; url.getParameter(Constants.SHUTDOWN_TIMEOUT_KEY, Constants.DEFAULT_SHUTDOWN_TIMEOUT); &#x2F;&#x2F;默认重连间隔2s，1800表示1小时warning一次. reconnect_warning_period &#x3D; url.getParameter(&quot;reconnect.waring.period&quot;, 1800); try &#123; &#x2F;&#x2F;具体实现在子类中 doOpen(); &#125; catch (Throwable t) &#123;。。。 &#125; try &#123; &#x2F;&#x2F; 连接 connect(); &#125; catch (RemotingException t) &#123;。。。&#125; &#x2F;&#x2F; TODO暂没理解 executor &#x3D; (ExecutorService) ExtensionLoader.getExtensionLoader(DataStore.class) .getDefaultExtension().get(Constants.CONSUMER_SIDE, Integer.toString(url.getPort())); ExtensionLoader.getExtensionLoader(DataStore.class) .getDefaultExtension().remove(Constants.CONSUMER_SIDE, Integer.toString(url.getPort()));&#125; 看下在NettyClient中doOpen()的实现： 1234567891011121314151617181920protected void doOpen() throws Throwable &#123; NettyHelper.setNettyLoggerFactory(); bootstrap &#x3D; new ClientBootstrap(channelFactory); &#x2F;&#x2F; config &#x2F;&#x2F; @see org.jboss.netty.channel.socket.SocketChannelConfig bootstrap.setOption(&quot;keepAlive&quot;, true); bootstrap.setOption(&quot;tcpNoDelay&quot;, true); bootstrap.setOption(&quot;connectTimeoutMillis&quot;, getTimeout()); final NettyHandler nettyHandler &#x3D; new NettyHandler(getUrl(), this); bootstrap.setPipelineFactory(new ChannelPipelineFactory() &#123; public ChannelPipeline getPipeline() &#123; NettyCodecAdapter adapter &#x3D; new NettyCodecAdapter(getCodec(), getUrl(), NettyClient.this); ChannelPipeline pipeline &#x3D; Channels.pipeline(); pipeline.addLast(&quot;decoder&quot;, adapter.getDecoder()); pipeline.addLast(&quot;encoder&quot;, adapter.getEncoder()); pipeline.addLast(&quot;handler&quot;, nettyHandler); return pipeline; &#125; &#125;);&#125; 这里是Netty3中的客户端连接的一些常规步骤，暂不做具体解析。open之后，就是真正连接服务端的操作了，connect()： 12345678910111213141516protected void connect() throws RemotingException &#123; connectLock.lock(); try &#123; if (isConnected()) &#123; return; &#125; &#x2F;&#x2F;初始化重连的线程 initConnectStatusCheckCommand(); &#x2F;&#x2F;连接，在子类中实现 doConnect(); reconnect_count.set(0); reconnect_error_log_flag.set(false); &#125; catch (RemotingException e) &#123;。。。&#125; finally &#123; connectLock.unlock(); &#125;&#125; NettyClient中的doConnect方法： 1234567891011121314151617181920212223242526272829303132333435363738protected void doConnect() throws Throwable &#123; long start &#x3D; System.currentTimeMillis(); &#x2F;&#x2F;消费者端开始连接，这一步的时候，服务提供者端就接到了连接请求，开始处理了 ChannelFuture future &#x3D; bootstrap.connect(getConnectAddress()); try&#123; boolean ret &#x3D; future.awaitUninterruptibly(getConnectTimeout(), TimeUnit.MILLISECONDS); if (ret &amp;&amp; future.isSuccess()) &#123; Channel newChannel &#x3D; future.getChannel(); newChannel.setInterestOps(Channel.OP_READ_WRITE); try &#123; &#x2F;&#x2F; 关闭旧的连接 Channel oldChannel &#x3D; NettyClient.this.channel; &#x2F;&#x2F; copy reference if (oldChannel !&#x3D; null) &#123; try &#123; oldChannel.close(); &#125; finally &#123; NettyChannel.removeChannelIfDisconnected(oldChannel); &#125; &#125; &#125; finally &#123; if (NettyClient.this.isClosed()) &#123; try &#123; newChannel.close(); &#125; finally &#123; NettyClient.this.channel &#x3D; null; NettyChannel.removeChannelIfDisconnected(newChannel); &#125; &#125; else &#123; NettyClient.this.channel &#x3D; newChannel; &#125; &#125; &#125; else if (future.getCause() !&#x3D; null) &#123; throw。。。 &#125; else &#123;throw 。。。 &#125; &#125;finally&#123; if (! isConnected()) &#123; future.cancel(); &#125; &#125;&#125; 这里连接的细节都交给了netty。 NettyClient初始化完成之后，返回给Transporters，再返回给HeaderExchanger，HeaderExchanger中将NettyClient包装成HeaderExchangeClient返回给DubboProtocol的initClient方法中，到此在getSharedClient中就获取到了一个ExchangeClient，然后包装一下返回client = new ReferenceCountExchangeClient(exchagneclient, ghostClientMap);。 到这里在DubboProtocol的refer方法中这句DubboInvoker&lt;T&gt; invoker = new DubboInvoker&lt;T&gt;(serviceType, url, getClients(url), invokers);创建DubboInvoker就已经解析完成，创建过程中连接了服务端，包含一个ExchangeClient等： 12345678public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; serviceType, URL url) throws RpcException &#123; &#x2F;&#x2F; create rpc invoker. DubboInvoker&lt;T&gt; invoker &#x3D; new DubboInvoker&lt;T&gt;(serviceType, url, getClients(url), invokers); &#x2F;&#x2F;将invoker缓存 invokers.add(invoker); &#x2F;&#x2F;返回invoker return invoker;&#125; 接着返回ProtocolFilterWrapper的refer方法，在这里会构建invoker链： 123456public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; return protocol.refer(type, url); &#125; return buildInvokerChain(protocol.refer(type, url), Constants.REFERENCE_FILTER_KEY, Constants.CONSUMER);&#125; 接着再返回到ProtocolListenerWrapper的refer方法，这里会初始化监听器，包装： 123456789public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException &#123; if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) &#123; return protocol.refer(type, url); &#125; return new ListenerInvokerWrapper&lt;T&gt;(protocol.refer(type, url), Collections.unmodifiableList( ExtensionLoader.getExtensionLoader(InvokerListener.class) .getActivateExtension(url, Constants.INVOKER_LISTENER_KEY)));&#125; 接着在返回到toInvokers方法，然后返回refreshInvoker方法的Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap = toInvokers(invokerUrls) ;这就获得了Invoker，接着就是方法名映射Invoker列表：Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; newMethodInvokerMap = toMethodInvokers(newUrlInvokerMap);这里将invokers列表转成与方法的映射关系。到这里refreshInvoker方法就完成了，在往上就返回到AbstractRegistry的notify方法，到这里也完成了。 创建服务代理到这里有关消费者端注册到注册中心和订阅注册中心就完事儿了，这部分是在RegistryProtocol.doRefer方法中，这个方法最后一句是return cluster.join(directory);，这里由Cluster组件创建一个Invoker并返回，这里的cluster默认是用FailoverCluster，最后返回的是经过MockClusterInvoker包装过的FailoverCluster。继续返回到ReferenceConfig中createProxy方法，这时候我们已经完成了消费者端引用服务的Invoker。然后最后返回的是根据我们得到的invoker创建的服务代理return (T) proxyFactory.getProxy(invoker);。这里proxyFactory是我们在最上面列出的动态生成的代码。 首先经过AbstractProxyFactory的处理： 1234567891011121314151617181920public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker) throws RpcException &#123; Class&lt;?&gt;[] interfaces &#x3D; null; String config &#x3D; invoker.getUrl().getParameter(&quot;interfaces&quot;); if (config !&#x3D; null &amp;&amp; config.length() &gt; 0) &#123; String[] types &#x3D; Constants.COMMA_SPLIT_PATTERN.split(config); if (types !&#x3D; null &amp;&amp; types.length &gt; 0) &#123; interfaces &#x3D; new Class&lt;?&gt;[types.length + 2]; interfaces[0] &#x3D; invoker.getInterface(); interfaces[1] &#x3D; EchoService.class; for (int i &#x3D; 0; i &lt; types.length; i ++) &#123; interfaces[i + 1] &#x3D; ReflectUtils.forName(types[i]); &#125; &#125; &#125; if (interfaces &#x3D;&#x3D; null) &#123; interfaces &#x3D; new Class&lt;?&gt;[] &#123;invoker.getInterface(), EchoService.class&#125;; &#125; &#x2F;&#x2F;这里默认使用的是JavassistProxyFactory的实现 return getProxy(invoker, interfaces);&#125; 然后经过StubProxyFactoryWrapper的处理： 12345678910111213141516171819202122232425262728293031323334353637383940414243public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker) throws RpcException &#123; T proxy &#x3D; proxyFactory.getProxy(invoker); if (GenericService.class !&#x3D; invoker.getInterface()) &#123; String stub &#x3D; invoker.getUrl().getParameter(Constants.STUB_KEY, invoker.getUrl().getParameter(Constants.LOCAL_KEY)); if (ConfigUtils.isNotEmpty(stub)) &#123; Class&lt;?&gt; serviceType &#x3D; invoker.getInterface(); if (ConfigUtils.isDefault(stub)) &#123; if (invoker.getUrl().hasParameter(Constants.STUB_KEY)) &#123; stub &#x3D; serviceType.getName() + &quot;Stub&quot;; &#125; else &#123; stub &#x3D; serviceType.getName() + &quot;Local&quot;; &#125; &#125; try &#123; Class&lt;?&gt; stubClass &#x3D; ReflectUtils.forName(stub); if (! serviceType.isAssignableFrom(stubClass)) &#123; throw new IllegalStateException(&quot;The stub implemention class &quot; + stubClass.getName() + &quot; not implement interface &quot; + serviceType.getName()); &#125; try &#123; Constructor&lt;?&gt; constructor &#x3D; ReflectUtils.findConstructor(stubClass, serviceType); proxy &#x3D; (T) constructor.newInstance(new Object[] &#123;proxy&#125;); &#x2F;&#x2F;export stub service URL url &#x3D; invoker.getUrl(); if (url.getParameter(Constants.STUB_EVENT_KEY, Constants.DEFAULT_STUB_EVENT))&#123; url &#x3D; url.addParameter(Constants.STUB_EVENT_METHODS_KEY, StringUtils.join(Wrapper.getWrapper(proxy.getClass()).getDeclaredMethodNames(), &quot;,&quot;)); url &#x3D; url.addParameter(Constants.IS_SERVER_KEY, Boolean.FALSE.toString()); try&#123; export(proxy, (Class)invoker.getInterface(), url); &#125;catch (Exception e) &#123; LOGGER.error(&quot;export a stub service error.&quot;, e); &#125; &#125; &#125; catch (NoSuchMethodException e) &#123; throw new IllegalStateException(&quot;No such constructor \&quot;public &quot; + stubClass.getSimpleName() + &quot;(&quot; + serviceType.getName() + &quot;)\&quot; in stub implemention class &quot; + stubClass.getName(), e); &#125; &#125; catch (Throwable t) &#123; LOGGER.error(&quot;Failed to create stub implemention class &quot; + stub + &quot; in consumer &quot; + NetUtils.getLocalHost() + &quot; use dubbo version &quot; + Version.getVersion() + &quot;, cause: &quot; + t.getMessage(), t); &#x2F;&#x2F; ignore &#125; &#125; &#125; return proxy;&#125; 返回代理。到此HelloService helloService = (HelloService) applicationContext.getBean(&quot;helloService&quot;);就解析完成了，得到了服务的代理，代理会被注册到Spring容器中，可以调用服务方法了。接下来的方法调用过程，是消费者发送请求，提供者处理，然后消费者接受处理结果的请求。 初始化的过程：主要做了注册到注册中心，监听注册中心，连接到服务提供者端，创建代理。这些都是为了下面消费者和提供者之间的通信做准备。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo中编码和解码的解析]]></title>
      <url>%2F2017%2F03%2F19%2FDubbo%E4%B8%AD%E7%BC%96%E7%A0%81%E5%92%8C%E8%A7%A3%E7%A0%81%E7%9A%84%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[（这里做的解析不是很详细，等到走完整个流程再来解析）Dubbo中编解码的工作由Codec2接口的实现来处理，回想一下第一次接触到Codec2相关的内容是在服务端暴露服务的时候，根据具体的协议去暴露服务的步骤中，在DubboProtocol的createServer方法中： 1234567891011private ExchangeServer createServer(URL url) &#123; 。。。 &#x2F;&#x2F;这里url会添加codec&#x3D;dubbo url &#x3D; url.addParameter(Constants.CODEC_KEY, Version.isCompatibleVersion() ? COMPATIBLE_CODEC_NAME : DubboCodec.NAME); ExchangeServer server; try &#123; server &#x3D; Exchangers.bind(url, requestHandler); &#125; 。。。 return server;&#125; 紧接着进入Exchangers.bind(url, requestHandler);： 12345public static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; &#x2F;&#x2F;如果url中没有codec属性，就会添加codec&#x3D;exchange url &#x3D; url.addParameterIfAbsent(Constants.CODEC_KEY, &quot;exchange&quot;); return getExchanger(url).bind(url, handler);&#125; 然后会继续进入HeaderExchanger的bind方法： 123public ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))));&#125; 在这里会创建一个DecodeHandler实例。继续跟踪Transporters的bind方法，会发现直接返回一个NettyServer实例，在NettyServer的父类AbstractEndpoint构造方法初始的时候，会根据url获取一个ChannelCodec，并将其赋值给codec存放到NettyServer的实例中。 我们先看下getChannelCodec(url);方法： 1234567891011121314protected static Codec2 getChannelCodec(URL url) &#123; &#x2F;&#x2F;获取codecName，不存在的话，默认为telnet String codecName &#x3D; url.getParameter(Constants.CODEC_KEY, &quot;telnet&quot;); &#x2F;&#x2F;先看下是不是Codec2的实现，是的话就根据SPI扩展机制获得Codec2扩展的实现 &#x2F;&#x2F;我们这里默认使用的是DubboCountCodec if (ExtensionLoader.getExtensionLoader(Codec2.class).hasExtension(codecName)) &#123; return ExtensionLoader.getExtensionLoader(Codec2.class).getExtension(codecName); &#125; else &#123; &#x2F;&#x2F;如果不是Codec2的实现，就去查找Codec的实现 &#x2F;&#x2F;然后使用CodecAdapter适配器类来转换成Codec2 return new CodecAdapter(ExtensionLoader.getExtensionLoader(Codec.class) .getExtension(codecName)); &#125;&#125; 这里返回的是Codec2，而Codec这个接口已经被标记为过时。到这里的话，在NettyServer中就会存在一个Codec2的实例了。 在继续往下看到NettyServer中的doOpen()方法，这里是使用Netty的逻辑打开服务并绑定监听服务的地方： 123456789101112131415161718192021222324protected void doOpen() throws Throwable &#123; NettyHelper.setNettyLoggerFactory(); ExecutorService boss &#x3D; Executors.newCachedThreadPool(new NamedThreadFactory(&quot;NettyServerBoss&quot;, true)); ExecutorService worker &#x3D; Executors.newCachedThreadPool(new NamedThreadFactory(&quot;NettyServerWorker&quot;, true)); ChannelFactory channelFactory &#x3D; new NioServerSocketChannelFactory(boss, worker, getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS)); bootstrap &#x3D; new ServerBootstrap(channelFactory); final NettyHandler nettyHandler &#x3D; new NettyHandler(getUrl(), this); channels &#x3D; nettyHandler.getChannels(); bootstrap.setPipelineFactory(new ChannelPipelineFactory() &#123; public ChannelPipeline getPipeline() &#123; &#x2F;&#x2F;这里的getCodec方法获取到的codec就是在AbstractEndpoint中我们获取到的codec &#x2F;&#x2F;NettyCodecAdapter，适配器类 NettyCodecAdapter adapter &#x3D; new NettyCodecAdapter(getCodec() ,getUrl(), NettyServer.this); ChannelPipeline pipeline &#x3D; Channels.pipeline(); pipeline.addLast(&quot;decoder&quot;, adapter.getDecoder());&#x2F;&#x2F;SimpleChannelUpstreamHandler pipeline.addLast(&quot;encoder&quot;, adapter.getEncoder());&#x2F;&#x2F;OneToOneEncoder pipeline.addLast(&quot;handler&quot;, nettyHandler); return pipeline; &#125; &#125;); &#x2F;&#x2F; bind channel &#x3D; bootstrap.bind(getBindAddress());&#125; 这里就在Netty的pipeline中添加了编解码器。这里涉及到Netty的相关流程，可以先了解下Netty3服务端流程简介。 decoder为解码器，是一个SimpleChannelUpstreamHandler，从Socket到Netty中的时候，需要解码，也就是服务提供端接收到消费者的请求的时候，需要解码。 encoder是编码器，是OneToOneEncoder，这个类实现了ChannelDownstreamHandler，从服务提供端发送给服务消费者的时候，需要编码。 nettyHandler实现了ChannelUpstreamHandler, ChannelDownstreamHandler两个，上下的时候都需要处理。 接收到服务消费者的请求的时候，会先执行decoder，然后执行nettyHandler。 发送给消费者的时候，会先执行nettyHandler，然后执行encoder。 dubbo协议头（这里做的解析不是很详细，等到走完整个流程再来解析）Dubbo中编解码的工作由Codec2接口的实现来处理，回想一下第一次接触到Codec2相关的内容是在服务端暴露服务的时候，根据具体的协议去暴露服务的步骤中，在DubboProtocol的createServer方法中： 1234567891011private ExchangeServer createServer(URL url) &#123; 。。。 &#x2F;&#x2F;这里url会添加codec&#x3D;dubbo url &#x3D; url.addParameter(Constants.CODEC_KEY, Version.isCompatibleVersion() ? COMPATIBLE_CODEC_NAME : DubboCodec.NAME); ExchangeServer server; try &#123; server &#x3D; Exchangers.bind(url, requestHandler); &#125; 。。。 return server;&#125; 紧接着进入Exchangers.bind(url, requestHandler);： 12345public static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; &#x2F;&#x2F;如果url中没有codec属性，就会添加codec&#x3D;exchange url &#x3D; url.addParameterIfAbsent(Constants.CODEC_KEY, &quot;exchange&quot;); return getExchanger(url).bind(url, handler);&#125; 然后会继续进入HeaderExchanger的bind方法： 123public ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))));&#125; 在这里会创建一个DecodeHandler实例。继续跟踪Transporters的bind方法，会发现直接返回一个NettyServer实例，在NettyServer的父类AbstractEndpoint构造方法初始的时候，会根据url获取一个ChannelCodec，并将其赋值给codec存放到NettyServer的实例中。 我们先看下getChannelCodec(url);方法： 1234567891011121314protected static Codec2 getChannelCodec(URL url) &#123; &#x2F;&#x2F;获取codecName，不存在的话，默认为telnet String codecName &#x3D; url.getParameter(Constants.CODEC_KEY, &quot;telnet&quot;); &#x2F;&#x2F;先看下是不是Codec2的实现，是的话就根据SPI扩展机制获得Codec2扩展的实现 &#x2F;&#x2F;我们这里默认使用的是DubboCountCodec if (ExtensionLoader.getExtensionLoader(Codec2.class).hasExtension(codecName)) &#123; return ExtensionLoader.getExtensionLoader(Codec2.class).getExtension(codecName); &#125; else &#123; &#x2F;&#x2F;如果不是Codec2的实现，就去查找Codec的实现 &#x2F;&#x2F;然后使用CodecAdapter适配器类来转换成Codec2 return new CodecAdapter(ExtensionLoader.getExtensionLoader(Codec.class) .getExtension(codecName)); &#125;&#125; 这里返回的是Codec2，而Codec这个接口已经被标记为过时。到这里的话，在NettyServer中就会存在一个Codec2的实例了。 在继续往下看到NettyServer中的doOpen()方法，这里是使用Netty的逻辑打开服务并绑定监听服务的地方： 123456789101112131415161718192021222324protected void doOpen() throws Throwable &#123; NettyHelper.setNettyLoggerFactory(); ExecutorService boss &#x3D; Executors.newCachedThreadPool(new NamedThreadFactory(&quot;NettyServerBoss&quot;, true)); ExecutorService worker &#x3D; Executors.newCachedThreadPool(new NamedThreadFactory(&quot;NettyServerWorker&quot;, true)); ChannelFactory channelFactory &#x3D; new NioServerSocketChannelFactory(boss, worker, getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS)); bootstrap &#x3D; new ServerBootstrap(channelFactory); final NettyHandler nettyHandler &#x3D; new NettyHandler(getUrl(), this); channels &#x3D; nettyHandler.getChannels(); bootstrap.setPipelineFactory(new ChannelPipelineFactory() &#123; public ChannelPipeline getPipeline() &#123; &#x2F;&#x2F;这里的getCodec方法获取到的codec就是在AbstractEndpoint中我们获取到的codec &#x2F;&#x2F;NettyCodecAdapter，适配器类 NettyCodecAdapter adapter &#x3D; new NettyCodecAdapter(getCodec() ,getUrl(), NettyServer.this); ChannelPipeline pipeline &#x3D; Channels.pipeline(); pipeline.addLast(&quot;decoder&quot;, adapter.getDecoder());&#x2F;&#x2F;SimpleChannelUpstreamHandler pipeline.addLast(&quot;encoder&quot;, adapter.getEncoder());&#x2F;&#x2F;OneToOneEncoder pipeline.addLast(&quot;handler&quot;, nettyHandler); return pipeline; &#125; &#125;); &#x2F;&#x2F; bind channel &#x3D; bootstrap.bind(getBindAddress());&#125; 这里就在Netty的pipeline中添加了编解码器。这里涉及到Netty的相关流程，可以先了解下Netty3服务端流程简介。 decoder为解码器，是一个SimpleChannelUpstreamHandler，从Socket到Netty中的时候，需要解码，也就是服务提供端接收到消费者的请求的时候，需要解码。 encoder是编码器，是OneToOneEncoder，这个类实现了ChannelDownstreamHandler，从服务提供端发送给服务消费者的时候，需要编码。 nettyHandler实现了ChannelUpstreamHandler, ChannelDownstreamHandler两个，上下的时候都需要处理。 接收到服务消费者的请求的时候，会先执行decoder，然后执行nettyHandler。 发送给消费者的时候，会先执行nettyHandler，然后执行encoder。 dubbo协议头 协议头是16字节的定长数据： 2字节short类型的Magic 1字节的消息标志位 5位序列化id 1位心跳还是正常请求 1位双向还是单向 1位请求还是响应 1字节的状态位 8字节的消息id 4字节数据长度 编码的过程首先会判断是请求还是响应，代码在ExchangeCodec的encode方法： 123456789public void encode(Channel channel, ChannelBuffer buffer, Object msg) throws IOException &#123; if (msg instanceof Request) &#123;&#x2F;&#x2F;Request类型 encodeRequest(channel, buffer, (Request) msg); &#125; else if (msg instanceof Response) &#123;&#x2F;&#x2F;Response类型 encodeResponse(channel, buffer, (Response) msg); &#125; else &#123;&#x2F;&#x2F;telenet类型的 super.encode(channel, buffer, msg); &#125;&#125; 服务提供者对响应信息编码在服务提供者端一般是对响应来做编码，所以这里重点看下encodeResponse。 encodeResponse： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081protected void encodeResponse(Channel channel, ChannelBuffer buffer, Response res) throws IOException &#123; try &#123; &#x2F;&#x2F;序列化方式 &#x2F;&#x2F;也是根据SPI扩展来获取，url中没指定的话默认使用hessian2 Serialization serialization &#x3D; getSerialization(channel); &#x2F;&#x2F;长度为16字节的数组，协议头 byte[] header &#x3D; new byte[HEADER_LENGTH]; &#x2F;&#x2F;魔数0xdabb Bytes.short2bytes(MAGIC, header); &#x2F;&#x2F;序列化方式 header[2] &#x3D; serialization.getContentTypeId(); &#x2F;&#x2F;心跳消息还是正常消息 if (res.isHeartbeat()) header[2] |&#x3D; FLAG_EVENT; &#x2F;&#x2F;响应状态 byte status &#x3D; res.getStatus(); header[3] &#x3D; status; &#x2F;&#x2F;设置请求id Bytes.long2bytes(res.getId(), header, 4); &#x2F;&#x2F;buffer为1024字节的ChannelBuffer &#x2F;&#x2F;获取buffer的写入位置 int savedWriteIndex &#x3D; buffer.writerIndex(); &#x2F;&#x2F;需要再加上协议头的长度之后，才是正确的写入位置 buffer.writerIndex(savedWriteIndex + HEADER_LENGTH); ChannelBufferOutputStream bos &#x3D; new ChannelBufferOutputStream(buffer); ObjectOutput out &#x3D; serialization.serialize(channel.getUrl(), bos); &#x2F;&#x2F; 对响应信息或者错误消息进行编码 if (status &#x3D;&#x3D; Response.OK) &#123; if (res.isHeartbeat()) &#123; &#x2F;&#x2F;心跳 encodeHeartbeatData(channel, out, res.getResult()); &#125; else &#123; &#x2F;&#x2F;正常响应 encodeResponseData(channel, out, res.getResult()); &#125; &#125; &#x2F;&#x2F;错误消息 else out.writeUTF(res.getErrorMessage()); out.flushBuffer(); bos.flush(); bos.close(); &#x2F;&#x2F;写出去的消息的长度 int len &#x3D; bos.writtenBytes(); &#x2F;&#x2F;查看消息长度是否过长 checkPayload(channel, len); Bytes.int2bytes(len, header, 12); &#x2F;&#x2F;重置写入的位置 buffer.writerIndex(savedWriteIndex); &#x2F;&#x2F;向buffer中写入消息头 buffer.writeBytes(header); &#x2F;&#x2F; write header. &#x2F;&#x2F;buffer写出去的位置从writerIndex开始，加上header长度，加上数据长度 buffer.writerIndex(savedWriteIndex + HEADER_LENGTH + len); &#125; catch (Throwable t) &#123; &#x2F;&#x2F; 发送失败信息给Consumer，否则Consumer只能等超时了 if (! res.isEvent() &amp;&amp; res.getStatus() !&#x3D; Response.BAD_RESPONSE) &#123; try &#123; &#x2F;&#x2F; FIXME 在Codec中打印出错日志？在IoHanndler的caught中统一处理？ logger.warn(&quot;Fail to encode response: &quot; + res + &quot;, send bad_response info instead, cause: &quot; + t.getMessage(), t); Response r &#x3D; new Response(res.getId(), res.getVersion()); r.setStatus(Response.BAD_RESPONSE); r.setErrorMessage(&quot;Failed to send response: &quot; + res + &quot;, cause: &quot; + StringUtils.toString(t)); channel.send(r); return; &#125; catch (RemotingException e) &#123; logger.warn(&quot;Failed to send bad_response info back: &quot; + res + &quot;, cause: &quot; + e.getMessage(), e); &#125; &#125; &#x2F;&#x2F; 重新抛出收到的异常 if (t instanceof IOException) &#123; throw (IOException) t; &#125; else if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else if (t instanceof Error) &#123; throw (Error) t; &#125; else &#123; throw new RuntimeException(t.getMessage(), t); &#125; &#125;&#125; 服务消费者对请求信息编码消费者端暂先不做解析 解码的过程服务提供者对请求消息的解码decode方法一次只会解析一个完整的dubbo协议包，但是每次收到的协议包不一定是完整的，或者有可能是多个协议包。看下代码解析，首先看NettyCodecAdapter的内部类InternalDecoder的messageReceived方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public void messageReceived(ChannelHandlerContext ctx, MessageEvent event) throws Exception &#123; Object o &#x3D; event.getMessage(); if (! (o instanceof ChannelBuffer)) &#123; ctx.sendUpstream(event); return; &#125; ChannelBuffer input &#x3D; (ChannelBuffer) o; int readable &#x3D; input.readableBytes(); if (readable &lt;&#x3D; 0) &#123; return; &#125; com.alibaba.dubbo.remoting.buffer.ChannelBuffer message; if (buffer.readable()) &#123; if (buffer instanceof DynamicChannelBuffer) &#123; buffer.writeBytes(input.toByteBuffer()); message &#x3D; buffer; &#125; else &#123; int size &#x3D; buffer.readableBytes() + input.readableBytes(); message &#x3D; com.alibaba.dubbo.remoting.buffer.ChannelBuffers.dynamicBuffer( size &gt; bufferSize ? size : bufferSize); message.writeBytes(buffer, buffer.readableBytes()); message.writeBytes(input.toByteBuffer()); &#125; &#125; else &#123; message &#x3D; com.alibaba.dubbo.remoting.buffer.ChannelBuffers.wrappedBuffer( input.toByteBuffer()); &#125; NettyChannel channel &#x3D; NettyChannel.getOrAddChannel(ctx.getChannel(), url, handler); Object msg; &#x2F;&#x2F;读索引 int saveReaderIndex; try &#123; do &#123; saveReaderIndex &#x3D; message.readerIndex(); try &#123; &#x2F;&#x2F;解码 msg &#x3D; codec.decode(channel, message); &#125; catch (IOException e) &#123; buffer &#x3D; com.alibaba.dubbo.remoting.buffer.ChannelBuffers.EMPTY_BUFFER; throw e; &#125; &#x2F;&#x2F;不完整的协议包 if (msg &#x3D;&#x3D; Codec2.DecodeResult.NEED_MORE_INPUT) &#123; &#x2F;&#x2F;重置读索引 message.readerIndex(saveReaderIndex); &#x2F;&#x2F;跳出循环，之后在finally中把message赋值给buffer保存起来，等到下次接收到数据包的时候会追加到buffer的后面 break; &#125; else &#123;&#x2F;&#x2F;有多个协议包，触发messageReceived事件 if (saveReaderIndex &#x3D;&#x3D; message.readerIndex()) &#123; buffer &#x3D; com.alibaba.dubbo.remoting.buffer.ChannelBuffers.EMPTY_BUFFER; throw new IOException(&quot;Decode without read data.&quot;); &#125; if (msg !&#x3D; null) &#123; Channels.fireMessageReceived(ctx, msg, event.getRemoteAddress()); &#125; &#125; &#125; while (message.readable()); &#125; finally &#123; if (message.readable()) &#123; message.discardReadBytes(); buffer &#x3D; message; &#125; else &#123; buffer &#x3D; com.alibaba.dubbo.remoting.buffer.ChannelBuffers.EMPTY_BUFFER; &#125; NettyChannel.removeChannelIfDisconnected(ctx.getChannel()); &#125;&#125; 继续看codec.decode(channel, message);这里是DubboCountCodec的decode方法： 1234567891011121314151617181920212223242526public Object decode(Channel channel, ChannelBuffer buffer) throws IOException &#123; &#x2F;&#x2F;当前的读索引记录下来 int save &#x3D; buffer.readerIndex(); &#x2F;&#x2F;多消息 MultiMessage result &#x3D; MultiMessage.create(); do &#123; &#x2F;&#x2F;解码消息 Object obj &#x3D; codec.decode(channel, buffer); &#x2F;&#x2F;不是完整的协议包 if (Codec2.DecodeResult.NEED_MORE_INPUT &#x3D;&#x3D; obj) &#123; buffer.readerIndex(save); break; &#125; else &#123;&#x2F;&#x2F;多个协议包 result.addMessage(obj); logMessageLength(obj, buffer.readerIndex() - save); save &#x3D; buffer.readerIndex(); &#125; &#125; while (true); if (result.isEmpty()) &#123; return Codec2.DecodeResult.NEED_MORE_INPUT; &#125; if (result.size() &#x3D;&#x3D; 1) &#123; return result.get(0); &#125; return result;&#125; 继续看ExchangeCodec的decode方法： 123456789public Object decode(Channel channel, ChannelBuffer buffer) throws IOException &#123; &#x2F;&#x2F;可读字节数 int readable &#x3D; buffer.readableBytes(); byte[] header &#x3D; new byte[Math.min(readable, HEADER_LENGTH)]; &#x2F;&#x2F;协议头 buffer.readBytes(header); &#x2F;&#x2F;解码 return decode(channel, buffer, readable, header);&#125; 解码decode： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647protected Object decode(Channel channel, ChannelBuffer buffer, int readable, byte[] header) throws IOException &#123; &#x2F;&#x2F;检查魔数. if (readable &gt; 0 &amp;&amp; header[0] !&#x3D; MAGIC_HIGH || readable &gt; 1 &amp;&amp; header[1] !&#x3D; MAGIC_LOW) &#123; int length &#x3D; header.length; if (header.length &lt; readable) &#123; header &#x3D; Bytes.copyOf(header, readable); buffer.readBytes(header, length, readable - length); &#125; for (int i &#x3D; 1; i &lt; header.length - 1; i ++) &#123; if (header[i] &#x3D;&#x3D; MAGIC_HIGH &amp;&amp; header[i + 1] &#x3D;&#x3D; MAGIC_LOW) &#123; buffer.readerIndex(buffer.readerIndex() - header.length + i); header &#x3D; Bytes.copyOf(header, i); break; &#125; &#125; &#x2F;&#x2F;telenet return super.decode(channel, buffer, readable, header); &#125; &#x2F;&#x2F;不完整的包 if (readable &lt; HEADER_LENGTH) &#123; return DecodeResult.NEED_MORE_INPUT; &#125; &#x2F;&#x2F;数据长度 int len &#x3D; Bytes.bytes2int(header, 12); checkPayload(channel, len); int tt &#x3D; len + HEADER_LENGTH; if( readable &lt; tt ) &#123; return DecodeResult.NEED_MORE_INPUT; &#125; &#x2F;&#x2F; limit input stream. ChannelBufferInputStream is &#x3D; new ChannelBufferInputStream(buffer, len); try &#123; &#x2F;&#x2F;解码数据 return decodeBody(channel, is, header); &#125; finally &#123; if (is.available() &gt; 0) &#123; try &#123; StreamUtils.skipUnusedStream(is); &#125; catch (IOException e) &#123; &#125; &#125; &#125;&#125; decodeBody解析数据部分： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970protected Object decodeBody(Channel channel, InputStream is, byte[] header) throws IOException &#123; byte flag &#x3D; header[2], proto &#x3D; (byte) (flag &amp; SERIALIZATION_MASK); &#x2F;&#x2F;获取序列化方式 Serialization s &#x3D; CodecSupport.getSerialization(channel.getUrl(), proto); &#x2F;&#x2F;反序列化 ObjectInput in &#x3D; s.deserialize(channel.getUrl(), is); &#x2F;&#x2F;获取请求id long id &#x3D; Bytes.bytes2long(header, 4); &#x2F;&#x2F;这里是解码响应数据 if ((flag &amp; FLAG_REQUEST) &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F;response的id设为来时候的Request的id，这样才能对上暗号 Response res &#x3D; new Response(id); &#x2F;&#x2F;判断是什么类型请求 if ((flag &amp; FLAG_EVENT) !&#x3D; 0) &#123; res.setEvent(Response.HEARTBEAT_EVENT); &#125; &#x2F;&#x2F;获取状态 byte status &#x3D; header[3]; res.setStatus(status); if (status &#x3D;&#x3D; Response.OK) &#123; try &#123; Object data; if (res.isHeartbeat()) &#123; &#x2F;&#x2F;解码心跳数据 data &#x3D; decodeHeartbeatData(channel, in); &#125; else if (res.isEvent()) &#123; &#x2F;&#x2F;事件 data &#x3D; decodeEventData(channel, in); &#125; else &#123; &#x2F;&#x2F;响应 data &#x3D; decodeResponseData(channel, in, getRequestData(id)); &#125; res.setResult(data); &#125; catch (Throwable t) &#123; res.setStatus(Response.CLIENT_ERROR); res.setErrorMessage(StringUtils.toString(t)); &#125; &#125; else &#123; res.setErrorMessage(in.readUTF()); &#125; return res; &#125; else &#123;&#x2F;&#x2F;这是解码请求数据 &#x2F;&#x2F; request的id Request req &#x3D; new Request(id); req.setVersion(&quot;2.0.0&quot;); req.setTwoWay((flag &amp; FLAG_TWOWAY) !&#x3D; 0); if ((flag &amp; FLAG_EVENT) !&#x3D; 0) &#123; req.setEvent(Request.HEARTBEAT_EVENT); &#125; try &#123; Object data; if (req.isHeartbeat()) &#123; &#x2F;&#x2F;心跳 data &#x3D; decodeHeartbeatData(channel, in); &#125; else if (req.isEvent()) &#123; &#x2F;&#x2F;事件 data &#x3D; decodeEventData(channel, in); &#125; else &#123; &#x2F;&#x2F;请求 data &#x3D; decodeRequestData(channel, in); &#125; req.setData(data); &#125; catch (Throwable t) &#123; &#x2F;&#x2F; bad request req.setBroken(true); req.setData(t); &#125; return req; &#125;&#125; 具体的解码细节交给底层解码器，这里是使用的hessian2。 服务消费者对响应消息的解码暂先不做解释。 协议头是16字节的定长数据： 2字节short类型的Magic 1字节的消息标志位 5位序列化id 1位心跳还是正常请求 1位双向还是单向 1位请求还是响应 1字节的状态位 8字节的消息id 4字节数据长度 编码的过程首先会判断是请求还是响应，代码在ExchangeCodec的encode方法： 123456789public void encode(Channel channel, ChannelBuffer buffer, Object msg) throws IOException &#123; if (msg instanceof Request) &#123;&#x2F;&#x2F;Request类型 encodeRequest(channel, buffer, (Request) msg); &#125; else if (msg instanceof Response) &#123;&#x2F;&#x2F;Response类型 encodeResponse(channel, buffer, (Response) msg); &#125; else &#123;&#x2F;&#x2F;telenet类型的 super.encode(channel, buffer, msg); &#125;&#125; 服务提供者对响应信息编码在服务提供者端一般是对响应来做编码，所以这里重点看下encodeResponse。 encodeResponse： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081protected void encodeResponse(Channel channel, ChannelBuffer buffer, Response res) throws IOException &#123; try &#123; &#x2F;&#x2F;序列化方式 &#x2F;&#x2F;也是根据SPI扩展来获取，url中没指定的话默认使用hessian2 Serialization serialization &#x3D; getSerialization(channel); &#x2F;&#x2F;长度为16字节的数组，协议头 byte[] header &#x3D; new byte[HEADER_LENGTH]; &#x2F;&#x2F;魔数0xdabb Bytes.short2bytes(MAGIC, header); &#x2F;&#x2F;序列化方式 header[2] &#x3D; serialization.getContentTypeId(); &#x2F;&#x2F;心跳消息还是正常消息 if (res.isHeartbeat()) header[2] |&#x3D; FLAG_EVENT; &#x2F;&#x2F;响应状态 byte status &#x3D; res.getStatus(); header[3] &#x3D; status; &#x2F;&#x2F;设置请求id Bytes.long2bytes(res.getId(), header, 4); &#x2F;&#x2F;buffer为1024字节的ChannelBuffer &#x2F;&#x2F;获取buffer的写入位置 int savedWriteIndex &#x3D; buffer.writerIndex(); &#x2F;&#x2F;需要再加上协议头的长度之后，才是正确的写入位置 buffer.writerIndex(savedWriteIndex + HEADER_LENGTH); ChannelBufferOutputStream bos &#x3D; new ChannelBufferOutputStream(buffer); ObjectOutput out &#x3D; serialization.serialize(channel.getUrl(), bos); &#x2F;&#x2F; 对响应信息或者错误消息进行编码 if (status &#x3D;&#x3D; Response.OK) &#123; if (res.isHeartbeat()) &#123; &#x2F;&#x2F;心跳 encodeHeartbeatData(channel, out, res.getResult()); &#125; else &#123; &#x2F;&#x2F;正常响应 encodeResponseData(channel, out, res.getResult()); &#125; &#125; &#x2F;&#x2F;错误消息 else out.writeUTF(res.getErrorMessage()); out.flushBuffer(); bos.flush(); bos.close(); &#x2F;&#x2F;写出去的消息的长度 int len &#x3D; bos.writtenBytes(); &#x2F;&#x2F;查看消息长度是否过长 checkPayload(channel, len); Bytes.int2bytes(len, header, 12); &#x2F;&#x2F;重置写入的位置 buffer.writerIndex(savedWriteIndex); &#x2F;&#x2F;向buffer中写入消息头 buffer.writeBytes(header); &#x2F;&#x2F; write header. &#x2F;&#x2F;buffer写出去的位置从writerIndex开始，加上header长度，加上数据长度 buffer.writerIndex(savedWriteIndex + HEADER_LENGTH + len); &#125; catch (Throwable t) &#123; &#x2F;&#x2F; 发送失败信息给Consumer，否则Consumer只能等超时了 if (! res.isEvent() &amp;&amp; res.getStatus() !&#x3D; Response.BAD_RESPONSE) &#123; try &#123; &#x2F;&#x2F; FIXME 在Codec中打印出错日志？在IoHanndler的caught中统一处理？ logger.warn(&quot;Fail to encode response: &quot; + res + &quot;, send bad_response info instead, cause: &quot; + t.getMessage(), t); Response r &#x3D; new Response(res.getId(), res.getVersion()); r.setStatus(Response.BAD_RESPONSE); r.setErrorMessage(&quot;Failed to send response: &quot; + res + &quot;, cause: &quot; + StringUtils.toString(t)); channel.send(r); return; &#125; catch (RemotingException e) &#123; logger.warn(&quot;Failed to send bad_response info back: &quot; + res + &quot;, cause: &quot; + e.getMessage(), e); &#125; &#125; &#x2F;&#x2F; 重新抛出收到的异常 if (t instanceof IOException) &#123; throw (IOException) t; &#125; else if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else if (t instanceof Error) &#123; throw (Error) t; &#125; else &#123; throw new RuntimeException(t.getMessage(), t); &#125; &#125;&#125; 服务消费者对请求信息编码消费者端暂先不做解析 解码的过程服务提供者对请求消息的解码decode方法一次只会解析一个完整的dubbo协议包，但是每次收到的协议包不一定是完整的，或者有可能是多个协议包。看下代码解析，首先看NettyCodecAdapter的内部类InternalDecoder的messageReceived方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public void messageReceived(ChannelHandlerContext ctx, MessageEvent event) throws Exception &#123; Object o &#x3D; event.getMessage(); if (! (o instanceof ChannelBuffer)) &#123; ctx.sendUpstream(event); return; &#125; ChannelBuffer input &#x3D; (ChannelBuffer) o; int readable &#x3D; input.readableBytes(); if (readable &lt;&#x3D; 0) &#123; return; &#125; com.alibaba.dubbo.remoting.buffer.ChannelBuffer message; if (buffer.readable()) &#123; if (buffer instanceof DynamicChannelBuffer) &#123; buffer.writeBytes(input.toByteBuffer()); message &#x3D; buffer; &#125; else &#123; int size &#x3D; buffer.readableBytes() + input.readableBytes(); message &#x3D; com.alibaba.dubbo.remoting.buffer.ChannelBuffers.dynamicBuffer( size &gt; bufferSize ? size : bufferSize); message.writeBytes(buffer, buffer.readableBytes()); message.writeBytes(input.toByteBuffer()); &#125; &#125; else &#123; message &#x3D; com.alibaba.dubbo.remoting.buffer.ChannelBuffers.wrappedBuffer( input.toByteBuffer()); &#125; NettyChannel channel &#x3D; NettyChannel.getOrAddChannel(ctx.getChannel(), url, handler); Object msg; &#x2F;&#x2F;读索引 int saveReaderIndex; try &#123; do &#123; saveReaderIndex &#x3D; message.readerIndex(); try &#123; &#x2F;&#x2F;解码 msg &#x3D; codec.decode(channel, message); &#125; catch (IOException e) &#123; buffer &#x3D; com.alibaba.dubbo.remoting.buffer.ChannelBuffers.EMPTY_BUFFER; throw e; &#125; &#x2F;&#x2F;不完整的协议包 if (msg &#x3D;&#x3D; Codec2.DecodeResult.NEED_MORE_INPUT) &#123; &#x2F;&#x2F;重置读索引 message.readerIndex(saveReaderIndex); &#x2F;&#x2F;跳出循环，之后在finally中把message赋值给buffer保存起来，等到下次接收到数据包的时候会追加到buffer的后面 break; &#125; else &#123;&#x2F;&#x2F;有多个协议包，触发messageReceived事件 if (saveReaderIndex &#x3D;&#x3D; message.readerIndex()) &#123; buffer &#x3D; com.alibaba.dubbo.remoting.buffer.ChannelBuffers.EMPTY_BUFFER; throw new IOException(&quot;Decode without read data.&quot;); &#125; if (msg !&#x3D; null) &#123; Channels.fireMessageReceived(ctx, msg, event.getRemoteAddress()); &#125; &#125; &#125; while (message.readable()); &#125; finally &#123; if (message.readable()) &#123; message.discardReadBytes(); buffer &#x3D; message; &#125; else &#123; buffer &#x3D; com.alibaba.dubbo.remoting.buffer.ChannelBuffers.EMPTY_BUFFER; &#125; NettyChannel.removeChannelIfDisconnected(ctx.getChannel()); &#125;&#125; 继续看codec.decode(channel, message);这里是DubboCountCodec的decode方法： 1234567891011121314151617181920212223242526public Object decode(Channel channel, ChannelBuffer buffer) throws IOException &#123; &#x2F;&#x2F;当前的读索引记录下来 int save &#x3D; buffer.readerIndex(); &#x2F;&#x2F;多消息 MultiMessage result &#x3D; MultiMessage.create(); do &#123; &#x2F;&#x2F;解码消息 Object obj &#x3D; codec.decode(channel, buffer); &#x2F;&#x2F;不是完整的协议包 if (Codec2.DecodeResult.NEED_MORE_INPUT &#x3D;&#x3D; obj) &#123; buffer.readerIndex(save); break; &#125; else &#123;&#x2F;&#x2F;多个协议包 result.addMessage(obj); logMessageLength(obj, buffer.readerIndex() - save); save &#x3D; buffer.readerIndex(); &#125; &#125; while (true); if (result.isEmpty()) &#123; return Codec2.DecodeResult.NEED_MORE_INPUT; &#125; if (result.size() &#x3D;&#x3D; 1) &#123; return result.get(0); &#125; return result;&#125; 继续看ExchangeCodec的decode方法： 123456789public Object decode(Channel channel, ChannelBuffer buffer) throws IOException &#123; &#x2F;&#x2F;可读字节数 int readable &#x3D; buffer.readableBytes(); byte[] header &#x3D; new byte[Math.min(readable, HEADER_LENGTH)]; &#x2F;&#x2F;协议头 buffer.readBytes(header); &#x2F;&#x2F;解码 return decode(channel, buffer, readable, header);&#125; 解码decode： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647protected Object decode(Channel channel, ChannelBuffer buffer, int readable, byte[] header) throws IOException &#123; &#x2F;&#x2F;检查魔数. if (readable &gt; 0 &amp;&amp; header[0] !&#x3D; MAGIC_HIGH || readable &gt; 1 &amp;&amp; header[1] !&#x3D; MAGIC_LOW) &#123; int length &#x3D; header.length; if (header.length &lt; readable) &#123; header &#x3D; Bytes.copyOf(header, readable); buffer.readBytes(header, length, readable - length); &#125; for (int i &#x3D; 1; i &lt; header.length - 1; i ++) &#123; if (header[i] &#x3D;&#x3D; MAGIC_HIGH &amp;&amp; header[i + 1] &#x3D;&#x3D; MAGIC_LOW) &#123; buffer.readerIndex(buffer.readerIndex() - header.length + i); header &#x3D; Bytes.copyOf(header, i); break; &#125; &#125; &#x2F;&#x2F;telenet return super.decode(channel, buffer, readable, header); &#125; &#x2F;&#x2F;不完整的包 if (readable &lt; HEADER_LENGTH) &#123; return DecodeResult.NEED_MORE_INPUT; &#125; &#x2F;&#x2F;数据长度 int len &#x3D; Bytes.bytes2int(header, 12); checkPayload(channel, len); int tt &#x3D; len + HEADER_LENGTH; if( readable &lt; tt ) &#123; return DecodeResult.NEED_MORE_INPUT; &#125; &#x2F;&#x2F; limit input stream. ChannelBufferInputStream is &#x3D; new ChannelBufferInputStream(buffer, len); try &#123; &#x2F;&#x2F;解码数据 return decodeBody(channel, is, header); &#125; finally &#123; if (is.available() &gt; 0) &#123; try &#123; StreamUtils.skipUnusedStream(is); &#125; catch (IOException e) &#123; &#125; &#125; &#125;&#125; decodeBody解析数据部分： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970protected Object decodeBody(Channel channel, InputStream is, byte[] header) throws IOException &#123; byte flag &#x3D; header[2], proto &#x3D; (byte) (flag &amp; SERIALIZATION_MASK); &#x2F;&#x2F;获取序列化方式 Serialization s &#x3D; CodecSupport.getSerialization(channel.getUrl(), proto); &#x2F;&#x2F;反序列化 ObjectInput in &#x3D; s.deserialize(channel.getUrl(), is); &#x2F;&#x2F;获取请求id long id &#x3D; Bytes.bytes2long(header, 4); &#x2F;&#x2F;这里是解码响应数据 if ((flag &amp; FLAG_REQUEST) &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F;response的id设为来时候的Request的id，这样才能对上暗号 Response res &#x3D; new Response(id); &#x2F;&#x2F;判断是什么类型请求 if ((flag &amp; FLAG_EVENT) !&#x3D; 0) &#123; res.setEvent(Response.HEARTBEAT_EVENT); &#125; &#x2F;&#x2F;获取状态 byte status &#x3D; header[3]; res.setStatus(status); if (status &#x3D;&#x3D; Response.OK) &#123; try &#123; Object data; if (res.isHeartbeat()) &#123; &#x2F;&#x2F;解码心跳数据 data &#x3D; decodeHeartbeatData(channel, in); &#125; else if (res.isEvent()) &#123; &#x2F;&#x2F;事件 data &#x3D; decodeEventData(channel, in); &#125; else &#123; &#x2F;&#x2F;响应 data &#x3D; decodeResponseData(channel, in, getRequestData(id)); &#125; res.setResult(data); &#125; catch (Throwable t) &#123; res.setStatus(Response.CLIENT_ERROR); res.setErrorMessage(StringUtils.toString(t)); &#125; &#125; else &#123; res.setErrorMessage(in.readUTF()); &#125; return res; &#125; else &#123;&#x2F;&#x2F;这是解码请求数据 &#x2F;&#x2F; request的id Request req &#x3D; new Request(id); req.setVersion(&quot;2.0.0&quot;); req.setTwoWay((flag &amp; FLAG_TWOWAY) !&#x3D; 0); if ((flag &amp; FLAG_EVENT) !&#x3D; 0) &#123; req.setEvent(Request.HEARTBEAT_EVENT); &#125; try &#123; Object data; if (req.isHeartbeat()) &#123; &#x2F;&#x2F;心跳 data &#x3D; decodeHeartbeatData(channel, in); &#125; else if (req.isEvent()) &#123; &#x2F;&#x2F;事件 data &#x3D; decodeEventData(channel, in); &#125; else &#123; &#x2F;&#x2F;请求 data &#x3D; decodeRequestData(channel, in); &#125; req.setData(data); &#125; catch (Throwable t) &#123; &#x2F;&#x2F; bad request req.setBroken(true); req.setData(t); &#125; return req; &#125;&#125; 具体的解码细节交给底层解码器，这里是使用的hessian2。 服务消费者对响应消息的解码暂先不做解释。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Netty3服务端流程简介]]></title>
      <url>%2F2017%2F03%2F19%2FNetty3%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%B5%81%E7%A8%8B%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[在学习Dubbo的时候需要学习Netty的流程等，在此做一个简单的入门学习。Dubbo中使用的是Netty3，所以这里说的都是Netty3。 Netty3可以看成是对Reactor的实现，所以先简单看下Reactor模式。 Reactor模式Reactor模式是基于事件驱动的，有以下几种角色存在： Handle，句柄，用来表示打开的文件，打开的连接等，Java NIO中使用Channel来表示。 Synchronous Event Demultiplexer，阻塞的等待发生在句柄上的一个或多个事件，就是监听事件的到来。Java NIO中使用Selector来表示。 EventHandler接口，来处理不同的请求事件。 Concrete Event Handler，EventHandler实现。 Initiation Dispatcher（Reactor），用来管理EventHandler；有事件到来时分发事件到EventHandler上去处理。 Netty中的Reactor模式Netty中使用了两层Reactor，Main Reactor用于处理连接请求，Sub Reactor用于处理请求连接之后的读写请求。 Netty中各类释义ChannelReactor模式中使用Handle来表示打开的连接，也就是事件源，在java nio中使用Channel来抽象事件源，Netty中的Channel是自己的抽象。 ChannelEvent在Netty中使用ChannelEvent来抽象在事件源中可以产生的各种事件。 ChannelHandler作用就是Reactor模式中的EventHandler，用来处理事件请求。有两个子接口： ChannelDownstreamHandler，处理从Netty内部流向Socket的事件。 ChannelUpstreamHandler，处理从Socket进入Netty内部的事件。 ChannelPipeline每个Channel都会有一个ChannelPipeline，用来管理ChannelHandler。ChannelPipeline内部有一个ChannelHandler的双向链表，以Upstream为正方向，Downstream为负方向。 NioSelector对应的是Reactor模式中的Synchronous Event Demultiplexer，Java NIO使用Selector，每个Channel都会把自己注册到Selector上，Selector就可以监听Channel中发生的事件。当有事件发生的时候，会生成ChannelEvent实例，该事件会被发送到Channel对应的ChannelPipeline中，然后交给ChannelHandler处理。 NioSelector有两个实现： Boss，是Main Reactor，用来处理新连接加入的事件。 Worker，是Sub Reactor，用来处理各个连接的读写事件。 ChannelSinkChannelSink可以看成Handler最后的一个处于末尾的万能handler，只有DownStream包含ChannelSink。 服务端例子1234567891011121314151617181920212223242526public class NettyServerTest &#123; private final int port; public NettyServerTest(int port)&#123; this.port &#x3D; port; &#125; public void startServer()&#123; ChannelFactory channelFactory &#x3D; new NioServerSocketChannelFactory(Executors.newCachedThreadPool(),Executors.newCachedThreadPool()); ServerBootstrap serverBootstrap &#x3D; new ServerBootstrap(channelFactory); serverBootstrap.setPipelineFactory(new ChannelPipelineFactory() &#123; @Override public ChannelPipeline getPipeline() throws Exception &#123; return Channels.pipeline(new ServerHandlerTest()); &#125; &#125;); serverBootstrap.bind(new InetSocketAddress(port)); &#125; public static void main(String[] args) &#123; new NettyServerTest(8888).startServer(); &#125;&#125; 12345678910111213141516171819202122public class ServerHandlerTest extends SimpleChannelUpstreamHandler &#123; @Override public void messageReceived(ChannelHandlerContext ctx, MessageEvent e) throws Exception &#123; ChannelBuffer channelBuffer &#x3D; (ChannelBuffer)e.getMessage(); String msg &#x3D; channelBuffer.toString(Charset.defaultCharset()); if(msg !&#x3D; null &amp;&amp; !&quot;&quot;.equals(msg))&#123; System.out.println(&quot;服务端接收到消息：&quot; + msg); ChannelBuffer sendMsg &#x3D; ChannelBuffers.dynamicBuffer(); sendMsg.writeBytes(&quot;我是服务器，已经接到消息&quot;.getBytes()); e.getChannel().write(sendMsg); &#125;else &#123; e.getChannel().write(&quot;我是服务器，收到了空消息&quot;); &#125; e.getChannel().close(); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, ExceptionEvent e) throws Exception &#123; e.getCause(); e.getChannel().close(); &#125;&#125; ChannelFactory主要是用来产生Channel实例和ChannelSink实例。 ChannelPipelineFactory主要是用于具体传输数据的处理，是我们自己实现具体内容，一般我们是往里面添加Handler实现。 大概的流程是： 首先使用Boss和Worker两个线程池来初始化一个ChannelFactory。 使用ChannelFactory来初始化一个ServerBootstrap实例。 为ServerBootstrap设置pipelineFactory，这里用来添加各种处理用的Handler。 使用Bind方法绑定并监听。 Handler处理顺序Handler跟Servlet中的Filter类似，在Netty中，Handler存在于Pipeline中，是一个链状的。 在Netty中存在两种ChannelHandler，一种是ChannelDownstreamHandler，另外一种是ChannelUpstreamHandler，从Socket流向Netty内部的数据经过ChannelUpstreamHandler处理，而从Netty内部流向Socket的数据由ChannelDownstreamHandler处理。 有关具体的分析和源码分析，等到dubbo分析完成之后，再做。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo中暴露服务的过程解析]]></title>
      <url>%2F2017%2F02%2F19%2FDubbo%E4%B8%AD%E6%9A%B4%E9%9C%B2%E6%9C%8D%E5%8A%A1%E7%9A%84%E8%BF%87%E7%A8%8B%E8%A7%A3%E6%9E%90%2F</url>
      <content type="text"><![CDATA[dubbo暴露服务有两种情况，一种是设置了延迟暴露（比如delay=”5000”），另外一种是没有设置延迟暴露或者延迟设置为-1（delay=”-1”）： 设置了延迟暴露，dubbo在Spring实例化bean（initializeBean）的时候会对实现了InitializingBean的类进行回调，回调方法是afterPropertySet()，如果设置了延迟暴露，dubbo在这个方法中进行服务的发布。 没有设置延迟或者延迟为-1，dubbo会在Spring实例化完bean之后，在刷新容器最后一步发布ContextRefreshEvent事件的时候，通知实现了ApplicationListener的类进行回调onApplicationEvent，dubbo会在这个方法中发布服务。 但是不管延迟与否，都是使用ServiceConfig的export()方法进行服务的暴露。使用export初始化的时候会将Bean对象转换成URL格式，所有Bean属性转换成URL的参数。 以没有设置延迟暴露熟属性的过程为例。 简易的暴露流程 首先将服务的实现封装成一个Invoker，Invoker中封装了服务的实现类。 将Invoker封装成Exporter，并缓存起来，缓存里使用Invoker的url作为key。 服务端Server启动，监听端口。（请求来到时，根据请求信息生成key，到缓存查找Exporter，就找到了Invoker，就可以完成调用。） Spring容器初始化调用当Spring容器实例化bean完成，走到最后一步发布ContextRefreshEvent事件的时候，ServiceBean会执行onApplicationEvent方法，该方法调用ServiceConfig的export方法。 ServiceConfig初始化的时候，会先初始化静态变量protocol和proxyFactory，这两个变量初始化的结果是通过dubbo的spi扩展机制得到的。 生成的protocol实例是： 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.alibaba.dubbo.rpc;import com.alibaba.dubbo.common.extension.ExtensionLoader;public class Protocol$Adpative implements com.alibaba.dubbo.rpc.Protocol &#123; public com.alibaba.dubbo.rpc.Invoker refer(java.lang.Class arg0, com.alibaba.dubbo.common.URL arg1) throws java.lang.Class &#123; if (arg1 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;url &#x3D;&#x3D; null&quot;); com.alibaba.dubbo.common.URL url &#x3D; arg1; String extName &#x3D; ( url.getProtocol() &#x3D;&#x3D; null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); com.alibaba.dubbo.rpc.Protocol extension &#x3D; (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); &#125; public com.alibaba.dubbo.rpc.Exporter export(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker &#123; if (arg0 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument &#x3D;&#x3D; null&quot;); if (arg0.getUrl() &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument getUrl() &#x3D;&#x3D; null&quot;);com.alibaba.dubbo.common.URL url &#x3D; arg0.getUrl(); &#x2F;&#x2F;根据URL配置信息获取Protocol协议，默认是dubbo String extName &#x3D; ( url.getProtocol() &#x3D;&#x3D; null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); &#x2F;&#x2F;根据协议名，获取Protocol的实现 &#x2F;&#x2F;获得Protocol的实现过程中，会对Protocol先进行依赖注入，然后进行Wrapper包装，最后返回被修改过的Protocol &#x2F;&#x2F;包装经过了ProtocolFilterWrapper，ProtocolListenerWrapper，RegistryProtocol com.alibaba.dubbo.rpc.Protocol extension &#x3D; (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName); return extension.export(arg0); &#125; public void destroy() &#123; throw new UnsupportedOperationException(&quot;method public abstract void com.alibaba.dubbo.rpc.Protocol.destroy() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!&quot;); &#125; public int getDefaultPort() &#123; throw new UnsupportedOperationException(&quot;method public abstract int com.alibaba.dubbo.rpc.Protocol.getDefaultPort() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!&quot;); &#125;&#125; 生成的proxyFactory实例： 123456789101112131415161718192021222324252627282930313233package com.alibaba.dubbo.rpc;import com.alibaba.dubbo.common.extension.ExtensionLoader;public class ProxyFactory$Adpative implements com.alibaba.dubbo.rpc.ProxyFactory &#123; public com.alibaba.dubbo.rpc.Invoker getInvoker(java.lang.Object arg0, java.lang.Class arg1, com.alibaba.dubbo.common.URL arg2) throws java.lang.Object &#123; if (arg2 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;url &#x3D;&#x3D; null&quot;); com.alibaba.dubbo.common.URL url &#x3D; arg2; String extName &#x3D; url.getParameter(&quot;proxy&quot;, &quot;javassist&quot;); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.ProxyFactory) name from url(&quot; + url.toString() + &quot;) use keys([proxy])&quot;); com.alibaba.dubbo.rpc.ProxyFactory extension &#x3D; (com.alibaba.dubbo.rpc.ProxyFactory)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getInvoker(arg0, arg1, arg2); &#125; public java.lang.Object getProxy(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker &#123; if (arg0 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument &#x3D;&#x3D; null&quot;); if (arg0.getUrl() &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument getUrl() &#x3D;&#x3D; null&quot;);com.alibaba.dubbo.common.URL url &#x3D; arg0.getUrl(); String extName &#x3D; url.getParameter(&quot;proxy&quot;, &quot;javassist&quot;); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.ProxyFactory) name from url(&quot; + url.toString() + &quot;) use keys([proxy])&quot;); com.alibaba.dubbo.rpc.ProxyFactory extension &#x3D; (com.alibaba.dubbo.rpc.ProxyFactory)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.ProxyFactory.class).getExtension(extName); return extension.getProxy(arg0); &#125;&#125; 生成的代码中可以看到，默认的Protocol实现是dubbo，默认的proxy是javassist。 ServiceConfig的exportexport的步骤简介 首先会检查各种配置信息，填充各种属性，总之就是保证我在开始暴露服务之前，所有的东西都准备好了，并且是正确的。 加载所有的注册中心，因为我们暴露服务需要注册到注册中心中去。 根据配置的所有协议和注册中心url分别进行导出。 进行导出的时候，又是一波属性的获取设置检查等操作。 如果配置的不是remote，则做本地导出。 如果配置的不是local，则暴露为远程服务。 不管是本地还是远程服务暴露，首先都会获取Invoker。 获取完Invoker之后，转换成对外的Exporter，缓存起来。 export方法先判断是否需要延迟暴露（这里我们使用的是不延迟暴露），然后执行doExport方法。 doExport方法先执行一系列的检查方法，然后调用doExportUrls方法。检查方法会检测dubbo的配置是否在Spring配置文件中声明，没有的话读取properties文件初始化。 doExportUrls方法先调用loadRegistries获取所有的注册中心url，然后遍历调用doExportUrlsFor1Protocol方法。对于在标签中指定了registry属性的Bean，会在加载BeanDefinition的时候就加载了注册中心。 获取注册中心url，会把注册的信息都放在一个URL对象中，一个URL内容如下： 1registry:&#x2F;&#x2F;127.0.0.1:2181&#x2F;com.alibaba.dubbo.registry.RegistryService?application&#x3D;dubbo-provider&amp;application.version&#x3D;1.0&amp;dubbo&#x3D;2.5.3&amp;environment&#x3D;product&amp;organization&#x3D;china&amp;owner&#x3D;cheng.xi&amp;pid&#x3D;2939&amp;registry&#x3D;zookeeper&amp;timestamp&#x3D;1488898049284 doExportUrlsFor1Protocol根据不同的协议将服务以URL形式暴露。如果scope配置为none则不暴露，如果服务未配置成remote，则本地暴露exportLocal，如果未配置成local，则注册服务registryProcotol。 这里的URL是： 1dubbo:&#x2F;&#x2F;192.168.1.100:20880&#x2F;dubbo.common.hello.service.HelloService?anyhost&#x3D;true&amp;application&#x3D;dubbo-provider&amp;application.version&#x3D;1.0&amp;delay&#x3D;5000&amp;dubbo&#x3D;2.5.3&amp;environment&#x3D;product&amp;interface&#x3D;dubbo.common.hello.service.HelloService&amp;methods&#x3D;sayHello&amp;organization&#x3D;china&amp;owner&#x3D;cheng.xi&amp;pid&#x3D;2939&amp;side&#x3D;provider&amp;timestamp&#x3D;1488898464953 本地暴露这时候会先做本地暴露，exportLocal(url);： 1234567891011121314151617181920private void exportLocal(URL url) &#123; if (!Constants.LOCAL_PROTOCOL.equalsIgnoreCase(url.getProtocol())) &#123; &#x2F;&#x2F;这时候转成本地暴露的url：injvm:&#x2F;&#x2F;127.0.0.1&#x2F;dubbo.common.hello.service.HelloService?anyhost&#x3D;true&amp; &#x2F;&#x2F;application&#x3D;dubbo-provider&amp;application.version&#x3D;1.0&amp;dubbo&#x3D;2.5.3&amp;environment&#x3D;product&amp; &#x2F;&#x2F;interface&#x3D;dubbo.common.hello.service.HelloService&amp;methods&#x3D;sayHello&amp; &#x2F;&#x2F;organization&#x3D;china&amp;owner&#x3D;cheng.xi&amp;pid&#x3D;720&amp;side&#x3D;provider&amp;timestamp&#x3D;1489716708276 URL local &#x3D; URL.valueOf(url.toFullString()) .setProtocol(Constants.LOCAL_PROTOCOL) .setHost(NetUtils.LOCALHOST) .setPort(0); &#x2F;&#x2F;首先还是先获得Invoker &#x2F;&#x2F;然后导出成Exporter，并缓存 &#x2F;&#x2F;这里的proxyFactory实际是JavassistProxyFactory &#x2F;&#x2F;有关详细的获得Invoke以及exporter会在下面的流程解析，在本地暴露这个流程就不再说明。 Exporter&lt;?&gt; exporter &#x3D; protocol.export( proxyFactory.getInvoker(ref, (Class) interfaceClass, local)); exporters.add(exporter); logger.info(&quot;Export dubbo service &quot; + interfaceClass.getName() +&quot; to local registry&quot;); &#125;&#125; 暴露为远程服务接下来是暴露为远程服务，跟本地暴露的流程一样还是先获取Invoker，然后导出成Exporter： 123456789&#x2F;&#x2F;根据服务具体实现，实现接口，以及registryUrl通过ProxyFactory将HelloServiceImpl封装成一个本地执行的Invoker&#x2F;&#x2F;invoker是对具体实现的一种代理。&#x2F;&#x2F;这里proxyFactory是上面列出的生成的代码 Invoker&lt;?&gt; invoker &#x3D; proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString())); &#x2F;&#x2F;使用Protocol将invoker导出成一个Exporter &#x2F;&#x2F;暴露封装服务invoker &#x2F;&#x2F;调用Protocol生成的适配类的export方法 &#x2F;&#x2F;这里的protocol是上面列出的生成的代码 Exporter&lt;?&gt; exporter &#x3D; protocol.export(invoker); 关于Invoker，Exporter等的解释参见最下面的内容。 暴露远程服务时的获取Invoker过程服务实现类转换成Invoker，大概的步骤是： 根据上面生成的proxyFactory方法调用具体的ProxyFactory实现类的getInvoker方法获取Invoker。 getInvoker的过程是，首先对实现类做一个包装，生成一个包装后的类。 然后新创建一个Invoker实例，这个Invoker中包含着生成的Wrapper类，Wrapper类中有具体的实现类。 1Invoker&lt;?&gt; invoker &#x3D; proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString())); 这行代码中包含服务实现类转换成Invoker的过程，其中proxyFactory是上面列出的动态生成的代码，其中getInvoker的代码为（做了精简，把包都去掉了）： 1234567891011121314public Invoker getInvoker(Object arg0, Class arg1, URL arg2) throws Object &#123; if (arg2 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;url &#x3D;&#x3D; null&quot;); &#x2F;&#x2F;传进来的url是dubbo:&#x2F;&#x2F;192.168.110.197:20880&#x2F;dubbo.common.hello.service.HelloService?anyhost&#x3D;true&amp;application&#x3D;dubbo-provider &#x2F;&#x2F;&amp;application.version&#x3D;1.0&amp;dubbo&#x3D;2.5.3&amp;environment&#x3D;product&amp;interface&#x3D;dubbo.common.hello.service.HelloService&amp;methods&#x3D;sayHello&amp;organization&#x3D;china&amp;owner&#x3D;cheng.xi &#x2F;&#x2F;&amp;pid&#x3D;28191&amp;side&#x3D;provider&amp;timestamp&#x3D;1489027396094 URL url &#x3D; arg2; &#x2F;&#x2F;没有proxy参数配置，默认使用javassist String extName &#x3D; url.getParameter(&quot;proxy&quot;, &quot;javassist&quot;); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(ProxyFactory) name from url(&quot; + url.toString() + &quot;) use keys([proxy])&quot;); &#x2F;&#x2F;这一步就使用javassist来获取ProxyFactory的实现类JavassistProxyFactory ProxyFactory extension &#x3D; (ProxyFactory)ExtensionLoader.getExtensionLoader(ProxyFactory.class).getExtension(extName); &#x2F;&#x2F;JavassistProxyFactory的getInvoker方法 return extension.getInvoker(arg0, arg1, arg2);&#125; 使用JavassistProxyFactory获取InvokerJavassistProxyFactory的getInvoker方法： 1234567891011121314151617public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; &#x2F;&#x2F; TODO Wrapper类不能正确处理带$的类名 &#x2F;&#x2F;第一步封装一个Wrapper类 &#x2F;&#x2F;该类是手动生成的 &#x2F;&#x2F;如果类是以$开头，就使用接口类型获取，其他的使用实现类获取 final Wrapper wrapper &#x3D; Wrapper.getWrapper(proxy.getClass().getName().indexOf(&#39;$&#39;) &lt; 0 ? proxy.getClass() : type); &#x2F;&#x2F;返回一个Invoker实例，doInvoke方法中直接返回上面wrapper的invokeMethod &#x2F;&#x2F;关于生成的wrapper，请看下面列出的生成的代码，其中invokeMethod方法中就有实现类对实际方法的调用 return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &#125; &#125;;&#125; 生成wrapper类的过程，首先看getWrapper方法： 123456789101112131415public static Wrapper getWrapper(Class&lt;?&gt; c)&#123; while( ClassGenerator.isDynamicClass(c) ) &#x2F;&#x2F; can not wrapper on dynamic class. c &#x3D; c.getSuperclass(); &#x2F;&#x2F;Object类型的 if( c &#x3D;&#x3D; Object.class ) return OBJECT_WRAPPER; &#x2F;&#x2F;先去Wrapper缓存中查找 Wrapper ret &#x3D; WRAPPER_MAP.get(c); if( ret &#x3D;&#x3D; null ) &#123; &#x2F;&#x2F;缓存中不存在，生成Wrapper类，放到缓存 ret &#x3D; makeWrapper(c); WRAPPER_MAP.put(c,ret); &#125; return ret;&#125; makeWrapper方法代码不在列出，太长了。就是生成一个继承自Wrapper的类，最后的结果大概是： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class Wrapper1 extends Wrapper &#123; public static String[] pns; public static Map pts; public static String[] mns; &#x2F;&#x2F; all method name array. public static String[] dmns; public static Class[] mts0; public String[] getPropertyNames() &#123; return pns; &#125; public boolean hasProperty(String n) &#123; return pts.containsKey($1); &#125; public Class getPropertyType(String n) &#123; return (Class) pts.get($1); &#125; public String[] getMethodNames() &#123; return mns; &#125; public String[] getDeclaredMethodNames() &#123; return dmns; &#125; public void setPropertyValue(Object o, String n, Object v) &#123; dubbo.provider.hello.service.impl.HelloServiceImpl w; try &#123; w &#x3D; ((dubbo.provider.hello.service.impl.HelloServiceImpl) $1); &#125; catch (Throwable e) &#123; throw new IllegalArgumentException(e); &#125; throw new com.alibaba.dubbo.common.bytecode.NoSuchPropertyException(&quot;Not found property \&quot;&quot; + $2 + &quot;\&quot; filed or setter method in class dubbo.provider.hello.service.impl.HelloServiceImpl.&quot;); &#125; public Object getPropertyValue(Object o, String n) &#123; dubbo.provider.hello.service.impl.HelloServiceImpl w; try &#123; w &#x3D; ((dubbo.provider.hello.service.impl.HelloServiceImpl) $1); &#125; catch (Throwable e) &#123; throw new IllegalArgumentException(e); &#125; throw new com.alibaba.dubbo.common.bytecode.NoSuchPropertyException(&quot;Not found property \&quot;&quot; + $2 + &quot;\&quot; filed or setter method in class dubbo.provider.hello.service.impl.HelloServiceImpl.&quot;); &#125; public Object invokeMethod(Object o, String n, Class[] p, Object[] v) throws java.lang.reflect.InvocationTargetException &#123; dubbo.provider.hello.service.impl.HelloServiceImpl w; try &#123; w &#x3D; ((dubbo.provider.hello.service.impl.HelloServiceImpl) $1); &#125; catch (Throwable e) &#123; throw new IllegalArgumentException(e); &#125; try &#123; if (&quot;sayHello&quot;.equals($2) &amp;&amp; $3.length &#x3D;&#x3D; 0) &#123; w.sayHello(); return null; &#125; &#125; catch (Throwable e) &#123; throw new java.lang.reflect.InvocationTargetException(e); &#125; throw new com.alibaba.dubbo.common.bytecode.NoSuchMethodException(&quot;Not found method \&quot;&quot; + $2 + &quot;\&quot; in class dubbo.provider.hello.service.impl.HelloServiceImpl.&quot;); &#125;&#125; 生成完Wrapper以后，返回一个AbstractProxyInvoker实例。至此生成Invoker的步骤就完成了。可以看到Invoker执行方法的时候，会调用Wrapper的invokeMethod，这个方法中会有真实的实现类调用真实方法的代码。 使用JdkProxyFactory获取invokerJdkProxyFactory的getInvoker方法： 1234567891011public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; Method method &#x3D; proxy.getClass().getMethod(methodName, parameterTypes); return method.invoke(proxy, arguments); &#125; &#125;;&#125; 直接返回一个AbstractProxyInvoker实例，没有做处理，只是使用反射调用具体的方法。 JdkProxyFactory的getProxy方法： 123public &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker, Class&lt;?&gt;[] interfaces) &#123; return (T) Proxy.newProxyInstance(Thread.currentThread().getContextClassLoader(), interfaces, new InvokerInvocationHandler(invoker));&#125; 使用Java的反射机制生成一个代理类。 暴露远程服务时导出Invoker为ExporterInvoker导出为Exporter分为两种情况，第一种是Registry类型的Invoker，第二种是其他协议类型的Invoker，分开解析。 代码入口： 1Exporter&lt;?&gt; exporter &#x3D; protocol.export(invoker); Registry类型的Invoker处理过程大概的步骤是： 经过两个不用做任何处理的Wrapper类，然后到达RegistryProtocol中。 通过具体的协议导出Invoker为Exporter。 注册服务到注册中心。 订阅注册中心的服务。 生成一个新的Exporter实例，将上面的Exporter进行引入，然后返回。 protocol是上面列出的动态生成的代码，会先调用ProtocolListenerWrapper，这个Wrapper负责初始化暴露和引用服务的监听器。对于Registry类型的不做处理，代码如下： 12345678910public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; &#x2F;&#x2F;registry类型的Invoker，不需要做处理 if (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123; return protocol.export(invoker); &#125; &#x2F;&#x2F;非Registry类型的Invoker，需要被监听器包装 return new ListenerExporterWrapper&lt;T&gt;(protocol.export(invoker), Collections.unmodifiableList(ExtensionLoader.getExtensionLoader(ExporterListener.class) .getActivateExtension(invoker.getUrl(), Constants.EXPORTER_LISTENER_KEY)));&#125; 接着调用ProtocolFilterWrapper中的export方法，ProtocolFilterWrapper负责初始化invoker所有的Filter。代码如下： 12345678public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; &#x2F;&#x2F;Registry类型的Invoker不做处理 if (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123; return protocol.export(invoker); &#125; &#x2F;&#x2F;非Registry类型的Invoker需要先构建调用链，然后再导出 return protocol.export(buildInvokerChain(invoker, Constants.SERVICE_FILTER_KEY, Constants.PROVIDER));&#125; 这里我们先解析的是Registry类型的Invoker，接着就会调用RegistryProtocol的export方法，RegistryProtocol负责注册服务到注册中心和向注册中心订阅服务。代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public &lt;T&gt; Exporter&lt;T&gt; export(final Invoker&lt;T&gt; originInvoker) throws RpcException &#123; &#x2F;&#x2F;export invoker &#x2F;&#x2F;这里就交给了具体的协议去暴露服务（先不解析，留在后面，可以先去后面看下导出过程） final ExporterChangeableWrapper&lt;T&gt; exporter &#x3D; doLocalExport(originInvoker); &#x2F;&#x2F;registry provider &#x2F;&#x2F;根据invoker中的url获取Registry实例 &#x2F;&#x2F;并且连接到注册中心 &#x2F;&#x2F;此时提供者作为消费者引用注册中心核心服务RegistryService final Registry registry &#x3D; getRegistry(originInvoker); &#x2F;&#x2F;注册到注册中心的URL final URL registedProviderUrl &#x3D; getRegistedProviderUrl(originInvoker); &#x2F;&#x2F;调用远端注册中心的register方法进行服务注册 &#x2F;&#x2F;若有消费者订阅此服务，则推送消息让消费者引用此服务。 &#x2F;&#x2F;注册中心缓存了所有提供者注册的服务以供消费者发现。 registry.register(registedProviderUrl); &#x2F;&#x2F; 订阅override数据 &#x2F;&#x2F; FIXME 提供者订阅时，会影响同一JVM即暴露服务，又引用同一服务的的场景，因为subscribed以服务名为缓存的key，导致订阅信息覆盖。 final URL overrideSubscribeUrl &#x3D; getSubscribedOverrideUrl(registedProviderUrl); final OverrideListener overrideSubscribeListener &#x3D; new OverrideListener(overrideSubscribeUrl); overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener); &#x2F;&#x2F;提供者向注册中心订阅所有注册服务的覆盖配置 &#x2F;&#x2F;当注册中心有此服务的覆盖配置注册进来时，推送消息给提供者，重新暴露服务，这由管理页面完成。 registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener); &#x2F;&#x2F;保证每次export都返回一个新的exporter实例 &#x2F;&#x2F;返回暴露后的Exporter给上层ServiceConfig进行缓存，便于后期撤销暴露。 return new Exporter&lt;T&gt;() &#123; public Invoker&lt;T&gt; getInvoker() &#123; return exporter.getInvoker(); &#125; public void unexport() &#123; try &#123; exporter.unexport(); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; try &#123; registry.unregister(registedProviderUrl); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; try &#123; overrideListeners.remove(overrideSubscribeUrl); registry.unsubscribe(overrideSubscribeUrl, overrideSubscribeListener); &#125; catch (Throwable t) &#123; logger.warn(t.getMessage(), t); &#125; &#125; &#125;;&#125; 交给具体的协议去暴露服务先不解析，留在后面，可以先去后面看下导出过程，然后再回来接着看注册到注册中心的过程。具体协议暴露服务主要是打开服务器和端口，进行监听。 连接注册中心并获取Registry实例具体的协议进行暴露并且返回了一个ExporterChangeableWrapper之后，接下来看下一步连接注册中心并注册到注册中心，代码是在RegistryProtocol的export方法： 123456789101112&#x2F;&#x2F;先假装此步已经分析完final ExporterChangeableWrapper&lt;T&gt; exporter &#x3D; doLocalExport(originInvoker);&#x2F;&#x2F;得到具体的注册中心，连接注册中心，此时提供者作为消费者引用注册中心核心服务RegistryServicefinal Registry registry &#x3D; getRegistry(originInvoker);final URL registedProviderUrl &#x3D; getRegistedProviderUrl(originInvoker);&#x2F;&#x2F;调用远端注册中心的register方法进行服务注册&#x2F;&#x2F;若有消费者订阅此服务，则推送消息让消费者引用此服务registry.register(registedProviderUrl);&#x2F;&#x2F;提供者向注册中心订阅所有注册服务的覆盖配置registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener);&#x2F;&#x2F;返回暴露后的Exporter给上层ServiceConfig进行缓存return new Exporter&lt;T&gt;() &#123;。。。&#125; getRegistry(originInvoker)方法： 123456789101112131415161718192021&#x2F;&#x2F;根据invoker的地址获取registry实例private Registry getRegistry(final Invoker&lt;?&gt; originInvoker)&#123; &#x2F;&#x2F;获取invoker中的registryUrl URL registryUrl &#x3D; originInvoker.getUrl(); if (Constants.REGISTRY_PROTOCOL.equals(registryUrl.getProtocol())) &#123; &#x2F;&#x2F;获取registry的值，这里获得是zookeeper，默认值是dubbo String protocol &#x3D; registryUrl.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_DIRECTORY); &#x2F;&#x2F;这里获取到的url为： &#x2F;&#x2F;zookeeper:&#x2F;&#x2F;127.0.0.1:2181&#x2F;com.alibaba.dubbo.registry.RegistryService? &#x2F;&#x2F;application&#x3D;dubbo-provider&amp;application.version&#x3D;1.0&amp;dubbo&#x3D;2.5.3&amp; &#x2F;&#x2F;environment&#x3D;product&amp;export&#x3D;dubbo%3A%2F%2F192.168.1.100%3A20880%2F &#x2F;&#x2F;dubbo.common.hello.service.HelloService%3Fanyhost%3Dtrue%26application%3Ddubbo-provider%26 &#x2F;&#x2F;application.version%3D1.0%26dubbo%3D2.5.3%26environment%3Dproduct%26 &#x2F;&#x2F;interface%3Ddubbo.common.hello.service.HelloService%26methods%3DsayHello%26 &#x2F;&#x2F;organization%3Dchina%26owner%3Dcheng.xi%26pid%3D9457%26side%3Dprovider%26timestamp%3D1489807681627&amp;organization&#x3D;china&amp;owner&#x3D;cheng.xi&amp; &#x2F;&#x2F;pid&#x3D;9457&amp;timestamp&#x3D;1489807680193 registryUrl &#x3D; registryUrl.setProtocol(protocol).removeParameter(Constants.REGISTRY_KEY); &#125; &#x2F;&#x2F;根据SPI机制获取具体的Registry实例，这里获取到的是ZookeeperRegistry return registryFactory.getRegistry(registryUrl);&#125; 这里的registryFactory是动态生成的代码，如下： 12345678910111213141516import com.alibaba.dubbo.common.extension.ExtensionLoader;public class RegistryFactory$Adpative implements com.alibaba.dubbo.registry.RegistryFactory &#123; public com.alibaba.dubbo.registry.Registry getRegistry(com.alibaba.dubbo.common.URL arg0) &#123; if (arg0 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;url &#x3D;&#x3D; null&quot;); com.alibaba.dubbo.common.URL url &#x3D; arg0; String extName &#x3D; ( url.getProtocol() &#x3D;&#x3D; null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.registry.RegistryFactory) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); com.alibaba.dubbo.registry.RegistryFactory extension &#x3D; (com.alibaba.dubbo.registry.RegistryFactory)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.registry.RegistryFactory.class).getExtension(extName); return extension.getRegistry(arg0); &#125;&#125; 所以这里registryFactory.getRegistry(registryUrl)用的是ZookeeperRegistryFactory。 先看下getRegistry方法，会发现该方法会在AbstractRegistryFactory中实现： 1234567891011121314151617181920212223242526272829public Registry getRegistry(URL url) &#123; url &#x3D; url.setPath(RegistryService.class.getName()) .addParameter(Constants.INTERFACE_KEY, RegistryService.class.getName()) .removeParameters(Constants.EXPORT_KEY, Constants.REFER_KEY); &#x2F;&#x2F;这里key为： &#x2F;&#x2F;zookeeper:&#x2F;&#x2F;127.0.0.1:2181&#x2F;com.alibaba.dubbo.registry.RegistryService String key &#x3D; url.toServiceString(); &#x2F;&#x2F; 锁定注册中心获取过程，保证注册中心单一实例 LOCK.lock(); try &#123; &#x2F;&#x2F;先从缓存中获取Registry实例 Registry registry &#x3D; REGISTRIES.get(key); if (registry !&#x3D; null) &#123; return registry; &#125; &#x2F;&#x2F;创建registry，会直接new一个ZookeeperRegistry返回 &#x2F;&#x2F;具体创建实例是子类来实现的 registry &#x3D; createRegistry(url); if (registry &#x3D;&#x3D; null) &#123; throw new IllegalStateException(&quot;Can not create registry &quot; + url); &#125; &#x2F;&#x2F;放到缓存中 REGISTRIES.put(key, registry); return registry; &#125; finally &#123; &#x2F;&#x2F; 释放锁 LOCK.unlock(); &#125;&#125; createRegistry(url);是在子类中实现的，这里是ZookeeperRegistry，首先需要经过AbstractRegistry的构造： 123456789101112131415161718192021222324public AbstractRegistry(URL url) &#123; &#x2F;&#x2F;url保存起来 setUrl(url); &#x2F;&#x2F; 启动文件保存定时器 &#x2F;&#x2F; syncSaveFile &#x3D; url.getParameter(Constants.REGISTRY_FILESAVE_SYNC_KEY, false); &#x2F;&#x2F;保存的文件为： &#x2F;&#x2F;&#x2F;home&#x2F;xxx&#x2F;.dubbo&#x2F;dubbo-registry-127.0.0.1.cache String filename &#x3D; url.getParameter(Constants.FILE_KEY, System.getProperty(&quot;user.home&quot;) + &quot;&#x2F;.dubbo&#x2F;dubbo-registry-&quot; + url.getHost() + &quot;.cache&quot;); File file &#x3D; null; if (ConfigUtils.isNotEmpty(filename)) &#123; file &#x3D; new File(filename); if(! file.exists() &amp;&amp; file.getParentFile() !&#x3D; null &amp;&amp; ! file.getParentFile().exists())&#123; if(! file.getParentFile().mkdirs())&#123; throw new IllegalArgumentException(&quot;Invalid registry store file &quot; + file + &quot;, cause: Failed to create directory &quot; + file.getParentFile() + &quot;!&quot;); &#125; &#125; &#125; this.file &#x3D; file; &#x2F;&#x2F;加载文件中的属性 loadProperties(); &#x2F;&#x2F;通知订阅 notify(url.getBackupUrls());&#125; 获取Registry时的订阅notify()方法： 12345678910111213141516171819202122protected void notify(List&lt;URL&gt; urls) &#123; if(urls &#x3D;&#x3D; null || urls.isEmpty()) return; &#x2F;&#x2F;getSubscribed()方法获取订阅者列表 &#x2F;&#x2F;订阅者Entry里每个URL都对应着n个NotifyListener for (Map.Entry&lt;URL, Set&lt;NotifyListener&gt;&gt; entry : getSubscribed().entrySet()) &#123; URL url &#x3D; entry.getKey(); if(! UrlUtils.isMatch(url, urls.get(0))) &#123; continue; &#125; Set&lt;NotifyListener&gt; listeners &#x3D; entry.getValue(); if (listeners !&#x3D; null) &#123; for (NotifyListener listener : listeners) &#123; try &#123; &#x2F;&#x2F;通知每个监听器 notify(url, listener, filterEmpty(url, urls)); &#125; catch (Throwable t) &#123;&#125; &#125; &#125; &#125;&#125; notify(url, listener, filterEmpty(url, urls));代码： 1234567891011121314151617181920212223242526272829303132protected void notify(URL url, NotifyListener listener, List&lt;URL&gt; urls) &#123; Map&lt;String, List&lt;URL&gt;&gt; result &#x3D; new HashMap&lt;String, List&lt;URL&gt;&gt;(); for (URL u : urls) &#123; if (UrlUtils.isMatch(url, u)) &#123; &#x2F;&#x2F;分类 String category &#x3D; u.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); List&lt;URL&gt; categoryList &#x3D; result.get(category); if (categoryList &#x3D;&#x3D; null) &#123; categoryList &#x3D; new ArrayList&lt;URL&gt;(); result.put(category, categoryList); &#125; categoryList.add(u); &#125; &#125; if (result.size() &#x3D;&#x3D; 0) &#123; return; &#125; Map&lt;String, List&lt;URL&gt;&gt; categoryNotified &#x3D; notified.get(url); if (categoryNotified &#x3D;&#x3D; null) &#123; notified.putIfAbsent(url, new ConcurrentHashMap&lt;String, List&lt;URL&gt;&gt;()); categoryNotified &#x3D; notified.get(url); &#125; for (Map.Entry&lt;String, List&lt;URL&gt;&gt; entry : result.entrySet()) &#123; String category &#x3D; entry.getKey(); List&lt;URL&gt; categoryList &#x3D; entry.getValue(); categoryNotified.put(category, categoryList); &#x2F;&#x2F;保存到主目录下的.dubbo目录下 saveProperties(url); &#x2F;&#x2F;上面获取到的监听器进行通知 listener.notify(categoryList); &#125;&#125; AbstractRegistry构造器初始化完，接着调用FailbackRegistry构造器初始化： 12345678910111213141516public FailbackRegistry(URL url) &#123; super(url); &#x2F;&#x2F;重试时间，默认5000ms int retryPeriod &#x3D; url.getParameter(Constants.REGISTRY_RETRY_PERIOD_KEY, Constants.DEFAULT_REGISTRY_RETRY_PERIOD); &#x2F;&#x2F;启动失败重试定时器 this.retryFuture &#x3D; retryExecutor.scheduleWithFixedDelay(new Runnable() &#123; public void run() &#123; &#x2F;&#x2F; 检测并连接注册中心 try &#123; &#x2F;&#x2F;重试方法由每个具体子类实现 &#x2F;&#x2F;获取到注册失败的，然后尝试注册 retry(); &#125; catch (Throwable t) &#123; &#x2F;&#x2F; 防御性容错&#125; &#125; &#125;, retryPeriod, retryPeriod, TimeUnit.MILLISECONDS);&#125; 最后回到ZookeeperRegistry的构造初始化： 12345678910111213141516171819202122232425262728293031public ZookeeperRegistry(URL url, ZookeeperTransporter zookeeperTransporter) &#123; super(url); if (url.isAnyHost()) &#123; throw new IllegalStateException(&quot;registry address &#x3D;&#x3D; null&quot;); &#125; &#x2F;&#x2F;获得到注册中心中的分组，默认dubbo String group &#x3D; url.getParameter(Constants.GROUP_KEY, DEFAULT_ROOT); if (! group.startsWith(Constants.PATH_SEPARATOR)) &#123; group &#x3D; Constants.PATH_SEPARATOR + group; &#125; &#x2F;&#x2F;注册到注册中心的节点 this.root &#x3D; group; &#x2F;&#x2F;使用zookeeperTansporter去连接 &#x2F;&#x2F;ZookeeperTransport这里是生成的自适应实现，默认使用ZkClientZookeeperTransporter &#x2F;&#x2F;ZkClientZookeeperTransporter的connect去实例化一个ZkClient实例 &#x2F;&#x2F;并且订阅状态变化的监听器subscribeStateChanges &#x2F;&#x2F;然后返回一个ZkClientZookeeperClient实例 zkClient &#x3D; zookeeperTransporter.connect(url); &#x2F;&#x2F;ZkClientZookeeperClient添加状态改变监听器 zkClient.addStateListener(new StateListener() &#123; public void stateChanged(int state) &#123; if (state &#x3D;&#x3D; RECONNECTED) &#123; try &#123; recover(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; &#125; &#125; &#125;);&#125; 获取注册到注册中心的url获取到了Registry，Registry实例中保存着连接到了zookeeper的zkClient实例之后，下一步获取要注册到注册中心的url（在RegistryProtocol中）。 123456final URL registedProviderUrl &#x3D; getRegistedProviderUrl(originInvoker);&#x2F;&#x2F;得到的URL是：&#x2F;&#x2F;dubbo:&#x2F;&#x2F;192.168.1.100:20880&#x2F;dubbo.common.hello.service.HelloService?&#x2F;&#x2F;anyhost&#x3D;true&amp;application&#x3D;dubbo-provider&amp;application.version&#x3D;1.0&amp;dubbo&#x3D;2.5.3&amp;environment&#x3D;product&amp;&#x2F;&#x2F;interface&#x3D;dubbo.common.hello.service.HelloService&amp;methods&#x3D;sayHello&amp;&#x2F;&#x2F;organization&#x3D;china&amp;owner&#x3D;cheng.xi&amp;pid&#x3D;9457&amp;side&#x3D;provider&amp;timestamp&#x3D;1489807681627 注册到注册中心然后调用registry.register(registedProviderUrl)注册到注册中心（在RegistryProtocol中）。register方法的实现在FailbackRegistry中： 123456789101112131415161718192021222324252627public void register(URL url) &#123; super.register(url); failedRegistered.remove(url); failedUnregistered.remove(url); try &#123; &#x2F;&#x2F; 向服务器端发送注册请求 &#x2F;&#x2F;调用子类具体实现，发送注册请求 doRegister(url); &#125; catch (Exception e) &#123; Throwable t &#x3D; e; &#x2F;&#x2F; 如果开启了启动时检测，则直接抛出异常 boolean check &#x3D; getUrl().getParameter(Constants.CHECK_KEY, true) &amp;&amp; url.getParameter(Constants.CHECK_KEY, true) &amp;&amp; ! Constants.CONSUMER_PROTOCOL.equals(url.getProtocol()); boolean skipFailback &#x3D; t instanceof SkipFailbackWrapperException; if (check || skipFailback) &#123; if(skipFailback) &#123; t &#x3D; t.getCause(); &#125; throw 。。。 &#125; else &#123; &#125; &#x2F;&#x2F; 将失败的注册请求记录到失败列表，定时重试 failedRegistered.add(url); &#125;&#125; doRegister(url);在这里是ZookeeperRegistry中具体实现的，这里将会注册到注册中心： 12345678910111213141516protected void doRegister(URL url) &#123; try &#123; &#x2F;&#x2F;这里zkClient就是我们上面调用构造的时候生成的 &#x2F;&#x2F;ZkClientZookeeperClient &#x2F;&#x2F;保存着连接到Zookeeper的zkClient实例 &#x2F;&#x2F;开始注册，也就是在Zookeeper中创建节点 &#x2F;&#x2F;这里toUrlPath获取到的path为： &#x2F;&#x2F;&#x2F;dubbo&#x2F;dubbo.common.hello.service.HelloService&#x2F;providers&#x2F;dubbo%3A%2F%2F192.168.1.100%3A20880%2F &#x2F;&#x2F;dubbo.common.hello.service.HelloService%3Fanyhost%3Dtrue%26application%3Ddubbo-provider%26 &#x2F;&#x2F;application.version%3D1.0%26dubbo%3D2.5.3%26environment%3Dproduct%26interface%3D &#x2F;&#x2F;dubbo.common.hello.service.HelloService%26methods%3DsayHello%26 &#x2F;&#x2F;organization%3Dchina%26owner%3Dcheng.xi%26pid%3D8920%26side%3Dprovider%26timestamp%3D1489828029449 &#x2F;&#x2F;默认创建的节点是临时节点 zkClient.create(toUrlPath(url), url.getParameter(Constants.DYNAMIC_KEY, true)); &#125; catch (Throwable e) &#123; &#125;&#125; 经过这一步之后，Zookeeper中就有节点存在了，具体节点为： 12345678910&#x2F;dubbo dubbo.common.hello.service.HelloService providers &#x2F;dubbo&#x2F;dubbo.common.hello.service.HelloService&#x2F;providers&#x2F; dubbo%3A%2F%2F192.168.1.100%3A20880%2Fdubbo.common.hello.service.HelloService%3F anyhost%3Dtrue%26application%3Ddubbo-provider%26 application.version%3D1.0%26dubbo%3D2.5.3%26environment%3Dproduct%26 interface%3Ddubbo.common.hello.service.HelloService%26methods%3DsayHello%26 organization%3Dchina%26owner%3Dcheng.xi%26pid%3D13239%26side%3D provider%26timestamp%3D1489829293525 订阅注册中心的服务在注册到注册中心之后，registry会去订阅覆盖配置的服务，这一步之后就会在/dubbo/dubbo.common.hello.service/HelloService节点下多一个configurators节点。（具体过程暂先不解析）。 返回新Exporter实例最后返回Exporter新实例，返回到ServiceConfig中。服务的发布就算完成了。 交给具体的协议进行服务暴露这里也就是非Registry类型的Invoker的导出过程。主要的步骤是将本地ip和20880端口打开，进行监听。最后包装成exporter返回。 doLocalExport(invoker)： 12345678910111213141516171819202122232425262728293031323334private &lt;T&gt; ExporterChangeableWrapper&lt;T&gt; doLocalExport(final Invoker&lt;T&gt; originInvoker)&#123; &#x2F;&#x2F;原始的invoker中的url： &#x2F;&#x2F;registry:&#x2F;&#x2F;127.0.0.1:2181&#x2F;com.alibaba.dubbo.registry.RegistryService? &#x2F;&#x2F;application&#x3D;dubbo-provider&amp;application.version&#x3D;1.0&amp;dubbo&#x3D;2.5.3 &#x2F;&#x2F;&amp;environment&#x3D;product&amp;export&#x3D;dubbo%3A%2F%2F10.42.0.1%3A20880%2F &#x2F;&#x2F;dubbo.common.hello.service.HelloService%3Fanyhost%3Dtrue%26application%3Ddubbo-provider%26 &#x2F;&#x2F;application.version%3D1.0%26dubbo%3D2.5.3%26environment%3Dproduct%26 &#x2F;&#x2F;interface%3Ddubbo.common.hello.service.HelloService%26methods%3DsayHello%26 &#x2F;&#x2F;organization%3Dchina%26owner%3Dcheng.xi%26pid%3D7876%26side%3Dprovider%26timestamp%3D1489057305001&amp; &#x2F;&#x2F;organization&#x3D;china&amp;owner&#x3D;cheng.xi&amp;pid&#x3D;7876&amp;registry&#x3D;zookeeper&amp;timestamp&#x3D;1489057304900 &#x2F;&#x2F;从原始的invoker中得到的key： &#x2F;&#x2F;dubbo:&#x2F;&#x2F;10.42.0.1:20880&#x2F;dubbo.common.hello.service.HelloService?anyhost&#x3D;true&amp;application&#x3D;dubbo-provider&amp; &#x2F;&#x2F;application.version&#x3D;1.0&amp;dubbo&#x3D;2.5.3&amp;environment&#x3D;product&amp;interface&#x3D;dubbo.common.hello.service.HelloService&amp; &#x2F;&#x2F;methods&#x3D;sayHello&amp;organization&#x3D;china&amp;owner&#x3D;cheng.xi&amp;pid&#x3D;7876&amp;side&#x3D;provider&amp;timestamp&#x3D;1489057305001 String key &#x3D; getCacheKey(originInvoker); ExporterChangeableWrapper&lt;T&gt; exporter &#x3D; (ExporterChangeableWrapper&lt;T&gt;) bounds.get(key); if (exporter &#x3D;&#x3D; null) &#123; synchronized (bounds) &#123; exporter &#x3D; (ExporterChangeableWrapper&lt;T&gt;) bounds.get(key); if (exporter &#x3D;&#x3D; null) &#123; &#x2F;&#x2F;得到一个Invoker代理，里面包含原来的Invoker final Invoker&lt;?&gt; invokerDelegete &#x3D; new InvokerDelegete&lt;T&gt;(originInvoker, getProviderUrl(originInvoker)); &#x2F;&#x2F;此处protocol还是最上面生成的代码，调用代码中的export方法，会根据协议名选择调用具体的实现类 &#x2F;&#x2F;这里我们需要调用DubboProtocol的export方法 &#x2F;&#x2F;这里的使用具体协议进行导出的invoker是个代理invoker &#x2F;&#x2F;导出完之后，返回一个新的ExporterChangeableWrapper实例 exporter &#x3D; new ExporterChangeableWrapper&lt;T&gt;((Exporter&lt;T&gt;)protocol.export(invokerDelegete), originInvoker); bounds.put(key, exporter); &#125; &#125; &#125; return (ExporterChangeableWrapper&lt;T&gt;) exporter;&#125; 使用dubbo协议导出这里protocol.export(invokerDelegete)就要去具体的DubboProtocol中执行了，DubboProtocol的外面包裹着ProtocolFilterWrapper，再外面还包裹着ProtocolListenerWrapper。会先经过ProtocolListenerWrapper： 1234567891011121314public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; &#x2F;&#x2F;Registry类型的Invoker if (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123; return protocol.export(invoker); &#125; &#x2F;&#x2F;其他具体协议类型的Invoker &#x2F;&#x2F;先进行导出protocol.export(invoker) &#x2F;&#x2F;然后获取自适应的监听器 &#x2F;&#x2F;最后返回的是包装了监听器的Exporter &#x2F;&#x2F;这里监听器的获取是getActivateExtension，如果指定了listener就加载实现，没有指定就不加载 return new ListenerExporterWrapper&lt;T&gt;(protocol.export(invoker), Collections.unmodifiableList(ExtensionLoader.getExtensionLoader(ExporterListener.class) .getActivateExtension(invoker.getUrl(), Constants.EXPORTER_LISTENER_KEY)));&#125; 再经过ProtocolFilterWrapper： 123456789public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; &#x2F;&#x2F;Registry类型的Invoker if (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) &#123; return protocol.export(invoker); &#125; &#x2F;&#x2F;其他具体协议类型的Invoker &#x2F;&#x2F;先构建Filter链，然后再导出 return protocol.export(buildInvokerChain(invoker, Constants.SERVICE_FILTER_KEY, Constants.PROVIDER));&#125; 查看下构建Invoker链的方法： 1234567891011121314151617181920212223242526272829303132333435363738394041private static &lt;T&gt; Invoker&lt;T&gt; buildInvokerChain(final Invoker&lt;T&gt; invoker, String key, String group) &#123; &#x2F;&#x2F;我们要处理的那个Invoker作为处理链的最后一个 Invoker&lt;T&gt; last &#x3D; invoker; &#x2F;&#x2F;根据key和group获取自动激活的Filter List&lt;Filter&gt; filters &#x3D; ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group); if (filters.size() &gt; 0) &#123; &#x2F;&#x2F;把所有的过滤器都挨个连接起来，最后一个是我们真正的Invoker for (int i &#x3D; filters.size() - 1; i &gt;&#x3D; 0; i --) &#123; final Filter filter &#x3D; filters.get(i); final Invoker&lt;T&gt; next &#x3D; last; last &#x3D; new Invoker&lt;T&gt;() &#123; public Class&lt;T&gt; getInterface() &#123; return invoker.getInterface(); &#125; public URL getUrl() &#123; return invoker.getUrl(); &#125; public boolean isAvailable() &#123; return invoker.isAvailable(); &#125; public Result invoke(Invocation invocation) throws RpcException &#123; return filter.invoke(next, invocation); &#125; public void destroy() &#123; invoker.destroy(); &#125; @Override public String toString() &#123; return invoker.toString(); &#125; &#125;; &#125; &#125; return last;&#125; 接着就到了DubboProtocol的export方法，这里进行暴露服务： 12345678910111213141516171819202122232425262728293031323334353637383940414243public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException &#123; &#x2F;&#x2F;dubbo:&#x2F;&#x2F;10.42.0.1:20880&#x2F;dubbo.common.hello.service.HelloService? &#x2F;&#x2F;anyhost&#x3D;true&amp;application&#x3D;dubbo-provider&amp; &#x2F;&#x2F;application.version&#x3D;1.0&amp;dubbo&#x3D;2.5.3&amp;environment&#x3D;product&amp; &#x2F;&#x2F;interface&#x3D;dubbo.common.hello.service.HelloService&amp; &#x2F;&#x2F;methods&#x3D;sayHello&amp;organization&#x3D;china&amp;owner&#x3D;cheng.xi&amp; &#x2F;&#x2F;pid&#x3D;7876&amp;side&#x3D;provider&amp;timestamp&#x3D;1489057305001 URL url &#x3D; invoker.getUrl(); &#x2F;&#x2F; export service. &#x2F;&#x2F;key由serviceName，port，version，group组成 &#x2F;&#x2F;当nio客户端发起远程调用时，nio服务端通过此key来决定调用哪个Exporter，也就是执行的Invoker。 &#x2F;&#x2F;dubbo.common.hello.service.HelloService:20880 String key &#x3D; serviceKey(url); &#x2F;&#x2F;将Invoker转换成Exporter &#x2F;&#x2F;直接new一个新实例 &#x2F;&#x2F;没做啥处理，就是做一些赋值操作 &#x2F;&#x2F;这里的exporter就包含了invoker DubboExporter&lt;T&gt; exporter &#x3D; new DubboExporter&lt;T&gt;(invoker, key, exporterMap); &#x2F;&#x2F;缓存要暴露的服务，key是上面生成的 exporterMap.put(key, exporter); &#x2F;&#x2F;export an stub service for dispaching event &#x2F;&#x2F;是否支持本地存根 &#x2F;&#x2F;远程服务后，客户端通常只剩下接口，而实现全在服务器端， &#x2F;&#x2F;但提供方有些时候想在客户端也执行部分逻辑，比如：做ThreadLocal缓存， &#x2F;&#x2F;提前验证参数，调用失败后伪造容错数据等等，此时就需要在API中带上Stub， &#x2F;&#x2F;客户端生成Proxy实，会把Proxy通过构造函数传给Stub， &#x2F;&#x2F;然后把Stub暴露组给用户，Stub可以决定要不要去调Proxy。 Boolean isStubSupportEvent &#x3D; url.getParameter(Constants.STUB_EVENT_KEY,Constants.DEFAULT_STUB_EVENT); Boolean isCallbackservice &#x3D; url.getParameter(Constants.IS_CALLBACK_SERVICE, false); if (isStubSupportEvent &amp;&amp; !isCallbackservice)&#123; String stubServiceMethods &#x3D; url.getParameter(Constants.STUB_EVENT_METHODS_KEY); if (stubServiceMethods &#x3D;&#x3D; null || stubServiceMethods.length() &#x3D;&#x3D; 0 )&#123; &#125; else &#123; stubServiceMethodsMap.put(url.getServiceKey(), stubServiceMethods); &#125; &#125; &#x2F;&#x2F;根据URL绑定IP与端口，建立NIO框架的Server openServer(url); return exporter;&#125; 上面得到的Exporter会被放到缓存中去，key就是上面生成的，客户端就可以发请求根据key找到Exporter，然后找到invoker进行调用了。接下来是创建服务器并监听端口。 接着调用openServer方法创建NIO Server进行监听： 123456789101112131415161718192021222324private void openServer(URL url) &#123; &#x2F;&#x2F; find server. &#x2F;&#x2F;key是IP:PORT &#x2F;&#x2F;192.168.110.197:20880 String key &#x3D; url.getAddress(); &#x2F;&#x2F;client 也可以暴露一个只有server可以调用的服务。 boolean isServer &#x3D; url.getParameter(Constants.IS_SERVER_KEY,true); if (isServer) &#123; ExchangeServer server &#x3D; serverMap.get(key); &#x2F;&#x2F;同一JVM中，同协议的服务，共享同一个Server， &#x2F;&#x2F;第一个暴露服务的时候创建server， &#x2F;&#x2F;以后相同协议的服务都使用同一个server if (server &#x3D;&#x3D; null) &#123; serverMap.put(key, createServer(url)); &#125; else &#123; &#x2F;&#x2F;同协议的服务后来暴露服务的则使用第一次创建的同一Server &#x2F;&#x2F;server支持reset,配合override功能使用 &#x2F;&#x2F;accept、idleTimeout、threads、heartbeat参数的变化会引起Server的属性发生变化 &#x2F;&#x2F;这时需要重新设置Server server.reset(url); &#125; &#125;&#125; 继续看createServer方法： 12345678910111213141516171819202122232425262728293031323334353637&#x2F;&#x2F;url为：&#x2F;&#x2F;dubbo:&#x2F;&#x2F;192.168.110.197:20880&#x2F;dubbo.common.hello.service.HelloService?&#x2F;&#x2F;anyhost&#x3D;true&amp;application&#x3D;dubbo-provider&amp;&#x2F;&#x2F;application.version&#x3D;1.0&amp;dubbo&#x3D;2.5.3&amp;environment&#x3D;product&amp;&#x2F;&#x2F;interface&#x3D;dubbo.common.hello.service.HelloService&amp;&#x2F;&#x2F;methods&#x3D;sayHello&amp;organization&#x3D;china&amp;owner&#x3D;cheng.xi&amp;&#x2F;&#x2F;pid&#x3D;720&amp;side&#x3D;provider&amp;timestamp&#x3D;1489716708276private ExchangeServer createServer(URL url) &#123; &#x2F;&#x2F;默认开启server关闭时发送readonly事件 url &#x3D; url.addParameterIfAbsent(Constants.CHANNEL_READONLYEVENT_SENT_KEY, Boolean.TRUE.toString()); &#x2F;&#x2F;默认开启heartbeat url &#x3D; url.addParameterIfAbsent(Constants.HEARTBEAT_KEY, String.valueOf(Constants.DEFAULT_HEARTBEAT)); &#x2F;&#x2F;默认使用netty String str &#x3D; url.getParameter(Constants.SERVER_KEY, Constants.DEFAULT_REMOTING_SERVER); if (str !&#x3D; null &amp;&amp; str.length() &gt; 0 &amp;&amp; ! ExtensionLoader.getExtensionLoader(Transporter.class).hasExtension(str)) throw new RpcException(&quot;Unsupported server type: &quot; + str + &quot;, url: &quot; + url); url &#x3D; url.addParameter(Constants.CODEC_KEY, Version.isCompatibleVersion() ? COMPATIBLE_CODEC_NAME : DubboCodec.NAME); ExchangeServer server; try &#123; &#x2F;&#x2F;Exchangers是门面类，里面封装的是Exchanger的逻辑。 &#x2F;&#x2F;Exchanger默认只有一个实现HeaderExchanger. &#x2F;&#x2F;Exchanger负责数据交换和网络通信。 &#x2F;&#x2F;从Protocol进入Exchanger，标志着程序进入了remote层。 &#x2F;&#x2F;这里requestHandler是ExchangeHandlerAdapter server &#x3D; Exchangers.bind(url, requestHandler); &#125; catch (RemotingException e) &#123; &#125; str &#x3D; url.getParameter(Constants.CLIENT_KEY); if (str !&#x3D; null &amp;&amp; str.length() &gt; 0) &#123; Set&lt;String&gt; supportedTypes &#x3D; ExtensionLoader.getExtensionLoader(Transporter.class).getSupportedExtensions(); if (!supportedTypes.contains(str)) &#123; throw new RpcException(&quot;Unsupported client type: &quot; + str); &#125; &#125; return server;&#125; Exchangers.bind方法： 123456public static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; url &#x3D; url.addParameterIfAbsent(Constants.CODEC_KEY, &quot;exchange&quot;); &#x2F;&#x2F;getExchanger方法根据url获取到一个默认的实现HeaderExchanger &#x2F;&#x2F;调用HeaderExchanger的bind方法 return getExchanger(url).bind(url, handler);&#125; HeaderExchanger的bind方法： 1234567public ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException &#123; &#x2F;&#x2F;直接返回一个HeaderExchangeServer &#x2F;&#x2F;先创建一个HeaderExchangeHandler &#x2F;&#x2F;再创建一个DecodeHandler &#x2F;&#x2F;最后调用Transporters.bind return new HeaderExchangeServer(Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))));&#125; 这里会先创建一个HeaderExchangerHandler，包含着ExchangeHandlerAdapter，接着创建一个DecodeHandler，会包含前面的handler，接下来调用Transporters的bind方法，返回一个Server，接着用HeaderExchangeServer包装一下，就返回给Protocol层了。 在HeaderExchangerServer包装的时候会启动心跳定时器startHeatbeatTimer();，暂不解析。 Transports的bind方法： 123456789101112public static Server bind(URL url, ChannelHandler... handlers) throws RemotingException &#123; ChannelHandler handler; if (handlers.length &#x3D;&#x3D; 1) &#123; handler &#x3D; handlers[0]; &#125; else &#123; &#x2F;&#x2F;如果有多个handler的话，需要使用分发器包装下 handler &#x3D; new ChannelHandlerDispatcher(handlers); &#125; &#x2F;&#x2F;getTransporter()获取一个Adaptive的Transporter &#x2F;&#x2F;然后调用bind方法（默认是NettyTransporter的bind方法） return getTransporter().bind(url, handler);&#125; getTransporter()生成的Transporter的代码如下： 123456789101112131415161718192021222324252627import com.alibaba.dubbo.common.extension.ExtensionLoader;public class Transporter$Adpative implements com.alibaba.dubbo.remoting.Transporter &#123; public com.alibaba.dubbo.remoting.Server bind(com.alibaba.dubbo.common.URL arg0, com.alibaba.dubbo.remoting.ChannelHandler arg1) throws com.alibaba.dubbo.common.URL &#123; if (arg0 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;url &#x3D;&#x3D; null&quot;); com.alibaba.dubbo.common.URL url &#x3D; arg0; &#x2F;&#x2F;Server默认使用netty String extName &#x3D; url.getParameter(&quot;server&quot;, url.getParameter(&quot;transporter&quot;, &quot;netty&quot;)); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.remoting.Transporter) name from url(&quot; + url.toString() + &quot;) use keys([server, transporter])&quot;); &#x2F;&#x2F;获取到一个NettyTransporter com.alibaba.dubbo.remoting.Transporter extension &#x3D; (com.alibaba.dubbo.remoting.Transporter)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.remoting.Transporter.class).getExtension(extName); &#x2F;&#x2F;调用NettyTransporter的bind方法 return extension.bind(arg0, arg1); &#125; public com.alibaba.dubbo.remoting.Client connect(com.alibaba.dubbo.common.URL arg0, com.alibaba.dubbo.remoting.ChannelHandler arg1) throws com.alibaba.dubbo.common.URL &#123; if (arg0 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;url &#x3D;&#x3D; null&quot;); com.alibaba.dubbo.common.URL url &#x3D; arg0; String extName &#x3D; url.getParameter(&quot;client&quot;, url.getParameter(&quot;transporter&quot;, &quot;netty&quot;)); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.remoting.Transporter) name from url(&quot; + url.toString() + &quot;) use keys([client, transporter])&quot;); com.alibaba.dubbo.remoting.Transporter extension &#x3D; (com.alibaba.dubbo.remoting.Transporter)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.remoting.Transporter.class).getExtension(extName); return extension.connect(arg0, arg1);&#125;&#125; NettyTransporter的bind方法： 1234 public Server bind(URL url, ChannelHandler listener) throws RemotingException &#123; &#x2F;&#x2F;创建一个Server return new NettyServer(url, listener);&#125; 12345public NettyServer(URL url, ChannelHandler handler) throws RemotingException&#123; &#x2F;&#x2F;handler先经过ChannelHandlers的包装方法 &#x2F;&#x2F;然后再初始化 super(url, ChannelHandlers.wrap(handler, ExecutorUtil.setThreadName(url, SERVER_THREAD_POOL_NAME)));&#125; ChannelHandlers.wrap方法中会根据SPI扩展机制动态生成Dispatcher的自适应类，生成的代码不在列出，默认使用AllDispatcher处理，会返回一个AllChannelHandler，会把线程池和DataStore都初始化了。然后经过HeartbeatHandler封装，再经过MultiMessageHandler封装后返回。 NettyServer构造，会依次经过AbstractPeer，AbstractEndpoint，AbstractServer，NettyServer的初始化。重点看下AbstractServer的构造方法： 123456789101112131415161718public AbstractServer(URL url, ChannelHandler handler) throws RemotingException &#123; super(url, handler); localAddress &#x3D; getUrl().toInetSocketAddress(); String host &#x3D; url.getParameter(Constants.ANYHOST_KEY, false) || NetUtils.isInvalidLocalHost(getUrl().getHost()) ? NetUtils.ANYHOST : getUrl().getHost(); bindAddress &#x3D; new InetSocketAddress(host, getUrl().getPort()); this.accepts &#x3D; url.getParameter(Constants.ACCEPTS_KEY, Constants.DEFAULT_ACCEPTS); this.idleTimeout &#x3D; url.getParameter(Constants.IDLE_TIMEOUT_KEY, Constants.DEFAULT_IDLE_TIMEOUT); try &#123; &#x2F;&#x2F;初始化的时候会打开Server &#x2F;&#x2F;具体实现这里是NettyServer中 doOpen(); &#125; catch (Throwable t) &#123; &#125; if (handler instanceof WrappedChannelHandler )&#123; executor &#x3D; ((WrappedChannelHandler)handler).getExecutor(); &#125;&#125; 然后调用doOpen方法： 12345678910111213141516171819202122232425protected void doOpen() throws Throwable &#123; NettyHelper.setNettyLoggerFactory(); &#x2F;&#x2F;boss线程池 ExecutorService boss &#x3D; Executors.newCachedThreadPool(new NamedThreadFactory(&quot;NettyServerBoss&quot;, true)); &#x2F;&#x2F;worker线程池 ExecutorService worker &#x3D; Executors.newCachedThreadPool(new NamedThreadFactory(&quot;NettyServerWorker&quot;, true)); &#x2F;&#x2F;ChannelFactory，没有指定工作者线程数量，就使用cpu+1 ChannelFactory channelFactory &#x3D; new NioServerSocketChannelFactory(boss, worker, getUrl().getPositiveParameter(Constants.IO_THREADS_KEY, Constants.DEFAULT_IO_THREADS)); bootstrap &#x3D; new ServerBootstrap(channelFactory); final NettyHandler nettyHandler &#x3D; new NettyHandler(getUrl(), this); channels &#x3D; nettyHandler.getChannels(); bootstrap.setPipelineFactory(new ChannelPipelineFactory() &#123; public ChannelPipeline getPipeline() &#123; NettyCodecAdapter adapter &#x3D; new NettyCodecAdapter(getCodec() ,getUrl(), NettyServer.this); ChannelPipeline pipeline &#x3D; Channels.pipeline(); pipeline.addLast(&quot;decoder&quot;, adapter.getDecoder()); pipeline.addLast(&quot;encoder&quot;, adapter.getEncoder()); pipeline.addLast(&quot;handler&quot;, nettyHandler); return pipeline; &#125; &#125;); &#x2F;&#x2F; bind之后返回一个Channel channel &#x3D; bootstrap.bind(getBindAddress());&#125; doOpen方法创建Netty的Server端并打开，具体的事情就交给Netty去处理了，Netty的过程，原理，代码有时间再另行研究。 NIO框架接受到消息后，先由NettyCodecAdapter解码，再由NettyHandler处理具体的业务逻辑，再由NettyCodecAdapter编码后发送。 NettyServer既是Server又是Handler。 HeaderExchangerServer只是Server。 MultiMessageHandler是多消息处理Handler。 HeartbeatHandler是处理心跳事件的Handler。 AllChannelHandler是消息派发器，负责将请求放入线程池，并执行请求。 DecodeHandler是编解码Handler。 HeaderExchangerHandler是信息交换Handler，将请求转化成请求响应模式与同步转异步模式。 RequestHandler是最后执行的Handler，会在协议层选择Exporter后选择Invoker，进而执行Filter与Invoker，最终执行请求服务实现类方法。 Channel直接触发事件并执行Handler，Channel在有客户端连接Server的时候触发创建并封装成NettyChannel，再由HeaderExchangerHandler创建HeaderExchangerChannel，负责请求响应模式的处理。 NettyChannel其实是个Handler，HeaderExchangerChannel是个Channel， 消息的序列化与反序列化工作在NettyCodecAdapter中发起完成。 当有客户端连接Server时的连接过程： NettyHandler.connected() NettyServer.connected() MultiMessageHandler.connected() HeartbeatHandler.connected() AllChannelHandler.connected() DecodeHandler.connected() HeaderExchangerHandler.connected() requestHandler.connected() 执行服务的onconnect事件的监听方法 名词解释Invoker可执行的对象，执行具体的远程调用，能够根据方法名称，参数得到相应的执行结果。 Invocation，包含了需要执行的方法，参数等信息。目前实现类只有RpcInvocation。 有三种类型的Invoker： 本地执行类的Invoker。 远程通信执行类的Invoker。 多个远程通信执行类的Invoker聚合成集群版的Invoker。 以HelloService为例： 本地执行类的Invoker：在Server端有HelloServiceImpl实现，要执行该接口，只需要通过反射执行对应的实现类即可。 远程通信执行类的Invoker：在Client端要想执行该接口的实现方法，需要先进行远程通信，发送要执行的参数信息给Server端，Server端利用本地执行Invoker的方式执行，最后将结果发送给Client。 集群版的Invoker：Client端使用的时候，通过集群版的Invoker操作，Invoker会挑选一个远程通信类型的Invoker来执行。 提供者端的Invoker封装了服务实现类，URL，Type，状态都是只读并且线程安全。通过发起invoke来具体调用服务类。 ProxyFactory在服务提供者端，ProxyFactory主要服务的实现统一包装成一个Invoker，Invoker通过反射来执行具体的Service实现对象的方法。默认的实现是JavassistProxyFactory，代码如下： 123456789101112public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) &#123; &#x2F;&#x2F; TODO Wrapper类不能正确处理带$的类名 final Wrapper wrapper &#x3D; Wrapper.getWrapper(proxy.getClass().getName().indexOf(&#39;$&#39;) &lt; 0 ? proxy.getClass() : type); return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) &#123; @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable &#123; return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); &#125; &#125;;&#125; Protocol服务地址的发布和订阅。 Protocol是dubbo中的服务域，只在服务启用时加载，无状态，线程安全，是实体域Invoker暴露和引用的主功能入口，负责Invoker的生命周期管理，是Dubbo中远程服务调用层。 Protocol根据指定协议对外公布服务，当客户端根据协议调用这个服务时，Protocol会将客户端传递过来的Invocation参数交给Invoker去执行。 Protocol加入了远程通信协议，会根据客户端的请求来获取参数Invocation。 12345678910111213141516171819@Extension(&quot;dubbo&quot;)public interface Protocol &#123; int getDefaultPort(); &#x2F;&#x2F;对于服务提供端，将本地执行类的Invoker通过协议暴漏给外部 &#x2F;&#x2F;外部可以通过协议发送执行参数Invocation，然后交给本地Invoker来执行 @Adaptive &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException; &#x2F;&#x2F;这个是针对服务消费端的，服务消费者从注册中心获取服务提供者发布的服务信息 &#x2F;&#x2F;通过服务信息得知服务提供者使用的协议，然后服务消费者仍然使用该协议构造一个Invoker。这个Invoker是远程通信类的Invoker。 &#x2F;&#x2F;执行时，需要将执行信息通过指定协议发送给服务提供者，服务提供者接收到参数Invocation，然后交给服务提供者的本地Invoker来执行 @Adaptive &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException; void destroy();&#125; 关于RegistryProtocol和DubboProtocol的疑惑以下是官方文档说明： 暴露服务: (1) 只暴露服务端口： 在没有注册中心，直接暴露提供者的情况下，即：&lt;dubbo:service regisrty=&quot;N/A&quot; /&gt; or &lt;dubbo:registry address=&quot;N/A&quot; /&gt; ServiceConfig解析出的URL的格式为：dubbo://service-host/com.foo.FooService?version=1.0.0 基于扩展点的Adaptive机制，通过URL的”dubbo://“协议头识别，直接调用DubboProtocol的export()方法，打开服务端口。 (2) 向注册中心暴露服务： 在有注册中心，需要注册提供者地址的情况下，即：&lt;dubbo:registry address=&quot;zookeeper://10.20.153.10:2181&quot; /&gt; ServiceConfig解析出的URL的格式为：registry://registry-host/com.alibaba.dubbo.registry.RegistryService?export=URL.encode(&quot;dubbo://service-host/com.foo.FooService?version=1.0.0&quot;) 基于扩展点的Adaptive机制，通过URL的”registry://“协议头识别，就会调用RegistryProtocol的export()方法，将export参数中的提供者URL，先注册到注册中心，再重新传给Protocol扩展点进行暴露：dubbo://service-host/com.foo.FooService?version=1.0.0 基于扩展点的Adaptive机制，通过提供者URL的”dubbo://“协议头识别，就会调用DubboProtocol的export()方法，打开服务端口。 RegistryProtocol，注册中心协议集成，装饰真正暴露引用服务的协议，增强注册发布功能。 ServiceConfig中的protocol是被多层装饰的Protocol，是DubboProtocol+RegistryProtocol+ProtocolListenerWrapper+ProtocolFilterWrapper。 ProtocolFilterWrapper负责初始化invoker所有的Filter。 ProtocolListenerWrapper负责初始化暴露或引用服务的监听器。 RegistryProtocol负责注册服务到注册中心和向注册中心订阅服务。 DubboProtocol负责服务的具体暴露与引用，也负责网络传输层，信息交换层的初始化，以及底层NIO框架的初始化。 Exporter负责invoker的生命周期，包含一个Invoker对象，可以撤销服务。 Exchanger负责数据交换和网络通信的组件。每个Invoker都维护了一个ExchangeClient的 引用，并通过它和远端server进行通信。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Dubbo中SPI扩展机制详解]]></title>
      <url>%2F2017%2F02%2F18%2FDubbo%E4%B8%ADSPI%E6%89%A9%E5%B1%95%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[前面我们了解过了Java的SPI扩展机制，对于Java扩展机制的原理以及优缺点也有了大概的了解，这里继续深入一下Dubbo的扩展点加载机制。 Dubbo扩展点加载的功能Dubbo的扩展点加载机制类似于Java的SPI，我们知道Java的SPI在使用的时候，只能通过遍历来进行实现的查找和实例化，有可能会一次性把所有的实现都实例化，这样会造成有些不使用的扩展实现也会被实例化，这就会造成一定的资源浪费。有关Dubbo的改进，参照文档上的说明： JDK标准的SPI会一次性实例化扩展点所有实现，如果有扩展实现初始化很耗时，但如果没用上也加载，会很浪费资源。 如果扩展点加载失败，连扩展点的名称都拿不到了。比如：JDK标准的ScriptEngine，通过getName();获取脚本类型的名称，但如果RubyScriptEngine因为所依赖的jruby.jar不存在，导致RubyScriptEngine类加载失败，这个失败原因被吃掉了，和ruby对应不起来，当用户执行ruby脚本时，会报不支持ruby，而不是真正失败的原因。 增加了对扩展点IoC和AOP的支持，一个扩展点可以直接setter注入其它扩展点。 关于第一点，通过和Java的SPI对比，就能明白；第二点还未做测试，不太清楚其中的缘由；第三点对于IOC和AOP的支持下面简单介绍下。 扩展点自动装配功能（IOC）就是当加载一个扩展点时，会自动的注入这个扩展点所依赖的其他扩展点，如果描述不清楚的话，可以看下下面的例子： 12接口A，实现类A1，A2接口B，实现类B1，B2 其中实现类A1含有setB()方法，当通过扩展机制加载A的实现的时候，会自动的注入一个B的实现类，但是，此时不是注入B1，也不是注入B2，而是注入一个自适应的B的实现类：B$Adpative，该实现类是动态生成的，能够根据参数的不同，自动选择B1或者B2来进行调用。 扩展点自适应上面我们说，在自动装配的时候，并不是注入一个真正的实现，而是注入一个自适应的扩展点实现，其实就是动态的生成的代码，也就是手动拼装的代码，这段代码里会根据SPI上配置的信息来加入对于具体实现的选择功能。生成的代码类似于下面的，代码做了一下精简，把包都去掉了： 12345678910111213141516171819202122232425262728293031323334353637import com.alibaba.dubbo.common.extension.ExtensionLoader;public class Protocol$Adpative implements Protocol &#123; public Invoker refer(Class arg0, URL arg1) throws Class &#123; if (arg1 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;url &#x3D;&#x3D; null&quot;); URL url &#x3D; arg1; String extName &#x3D; ( url.getProtocol() &#x3D;&#x3D; null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); Protocol extension &#x3D; (Protocol)ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); &#125; public Exporter export(Invoker arg0) throws Invoker &#123; if (arg0 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;Invoker argument &#x3D;&#x3D; null&quot;); if (arg0.getUrl() &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;Invoker argument getUrl() &#x3D;&#x3D; null&quot;);URL url &#x3D; arg0.getUrl(); &#x2F;&#x2F;这里会根据url中的信息获取具体的实现类名 String extName &#x3D; ( url.getProtocol() &#x3D;&#x3D; null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); &#x2F;&#x2F;根据上面的实现类名，会在运行时，通过Dubbo的扩展机制加载具体实现类 Protocol extension &#x3D; (Protocol)ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(extName); return extension.export(arg0); &#125; public void destroy() &#123; throw new UnsupportedOperationException(&quot;method public abstract void Protocol.destroy() of interface Protocol is not adaptive method!&quot;); &#125; public int getDefaultPort() &#123; throw new UnsupportedOperationException(&quot;method public abstract int Protocol.getDefaultPort() of interface Protocol is not adaptive method!&quot;); &#125;&#125; 使用这种方式的原因也很容易能想到，在我们加载扩展点实现的时候，并没有调用实现的具体逻辑，那我们注入一个扩展点，也就不知道这个扩展点的实现具体是什么，所以要注入一个自适应的实现。等到运行时候，才根据自适应实现，来调用真正实现。 扩展点自动包装功能（AOP）先看下下面的示例，假如接口A还有另外一个实现者：AWrapper1： 1234567class AWrapper1 implements A&#123; private A a; AWrapper1(A a)&#123; this.a &#x3D; a; &#125; &#125; AWrapper1相当于A的包装类，类似于AOP的功能，AWrapper1增加了A的功能。当我们获取接口A的实现类的时候，得到的就是包装过的类。 Dubbo扩展点加载的实现首先还是定义接口，然后是接口的具体实现类，配置文件类似于Java的SPI配置文件，Dubbo的配置文件放在META-INF/dubbo/目录下，配置文件名为接口的全限定名，配置文件内容是配置名=扩展实现类的全限定名，加载实现类的功能是通过ExtensionLoader来实现，类似于Java中的ServiceLoader的作用。 另外，扩展点使用单一实例加载，需要确保线程安全性。 Dubbo扩展点加载的一些定义 @SPI注解，被此注解标记的接口，就表示是一个可扩展的接口。 @Adaptive注解，有两种注解方式：一种是注解在类上，一种是注解在方法上。 注解在类上，而且是注解在实现类上，目前dubbo只有AdaptiveCompiler和AdaptiveExtensionFactory类上标注了此注解，这是些特殊的类，ExtensionLoader需要依赖他们工作，所以得使用此方式。 注解在方法上，注解在接口的方法上，除了上面两个类之外，所有的都是注解在方法上。ExtensionLoader根据接口定义动态的生成适配器代码，并实例化这个生成的动态类。被Adaptive注解的方法会生成具体的方法实现。没有注解的方法生成的实现都是抛不支持的操作异常UnsupportedOperationException。被注解的方法在生成的动态类中，会根据url里的参数信息，来决定实际调用哪个扩展。 比如说这段代码： 1private static final Protocol refprotocol &#x3D; ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); 当上面代码执行的时候，我们其实还不知道要真正使用的Protocol是什么，可能是具体的实现DubboProtocol，也可能是其他的具体实现的Protocol，那么这时候refprotocol到底是什么呢？refprotocol其实是在调用getAdaptiveExtension()方法时候，自动生成的一个类，代码如下： 12345678910111213141516171819202122232425262728293031323334353637import com.alibaba.dubbo.common.extension.ExtensionLoader;public class Protocol$Adpative implements Protocol &#123; public Invoker refer(Class arg0, URL arg1) throws Class &#123; if (arg1 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;url &#x3D;&#x3D; null&quot;); URL url &#x3D; arg1; String extName &#x3D; ( url.getProtocol() &#x3D;&#x3D; null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); Protocol extension &#x3D; (Protocol)ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); &#125; public Exporter export(Invoker arg0) throws Invoker &#123; if (arg0 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;Invoker argument &#x3D;&#x3D; null&quot;); if (arg0.getUrl() &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;Invoker argument getUrl() &#x3D;&#x3D; null&quot;);URL url &#x3D; arg0.getUrl(); String extName &#x3D; ( url.getProtocol() &#x3D;&#x3D; null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); Protocol extension &#x3D; (Protocol)ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(extName); return extension.export(arg0); &#125; public void destroy() &#123; throw new UnsupportedOperationException(&quot;method public abstract void Protocol.destroy() of interface Protocol is not adaptive method!&quot;); &#125; public int getDefaultPort() &#123; throw new UnsupportedOperationException(&quot;method public abstract int Protocol.getDefaultPort() of interface Protocol is not adaptive method!&quot;); &#125;&#125; 可以看到被@Adaptive注解的方法都生成了具体的实现，并且实现逻辑都相同。而没有被注解的方法直接抛出不支持操作的异常。 当我们使用refprotocol调用方法的时候，其实是调用生成的类Protocol$Adpative中的方法，这里面的方法根据url中的参数配置来找到具体的实现类，找具体实现类的方式还是通过dubbo的扩展机制。比如url中可能会有protocol=dubbo，此时就可以根据这个dubbo来确定我们要找的类是DubboProtocol。可以查看下生成的代码中getExtension(extName)这里是根据具体的名字去查找实现类。 @Activate注解，此注解需要注解在类上或者方法上，并注明被激活的条件，以及所有的被激活实现类中的排序信息。 ExtensionLoader，是dubbo的SPI机制的查找服务实现的工具类，类似与Java的ServiceLoader，可做类比。dubbo约定扩展点配置文件放在classpath下的/META-INF/dubbo，/META-INF/dubbo/internal，/META-INF/services目录下，配置文件名为接口的全限定名，配置文件内容为配置名=扩展实现类的全限定名。 Dubbo扩展点加载的源码解析重点解析下ExtensionLoader这个类。Dubbo的扩展点使用单一实例去加载，缓存在ExtensionLoader中。每一个ExtensionLoader实例仅负责加载特定SPI扩展的实现，想要获得某个扩展的实现，首先要获得该扩展对应的ExtensionLoader实例。 以Protocol为例进行分析扩展点的加载： 1234&#x2F;&#x2F;这样使用，先获取ExtensionLoader实例，然后加载自适应的Protocol扩展点Protocol protocol &#x3D; ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();&#x2F;&#x2F;使用protocol.refer(Class&lt;T&gt; type, URL url))； 可以看到，使用扩展点加载的步骤大概有三步： 获取ExtensionLoader实例。 获取自适应实现。 使用获取到的实现。 下面我们就以这三步作为分界，来深入源码的解析。 获取ExtensionLoader实例第一步，getExtensionLoader(Protocol.class)，根据要加载的接口Protocol，创建出一个ExtensionLoader实例，加载完的实例会被缓存起来，下次再加载Protocol的ExtensionLoader的时候，会使用已经缓存的这个，不会再新建一个实例： 1234567891011121314151617181920212223242526public static &lt;T&gt; ExtensionLoader&lt;T&gt; getExtensionLoader(Class&lt;T&gt; type) &#123; &#x2F;&#x2F;扩展点类型不能为空 if (type &#x3D;&#x3D; null) throw new IllegalArgumentException(); &#x2F;&#x2F;扩展点类型只能是接口类型的 if(!type.isInterface()) &#123; throw new IllegalArgumentException(); &#125; &#x2F;&#x2F;没有添加@SPI注解，只有注解了@SPI的才会解析 if(!withExtensionAnnotation(type)) &#123; throw new IllegalArgumentException(); &#125; &#x2F;&#x2F;先从缓存中获取指定类型的ExtensionLoader &#x2F;&#x2F;EXTENSION_LOADERS是一个ConcurrentHashMap，缓存了所有已经加载的ExtensionLoader的实例 &#x2F;&#x2F;比如这里加载Protocol.class，就以Protocol.class作为key，以新创建的ExtensionLoader作为value &#x2F;&#x2F;每一个要加载的扩展点只会对应一个ExtensionLoader实例，也就是只会存在一个Protocol.class在缓存中 ExtensionLoader&lt;T&gt; loader &#x3D; (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); &#x2F;&#x2F;缓存中不存在 if (loader &#x3D;&#x3D; null) &#123; &#x2F;&#x2F;创建一个新的ExtensionLoader实例，放到缓存中去 &#x2F;&#x2F;对于每一个扩展，dubbo中只有一个对应的ExtensionLoader实例 EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader&lt;T&gt;(type)); loader &#x3D; (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); &#125; return loader;&#125; 上面代码返回一个ExtensionLoader实例，getExtensionLoader(Protocol.class)这一步没有进行任何的加载工作，只是获得了一个ExtensionLoader的实例。 ExtensionLoader的构造方法上面获取的是一个ExtensionLoader实例，接着看下构造实例的时候到底做了什么，我们发现在ExtensionLoader中只有一个私有的构造方法： 1234567891011private ExtensionLoader(Class&lt;?&gt; type) &#123; &#x2F;&#x2F;接口类型 this.type &#x3D; type; &#x2F;&#x2F;对于扩展类型是ExtensionFactory的，设置为null &#x2F;&#x2F;getAdaptiveExtension方法获取一个运行时自适应的扩展类型 &#x2F;&#x2F;每个Extension只能有一个@Adaptive类型的实现，如果么有，dubbo会自动生成一个类 &#x2F;&#x2F;objectFactory是一个ExtensionFactory类型的属性，主要用于加载需要注入的类型的实现 &#x2F;&#x2F;objectFactory主要用在注入那一步，详细说明见注入时候的说明 &#x2F;&#x2F;这里记住非ExtensionFactory类型的返回的都是一个AdaptiveExtensionFactory objectFactory &#x3D; (type &#x3D;&#x3D; ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());&#125; 不难理解，ExtensionFactory是主要是用来加载被注入的类的实现，分为SpiExtensionFactory和SpringExtensionFactory两个，分别用来加载SPI扩展实现和Spring中bean的实现。 获取自适应实现上面返回一个ExtensionLoader的实例之后，开始加载自适应实现，加载是在调用getAdaptiveExtension()方法中进行的： 12345getAdaptiveExtension()--&gt; createAdaptiveExtension()--&gt; getAdaptiveExtensionClass()--&gt; getExtensionClasses()--&gt; loadExtensionClasses() 先看下getAdaptiveExtension()方法，用来获取一个扩展的自适应实现类，最后返回的自适应实现类是一个类名为Protocol$Adaptive的类，并且这个类实现了Protocol接口： 123456789101112131415161718192021222324public T getAdaptiveExtension() &#123; &#x2F;&#x2F;先从实例缓存中查找实例对象 &#x2F;&#x2F;private final Holder&lt;Object&gt; cachedAdaptiveInstance &#x3D; new Holder&lt;Object&gt;(); &#x2F;&#x2F;在当前的ExtensionLoader中保存着一个Holder实例，用来缓存自适应实现类的实例 Object instance &#x3D; cachedAdaptiveInstance.get(); if (instance &#x3D;&#x3D; null) &#123;&#x2F;&#x2F;缓存中不存在 if(createAdaptiveInstanceError &#x3D;&#x3D; null) &#123; synchronized (cachedAdaptiveInstance) &#123; &#x2F;&#x2F;获取锁之后再检查一次缓存中是不是已经存在 instance &#x3D; cachedAdaptiveInstance.get(); if (instance &#x3D;&#x3D; null) &#123; try &#123; &#x2F;&#x2F;缓存中没有，就创建新的AdaptiveExtension实例 instance &#x3D; createAdaptiveExtension(); &#x2F;&#x2F;新实例加入缓存 cachedAdaptiveInstance.set(instance); &#125; catch (Throwable t) &#123;createAdaptiveInstanceError &#x3D; t; &#125; &#125; &#125; &#125; &#125; return (T) instance;&#125; 创建自适应扩展缓存中不存在自适应扩展的实例，表示还没有创建过自适应扩展的实例，接下来就是创建自适应扩展实现，createAdaptiveExtension()方法，用来创建自适应扩展类的实例： 12345678private T createAdaptiveExtension() &#123; try &#123; &#x2F;&#x2F;先通过getAdaptiveExtensionClass获取AdaptiveExtensionClass &#x2F;&#x2F;然后获取其实例 &#x2F;&#x2F;最后进行注入处理 return injectExtension((T) getAdaptiveExtensionClass().newInstance()); &#125; catch (Exception e) &#123;&#125;&#125; 获取自适应扩展类接着查看getAdaptiveExtensionClass()方法，用来获取一个自适应扩展的Class，这个Class将会在下一步被实例化： 123456789101112131415private Class&lt;?&gt; getAdaptiveExtensionClass() &#123; &#x2F;&#x2F;加载当前Extension的所有实现（这里举例是Protocol，只会加载Protocol的所有实现类），如果有@Adaptive类型的实现类，会赋值给cachedAdaptiveClass &#x2F;&#x2F;目前只有AdaptiveExtensionFactory和AdaptiveCompiler两个实现类是被注解了@Adaptive &#x2F;&#x2F;除了ExtensionFactory和Compiler类型的扩展之外，其他类型的扩展都是下面动态创建的的实现 getExtensionClasses(); &#x2F;&#x2F;加载完所有的实现之后，发现有cachedAdaptiveClass不为空 &#x2F;&#x2F;也就是说当前获取的自适应实现类是AdaptiveExtensionFactory或者是AdaptiveCompiler，就直接返回，这两个类是特殊用处的，不用代码生成，而是现成的代码 if (cachedAdaptiveClass !&#x3D; null) &#123; return cachedAdaptiveClass; &#125; &#x2F;&#x2F;没有找到Adaptive类型的实现，动态创建一个 &#x2F;&#x2F;比如Protocol的实现类，没有任何一个实现是用@Adaptive来注解的，只有Protocol接口的方法是有注解的 &#x2F;&#x2F;这时候就需要来动态的生成了，也就是生成Protocol$Adaptive return cachedAdaptiveClass &#x3D; createAdaptiveExtensionClass();&#125; 加载扩展类实现先看下getExtensionClasses()这个方法，加载所有的扩展类的实现： 123456789101112131415161718192021private Map&lt;String, Class&lt;?&gt;&gt; getExtensionClasses() &#123; &#x2F;&#x2F;从缓存中获取，cachedClasses也是一个Holder，Holder这里持有的是一个Map，key是扩展点实现名，value是扩展点实现类 &#x2F;&#x2F;这里会存放当前扩展点类型的所有的扩展点的实现类 &#x2F;&#x2F;这里以Protocol为例，就是会存放Protocol的所有实现类 &#x2F;&#x2F;比如key为dubbo，value为com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol &#x2F;&#x2F;cachedClasses扩展点实现名称对应的实现类 Map&lt;String, Class&lt;?&gt;&gt; classes &#x3D; cachedClasses.get(); &#x2F;&#x2F;如果为null，说明没有被加载过，就会进行加载，而且加载就只会进行这一次 if (classes &#x3D;&#x3D; null) &#123; synchronized (cachedClasses) &#123; classes &#x3D; cachedClasses.get(); if (classes &#x3D;&#x3D; null) &#123; &#x2F;&#x2F;如果没有加载过Extension的实现，进行扫描加载，完成后缓存起来 &#x2F;&#x2F;每个扩展点，其实现的加载只会这执行一次 classes &#x3D; loadExtensionClasses(); cachedClasses.set(classes); &#125; &#125; &#125; return classes;&#125; 看下loadExtensionClasses()方法，这个方法中加载扩展点的实现类： 12345678910111213141516171819202122232425262728private Map&lt;String, Class&lt;?&gt;&gt; loadExtensionClasses() &#123; final SPI defaultAnnotation &#x3D; type.getAnnotation(SPI.class); if(defaultAnnotation !&#x3D; null) &#123; &#x2F;&#x2F;当前Extension的默认实现名字 &#x2F;&#x2F;比如说Protocol接口，注解是@SPI(&quot;dubbo&quot;) &#x2F;&#x2F;这里dubbo就是默认的值 String value &#x3D; defaultAnnotation.value(); &#x2F;&#x2F;只能有一个默认的名字，如果多了，谁也不知道该用哪一个实现了。 if(value !&#x3D; null &amp;&amp; (value &#x3D; value.trim()).length() &gt; 0) &#123; String[] names &#x3D; NAME_SEPARATOR.split(value); if(names.length &gt; 1) &#123; throw new IllegalStateException(); &#125; &#x2F;&#x2F;默认的名字保存起来 if(names.length &#x3D;&#x3D; 1) cachedDefaultName &#x3D; names[0]; &#125; &#125; &#x2F;&#x2F;下面就开始从配置文件中加载扩展实现类 Map&lt;String, Class&lt;?&gt;&gt; extensionClasses &#x3D; new HashMap&lt;String, Class&lt;?&gt;&gt;(); &#x2F;&#x2F;从META-INF&#x2F;dubbo&#x2F;internal目录下加载 loadFile(extensionClasses, DUBBO_INTERNAL_DIRECTORY); &#x2F;&#x2F;从META-INF&#x2F;dubbo&#x2F;目录下加载 loadFile(extensionClasses, DUBBO_DIRECTORY); &#x2F;&#x2F;从META-INF&#x2F;services&#x2F;下加载 loadFile(extensionClasses, SERVICES_DIRECTORY); return extensionClasses;&#125; 从各个位置的配置文件中加载实现类，对于Protocol来说加载的文件是以com.alibaba.dubbo.rpc.Protocol为名称的文件，文件的内容是（有好几个同名的配置文件，这里直接把内容全部写在了一起）： 1234567891011121314151617181920212223registry&#x3D;com.alibaba.dubbo.registry.integration.RegistryProtocolfilter&#x3D;com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapperlistener&#x3D;com.alibaba.dubbo.rpc.protocol.ProtocolListenerWrappermock&#x3D;com.alibaba.dubbo.rpc.support.MockProtocoldubbo&#x3D;com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocolhessian&#x3D;com.alibaba.dubbo.rpc.protocol.hessian.HessianProtocolcom.alibaba.dubbo.rpc.protocol.http.HttpProtocolinjvm&#x3D;com.alibaba.dubbo.rpc.protocol.injvm.InjvmProtocolmemcached&#x3D;memcom.alibaba.dubbo.rpc.protocol.memcached.MemcachedProtocolredis&#x3D;com.alibaba.dubbo.rpc.protocol.redis.RedisProtocolrmi&#x3D;com.alibaba.dubbo.rpc.protocol.rmi.RmiProtocolthrift&#x3D;com.alibaba.dubbo.rpc.protocol.thrift.ThriftProtocolcom.alibaba.dubbo.rpc.protocol.webservice.WebServiceProtocol 看下loadFile()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126private void loadFile(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, String dir) &#123; &#x2F;&#x2F;配置文件的名称 &#x2F;&#x2F;这里type是扩展类，比如com.alibaba.dubbo.rpc.Protocol类 String fileName &#x3D; dir + type.getName(); try &#123; Enumeration&lt;java.net.URL&gt; urls; &#x2F;&#x2F;获取类加载器 ClassLoader classLoader &#x3D; findClassLoader(); &#x2F;&#x2F;获取对应配置文件名的所有的文件 if (classLoader !&#x3D; null) &#123; urls &#x3D; classLoader.getResources(fileName); &#125; else &#123; urls &#x3D; ClassLoader.getSystemResources(fileName); &#125; if (urls !&#x3D; null) &#123; &#x2F;&#x2F;遍历文件进行处理 while (urls.hasMoreElements()) &#123; &#x2F;&#x2F;配置文件路径 java.net.URL url &#x3D; urls.nextElement(); try &#123; BufferedReader reader &#x3D; new BufferedReader(new InputStreamReader(url.openStream(), &quot;utf-8&quot;)); try &#123; String line &#x3D; null; &#x2F;&#x2F;每次处理一行 while ((line &#x3D; reader.readLine()) !&#x3D; null) &#123; &#x2F;&#x2F;#号以后的为注释 final int ci &#x3D; line.indexOf(&#39;#&#39;); &#x2F;&#x2F;注释去掉 if (ci &gt;&#x3D; 0) line &#x3D; line.substring(0, ci); line &#x3D; line.trim(); if (line.length() &gt; 0) &#123; try &#123; String name &#x3D; null; &#x2F;&#x2F;&#x3D;号之前的为扩展名字，后面的为扩展类实现的全限定名 int i &#x3D; line.indexOf(&#39;&#x3D;&#39;); if (i &gt; 0) &#123; name &#x3D; line.substring(0, i).trim(); line &#x3D; line.substring(i + 1).trim(); &#125; if (line.length() &gt; 0) &#123; &#x2F;&#x2F;加载扩展类的实现 Class&lt;?&gt; clazz &#x3D; Class.forName(line, true, classLoader); &#x2F;&#x2F;查看类型是否匹配 &#x2F;&#x2F;type是Protocol接口 &#x2F;&#x2F;clazz就是Protocol的各个实现类 if (! type.isAssignableFrom(clazz)) &#123; throw new IllegalStateException(); &#125; &#x2F;&#x2F;如果实现类是@Adaptive类型的，会赋值给cachedAdaptiveClass，这个用来存放被@Adaptive注解的实现类 if (clazz.isAnnotationPresent(Adaptive.class)) &#123; if(cachedAdaptiveClass &#x3D;&#x3D; null) &#123; cachedAdaptiveClass &#x3D; clazz; &#125; else if (! cachedAdaptiveClass.equals(clazz)) &#123; throw new IllegalStateException(); &#125; &#125; else &#123;&#x2F;&#x2F;不是@Adaptice类型的类，就是没有注解@Adaptive的实现类 try &#123;&#x2F;&#x2F;判断是否是wrapper类型 &#x2F;&#x2F;如果得到的实现类的构造方法中的参数是扩展点类型的，就是一个Wrapper类 &#x2F;&#x2F;比如ProtocolFilterWrapper，实现了Protocol类， &#x2F;&#x2F;而它的构造方法是这样public ProtocolFilterWrapper(Protocol protocol) &#x2F;&#x2F;就说明这个类是一个包装类 clazz.getConstructor(type); &#x2F;&#x2F;cachedWrapperClasses用来存放当前扩展点实现类中的包装类 Set&lt;Class&lt;?&gt;&gt; wrappers &#x3D; cachedWrapperClasses; if (wrappers &#x3D;&#x3D; null) &#123; cachedWrapperClasses &#x3D; new ConcurrentHashSet&lt;Class&lt;?&gt;&gt;(); wrappers &#x3D; cachedWrapperClasses; &#125; wrappers.add(clazz); &#125; catch (NoSuchMethodException e) &#123; &#x2F;&#x2F;没有上面提到的构造器，则说明不是wrapper类型 &#x2F;&#x2F;获取无参构造 clazz.getConstructor(); &#x2F;&#x2F;没有名字，就是配置文件中没有xxx&#x3D;xxxx.com.xxx这种 if (name &#x3D;&#x3D; null || name.length() &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F;去找@Extension注解中配置的值 name &#x3D; findAnnotationName(clazz); &#x2F;&#x2F;如果还没找到名字，从类名中获取 if (name &#x3D;&#x3D; null || name.length() &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F;比如clazz是DubboProtocol，type是Protocol &#x2F;&#x2F;这里得到的name就是dubbo if (clazz.getSimpleName().length() &gt; type.getSimpleName().length() &amp;&amp; clazz.getSimpleName().endsWith(type.getSimpleName())) &#123; name &#x3D; clazz.getSimpleName().substring(0, clazz.getSimpleName().length() - type.getSimpleName().length()).toLowerCase(); &#125; else &#123; throw new IllegalStateException(&quot;); &#125; &#125; &#125; &#x2F;&#x2F;有可能配置了多个名字 String[] names &#x3D; NAME_SEPARATOR.split(name); if (names !&#x3D; null &amp;&amp; names.length &gt; 0) &#123; &#x2F;&#x2F;是否是Active类型的类 Activate activate &#x3D; clazz.getAnnotation(Activate.class); if (activate !&#x3D; null) &#123; &#x2F;&#x2F;第一个名字作为键，放进cachedActivates这个map中缓存 cachedActivates.put(names[0], activate); &#125; for (String n : names) &#123; if (! cachedNames.containsKey(clazz)) &#123; &#x2F;&#x2F;放入Extension实现类与名称映射的缓存中去，每个class只对应第一个名称有效 cachedNames.put(clazz, n); &#125; Class&lt;?&gt; c &#x3D; extensionClasses.get(n); if (c &#x3D;&#x3D; null) &#123; &#x2F;&#x2F;放入到extensionClasses缓存中去，多个name可能对应一份extensionClasses extensionClasses.put(n, clazz); &#125; else if (c !&#x3D; clazz) &#123; throw new IllegalStateException(); &#125; &#125; &#125; &#125; &#125; &#125; &#125; catch (Throwable t) &#123; &#125; &#125; &#125; &#x2F;&#x2F; end of while read lines &#125; finally &#123; reader.close(); &#125; &#125; catch (Throwable t) &#123; &#125; &#125; &#x2F;&#x2F; end of while urls &#125; &#125; catch (Throwable t) &#123; &#125;&#125; 到这里加载当前Extension的所有实现就已经完成了，继续返回getAdaptiveExtensionClass中，在调用完getExtensionClasses()之后，会首先检查是不是已经有@Adaptive注解的类被解析并加入到缓存中了，如果有就直接返回，这里的cachedAdaptiveClass中现在只能是AdaptiveExtensionFactory或者AdaptiveCompiler中的一个，如果没有，说明是一个普通扩展点，就动态创建一个，比如会创建一个Protocol$Adaptive。 创建自适应扩展类的代码看下createAdaptiveExtensionClass()这个方法，用来动态的创建自适应扩展类： 12345678910111213141516private Class&lt;?&gt; createAdaptiveExtensionClass() &#123; &#x2F;&#x2F;组装自适应扩展点类的代码 String code &#x3D; createAdaptiveExtensionClassCode(); &#x2F;&#x2F;获取到应用的类加载器 ClassLoader classLoader &#x3D; findClassLoader(); &#x2F;&#x2F;获取编译器 &#x2F;&#x2F;dubbo默认使用javassist &#x2F;&#x2F;这里还是使用扩展点机制来找具体的Compiler的实现 &#x2F;&#x2F;现在就知道cachedAdaptiveClass是啥意思了，如果没有AdaptiveExtensionFactory和AdaptiveCompiler这两个类，这里又要去走加载流程然后来生成扩展点类的代码，不就死循环了么。 &#x2F;&#x2F;这里解析Compiler的实现类的时候，会在getAdaptiveExtensionClass中直接返回 &#x2F;&#x2F;可以查看下AdaptiveCompiler这个类，如果我们没有指定，默认使用javassist &#x2F;&#x2F;这里Compiler是JavassistCompiler实例 com.alibaba.dubbo.common.compiler.Compiler compiler &#x3D; ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.common.compiler.Compiler.class).getAdaptiveExtension(); &#x2F;&#x2F;将代码转换成Class return compiler.compile(code, classLoader);&#125; 接着看下createAdaptiveExtensionClassCode()方法，用来组装自适应扩展类的代码（拼写源码，代码比较长不在列出），这里列出生成的Protocol$Adaptive： 12345678910111213141516171819202122232425262728293031323334353637import com.alibaba.dubbo.common.extension.ExtensionLoader;public class Protocol$Adpative implements com.alibaba.dubbo.rpc.Protocol &#123; public com.alibaba.dubbo.rpc.Invoker refer(java.lang.Class arg0, com.alibaba.dubbo.common.URL arg1) throws java.lang.Class &#123; if (arg1 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;url &#x3D;&#x3D; null&quot;); com.alibaba.dubbo.common.URL url &#x3D; arg1; String extName &#x3D; ( url.getProtocol() &#x3D;&#x3D; null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); com.alibaba.dubbo.rpc.Protocol extension &#x3D; (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); &#125; public com.alibaba.dubbo.rpc.Exporter export(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.Invoker &#123; if (arg0 &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument &#x3D;&#x3D; null&quot;); if (arg0.getUrl() &#x3D;&#x3D; null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument getUrl() &#x3D;&#x3D; null&quot;);com.alibaba.dubbo.common.URL url &#x3D; arg0.getUrl(); String extName &#x3D; ( url.getProtocol() &#x3D;&#x3D; null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); com.alibaba.dubbo.rpc.Protocol extension &#x3D; (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName); return extension.export(arg0); &#125; public void destroy() &#123; throw new UnsupportedOperationException(&quot;method public abstract void com.alibaba.dubbo.rpc.Protocol.destroy() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!&quot;); &#125; public int getDefaultPort() &#123; throw new UnsupportedOperationException(&quot;method public abstract int com.alibaba.dubbo.rpc.Protocol.getDefaultPort() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!&quot;); &#125;&#125; 其他具体的扩展点的生成也类似。在生成完代码之后，是找到ClassLoader，然后获取到Compiler的自适应实现，这里得到的就是AdaptiveCompiler，最后调用compiler.compile(code, classLoader);来编译上面生成的类并返回，先进入AdaptiveCompiler的compile方法： 123456789101112131415public Class&lt;?&gt; compile(String code, ClassLoader classLoader) &#123; Compiler compiler; &#x2F;&#x2F;得到一个ExtensionLoader ExtensionLoader&lt;Compiler&gt; loader &#x3D; ExtensionLoader.getExtensionLoader(Compiler.class); &#x2F;&#x2F;默认的Compiler名字 String name &#x3D; DEFAULT_COMPILER; &#x2F;&#x2F; copy reference &#x2F;&#x2F;有指定了Compiler名字，就使用指定的名字来找到Compiler实现类 if (name !&#x3D; null &amp;&amp; name.length() &gt; 0) &#123; compiler &#x3D; loader.getExtension(name); &#125; else &#123;&#x2F;&#x2F;没有指定Compiler名字，就查找默认的Compiler的实现类 compiler &#x3D; loader.getDefaultExtension(); &#125; &#x2F;&#x2F;调用具体的实现类来进行编译 return compiler.compile(code, classLoader);&#125; 获取指定名字的扩展先看下根据具体的名字来获取扩展的实现类loader.getExtension(name);，loader是ExtensionLoader&lt;Compiler&gt;类型的。这里就是比Java的SPI要方便的地方，Java的SPI只能通过遍历所有的实现类来查找，而dubbo能够指定一个名字查找。代码如下： 1234567891011121314151617181920212223242526272829303132public T getExtension(String name) &#123; if (name &#x3D;&#x3D; null || name.length() &#x3D;&#x3D; 0) throw new IllegalArgumentException(&quot;Extension name &#x3D;&#x3D; null&quot;); &#x2F;&#x2F;如果name指定为true，则获取默认实现 if (&quot;true&quot;.equals(name)) &#123; &#x2F;&#x2F;默认实现查找在下面解析 return getDefaultExtension(); &#125; &#x2F;&#x2F;先从缓存获取Holder，cachedInstance是一个ConcurrentHashMap，键是扩展的name，值是一个持有name对应的实现类实例的Holder。 Holder&lt;Object&gt; holder &#x3D; cachedInstances.get(name); &#x2F;&#x2F;如果当前name对应的Holder不存在，就创建一个，添加进map中 if (holder &#x3D;&#x3D; null) &#123; cachedInstances.putIfAbsent(name, new Holder&lt;Object&gt;()); holder &#x3D; cachedInstances.get(name); &#125; &#x2F;&#x2F;从Holder中获取保存的实例 Object instance &#x3D; holder.get(); &#x2F;&#x2F;不存在，就需要根据这个name找到实现类，实例化一个 if (instance &#x3D;&#x3D; null) &#123; synchronized (holder) &#123; instance &#x3D; holder.get(); if (instance &#x3D;&#x3D; null) &#123; &#x2F;&#x2F;缓存不存在，创建实例 instance &#x3D; createExtension(name); &#x2F;&#x2F;加入缓存 holder.set(instance); &#125; &#125; &#125; &#x2F;&#x2F;存在，就直接返回 return (T) instance;&#125; 创建扩展实例，createExtension(name);： 1234567891011121314151617181920212223242526272829private T createExtension(String name) &#123; &#x2F;&#x2F;getExtensionClasses加载当前Extension的所有实现 &#x2F;&#x2F;上面已经解析过，返回的是一个Map，键是name，值是name对应的Class &#x2F;&#x2F;根据name查找对应的Class Class&lt;?&gt; clazz &#x3D; getExtensionClasses().get(name); &#x2F;&#x2F;如果这时候class还不存在，说明在所有的配置文件中都没找到定义，抛异常 if (clazz &#x3D;&#x3D; null) &#123; throw findException(name); &#125; try &#123; &#x2F;&#x2F;从已创建实例缓存中获取 T instance &#x3D; (T) EXTENSION_INSTANCES.get(clazz); &#x2F;&#x2F;不存在的话就创建一个新实例，加入到缓存中去 if (instance &#x3D;&#x3D; null) &#123; EXTENSION_INSTANCES.putIfAbsent(clazz, (T) clazz.newInstance()); instance &#x3D; (T) EXTENSION_INSTANCES.get(clazz); &#125; &#x2F;&#x2F;属性注入 injectExtension(instance); &#x2F;&#x2F;Wrapper的包装 Set&lt;Class&lt;?&gt;&gt; wrapperClasses &#x3D; cachedWrapperClasses; if (wrapperClasses !&#x3D; null &amp;&amp; wrapperClasses.size() &gt; 0) &#123; for (Class&lt;?&gt; wrapperClass : wrapperClasses) &#123; instance &#x3D; injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); &#125; &#125; return instance; &#125; catch (Throwable t) &#123; &#125;&#125; 有关属性注入和Wrapper的包装，下面再讲。到这里Compiler就能获得到一个指定name的具体实现类的实例了，然后就是调用实例的compile()方法对生成的代码进行编译。 获取默认扩展实现如果在AdaptiveCompiler中没有找到指定的名字，就会找默认的扩展实现loader.getDefaultExtension();： 123456789101112public T getDefaultExtension() &#123; &#x2F;&#x2F;首先还是先去加载所有的扩展实现 &#x2F;&#x2F;加载的时候会设置默认的名字cachedDefaultName，这个名字是在@SPI中指定的，比如Compiler就指定了@SPI(&quot;javassist&quot;)，所以这里是javassist getExtensionClasses(); if(null &#x3D;&#x3D; cachedDefaultName || cachedDefaultName.length() &#x3D;&#x3D; 0 || &quot;true&quot;.equals(cachedDefaultName)) &#123; return null; &#125; &#x2F;&#x2F;根据javassist这个名字去查找扩展实现 &#x2F;&#x2F;具体的过程上面已经解析过了 return getExtension(cachedDefaultName);&#125; 关于javassist编译Class的过程暂先不说明。我们接着流程看： 12345678 private T createAdaptiveExtension() &#123; try &#123; &#x2F;&#x2F;先通过getAdaptiveExtensionClass获取AdaptiveExtensionClass（在上面这一步已经解析了，获得到了一个自适应实现类的Class） &#x2F;&#x2F;然后获取其实例，newInstance进行实例 &#x2F;&#x2F;最后进行注入处理injectExtension return injectExtension((T) getAdaptiveExtensionClass().newInstance()); &#125; catch (Exception e) &#123; &#125;&#125; 扩展点注入接下来就是有关扩展点的注入的问题了，injectExtension，关于注入的解释查看最上面扩展点自动装配（IOC）的说明，injectExtension方法： 1234567891011121314151617181920212223242526272829303132333435&#x2F;&#x2F;这里的实例是Xxxx$Adaptiveprivate T injectExtension(T instance) &#123; try &#123; &#x2F;&#x2F;关于objectFactory的来路，先看下面的解析 &#x2F;&#x2F;这里的objectFactory是AdaptiveExtensionFactory if (objectFactory !&#x3D; null) &#123; &#x2F;&#x2F;遍历扩展实现类实例的方法 for (Method method : instance.getClass().getMethods()) &#123; &#x2F;&#x2F;只处理set方法 &#x2F;&#x2F;set开头，只有一个参数，public if (method.getName().startsWith(&quot;set&quot;) &amp;&amp; method.getParameterTypes().length &#x3D;&#x3D; 1 &amp;&amp; Modifier.isPublic(method.getModifiers())) &#123; &#x2F;&#x2F;set方法参数类型 Class&lt;?&gt; pt &#x3D; method.getParameterTypes()[0]; try &#123; &#x2F;&#x2F;setter方法对应的属性名 String property &#x3D; method.getName().length() &gt; 3 ? method.getName().substring(3, 4).toLowerCase() + method.getName().substring(4) : &quot;&quot;; &#x2F;&#x2F;根据类型和名称信息从ExtensionFactory中获取 &#x2F;&#x2F;比如在某个扩展实现类中会有setProtocol(Protocol protocol)这样的set方法 &#x2F;&#x2F;这里pt就是Protocol，property就是protocol &#x2F;&#x2F;AdaptiveExtensionFactory就会根据这两个参数去查找对应的扩展实现类 &#x2F;&#x2F;这里就会返回Protocol$Adaptive Object object &#x3D; objectFactory.getExtension(pt, property); if (object !&#x3D; null) &#123;&#x2F;&#x2F;说明set方法的参数是扩展点类型，进行注入 &#x2F;&#x2F;为set方法注入一个自适应的实现类 method.invoke(instance, object); &#125; &#125; catch (Exception e) &#123; &#125; &#125; &#125; &#125; &#125; catch (Exception e) &#123;&#125; return instance;&#125; 有关AdaptiveExtensionFactory中获取Extension的过程，会首先在实例化的时候得到ExtensionFactory的具体实现类，然后遍历每个ExtensionFactory的实现类，分别在每个ExtensionFactory的实现类中获取Extension。 这里使用SpiExtensionFactory的获取扩展的方法为例，getExtension，也是先判断给定类是否是注解了@SPI的接口，然后根据类去获取ExtensionLoader，在使用得到的ExtensionLoader去加载自适应扩展。 objectFactory的来历objectFactory的来路，在ExtensionLoader中有个私有构造器： 123456789101112131415&#x2F;&#x2F;当我们调用getExtensionLoader这个静态方法的时候，会触发ExtensionLoader类的实例化，会先初始化静态变量和静态块，然后是构造代码块，最后是构造器的初始化private ExtensionLoader(Class&lt;?&gt; type) &#123; this.type &#x3D; type; &#x2F;&#x2F;这里会获得一个AdaptiveExtensionFactory &#x2F;&#x2F;根据类型和名称信息从ExtensionFactory中获取 &#x2F;&#x2F;获取实现 &#x2F;&#x2F;为什么要使用对象工厂来获取setter方法中对应的实现？ &#x2F;&#x2F;不能通过spi直接获取自适应实现吗？比如ExtensionLoader.getExtension(pt); &#x2F;&#x2F;因为setter方法中有可能是一个spi，也有可能是普通的bean &#x2F;&#x2F;所以此时不能写死通过spi获取，还需要有其他方式来获取实现进行注入 &#x2F;&#x2F; dubbo中有两个实现，一个是spi的ExtensionFactory，一个是spring的ExtensionFactory &#x2F;&#x2F;如果还有其他的，我们可以自定义ExtensionFactory &#x2F;&#x2F;objectFactory是AdaptiveExtensionFactory实例 objectFactory &#x3D; (type &#x3D;&#x3D; ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());&#125; 到此为止createAdaptiveExtension方法解析完成，接着返回上层getAdaptiveExtension()方法中，发现创建完自适应扩展实例之后，就会加入到cachedAdaptiveInstance缓存起来，然后就会返回给调用的地方一个Xxx$Adaptive实例。 走到这里，下面的代码就解析完了： 1private static final Protocol refprotocol &#x3D; ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); 得到扩展之后的使用我们得到了一个Protocol$Adaptive实例，接着就是调用了，比如说我们要调用refprotocol.refer(Class&lt;T&gt; type, URL url))方法，由于这里refprotocol是一个Protocol$Adaptive实例，所以就先调用这个实例的refer方法，这里的实例的代码在最上面： 12345678910111213&#x2F;&#x2F;这里为了好看，代码做了精简，包名都去掉了public Invoker refer(Class arg0, URL arg1) throws Class &#123; if (arg1 &#x3D;&#x3D; null) throw new IllegalArgumentException(); URL url &#x3D; arg1; String extName &#x3D; ( url.getProtocol() &#x3D;&#x3D; null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName &#x3D;&#x3D; null) throw new IllegalStateException(); Protocol extension &#x3D; (Protocol)ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); &#125; 可以看到这里首先根据url中的参数获取扩展名字，如果url中没有就使用默认的扩展名，然后根据扩展名去获取具体的实现。关于getExtension(String name)上面已经解析过一次，这里再次列出： 1234567891011121314151617181920212223242526272829303132public T getExtension(String name) &#123; if (name &#x3D;&#x3D; null || name.length() &#x3D;&#x3D; 0) throw new IllegalArgumentException(&quot;Extension name &#x3D;&#x3D; null&quot;); &#x2F;&#x2F;如果name指定为true，则获取默认实现 if (&quot;true&quot;.equals(name)) &#123; &#x2F;&#x2F;默认实现查找在下面解析 return getDefaultExtension(); &#125; &#x2F;&#x2F;先从缓存获取Holder，cachedInstance是一个ConcurrentHashMap，键是扩展的name，值是一个持有name对应的实现类实例的Holder。 Holder&lt;Object&gt; holder &#x3D; cachedInstances.get(name); &#x2F;&#x2F;如果当前name对应的Holder不存在，就创建一个，添加进map中 if (holder &#x3D;&#x3D; null) &#123; cachedInstances.putIfAbsent(name, new Holder&lt;Object&gt;()); holder &#x3D; cachedInstances.get(name); &#125; &#x2F;&#x2F;从Holder中获取保存的实例 Object instance &#x3D; holder.get(); &#x2F;&#x2F;不存在，就需要根据这个name找到实现类，实例化一个 if (instance &#x3D;&#x3D; null) &#123; synchronized (holder) &#123; instance &#x3D; holder.get(); if (instance &#x3D;&#x3D; null) &#123; &#x2F;&#x2F;缓存不存在，创建实例 instance &#x3D; createExtension(name); &#x2F;&#x2F;加入缓存 holder.set(instance); &#125; &#125; &#125; &#x2F;&#x2F;存在，就直接返回 return (T) instance;&#125; 创建扩展实例，createExtension(name);： 12345678910111213141516171819202122232425262728293031323334353637383940private T createExtension(String name) &#123; &#x2F;&#x2F;getExtensionClasses加载当前Extension的所有实现 &#x2F;&#x2F;上面已经解析过，返回的是一个Map，键是name，值是name对应的Class &#x2F;&#x2F;根据name查找对应的Class &#x2F;&#x2F;比如name是dubbo，Class就是com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol Class&lt;?&gt; clazz &#x3D; getExtensionClasses().get(name); &#x2F;&#x2F;如果这时候class还不存在，说明在所有的配置文件中都没找到定义，抛异常 if (clazz &#x3D;&#x3D; null) &#123; throw findException(name); &#125; try &#123; &#x2F;&#x2F;从已创建实例缓存中获取 T instance &#x3D; (T) EXTENSION_INSTANCES.get(clazz); &#x2F;&#x2F;不存在的话就创建一个新实例，加入到缓存中去 if (instance &#x3D;&#x3D; null) &#123; EXTENSION_INSTANCES.putIfAbsent(clazz, (T) clazz.newInstance()); instance &#x3D; (T) EXTENSION_INSTANCES.get(clazz); &#125; &#x2F;&#x2F;这里实例就是具体实现的实例了比如是DubboProtocol的实例 &#x2F;&#x2F;属性注入，在上面已经解析过了，根据实例中的setXxx方法进行注入 injectExtension(instance); &#x2F;&#x2F;Wrapper的包装 &#x2F;&#x2F;cachedWrapperClasses存放着所有的Wrapper类 &#x2F;&#x2F;cachedWrapperClasses是在加载扩展实现类的时候放进去的 &#x2F;&#x2F;Wrapper类的说明在最上面扩展点自动包装（AOP） Set&lt;Class&lt;?&gt;&gt; wrapperClasses &#x3D; cachedWrapperClasses; if (wrapperClasses !&#x3D; null &amp;&amp; wrapperClasses.size() &gt; 0) &#123; for (Class&lt;?&gt; wrapperClass : wrapperClasses) &#123; &#x2F;&#x2F;比如在包装之前的instance是DubboProtocol实例 &#x2F;&#x2F;先使用构造器来实例化当前的包装类 &#x2F;&#x2F;包装类中就已经包含了我们的DubboProtocol实例 &#x2F;&#x2F;然后对包装类进行injectExtension注入，注入过程在上面 &#x2F;&#x2F;最后返回的Instance就是包装类的实例。 instance &#x3D; injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); &#125; &#125; &#x2F;&#x2F;这里返回的是经过所有的包装类包装之后的实例 return instance; &#125; catch (Throwable t) &#123; &#125;&#125; 获取的Extension是经过层层包装的扩展实现，然后就是调用经过包装的refer方法了，这就到了具体的实现中的方法了。 到此为止调用refprotocol.refer(Class&lt;T&gt; type, URL url))方法的过程也解析完了。 关于getActivateExtension方法的解析，等下再添加。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring的ApplicationContext事件机制]]></title>
      <url>%2F2017%2F02%2F15%2FSpring%E7%9A%84ApplicationContext%E4%BA%8B%E4%BB%B6%E6%9C%BA%E5%88%B6%2F</url>
      <content type="text"><![CDATA[ApplicationContext中事件处理是由ApplicationEvent类和ApplicationListener接口来提供的。如果一个Bean实现了ApplicationListener接口，并且已经发布到容器中去，每次ApplicationContext发布一个ApplicationEvent事件，这个Bean就会接到通知。Spring事件机制是观察者模式的实现。 Spring中提供的标准事件： ContextRefreshEvent，当ApplicationContext容器初始化完成或者被刷新的时候，就会发布该事件。比如调用ConfigurableApplicationContext接口中的refresh()方法。此处的容器初始化指的是所有的Bean都被成功装载，后处理（post-processor）Bean被检测到并且激活，所有单例Bean都被预实例化，ApplicationContext容器已经可以使用。只要上下文没有被关闭，刷新可以被多次触发。XMLWebApplicationContext支持热刷新，GenericApplicationContext不支持热刷新。 ContextStartedEvent，当ApplicationContext启动的时候发布事件，即调用ConfigurableApplicationContext接口的start方法的时候。这里的启动是指，所有的被容器管理生命周期的Bean接受到一个明确的启动信号。在经常需要停止后重新启动的场合比较适用。 ContextStoppedEvent，当ApplicationContext容器停止的时候发布事件，即调用ConfigurableApplicationContext的close方法的时候。这里的停止是指，所有被容器管理生命周期的Bean接到一个明确的停止信号。 ContextClosedEvent，当ApplicationContext关闭的时候发布事件，即调用ConfigurableApplicationContext的close方法的时候，关闭指的是所有的单例Bean都被销毁。关闭上下后，不能重新刷新或者重新启动。 RequestHandledEvent，只能用于DispatcherServlet的web应用，Spring处理用户请求结束后，系统会触发该事件。 实现ApplicationEvent，容器事件，必须被ApplicationContext发布。 ApplicationListener，监听器，可由容器中任何监听器Bean担任。 实现了ApplicationListener接口之后，需要实现方法onApplicationEvent()，在容器将所有的Bean都初始化完成之后，就会执行该方法。 观察者模式观察者模式，Observer Pattern也叫作发布订阅模式Publish/Subscribe。定义对象间一对多的依赖关系，使得每当一个对象改变状态，则所有依赖与它的对象都会得到通知，并被自动更新。 观察者模式的几角色名称： Subject被观察者，定义被观察者必须实现的职责，它能动态的增加取消观察者，它一般是抽象类或者是实现类，仅仅完成作为被观察者必须实现的职责：管理观察者并通知观察者。 Observer观察者，观察者接受到消息后，即进行更新操作，对接收到的信息进行处理。 ConcreteSubject具体的被观察者，定义被观察者自己的业务逻辑，同时定义对哪些事件进行通知。 ConcreteObserver具体的观察者，每个观察者接收到消息后的处理反应是不同的，每个观察者都有自己的处理逻辑。 观察者模式的优点 观察者和被观察者之间是抽象耦合，不管是增加观察者还是被观察者都非常容易扩展。 建立一套触发机制。 观察者模式的缺点观察者模式需要考虑开发效率和运行效率问题，一个被观察者，多个观察者，开发和调试比较复杂，Java消息的通知默认是顺序执行的，一个观察者卡壳，会影响整体的执行效率。这种情况一般考虑异步的方式。 使用场景 关联行为场景，关联是可拆分的。 事件多级触发场景。 跨系统的消息交换场景，如消息队列的处理机制。 Java中的观察者模式java.util.Observable类和java.util.Observer接口。 订阅发布模型观察者模式也叫作发布/订阅模式。 Spring中的观察者模式Spring在事件处理机制中使用了观察者模式： 事件，ApplicationEvent，该抽象类继承了EventObject，EventObject是JDK中的类，并建议所有的事件都应该继承自EventObject。 事件监听器，ApplicationListener，是一个接口，该接口继承了EventListener接口。EventListener接口是JDK中的，建议所有的事件监听器都应该继承EventListener。 事件发布，ApplicationEventPublisher，ApplicationContext继承了该接口，在ApplicationContext的抽象实现类AbstractApplicationContext中做了实现 AbstractApplicationContext类中publishEvent方法实现： 1234567891011public void publishEvent(ApplicationEvent event) &#123; Assert.notNull(event, &quot;Event must not be null&quot;); if (logger.isTraceEnabled()) &#123; logger.trace(&quot;Publishing event in &quot; + getDisplayName() + &quot;: &quot; + event); &#125; &#x2F;&#x2F;事件发布委托给ApplicationEventMulticaster来执行 getApplicationEventMulticaster().multicastEvent(event); if (this.parent !&#x3D; null) &#123; this.parent.publishEvent(event); &#125;&#125; ApplicationEventMulticaster的multicastEvent方法的实现在SimpleApplicationEventMulticaster类中： 12345678910111213141516public void multicastEvent(final ApplicationEvent event) &#123; &#x2F;&#x2F;获得监听器集合，遍历监听器，可支持同步和异步的广播事件 for (final ApplicationListener listener : getApplicationListeners(event)) &#123; Executor executor &#x3D; getTaskExecutor(); if (executor !&#x3D; null) &#123; executor.execute(new Runnable() &#123; public void run() &#123; listener.onApplicationEvent(event); &#125; &#125;); &#125; else &#123; listener.onApplicationEvent(event); &#125; &#125;&#125; 这就执行了了onApplicationEvent方法，这里是事件发生的地方。 Spring如何根据事件找到事件对应的监听器在Spring容器初始化的时候，也就是在refresh方法中： 1234567891011121314151617public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; ...... try &#123; ...... &#x2F;&#x2F; Initialize event multicaster for this context. &#x2F;&#x2F;初始化一个事件注册表 initApplicationEventMulticaster(); ...... &#x2F;&#x2F; Check for listener beans and register them. &#x2F;&#x2F;注册事件监听器 registerListeners(); ...... &#125; &#125;&#125; initApplicationEventMulticaster方法初始化事件注册表： 12345678910111213protected void initApplicationEventMulticaster() &#123; &#x2F;&#x2F;获得beanFactory ConfigurableListableBeanFactory beanFactory &#x3D; getBeanFactory(); &#x2F;&#x2F;先查找BeanFactory中是否有ApplicationEventMulticaster if (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) &#123; this.applicationEventMulticaster &#x3D; beanFactory.getBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class); &#125; else &#123;&#x2F;&#x2F;如果BeanFactory中不存在，就创建一个SimpleApplicationEventMulticaster this.applicationEventMulticaster &#x3D; new SimpleApplicationEventMulticaster(beanFactory); beanFactory.registerSingleton(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.applicationEventMulticaster); &#125;&#125; 在AbstractApplicationEventMulticaster类中有如下属性： 123456&#x2F;&#x2F;注册表private final ListenerRetriever defaultRetriever &#x3D; new ListenerRetriever(false);&#x2F;&#x2F;注册表的缓存private final Map&lt;ListenerCacheKey, ListenerRetriever&gt; retrieverCache &#x3D; new ConcurrentHashMap&lt;ListenerCacheKey, ListenerRetriever&gt;(64);private BeanFactory beanFactory; ListenerRetriever的结构如下： 123456&#x2F;&#x2F;用来存放监听事件public final Set&lt;ApplicationListener&gt; applicationListeners;&#x2F;&#x2F;存放监听事件的类名称public final Set&lt;String&gt; applicationListenerBeans;private final boolean preFiltered; 初始化注册表之后，就会把事件注册到注册表中，registerListeners()： 12345678910111213protected void registerListeners() &#123; &#x2F;&#x2F;获取所有的Listener，把事件的bean放到ApplicationEventMulticaster中 for (ApplicationListener&lt;?&gt; listener : getApplicationListeners()) &#123; getApplicationEventMulticaster().addApplicationListener(listener); &#125; &#x2F;&#x2F; Do not initialize FactoryBeans here: We need to leave all regular beans &#x2F;&#x2F; uninitialized to let post-processors apply to them! String[] listenerBeanNames &#x3D; getBeanNamesForType(ApplicationListener.class, true, false); &#x2F;&#x2F;把事件的名称放到ApplicationListenerBean里去。 for (String lisName : listenerBeanNames) &#123; getApplicationEventMulticaster().addApplicationListenerBean(lisName); &#125;&#125; Spring使用反射机制，通过方法getBeansOfType获取所有继承了ApplicationListener接口的监听器，然后把监听器放到注册表中，所以我们可以在Spring配置文件中配置自定义监听器，在Spring初始化的时候，会把监听器自动注册到注册表中去。 ApplicationContext发布事件可以参考上面的内容。发布事件的时候的一个方法，getApplicationListeners： 12345678910111213141516171819202122232425262728293031323334353637383940414243protected Collection&lt;ApplicationListener&gt; getApplicationListeners(ApplicationEvent event) &#123; &#x2F;&#x2F;获取事件类型 Class&lt;? extends ApplicationEvent&gt; eventType &#x3D; event.getClass(); &#x2F;&#x2F;或去事件源类型 Class sourceType &#x3D; event.getSource().getClass(); ListenerCacheKey cacheKey &#x3D; new ListenerCacheKey(eventType, sourceType); &#x2F;&#x2F;从缓存中查找ListenerRetriever ListenerRetriever retriever &#x3D; this.retrieverCache.get(cacheKey); &#x2F;&#x2F;缓存中存在，直接返回对应的Listener if (retriever !&#x3D; null) &#123; return retriever.getApplicationListeners(); &#125; else &#123;&#x2F;&#x2F;缓存中不存在，就获取相应的Listener retriever &#x3D; new ListenerRetriever(true); LinkedList&lt;ApplicationListener&gt; allListeners &#x3D; new LinkedList&lt;ApplicationListener&gt;(); Set&lt;ApplicationListener&gt; listeners; Set&lt;String&gt; listenerBeans; synchronized (this.defaultRetriever) &#123; listeners &#x3D; new LinkedHashSet&lt;ApplicationListener&gt;(this.defaultRetriever.applicationListeners); listenerBeans &#x3D; new LinkedHashSet&lt;String&gt;(this.defaultRetriever.applicationListenerBeans); &#125; &#x2F;&#x2F;根据事件类型，事件源类型，获取所需要的监听事件 for (ApplicationListener listener : listeners) &#123; if (supportsEvent(listener, eventType, sourceType)) &#123; retriever.applicationListeners.add(listener); allListeners.add(listener); &#125; &#125; if (!listenerBeans.isEmpty()) &#123; BeanFactory beanFactory &#x3D; getBeanFactory(); for (String listenerBeanName : listenerBeans) &#123; ApplicationListener listener &#x3D; beanFactory.getBean(listenerBeanName, ApplicationListener.class); if (!allListeners.contains(listener) &amp;&amp; supportsEvent(listener, eventType, sourceType)) &#123; retriever.applicationListenerBeans.add(listenerBeanName); allListeners.add(listener); &#125; &#125; &#125; OrderComparator.sort(allListeners); this.retrieverCache.put(cacheKey, retriever); return allListeners; &#125;&#125; 根据事件类型，事件源类型获取所需要的监听器supportsEvent(listener, eventType, sourceType)： 1234567protected boolean supportsEvent( ApplicationListener listener, Class&lt;? extends ApplicationEvent&gt; eventType, Class sourceType) &#123; SmartApplicationListener smartListener &#x3D; (listener instanceof SmartApplicationListener ? (SmartApplicationListener) listener : new GenericApplicationListenerAdapter(listener)); return (smartListener.supportsEventType(eventType) &amp;&amp; smartListener.supportsSourceType(sourceType));&#125; 这里没有进行实际的处理，实际处理在smartListener.supportsEventType(eventType)和smartListener.supportsSourceType(sourceType)方法中。 smartListener.supportsEventType(eventType)： 12345678910public boolean supportsEventType(Class&lt;? extends ApplicationEvent&gt; eventType) &#123; Class typeArg &#x3D; GenericTypeResolver.resolveTypeArgument(this.delegate.getClass(), ApplicationListener.class); if (typeArg &#x3D;&#x3D; null || typeArg.equals(ApplicationEvent.class)) &#123; Class targetClass &#x3D; AopUtils.getTargetClass(this.delegate); if (targetClass !&#x3D; this.delegate.getClass()) &#123; typeArg &#x3D; GenericTypeResolver.resolveTypeArgument(targetClass, ApplicationListener.class); &#125; &#125; return (typeArg &#x3D;&#x3D; null || typeArg.isAssignableFrom(eventType));&#125; 该方法主要的逻辑就是根据事件类型判断是否和监听器参数泛型的类型是否一致。 smartListener.supportsSourceType(sourceType)方法的实现为： 123public boolean supportsSourceType(Class&lt;?&gt; sourceType) &#123; return true;&#125; 定义自己的监听器要明确指定参数泛型，表明该监听器支持的事件，如果不指明具体的泛型，则没有监听器监听事件。 还可以定义自己的事件暂先不做解析。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring中Bean的生命周期]]></title>
      <url>%2F2017%2F02%2F12%2FSpring%E4%B8%ADBean%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%2F</url>
      <content type="text"><![CDATA[BeanFactory和ApplicationContext是Spring中两种很重要的容器，前者提供了最基本的依赖注入的支持，后者在继承前者的基础上进行了功能的拓展，增加了事件传播，资源访问，国际化的支持等功能。同时两者的生命周期也稍微有些不同。 BeanFactory中Bean的生命周期 容器寻找Bean的定义信息，并将其实例化。 使用依赖注入，Spring按照Bean定义信息配置Bean的所有属性。 如果Bean实现了BeanNameAware接口，工厂调用Bean的setBeanName()方法传递Bean的id。 如果实现了BeanFactoryAware接口，工厂调用setBeanFactory()方法传入工厂自身。 如果BeanPostProcessor和Bean关联，那么它们的postProcessBeforeInitialization()方法将被调用。（需要手动进行注册！） 如果Bean实现了InitializingBean接口，则会回调该接口的afterPropertiesSet()方法。 如果Bean指定了init-method方法，就会调用init-method方法。 如果BeanPostProcessor和Bean关联，那么它的postProcessAfterInitialization()方法将被调用。（需要手动注册！） 现在Bean已经可以使用了。 scope为singleton的Bean缓存在Spring IOC容器中。 scope为prototype的Bean生命周期交给客户端。 销毁。 如果Bean实现了DisposableBean接口，destory()方法将会被调用。 如果配置了destory-method方法，就调用这个方法。 ApplicationContext中Bean的生命周期 容器寻找Bean的定义信息，并将其实例化。会对scope为singleton且非懒加载的bean进行实例化 使用依赖注入，Spring按照Bean定义信息配置Bean的所有属性。 如果Bean实现了BeanNameAware接口，工厂调用Bean的setBeanName()方法传递Bean的id。 如果实现了BeanFactoryAware接口，工厂调用setBeanFactory()方法传入工厂自身。 如果实现了ApplicationContextAware接口，会调用该接口的setApplicationContext()方法，传入该Bean的ApplicationContext，这样该Bean就获得了自己所在的ApplicationContext。 如果Bean实现了BeanPostProcessor接口，则调用postProcessBeforeInitialization()方法。 如果Bean实现了InitializingBean接口，则会回调该接口的afterPropertiesSet()方法。 如果Bean制定了init-method方法，就会调用init-method方法。 如果Bean实现了BeanPostProcessor接口，则调用postProcessAfterInitialization()方法。 现在Bean已经可以使用了。 scope为singleton的Bean缓存在Spring IOC容器中。 scope为prototype的Bean生命周期交给客户端。 销毁。 如果Bean实现了DisposableBean接口，destory()方法将会被调用。 如果配置了destory-method方法，就调用这个方法。 两种容器中的不同之处 BeanFactory容器中不会调用ApplicationContext接口的setApplicationContext()方法。 BeanFactory中BeanPostProcessor接口的postProcessBeforeInitialzation()方法和postProcessAfterInitialization()方法不会自动调用，必须自己通过代码手动注册。 BeanFactory容器启动的时候，不会去实例化所有Bean,包括所有scope为singleton且非懒加载的Bean也是一样，而是在调用的时候去实例化。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring中IOC容器的初始化过程]]></title>
      <url>%2F2017%2F02%2F10%2FSpring%E4%B8%ADIOC%E5%AE%B9%E5%99%A8%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[Spring IOC容器初始化过程分为Resource定位，载入解析，注册。IOC容器初始化过程中不包含Bean的依赖注入。Bean的依赖注入一般会发生在第一次通过getBean向容器索取Bean的时候。 ClassPathXmlApplicationContext初始化过程实际的构造方法： 12345678910111213public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException &#123; &#x2F;&#x2F;super方法为容器设置好Bean资源加载器 &#x2F;&#x2F;该方法最终会调用到AbstractApplicationContext的无参构造方法 &#x2F;&#x2F;这里会默认设置解析路径的模式为Ant-style super(parent); &#x2F;&#x2F;设置Bean定义资源文件的路径 setConfigLocations(configLocations); if (refresh) &#123; &#x2F;&#x2F;调用容器的refresh，载入BeanDefinition的入口 refresh(); &#125;&#125; refresh()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; &#x2F;&#x2F; 调用容器准备刷新的方法，此方法中会获取容器的当前时间，给容器设置同步标识 &#x2F;&#x2F;初始化前的准备工作，例如对系统属性或环境变量进行准备以及验证。 prepareRefresh(); &#x2F;&#x2F;通知子类启动refreshBeanFactory的调用 &#x2F;&#x2F;初始化BeanFactory，并进行XML文件读取 &#x2F;&#x2F;ClassPathXmlApplicationContext包含着BeanFactory所提供的一切特征 &#x2F;&#x2F;这一步会复用BeanFactory中的配置文件读取解析以及其他功能 &#x2F;&#x2F;这一步之后ClassPathXmlApplicationContext已经包含了BeanFactory所提供的功能，可以进行Bean的提取等基础操作了。 ConfigurableListableBeanFactory beanFactory &#x3D; obtainFreshBeanFactory(); &#x2F;&#x2F;准备当前上下文用的BeanFactory，为BeanFactory配置容器特性，例如类加载器，事件处理器等各种功能填充。 &#x2F;&#x2F;对BeanFactory各种功能的填充，比如@Qualifier和@Autowired注解就是在这一步增加的支持 prepareBeanFactory(beanFactory); try &#123; &#x2F;&#x2F;为子类设置BeanFactory的后置处理器 &#x2F;&#x2F;子类覆盖方法做额外的处理。 postProcessBeanFactory(beanFactory); &#x2F;&#x2F;调用BeanFactoryPostProcessor，激活各种BeanFactory处理器 invokeBeanFactoryPostProcessors(beanFactory); &#x2F;&#x2F; Register bean processors that intercept bean creation. &#x2F;&#x2F;注册拦截Bean创建的Bean处理器，这里只是注册，真正调用实在getBean的时候。 registerBeanPostProcessors(beanFactory); &#x2F;&#x2F; Initialize message source for this context. &#x2F;&#x2F;为上下文初始化Message源，国际化处理 initMessageSource(); &#x2F;&#x2F; Initialize event multicaster for this context. &#x2F;&#x2F;初始化应用消息广播器，并放入applicationEventMulticaster bean中 initApplicationEventMulticaster(); &#x2F;&#x2F; Initialize other special beans in specific context subclasses. 留给子类来初始化其他的Bean onRefresh(); &#x2F;&#x2F; Check for listener beans and register them. 在所有注册的bean中查找Listener bean，注册到消息广播器中 registerListeners(); &#x2F;&#x2F; Instantiate all remaining (non-lazy-init) singletons. &#x2F;&#x2F;初始化剩下的单实例，非惰性的 finishBeanFactoryInitialization(beanFactory); &#x2F;&#x2F; Last step: publish corresponding event. 完成刷新过程，通知生命周期处理器lifecycleProcessor刷新过程，同时发出ContextRefreshEvent通知别人 finishRefresh(); &#125; catch (BeansException ex) &#123; &#x2F;&#x2F; Destroy already created singletons to avoid dangling resources. destroyBeans(); &#x2F;&#x2F; Reset &#39;active&#39; flag. cancelRefresh(ex); &#x2F;&#x2F; Propagate exception to caller. throw ex; &#125; &#125;&#125; 重点看下ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();这句，告诉子类启动refreshBeanFactory方法以及通过getBeanFactory获得BeanFactory： 12345678protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; refreshBeanFactory(); ConfigurableListableBeanFactory beanFactory &#x3D; getBeanFactory(); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Bean factory for &quot; + getDisplayName() + &quot;: &quot; + beanFactory); &#125; return beanFactory;&#125; refreshBeanFactory方法在AbstractRefreshableApplicationContext实现： 123456789101112131415161718192021protected final void refreshBeanFactory() throws BeansException &#123; &#x2F;&#x2F;如果已经存在BeanFactory，销毁并关闭 if (hasBeanFactory()) &#123; destroyBeans(); closeBeanFactory(); &#125; try &#123; &#x2F;&#x2F;创建IOC容器，创建了DefaultListableBeanFactory容器，给ApplicationContext使用 DefaultListableBeanFactory beanFactory &#x3D; createBeanFactory(); beanFactory.setSerializationId(getId()); customizeBeanFactory(beanFactory); &#x2F;&#x2F;启动对BeanDefinitions的载入 loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) &#123; this.beanFactory &#x3D; beanFactory; &#125; &#125; catch (IOException ex) &#123; throw new ApplicationContextException(&quot;I&#x2F;O error parsing bean definition source for &quot; + getDisplayName(), ex); &#125;&#125; 对BeanDefinition的载入，loadBeanDefinitions方法： 1234567891011121314protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; &#x2F;&#x2F;创建bean读取器，容器使用该读取器去读取Bean定义资源 XmlBeanDefinitionReader beanDefinitionReader &#x3D; new XmlBeanDefinitionReader(beanFactory); &#x2F;&#x2F;配置bean读取器 beanDefinitionReader.setEnvironment(this.getEnvironment()); beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); &#x2F;&#x2F;当Bean读取器读取Bean定义的xml资源文件时，启用xml的校验机制 initBeanDefinitionReader(beanDefinitionReader); &#x2F;&#x2F;通过beanDefinitionReader加载BeanDefinitions loadBeanDefinitions(beanDefinitionReader);&#125; loadBeanDefinitions(beanDefinitionReader)方法： 123456789101112protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws BeansException, IOException &#123; &#x2F;&#x2F;获得Bean配置文件的资源位置 Resource[] configResources &#x3D; getConfigResources(); if (configResources !&#x3D; null) &#123; reader.loadBeanDefinitions(configResources); &#125; String[] configLocations &#x3D; getConfigLocations(); if (configLocations !&#x3D; null) &#123; &#x2F;&#x2F;最终还是转换成Resource的形式去加载资源 reader.loadBeanDefinitions(configLocations); &#125;&#125; 在AbstractBeanDefinitionReader中的loadBeanDefinitions(configResources)方法： 12345678910public int loadBeanDefinitions(Resource... resources) throws BeanDefinitionStoreException &#123; Assert.notNull(resources, &quot;Resource array must not be null&quot;); int counter &#x3D; 0; for (Resource resource : resources) &#123; &#x2F;&#x2F;此处loadBeanDefinitions并没有实现，具体实现在各个子类中 &#x2F;&#x2F;比如XmlBeanDefinitionReader中 counter +&#x3D; loadBeanDefinitions(resource); &#125; return counter;&#125; XmlBeanDefinitionReader中的loadBeanDefinitions方法： 12345678910111213141516171819202122232425public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException &#123; Set&lt;EncodedResource&gt; currentResources &#x3D; this.resourcesCurrentlyBeingLoaded.get(); if (currentResources &#x3D;&#x3D; null) &#123; currentResources &#x3D; new HashSet&lt;EncodedResource&gt;(4); this.resourcesCurrentlyBeingLoaded.set(currentResources); &#125; try &#123; &#x2F;&#x2F;得到xml文件的InputStream InputStream inputStream &#x3D; encodedResource.getResource().getInputStream(); try &#123; &#x2F;&#x2F;得到InputSource InputSource inputSource &#x3D; new InputSource(inputStream); if (encodedResource.getEncoding() !&#x3D; null) &#123; inputSource.setEncoding(encodedResource.getEncoding()); &#125; &#x2F;&#x2F;doLoadBeanDefinitions是从xml文件中加载BeanDefinitions return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); &#125; finally &#123; inputStream.close(); &#125; &#125; catch (IOException ex) &#123;......&#125; finally &#123;......&#125;&#125; xml配置文件的读取以及转化为Bean对象的过程当Spring定位到xml之后，将xml转换为文件流的形式，作为InputSource和Resource对象传递给文档解析器进行解析，文档解析的开始是XmlDefinitionReader的doLoadBeanDefinitions方法。 1234567891011121314&#x2F;&#x2F;inputSource是SAX的InputSource&#x2F;&#x2F;resource对象是对xml文件描述的一个对象protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &#123; try &#123; &#x2F;&#x2F;xml的解析模式 int validationMode &#x3D; getValidationModeForResource(resource); &#x2F;&#x2F;将inputResource解析为Document对象 Document doc &#x3D; this.documentLoader.loadDocument( inputSource, getEntityResolver(), this.errorHandler, validationMode, isNamespaceAware()); &#x2F;&#x2F;Document传递给registerBeanDefinitions方法 &#x2F;&#x2F;此方法才是真正把Document对象解析为BeanDefinition对象的具体实现 return registerBeanDefinitions(doc, resource); &#125;&#125; registerBeanDefinitions方法： 1234567891011121314151617public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException &#123; &#x2F;&#x2F; Support old XmlBeanDefinitionParser SPI for backwards-compatibility. if (this.parserClass !&#x3D; null) &#123; XmlBeanDefinitionParser parser &#x3D; (XmlBeanDefinitionParser) BeanUtils.instantiateClass(this.parserClass); return parser.registerBeanDefinitions(this, doc, resource); &#125; &#x2F;&#x2F;先实例化一个BeanDefinitionDocumentReader，这个对象是通过BeanUtils.instantiateClass方法实例化出来的 &#x2F;&#x2F;实际上BeanUtils.instantiateClass中是封装了Java的反射的一些方法，通过基本的Java反射来构造实例。 BeanDefinitionDocumentReader documentReader &#x3D; createBeanDefinitionDocumentReader(); &#x2F;&#x2F;记录下注册之前BeanDefinition中对象的个数。 int countBefore &#x3D; getRegistry().getBeanDefinitionCount(); &#x2F;&#x2F;开始解析Document documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); return getRegistry().getBeanDefinitionCount() - countBefore;&#125; DefaultBeanDefinitionDocumentReader类中的registerBeanDefinitions方法： 1234567&#x2F;&#x2F;在这里解析Documentpublic void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) &#123; this.readerContext &#x3D; readerContext; logger.debug(&quot;Loading bean definitions&quot;); Element root &#x3D; doc.getDocumentElement(); doRegisterBeanDefinitions(root);&#125; doRegisterBeanDefinitions方法： 1234567891011121314151617181920212223protected void doRegisterBeanDefinitions(Element root) &#123; String profileSpec &#x3D; root.getAttribute(PROFILE_ATTRIBUTE); if (StringUtils.hasText(profileSpec)) &#123; Assert.state(this.environment !&#x3D; null, &quot;environment property must not be null&quot;); String[] specifiedProfiles &#x3D; StringUtils.tokenizeToStringArray(profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS); if (!this.environment.acceptsProfiles(specifiedProfiles)) &#123; return; &#125; &#125; &#x2F;&#x2F;BeanDefinitionParserDelegate对象描述了Spring中bean节点中定义的所有属性和子节点 BeanDefinitionParserDelegate parent &#x3D; this.delegate; this.delegate &#x3D; createHelper(readerContext, root, parent); &#x2F;&#x2F;xml解析的预处理，可以自己定义一些节点属性等，此方法Spring默认实现为空 preProcessXml(root); &#x2F;&#x2F;把Document对象解析为BeanDefinition对象 parseBeanDefinitions(root, this.delegate); &#x2F;&#x2F;xml解析的后处理，可以在解析完xml之后，实现自己的逻辑。Spring默认实现为空。 postProcessXml(root); this.delegate &#x3D; parent;&#125; parseBeanDefinitions方法： 12345678910111213141516171819202122232425262728&#x2F;&#x2F;解析在root级别的元素，比如import，alias，beanprotected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; &#x2F;&#x2F;校验是不是Spring的默认命名空间。 &#x2F;&#x2F;默认命名空间是http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans &#x2F;&#x2F;如果是Spring的默认命名空间，就按照默认命名空间来解析，否则就按照自定义标签来解析 if (delegate.isDefaultNamespace(root)) &#123; NodeList nl &#x3D; root.getChildNodes(); for (int i &#x3D; 0; i &lt; nl.getLength(); i++) &#123; Node node &#x3D; nl.item(i); if (node instanceof Element) &#123; Element ele &#x3D; (Element) node; &#x2F;&#x2F;查看子节点是不是默认命名空间，是就按照默认解析，不是就按照自定义标签进行解析 if (delegate.isDefaultNamespace(ele)) &#123; &#x2F;&#x2F;解析Spring默认的标签 parseDefaultElement(ele, delegate); &#125; else &#123; &#x2F;&#x2F;解析自定义标签 delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123; &#x2F;&#x2F;解析自定义标签 delegate.parseCustomElement(root); &#125;&#125; 解析默认的标签，parseDefaultElement方法： 12345678910111213141516&#x2F;&#x2F;此方法会依次解析文档中的import，alias，bean，beans标签private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) &#123; if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) &#123; importBeanDefinitionResource(ele); &#125; else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) &#123; processAliasRegistration(ele); &#125; else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) &#123; processBeanDefinition(ele, delegate); &#125; else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) &#123; &#x2F;&#x2F; recurse doRegisterBeanDefinitions(ele); &#125;&#125; import标签的解析，importBeanDefinitionResource方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950protected void importBeanDefinitionResource(Element ele) &#123; &#x2F;&#x2F;获取import标签中的resource属性，此属性表示资源地址 &#x2F;&#x2F;resource属性不可为空 String location &#x3D; ele.getAttribute(RESOURCE_ATTRIBUTE); if (!StringUtils.hasText(location)) &#123; getReaderContext().error(&quot;Resource location must not be empty&quot;, ele); return; &#125; &#x2F;&#x2F; 解析resource中的占位符为真正的路径，比如&quot;$&#123;user.dir&#125;&quot; location &#x3D; environment.resolveRequiredPlaceholders(location); Set&lt;Resource&gt; actualResources &#x3D; new LinkedHashSet&lt;Resource&gt;(4); &#x2F;&#x2F; 解析路径，判断是相对路径还是绝对路径 boolean absoluteLocation &#x3D; false; try &#123; absoluteLocation &#x3D; ResourcePatternUtils.isUrl(location) || ResourceUtils.toURI(location).isAbsolute(); &#125; catch (URISyntaxException ex) &#123;...&#125; &#x2F;&#x2F;绝对路径 if (absoluteLocation) &#123; try &#123; &#x2F;&#x2F;递归调用Bean的解析过程 int importCount &#x3D; getReaderContext().getReader().loadBeanDefinitions(location, actualResources); &#125; &#125; else &#123;&#x2F;&#x2F;相对路径，计算出绝对路径，进行递归调用解析过程 try &#123; int importCount; Resource relativeResource &#x3D; getReaderContext().getResource().createRelative(location); if (relativeResource.exists()) &#123; importCount &#x3D; getReaderContext().getReader().loadBeanDefinitions(relativeResource); actualResources.add(relativeResource); &#125; else &#123; String baseLocation &#x3D; getReaderContext().getResource().getURL().toString(); importCount &#x3D; getReaderContext().getReader().loadBeanDefinitions( StringUtils.applyRelativePath(baseLocation, location), actualResources); &#125; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Imported &quot; + importCount + &quot; bean definitions from relative location [&quot; + location + &quot;]&quot;); &#125; &#125; catch (IOException ex) &#123;......&#125; &#125; &#x2F;&#x2F;解析完成后进行监听器激活处理 Resource[] actResArray &#x3D; actualResources.toArray(new Resource[actualResources.size()]); getReaderContext().fireImportProcessed(location, actResArray, extractSource(ele));&#125; 总结 IOC容器初始化入口是在构造方法中调用refresh开始的。 通过ResourceLoader来完成资源文件位置的定位，DefaultResourceLoader是默认的实现，同时上下文本身就给除了ResourceLoader的实现。 创建的IOC容器是DefaultListableBeanFactory。 IOC对Bean的管理和依赖注入功能的实现是通过对其持有的BeanDefinition进行相关操作来完成的。 通过BeanDefinitionReader来完成定义信息的解析和Bean信息的注册。 XmlBeanDefinitionReader是BeanDefinitionReader的实现了，通过它来解析xml配置中的bean定义。 实际的处理过程是委托给BeanDefinitionParserDelegate来完成的。得到Bean的定义信息，这些信息在Spring中使用BeanDefinition对象来表示。 BeanDefinition的注册是由BeanDefinitionRegistry实现的registerBeanDefiition方法进行的。内部使用ConcurrentHashMap来保存BeanDefiition。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SNMP-MIB-SNMP4J简介]]></title>
      <url>%2F2016%2F12%2F27%2FSNMP-MIB-SNMP4J%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[SNMP全称Simple Network Management Protocol，简单网络管理协议。是TCP/IP协议的一部分，属于应用层协议。SNMP协议主要用来解决网络设备的管理，大多数的网络管理系统都是基于SNMP协议。通过该协议可以实现在被管理的设备上获取各种参数，还可以设置修改这些参数。 SNMP系统的组成一般SNMP系统组成大致有4个部分： 网络管理软件，也就是客户端，网络管理员或者是你和我可以通过管理软件对网络设备进行管理。也就是相当于我们平时使用的系统的后台管理。 网络设备，也就是被管理的设备，比如服务器，路由器，交换机等网络设备。 代理程序，代理程序运行在被管理的设备中，相当于服务器的角色。 MIB库，全称Management Information Base，相当于数据库。存储了被监控设备的各种参数和状态信息等。 SNMP协议就是用在网络管理软件和被管理的网络设备之间的协议，通过此协议被管理的网络设备才会听我们的话。 一般情况下做开发，比如我是做Java开发的，所需要做的就是开发网络管理软件，也就是客户端；服务器端的设备运行着代理程序，所有的信息都存储在MIB库中；我们要做的就是通过SNMP协议去读取和设置这些MIB库存的数据。 SNMP协议的结构SNMP使用UDP进行无连接操作，主要包括SNMP报头和协议数据单元： 版本标识符 团体名 PDU SNMP定义了五种报文，用来在管理软件和代理程序之间进行通信： get-request，从代理程序处获取信息 get-next-request，从代理程序处获取下一个参数值 set-request，设置代理程序的值 get-response，代理程序返回值，上面三种请求都会使代理程序返回参数值 trap，代理程序主动发送的报文 MIB库简介Management Information Base 管理信息库，每个被管理的设备都需要有MIB库的存在，我们才能对设备进行管理。 MIB库中定义了可访问的网络设备及其属性，通过OID，Object Identifer来区别。MIB采用分级树形结构，以下是结构图：![mib]MIB.png)结构类似于DNS和Unix的文件系统，例如1.3.6.1.2.1就代表iso.org.dod.internet.mgmt.mib。 net-snmpnet-snmp是一种开放源代码的简单网络管理协议（Simple Network Management Protocol）软件，可以安装在linux系统，unix以及windows上。作用就是上面提到的代理程序。 安装使用本次在Centos7上面安装使用net-snmp软件，具体步骤如下： 安装net-snmp： 1sudo yum install net-snmp* 安装完成之后，修改net-snmp配置文件/etc/snmp/snmpd.conf，在下面代码后面添加两行： 123## sec.name source community#com2sec local localhost COMMUNITY#com2sec mynetwork NETWORK&#x2F;24 COMMUNITY 添加两行如下： 12com2sec local localhost publiccom2sec mynet 192.168.0.0&#x2F;24 public 上面的192.168.0.0/24根据你的实际情况添加，我的局域网网段是192.168.1.xxx，所以上面写的是192.168.0.0，后面的24是子网掩码255.255.255.0。 修改完配置文件后，启动net-snmp服务： 1systemctl start snmpd.service 启动后可以使用以下命令查看启动是否有错： 1systemctl status snmpd.service -l 如果没有提示错误啥的，现在服务应该就已经起来了，可以使用以下命令测试下： 1snmpwalk -v1 -c public 192.168.110.198 后面的ip写net-snmp安装的那台机器的ip。回车后会输出以下信息(不会跟我的完全一样，只是类似的就对了)： 1234567891011SNMPv2-MIB::sysDescr.0 &#x3D; STRING: Linux localhost.localdomain 3.10.0-514.2.2.el7.x86_64 #1 SMP Tue Dec 6 23:06:41 UTC 2016 x86_64SNMPv2-MIB::sysObjectID.0 &#x3D; OID: NET-SNMP-MIB::netSnmpAgentOIDs.10DISMAN-EVENT-MIB::sysUpTimeInstance &#x3D; Timeticks: (4549) 0:00:45.49SNMPv2-MIB::sysContact.0 &#x3D; STRING: Root &lt;root@localhost&gt; (configure &#x2F;etc&#x2F;snmp&#x2F;snmp.local.conf)SNMPv2-MIB::sysName.0 &#x3D; STRING: localhost.localdomainSNMPv2-MIB::sysLocation.0 &#x3D; STRING: Unknown (edit &#x2F;etc&#x2F;snmp&#x2F;snmpd.conf)SNMPv2-MIB::sysORLastChange.0 &#x3D; Timeticks: (4) 0:00:00.04SNMPv2-MIB::sysORID.1 &#x3D; OID: SNMP-MPD-MIB::snmpMPDComplianceSNMPv2-MIB::sysORID.2 &#x3D; OID: SNMP-USER-BASED-SM-MIB::usmMIBComplianceSNMPv2-MIB::sysORID.3 &#x3D; OID: SNMP-FRAMEWORK-MIB::snmpFrameworkMIBCompliance........还有很多输出，省略了...... 使用SNMP4J开发简单的例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class GetCentosSystemInformation &#123; private final static String REMOTE_ADDRESS &#x3D; &quot;udp:192.168.110.198&#x2F;161&quot;; public static void main(String[] args) throws IOException &#123; &#x2F;&#x2F;初始化 Address remoteAddress &#x3D; GenericAddress.parse(REMOTE_ADDRESS); System.out.println(&quot;SNMP地址：&quot; + REMOTE_ADDRESS + &quot;；有效：&quot; + remoteAddress.isValid()); TransportMapping transportMapping &#x3D; new DefaultUdpTransportMapping(); Snmp snmp &#x3D; new Snmp(transportMapping); snmp.listen(); &#x2F;&#x2F;构造发送目标 CommunityTarget target &#x3D; new CommunityTarget(); target.setCommunity(new OctetString(&quot;public&quot;)); target.setAddress(remoteAddress); target.setVersion(SnmpConstants.version2c); target.setRetries(10); target.setTimeout(1500); &#x2F;&#x2F;构造发送内容 PDU pdu &#x3D; new PDU(); OID oid &#x3D; new OID(&quot;1.3.6.1.2.10&quot;); pdu.add(new VariableBinding(oid)); pdu.setType(PDU.GETNEXT); &#x2F;&#x2F;异步监听响应 ResponseListener responseListener &#x3D; new ResponseListener() &#123; @Override public void onResponse(ResponseEvent event) &#123; ((Snmp)event.getSource()).cancel(event.getRequest(),this); PDU response &#x3D; event.getResponse(); PDU request &#x3D; event.getRequest(); if(response &#x3D;&#x3D; null)&#123; System.out.println(&quot;请求超时：&quot; + response + &quot;，请求的内容：&quot; + request); &#125;else &#123; System.out.println(&quot;获取到信息：&quot; + response); &#125; &#125; &#125;; &#x2F;&#x2F;发送 snmp.send(pdu,target,null,responseListener); &#x2F;&#x2F;由于是异步获取信息，在这里需要程序不能结束运行，否则接收不到异步获取的消息。 System.in.read(); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[volatile简介]]></title>
      <url>%2F2016%2F12%2F15%2Fvolatile%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[Java允许线程访问共享变量。作为规则，为了确保共享变量被一致的和可靠的更新，线程应该确保它获得一个排它锁单独的获取这个变量。Java提供了第二种机制即volatile关键字，在某些情况下比锁更加方便。一个字段可以被声明为volatile，在这种情况下，Java内存模型确保所有线程看到的变量值都一样。（Java语言规范） 一个变量被volatile修饰后，这个变量就具备了可见性和禁止指令重排序的特性。 可见性Java内存模型中分为主存和线程的工作内存，线程的工作内存是私有的，其他线程无法看到。变量都存储在主存中，当线程需要一个变量的时候，首先会从主存中复制变量的副本到工作内存中，所以每个线程都拥有同一个变量得副本，他们对该变量副本的修改并不会影响到其他线程，修改后的变量副本需要写回主内存，这样就会导致有可能写回的值不一样，造成错误。此时可用volatile关键字修饰变量，保证每个线程对变量的修改，其他线程都是立即可见的。 禁止指令重排序Java执行语句的顺序可能和代码中写的顺序不同，使用volatile关键字，能保证它的执行顺序不会改变。 Volatile和Synchronizedvolatile修饰的变量具有可见性和禁止指令重排序特性，只能修饰变量。不具有原子性，使用在类似i++这种操作上是无效的。 synchronized修饰方法和代码块，具有互斥性，内存可见性，原子性。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ThreadLocal简介]]></title>
      <url>%2F2016%2F12%2F05%2FThreadLocal%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[ThreadLocal简介Java中的ThreadLocal类给每个线程分配一个只属于该线程的变量副本，可以用来实现线程间的数据隔离，当前线程的变量不能被其他线程访问。 ThreadLocal使用创建ThreadLocal变量1private ThreadLocal myThreadLocal &#x3D; new ThreadLocal(); 访问ThreadLocal变量设置需要保存的值：myThreadLocal.set(&quot;ThreadLocal value&quot;); 读取保存在ThreadLocal变量中的值：String threadLocalVlaue = (String) myThreadLocal.get(); ThreadLocal范型private ThreadLocal myThreadLocal = new ThreadLocal&lt;String&gt;() 初始化ThreadLocal的值12345private ThreadLocal myThreadLocal &#x3D; new ThreadLocal&lt;String&gt;()&#123; protected String initialVlaue()&#123; return &quot;initial value&quot;; &#125;&#125;; 源码分析源码版本： jdk7u80 最常用的方法就是get和set方法，所以先从这两个方法入手，分析下使用。 set(T value)将当前的线程局部变量的副本的值设置为指定的值。子类一般不需要重写该方法，只需要使用initialValue方法去设置初始值。 123456789101112public void set(T value) &#123; &#x2F;&#x2F;获取当前线程 Thread t &#x3D; Thread.currentThread(); &#x2F;&#x2F;从当前线程中得到当前线程的ThreadLocalMap ThreadLocalMap map &#x3D; getMap(t); if (map !&#x3D; null) &#x2F;&#x2F;不为空的话，调用ThreadLocalMap的set方法设置值 map.set(this, value); else &#x2F;&#x2F;ThreadLocalMap为null，还没有被初始化，创建新的map createMap(t, value);&#125; getMap(Thread t)获取指定的线程t的ThreadLocalMap 123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; createMap(t, value)为当前线程t初始化一个ThreadLocalMap用来存储值，初始值是value。 在Thread类中ThreadLocal.ThreadLocalMap threadLocals = null;是用来存储当前线程对应的ThreadLocalMap，属于线程私有的。所以createMap方法使用t.threadLocals = new ThreadLocalMap(this, firstValue);来设置。 123void createMap(Thread t, T firstValue) &#123; t.threadLocals &#x3D; new ThreadLocalMap(this, firstValue);&#125; ThreadLocal用来把变量的副本存储到线程中，变量的副本就只能是当前线程私有，而在线程中是通过ThreadLocalMap来存储副本的，所以有必要了解下ThreadLocalMap是怎么实现的。 ThreadLocalMapThreadLocalMap是一个自定义的HashMap，用来存储线程本地变量的值，类似与Map。ThreadLocalMap内部是使用Entry对象来存储。 EntryEntry继承了WeakReference，使用ThreadLocal作为key，value为ThreadLocal的值。 123456789static class Entry extends WeakReference&lt;ThreadLocal&gt; &#123; &#x2F;** The value associated with this ThreadLocal. *&#x2F; Object value; Entry(ThreadLocal k, Object v) &#123; super(k); value &#x3D; v; &#125;&#125; private static final int INITIAL_CAPACITY = 16;ThreadLocalMap的初始容量为16。 private Entry[] table;存放线程本地变量的数组。 private int size = 0; 线程本地变量的数目。 private int threshold 扩容的阈值。 扩容的阈值为指定长度的三分之二 123private void setThreshold(int len) &#123; threshold &#x3D; len * 2 &#x2F; 3;&#125; //构造方法，当我们第一次使用的时候会构造一个新的ThreadLocalMap 123456789101112ThreadLocalMap(ThreadLocal firstKey, Object firstValue) &#123; &#x2F;&#x2F;存放线程本地变量的数组，初始容量16 table &#x3D; new Entry[INITIAL_CAPACITY]; &#x2F;&#x2F;得到存放Entry的数组下标 int i &#x3D; firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); &#x2F;&#x2F;在得出的位置处新建一个Entry对象 table[i] &#x3D; new Entry(firstKey, firstValue); &#x2F;&#x2F;大小设为1 size &#x3D; 1; &#x2F;&#x2F;设置阈值 16*2&#x2F;3 setThreshold(INITIAL_CAPACITY);&#125; 使用给定的父map来构造一个ThreadLocalMap 1234567891011121314151617181920212223242526private ThreadLocalMap(ThreadLocalMap parentMap) &#123; &#x2F;&#x2F;父map中存放的线程本地变量数据 Entry[] parentTable &#x3D; parentMap.table; &#x2F;&#x2F;父map的长度 int len &#x3D; parentTable.length; &#x2F;&#x2F;设置阈值 setThreshold(len); &#x2F;&#x2F;新建长度为len的Entry数组 table &#x3D; new Entry[len]; &#x2F;&#x2F;循环把父map的数组的元素放到新数组中去，中间需要重新计算数组下标。 for (int j &#x3D; 0; j &lt; len; j++) &#123; Entry e &#x3D; parentTable[j]; if (e !&#x3D; null) &#123; ThreadLocal key &#x3D; e.get(); if (key !&#x3D; null) &#123; Object value &#x3D; key.childValue(e.value); Entry c &#x3D; new Entry(key, value); int h &#x3D; key.threadLocalHashCode &amp; (len - 1); while (table[h] !&#x3D; null) h &#x3D; nextIndex(h, len); table[h] &#x3D; c; size++; &#125; &#125; &#125;&#125; 根据key获取Entry 1234567891011private Entry getEntry(ThreadLocal key) &#123; &#x2F;&#x2F;计算数组下标 int i &#x3D; key.threadLocalHashCode &amp; (table.length - 1); &#x2F;&#x2F;获取元素 Entry e &#x3D; table[i]; if (e !&#x3D; null &amp;&amp; e.get() &#x3D;&#x3D; key) return e; else &#x2F;&#x2F;没有找到key的时候的处理 return getEntryAfterMiss(key, i, e);&#125; //当没有找到对应的key时候 123456789101112131415161718192021222324&#x2F;&#x2F;key ThreadLocal对象&#x2F;&#x2F;i 计算出来的数组下标&#x2F;&#x2F;e 在i处的entryprivate Entry getEntryAfterMiss(ThreadLocal key, int i, Entry e) &#123; Entry[] tab &#x3D; table; int len &#x3D; tab.length; while (e !&#x3D; null) &#123; &#x2F;&#x2F;获取key ThreadLocal k &#x3D; e.get(); &#x2F;&#x2F;找到key，返回e if (k &#x3D;&#x3D; key) return e; &#x2F;&#x2F;key为null，找不到，清除掉 if (k &#x3D;&#x3D; null) expungeStaleEntry(i); else &#x2F;&#x2F;key不为null，计算下一个数组下标 i &#x3D; nextIndex(i, len); &#x2F;&#x2F;返回下一个entry e &#x3D; tab[i]; &#125; return null;&#125; //存放指定的key和value 1234567891011121314151617181920212223242526272829303132333435private void set(ThreadLocal key, Object value) &#123; &#x2F;&#x2F;当前存放的数组 Entry[] tab &#x3D; table; &#x2F;&#x2F;数组长度 int len &#x3D; tab.length; &#x2F;&#x2F;根据key获取存放的数组下标 int i &#x3D; key.threadLocalHashCode &amp; (len-1); &#x2F;&#x2F;从第i个元素开始挨个遍历 for (Entry e &#x3D; tab[i]; e !&#x3D; null; e &#x3D; tab[i &#x3D; nextIndex(i, len)]) &#123; &#x2F;&#x2F;获取到i处的key ThreadLocal k &#x3D; e.get(); &#x2F;&#x2F;i处的key和要存放的key相等，将原来的值替换成新的值，返回。 if (k &#x3D;&#x3D; key) &#123; e.value &#x3D; value; return; &#125; &#x2F;&#x2F;i处key为null if (k &#x3D;&#x3D; null) &#123; &#x2F;&#x2F;替换原来的Entry replaceStaleEntry(key, value, i); return; &#125; &#125; &#x2F;&#x2F;不存在key，新建一个Entry tab[i] &#x3D; new Entry(key, value); &#x2F;&#x2F;size加1 int sz &#x3D; ++size; &#x2F;&#x2F;不能移除一些旧的entry并且新的size已经大于等于阈值了，需要重新扩容 if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;&#x3D; threshold) rehash();&#125; //rehash() 12345678private void rehash() &#123; &#x2F;&#x2F;首先清除旧的entry expungeStaleEntries(); &#x2F;&#x2F; size大于等于阈值的四分之三，将容量扩展为两倍 if (size &gt;&#x3D; threshold - threshold &#x2F; 4) resize();&#125; ThreadLocalMap内部的Entry的get和set基本就这些，接下来继续看ThreadLocal的get方法 public T get()12345678910111213public T get() &#123; &#x2F;&#x2F;获取当前线程 Thread t &#x3D; Thread.currentThread(); &#x2F;&#x2F;获取当前线程的ThreadLocalMap ThreadLocalMap map &#x3D; getMap(t); if (map !&#x3D; null) &#123; ThreadLocalMap.Entry e &#x3D; map.getEntry(this); if (e !&#x3D; null) return (T)e.value; &#125; &#x2F;&#x2F;map为空，设置初始值，并返回 return setInitialValue();&#125; private T setInitialValue()1234567891011private T setInitialValue() &#123; &#x2F;&#x2F;这里初始值为null T value &#x3D; initialValue(); Thread t &#x3D; Thread.currentThread(); ThreadLocalMap map &#x3D; getMap(t); if (map !&#x3D; null) map.set(this, value); else createMap(t, value); return value;&#125; remove()移除当前线程的ThreadLocalMap中的值 12345public void remove() &#123; ThreadLocalMap m &#x3D; getMap(Thread.currentThread()); if (m !&#x3D; null) m.remove(this); &#125; 总结一下get和set方法get方法： 首先获取到当前线程，然后获取当前线程内部的ThreadLocalMap，如果map不为空，就查找到Entry中的值，返回；如果map为空，设置初始值，并返回。 set方法： 首先获取到当前线程，然后获取当前线程内部的ThreadLocalMap，如果map不为空，直接使用Entry的set设置值，此方法会替换原来的值；如果map为空，说明没有使用过，新建一个map并使用当前线程和指定的值初始化。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java同步简介]]></title>
      <url>%2F2016%2F11%2F30%2FJava%E5%90%8C%E6%AD%A5%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[Java同步Java中同步一直都是很重要的问题，对于初学者来说也是不太容易能理解的问题。特在此记录一下有关Java中同步和锁的知识。主要涉及到同步的概念以及Java中解决的办法和简单的例子。有关锁Lock中的内容不在此做说明。 同步为什么需要同步这个问题不难回答。当牵扯到同步问题的时候，就离不开多线程了。简单举个例子，桌子上有一台2016新款MacBook pro，我和女朋友都想要去玩，我们俩同时伸向了那台电脑，后果可想而知（当然是我地上坐着玩手机去了！），我们俩都在抢那台电脑，谁也玩不了。这时候该怎么办？我们会约定好，一人半个小时，我在玩电脑的时候你拿着手机玩……就这样一人一段时间的玩。分析一下，电脑就是被竞争的资源，我和女朋友是两个线程，关于怎么玩电脑就需要同步来解决了，要不然不就打起来了么。 同步就是要多个运行的线程在一起良好的工作，在访问同一个资源时不会造成资源的错误或者混乱。 Java中同步的解决办法Java中内置了synchronized关键字来控制线程的同步。synchronized关键字可以修饰方法或者代码块，当有一个线程进入到了synchronized方法或者代码块中的时候，其他的线程就不能进入到此方法或者代码块中，必须等待刚才的线程完成退出synchronized方法或者代码块之后，等待的方法才能去执行。就是我女票玩电脑的时候，我就不能玩，必须等着。 锁synchronized其实就是实现锁的功能。Java中每个对象都有一个内置锁，每次需要访问同步方法或者同步块的时候，必须获得相应的锁。要不然等待的线程怎么能知道这块代码是不是被其他线程在用呢。 同步的几种情况synchronized修饰一个方法修饰一个方法时，能够保证同一时刻最多只有一个线程执行该方法中的代码。此时锁的是当前实例对象，如果该对象还有其他的synchronized方法，也不能被其他线程访问，因为当前对象的锁只有一个。但是对于该对象其他的非synchronized方法其他线程则可以访问。 synchronized修饰代码块此时代码块应该用synchronized(this)来修饰，锁的也是当前实例对象，该对象其他的同步方法和同步块也不能被其他线程访问。 synchronized修饰静态方法静态方法是属于类的而不属于对象的，所以静态方法的锁是类对象。一个synchronized静态方法被访问时，其他线程不能访问这个类的所有对象的同步方法。这个锁是类级别的。 synchronized(.class)修饰的代码块线程进入synchronized(.class)修饰的代码块，会将整个类的所有这个synchronized(.class) 同步代码块锁定，其他线程没有办法访问synchronized(.class)修饰的代码块。属于class级别的。但是其他线程可以访问非静态的同步方法或者代码块。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java多线程简介]]></title>
      <url>%2F2016%2F11%2F29%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[Java多线程简介Java中内置了对多线程的支持，让多线程的开发方便很多，但同时也带来了另外的复杂，线程间的交互以及很多的不确定性让多线程又显得很复杂。在此只是针对Java中多线程的基础做些说明，有关线程和进程的区别，以及多线程的好处和更深层的暂不多说。 线程的状态线程的状态定义在Thread类中一个State枚举类型： 新建状态（NEW），通过new Thread新建的线程处于新建状态，通常会调用start()方法来启动线程。 就绪状态（RUNNABLE），此时线程并没有在执行，而是可执行，在等待CPU调度去真正执行。就绪状态的线程有可能是刚调用start()方法进入就绪队列的线程，也有可能是等待其他资源的状态的线程。 阻塞状态（BLOCKED），等待锁的线程会处于阻塞状态，线程等待进入synchronized块或方法时候处于阻塞状态；线程调用了wait()方法后等待重新获取锁的时候也会处于阻塞状态。 等待状态（WAITING），线程调用了wait()方法并且没有设置超时时间会一直处于等待状态；线程调用了join()方法并且没有设置超时时间会一直处于等待状态；线程调用了LockSupport.park()方法会处于等待状态。 有等待时间的等待状态（TIMED_WAITING），线程调用了以下方法，并且设置了等待的时间，会处于等待状态：1. Thread.sleep;2. wait(long)设置了超时时间；3. join(long)设置了超时时间；4. LockSupport.parkNanos()方法；5. LockSupport.parkUntil()方法。 终止状态（TERMINATED），线程处于终止状态，已经完成了执行。 线程的生命周期线程的生命周期分为：新建（New），就绪（Runnable），运行（Running），阻塞（Blocked），死亡（Dead）五个阶段。 生命周期五个阶段之间的转换如图所示： Java多线程简介Java中内置了对多线程的支持，让多线程的开发方便很多，但同时也带来了另外的复杂，线程间的交互以及很多的不确定性让多线程又显得很复杂。在此只是针对Java中多线程的基础做些说明，有关线程和进程的区别，以及多线程的好处和更深层的暂不多说。 线程的状态线程的状态定义在Thread类中一个State枚举类型： 新建状态（NEW），通过new Thread新建的线程处于新建状态，通常会调用start()方法来启动线程。 就绪状态（RUNNABLE），此时线程并没有在执行，而是可执行，在等待CPU调度去真正执行。就绪状态的线程有可能是刚调用start()方法进入就绪队列的线程，也有可能是等待其他资源的状态的线程。 阻塞状态（BLOCKED），等待锁的线程会处于阻塞状态，线程等待进入synchronized块或方法时候处于阻塞状态；线程调用了wait()方法后等待重新获取锁的时候也会处于阻塞状态。 等待状态（WAITING），线程调用了wait()方法并且没有设置超时时间会一直处于等待状态；线程调用了join()方法并且没有设置超时时间会一直处于等待状态；线程调用了LockSupport.park()方法会处于等待状态。 有等待时间的等待状态（TIMED_WAITING），线程调用了以下方法，并且设置了等待的时间，会处于等待状态：1. Thread.sleep;2. wait(long)设置了超时时间；3. join(long)设置了超时时间；4. LockSupport.parkNanos()方法；5. LockSupport.parkUntil()方法。 终止状态（TERMINATED），线程处于终止状态，已经完成了执行。 线程的生命周期线程的生命周期分为：新建（New），就绪（Runnable），运行（Running），阻塞（Blocked），死亡（Dead）五个阶段。 生命周期五个阶段之间的转换如图所示： 新建（New）使用new关键字和Thread类创建一个线程之后，该线程就处于新建状态。新建跟普通Java对象的创建一样，由虚拟机分配内存，初始化成员变量等。接下来就等待调用start()方法。 就绪（Runnable）当已经新建的线程对象调用了start()方法，该线程就处于就绪状态。此时线程并没有直接运行，而是处于就绪队列中，需要等待JVM线程调度器的调用。 运行状态（Running）处于就绪状态的线程如果获取到了CPU，就可以执行进入运行状态。此时线程可以变成阻塞状态，就绪状态，死亡状态。 从运行状态转换到其他状态的几个条件： 失去CPU资源或者调用了yield()方法后线程进入就绪状态。 调用了sleep()方法，调用了阻塞IO方法，试图获取同步锁，等待通知notify或者调用了线程的suspend()方法后线程进入阻塞状态。 调用了stop()方法，遇到错误Error，遇到异常Exception，或者线程执行完成后线程进入死亡状态。 阻塞状态当线程调用了sleep()方法，调用了阻塞IO方法，试图获取同步锁，等待通知notify或者调用了线程的suspend()方法后，线程进入阻塞状态。被阻塞的线程会进入就绪状态，等待CPU调度重新进入运行状态。 从阻塞状态进入到就绪状态的几个条件： 调用了sleep()方法后时间已经到了。 调用的IO操作已经完成。 获取到了同步锁。 获得到了通知。 调用到了resume()方法。 死亡状态 遇到Error或者Exception，线程死亡 直接调用了stop()方法 线程执行完成，正常结束 Thread源码分析 源码版本：jdk7u80 yield() 字面意思是让出，让步。使当前线程从运行状态变成就绪状态。调用此方法之后，当前线程会把CPU执行时间让出去，供其他线程或者自己去获得CPU运行。 sleep(long millis)，sleep(long millis, int nanos) sleep方法强制使当前正在执行的方法暂停执行，会阻塞当前线程，让出CPU。这样可以让其他线程获取执行的机会。当睡眠时间到了之后，线程进入就绪状态。 在一个synchronized块中调用sleep()方法，对象持有的锁不会被释放，仍然占有该锁。 currentThread() 返回当前正在执行的线程对象。 start()该方法用来启动一个线程，线程启动后会执行run()方法中的代码。start()方法不能被重复调用。 stop()该方法可以用来停止一个线程的执行。该方法已经被弃用。 interrupt()该方法用来中断线程，设置中断状态为true。并没有被直接中断，而是设置了中断状态。 interrupted()测试当前线程是否已经中断，该方法还负责清除中断状态。 isInterrupted()判断中断状态。 isAlive()测试线程是否处于活动的状态。 suspend()把一个线程挂起，使线程处于阻塞状态，必须调用对应的resume()方法才能使线程进入可执行状态。已被废弃。 resume()把一个挂起的线程恢复执行。已被废弃。 setPriority()设置线程的优先级。 getPriority()获取线程的优先级。 setName(String)设置线程的名字。 getName()获取线程的名字。 getThreadGroup()获取线程组。 activeCount()获取当前线程所在线程组中活跃的线程数。 join(),join(long),join(long,int) 该方法可以把指定的线程加入到当前线程中。比如在线程A中调用线程B的join()方法，线程A会阻塞，直到线程B完成后，线程A才能继续执行。 setDaemon(boolean) 标记此线程为守护线程，此方法必须在start()方法之前调用。 isDaemon()判断是否是守护线程。 holdsLock(Object) 判断当前线程是否持有给定对象的锁。 getId()获得线程的id。 getState()获得当前线程的状态。 创建线程的方法主要有三种方法： 继承Thread类来创建线程，继承Thread类重写run方法，创建子类实例，调用start方法。 实现Runnable接口来创建线程，实现Runnable接口并实现run方法，创建Runnable实现类的实例，new一个Thread的实例，并以Runnable实现类的实例作为target，调用thread的start方法。 使用Callable和Future来创建线程，实现Callable接口并实现call方法，创建Callable实现类的实例并使用FutureTask类来包装Callable对象，使用FutureTask对象作为Thread的target创建启动新线程，最后调用FutureTask对象的get方法来获得子线程执行结束后的返回值。 前面两个不再举例子，最后一种代码如下： CallableDemo： 123456public class CallableDemo implements Callable&lt;Integer&gt;&#123; @Override public Integer call() throws Exception &#123; return new Random().nextInt(1000); &#125;&#125; CallableAndFutureTest： 12345678910111213141516public class CallableAndFutureTest &#123; public static void main(String[] args) &#123; Callable&lt;Integer&gt; callable &#x3D; new CallableDemo(); FutureTask&lt;Integer&gt; futureTask &#x3D; new FutureTask&lt;Integer&gt;(callable); new Thread(futureTask).start(); try &#123; Thread.sleep(5000); System.out.println(futureTask.get()); &#125;catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 线程间协作线程之间的通信协作可以使用Object对象中的wait()方法，notify()方法，notifyAll()方法来实现。 wait(),wait(long),wait(long,int) 该方法将当前线程进入休眠状态，wait()方法只能使用在同步方法或者同步块中调用。调用wait()方法后，当前线程释放锁。该线程处于该对象的等待池中。 notify()，notifyAll() 该方法用来通知那些可能在等待该对象的对象锁的其他线程。notify()方法必须在同步方法或代码块中调用。被唤醒的对象进入该对象的锁池中，锁池中的线程会去竞争该对象锁。 新建（New）使用new关键字和Thread类创建一个线程之后，该线程就处于新建状态。新建跟普通Java对象的创建一样，由虚拟机分配内存，初始化成员变量等。接下来就等待调用start()方法。 就绪（Runnable）当已经新建的线程对象调用了start()方法，该线程就处于就绪状态。此时线程并没有直接运行，而是处于就绪队列中，需要等待JVM线程调度器的调用。 运行状态（Running）处于就绪状态的线程如果获取到了CPU，就可以执行进入运行状态。此时线程可以变成阻塞状态，就绪状态，死亡状态。 从运行状态转换到其他状态的几个条件： 失去CPU资源或者调用了yield()方法后线程进入就绪状态。 调用了sleep()方法，调用了阻塞IO方法，试图获取同步锁，等待通知notify或者调用了线程的suspend()方法后线程进入阻塞状态。 调用了stop()方法，遇到错误Error，遇到异常Exception，或者线程执行完成后线程进入死亡状态。 阻塞状态当线程调用了sleep()方法，调用了阻塞IO方法，试图获取同步锁，等待通知notify或者调用了线程的suspend()方法后，线程进入阻塞状态。被阻塞的线程会进入就绪状态，等待CPU调度重新进入运行状态。 从阻塞状态进入到就绪状态的几个条件： 调用了sleep()方法后时间已经到了。 调用的IO操作已经完成。 获取到了同步锁。 获得到了通知。 调用到了resume()方法。 死亡状态 遇到Error或者Exception，线程死亡 直接调用了stop()方法 线程执行完成，正常结束 Thread源码分析 源码版本：jdk7u80 yield() 字面意思是让出，让步。使当前线程从运行状态变成就绪状态。调用此方法之后，当前线程会把CPU执行时间让出去，供其他线程或者自己去获得CPU运行。 sleep(long millis)，sleep(long millis, int nanos) sleep方法强制使当前正在执行的方法暂停执行，会阻塞当前线程，让出CPU。这样可以让其他线程获取执行的机会。当睡眠时间到了之后，线程进入就绪状态。 在一个synchronized块中调用sleep()方法，对象持有的锁不会被释放，仍然占有该锁。 currentThread() 返回当前正在执行的线程对象。 start()该方法用来启动一个线程，线程启动后会执行run()方法中的代码。start()方法不能被重复调用。 stop()该方法可以用来停止一个线程的执行。该方法已经被弃用。 interrupt()该方法用来中断线程，设置中断状态为true。并没有被直接中断，而是设置了中断状态。 interrupted()测试当前线程是否已经中断，该方法还负责清除中断状态。 isInterrupted()判断中断状态。 isAlive()测试线程是否处于活动的状态。 suspend()把一个线程挂起，使线程处于阻塞状态，必须调用对应的resume()方法才能使线程进入可执行状态。已被废弃。 resume()把一个挂起的线程恢复执行。已被废弃。 setPriority()设置线程的优先级。 getPriority()获取线程的优先级。 setName(String)设置线程的名字。 getName()获取线程的名字。 getThreadGroup()获取线程组。 activeCount()获取当前线程所在线程组中活跃的线程数。 join(),join(long),join(long,int) 该方法可以把指定的线程加入到当前线程中。比如在线程A中调用线程B的join()方法，线程A会阻塞，直到线程B完成后，线程A才能继续执行。 setDaemon(boolean) 标记此线程为守护线程，此方法必须在start()方法之前调用。 isDaemon()判断是否是守护线程。 holdsLock(Object) 判断当前线程是否持有给定对象的锁。 getId()获得线程的id。 getState()获得当前线程的状态。 创建线程的方法主要有三种方法： 继承Thread类来创建线程，继承Thread类重写run方法，创建子类实例，调用start方法。 实现Runnable接口来创建线程，实现Runnable接口并实现run方法，创建Runnable实现类的实例，new一个Thread的实例，并以Runnable实现类的实例作为target，调用thread的start方法。 使用Callable和Future来创建线程，实现Callable接口并实现call方法，创建Callable实现类的实例并使用FutureTask类来包装Callable对象，使用FutureTask对象作为Thread的target创建启动新线程，最后调用FutureTask对象的get方法来获得子线程执行结束后的返回值。 前面两个不再举例子，最后一种代码如下： CallableDemo： 123456public class CallableDemo implements Callable&lt;Integer&gt;&#123; @Override public Integer call() throws Exception &#123; return new Random().nextInt(1000); &#125;&#125; CallableAndFutureTest： 12345678910111213141516public class CallableAndFutureTest &#123; public static void main(String[] args) &#123; Callable&lt;Integer&gt; callable &#x3D; new CallableDemo(); FutureTask&lt;Integer&gt; futureTask &#x3D; new FutureTask&lt;Integer&gt;(callable); new Thread(futureTask).start(); try &#123; Thread.sleep(5000); System.out.println(futureTask.get()); &#125;catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 线程间协作线程之间的通信协作可以使用Object对象中的wait()方法，notify()方法，notifyAll()方法来实现。 wait(),wait(long),wait(long,int) 该方法将当前线程进入休眠状态，wait()方法只能使用在同步方法或者同步块中调用。调用wait()方法后，当前线程释放锁。该线程处于该对象的等待池中。 notify()，notifyAll() 该方法用来通知那些可能在等待该对象的对象锁的其他线程。notify()方法必须在同步方法或代码块中调用。被唤醒的对象进入该对象的锁池中，锁池中的线程会去竞争该对象锁。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MVC简介]]></title>
      <url>%2F2016%2F11%2F28%2FMVC%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[MVC简介面试的时候被问到关于MVC相关的知识，才发现自己只会说出来什么叫MVC，但是其详细的东西自己却无法顺利的表述出来，特在此记录下。 MVC基础MVC是Model-View-Controller的简称，是一种软件架构模式，也是经过很多人的长期实践最后得出来的很适合软件开发的一种模式。 M（Model）模型层，这应该是最底层的一层，这一层中我们需要处理的是业务逻辑和数据等等方面的东西，包括核心业务代码的编写，访问数据库或者文件进行数据处理，数据库等很多方面。 V（View）视图层，这一层是最上面的一层，用户可以看到并且进行操作的地方。 C（Controller）控制层，这部分处于中间，负责转发和处理请求，接收来自视图层用户的操作等，负责处理和转发；会根据情况传递到模型层，模型层做完处理之后，再由控制层根据实际情况返回到视图层去展示。另外一种情况是在模型层处理完之后，可以直接将结果返回给视图层。 Web MVCWeb开发中的MVC模式跟标准的MVC模式一样，但是Web MVC不能在模型层将结果主动推送给视图层，因为Web模式下是基于请求-响应模型的。其他的定义和流程都和标准MVC模式是一样的。 Web如何进化到MVC这里的Web进化主要利用Java开发方面的历程作说明，当然最开始的CGI不算是Java中的过程，但是还是需要它作为开头。 大致的历程为：CGI --&gt; Servlet --&gt; JSP --&gt; Model1 --&gt; Model2 CGI由于没有使用过CGI这种技术做过开发，只能使用维基上的定义来简单说明下。CGI是通用网关接口（Common Gateway Interface）的简称，多使用Perl语言编写，接受用户的请求，然后根据请求的返回给用户HTML页面。但是每次CGI请求都会生成一个新的进程去处理，对服务器来说压力太大，请求大的时候很快就会垮掉。 ServletServlet技术和CGI技术的作用是一样的，但是Servlet是Java体系中最早用来解决Web的技术。Java是平台无关的，同样Servlet也是，它比CGI更加的高高效，CGI针对请求生成的是进程级别的，而Servlet生成的是线程级别的。 Servlet的生命周期 加载和实例化 Servlet容器负责加载和实例化Servlet。 初始化 Servlet在实例化之后，会调用init()方法初始化。 服务 Servlet的service()方法对请求进行处理。 销毁 Servlet的destory()方法用来销毁Servlet实例，释放资源等。 Servlet缺点Servlet技术让Java有了Web方面的更好的选择，后来的技术很大一部分都是在Servlet的基础上发展来的。但是Servlet直接做开发还是显得很繁琐，我在使用Servlet做开发的时候遇到过很多的弊端，直接点说就是Servlet做开发时，把MVC的分层直接放到一起了，甚至html代码也得在Servlet里面直接输出。这样的做法对于后期维护修改或者页面的调试很是麻烦。现在直接用Servlet做开发已经很少用了，但是还是得作为必须要去学习的基础知识。 JSPJSP技术使用在html页面中嵌入脚本语言的方式来处理Servlet技术的不足，相对于Servlet来说有了很多进步，开发页面更加方便简单。但是实质上JSP最后还是被编译成了Servlet，表现逻辑以及控制和模型等方面的逻辑还是混杂在了一起，看起来好像是跟Servlet反过来一样。这种做法同样不可取。 Model1这种技术是JSP和JavaBean的组合，相对于JSP来说只是将业务逻辑放到了单独的JavaBean中去，可以理解为是JSP的增强，对JSP页面进行了简化，但是JSP页面仍然将表现逻辑，控制逻辑，业务逻辑等混杂到一起。这种做法仍然不可取。 Model2Model2采用JSP+Servlet+JavaBean来实现，其实这时候就可以认为是我们的Web MVC模型了，在实际使用中也是使用的这种模式。 JSP 使用html和jsp的标签来负责实现表现层；Servlet负责接收用户的请求，转交给模型层进行处理，返回结果给视图层等功能；JavaBean负责业务逻辑的处理，也就是模型层的功能。 到这里为止，开发过程中遇到的方式都已经介绍完了，也走到了MVC模式这一步。下面会简单介绍下MVC的框架相关知识。 Spring Web MVC先看一下Spring官方的一张请求处理流程图： MVC简介面试的时候被问到关于MVC相关的知识，才发现自己只会说出来什么叫MVC，但是其详细的东西自己却无法顺利的表述出来，特在此记录下。 MVC基础MVC是Model-View-Controller的简称，是一种软件架构模式，也是经过很多人的长期实践最后得出来的很适合软件开发的一种模式。 M（Model）模型层，这应该是最底层的一层，这一层中我们需要处理的是业务逻辑和数据等等方面的东西，包括核心业务代码的编写，访问数据库或者文件进行数据处理，数据库等很多方面。 V（View）视图层，这一层是最上面的一层，用户可以看到并且进行操作的地方。 C（Controller）控制层，这部分处于中间，负责转发和处理请求，接收来自视图层用户的操作等，负责处理和转发；会根据情况传递到模型层，模型层做完处理之后，再由控制层根据实际情况返回到视图层去展示。另外一种情况是在模型层处理完之后，可以直接将结果返回给视图层。 Web MVCWeb开发中的MVC模式跟标准的MVC模式一样，但是Web MVC不能在模型层将结果主动推送给视图层，因为Web模式下是基于请求-响应模型的。其他的定义和流程都和标准MVC模式是一样的。 Web如何进化到MVC这里的Web进化主要利用Java开发方面的历程作说明，当然最开始的CGI不算是Java中的过程，但是还是需要它作为开头。 大致的历程为：CGI --&gt; Servlet --&gt; JSP --&gt; Model1 --&gt; Model2 CGI由于没有使用过CGI这种技术做过开发，只能使用维基上的定义来简单说明下。CGI是通用网关接口（Common Gateway Interface）的简称，多使用Perl语言编写，接受用户的请求，然后根据请求的返回给用户HTML页面。但是每次CGI请求都会生成一个新的进程去处理，对服务器来说压力太大，请求大的时候很快就会垮掉。 ServletServlet技术和CGI技术的作用是一样的，但是Servlet是Java体系中最早用来解决Web的技术。Java是平台无关的，同样Servlet也是，它比CGI更加的高高效，CGI针对请求生成的是进程级别的，而Servlet生成的是线程级别的。 Servlet的生命周期 加载和实例化 Servlet容器负责加载和实例化Servlet。 初始化 Servlet在实例化之后，会调用init()方法初始化。 服务 Servlet的service()方法对请求进行处理。 销毁 Servlet的destory()方法用来销毁Servlet实例，释放资源等。 Servlet缺点Servlet技术让Java有了Web方面的更好的选择，后来的技术很大一部分都是在Servlet的基础上发展来的。但是Servlet直接做开发还是显得很繁琐，我在使用Servlet做开发的时候遇到过很多的弊端，直接点说就是Servlet做开发时，把MVC的分层直接放到一起了，甚至html代码也得在Servlet里面直接输出。这样的做法对于后期维护修改或者页面的调试很是麻烦。现在直接用Servlet做开发已经很少用了，但是还是得作为必须要去学习的基础知识。 JSPJSP技术使用在html页面中嵌入脚本语言的方式来处理Servlet技术的不足，相对于Servlet来说有了很多进步，开发页面更加方便简单。但是实质上JSP最后还是被编译成了Servlet，表现逻辑以及控制和模型等方面的逻辑还是混杂在了一起，看起来好像是跟Servlet反过来一样。这种做法同样不可取。 Model1这种技术是JSP和JavaBean的组合，相对于JSP来说只是将业务逻辑放到了单独的JavaBean中去，可以理解为是JSP的增强，对JSP页面进行了简化，但是JSP页面仍然将表现逻辑，控制逻辑，业务逻辑等混杂到一起。这种做法仍然不可取。 Model2Model2采用JSP+Servlet+JavaBean来实现，其实这时候就可以认为是我们的Web MVC模型了，在实际使用中也是使用的这种模式。 JSP 使用html和jsp的标签来负责实现表现层；Servlet负责接收用户的请求，转交给模型层进行处理，返回结果给视图层等功能；JavaBean负责业务逻辑的处理，也就是模型层的功能。 到这里为止，开发过程中遇到的方式都已经介绍完了，也走到了MVC模式这一步。下面会简单介绍下MVC的框架相关知识。 Spring Web MVC先看一下Spring官方的一张请求处理流程图：再看一下具体的流程： 第一步，用户发送请求（Incoming request）到前端控制器（Front controller） 前端控制器（Front controller）根据实际的请求信息来决定把请求委托给具体的页面控制器（Controller）。页面控制器用来处理实际的请求内容，直接返回或者需要Model层进行数据处理。 页面控制器（Controller）接收到请求后进行处理，处理完成后返回model数据，并委托给前端控制器（Front controller）进行渲染。 前端控制器（Front controller）根据逻辑视图名和model数据选择视图模板（View template）进行渲染，渲染完成后返回给前端控制器（Front controller）。 最后前端控制器将渲染后的最终结果返回给用户。 对应具体的源码分析不在此做过多说明。 再看一下具体的流程： 第一步，用户发送请求（Incoming request）到前端控制器（Front controller） 前端控制器（Front controller）根据实际的请求信息来决定把请求委托给具体的页面控制器（Controller）。页面控制器用来处理实际的请求内容，直接返回或者需要Model层进行数据处理。 页面控制器（Controller）接收到请求后进行处理，处理完成后返回model数据，并委托给前端控制器（Front controller）进行渲染。 前端控制器（Front controller）根据逻辑视图名和model数据选择视图模板（View template）进行渲染，渲染完成后返回给前端控制器（Front controller）。 最后前端控制器将渲染后的最终结果返回给用户。 对应具体的源码分析不在此做过多说明。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Executor框架简介]]></title>
      <url>%2F2016%2F08%2F11%2FExecutor%E6%A1%86%E6%9E%B6%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[Executor框架是在Java5中引入的，可以通过该框架来控制线程的启动，执行，关闭，简化并发编程。Executor框架把任务提交和执行解耦，要执行任务的人只需要把任务描述清楚提交即可，任务的执行提交人不需要去关心。 通过Executor框架来启动线程比使用Thread更好，更易管理，效率高，避免this逃逸问题。 Executor的实现还提供了对生命周期的支持，以及统计信息收集，应用程序管理机制和性能监视等机制。 Executor框架源码版本： jdk1.7.0_71 Executor框架由3大部分组成： 任务：被执行任务需要实现接口Runnable、Callable。 任务执行：任务执行机制的核心接口Executor，继承Executor的ExecutorService。CompletionService等。 异步计算的结果：Future和实现了Future接口的FutureTask类。 Executor是一个接口，只定义了一个方法void execute(Runnable command);该方法接受一个Runnable实例，作用就是执行提交的任务，实现在子类中。 ExecutorService也是一个接口，继承自Executor接口，提供了更多的方法，提供了生命周期的管理方法，以及可跟踪一个或多个异步任务执行状况的方法。 ExecutorService的生命周期包括三种状态：运行，关闭，终止。创建后便进入运行状态，当调用了shutdown()方法时，进入关闭状态，此时不再接受新任务，但是它还在执行已经提交了的任务，当所有的任务执行完后，便达到了终止状态。 shutdown()关闭当前服务，当调用此方法时，它将不再接受新的任务，已经提交的任务，还要继续执行完毕。 shutdownNow()1List&lt;Runnable&gt; shutdownNow(); 关闭当前服务，尚未执行的任务，不再执行；正在执行的任务，通过线程中断thread.interrupt。方法返回等待执行的任务列表。 isShutdown()程序是否已经关闭。 isTerminated()程序是否已经终止。已经关闭并且所有的任务都执行完成，返回true，其他返回false。 awaitTermination()12boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; 请求关闭、发生超时或者当前线程中断，无论哪一个首先发生之后，都将导致阻塞，直到所有任务完成执行。如果程序终止，返回true，如果超时，返回false，等待时发生中断，抛出异常。 submit(Callable task)1&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); 向Executor提交一个Clallable任务，并返回一个Future； submit(Runnable task, T result)1&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); 向Executor提交一个Runnable任务，并返回一个Future； submit(Runnable task)1Future&lt;?&gt; submit(Runnable task); 向Executor提交一个Runnable任务，并返回一个Future； invokeAll（）执行所有任务列表，当所有任务执行完成之后，返回Future列表。 invokeAny()在执行的任务集合中，任何一个完成就返回。 Executors提供了一系列静态工厂方法用于创建各种线程池。返回的线程池都实现了ExecutorService接口。 如果没有特殊要求，请尽量使用此类中提供的静态方法生成线程池。 大部分方法的底层实现都在ThreadPoolExecutor类中，有关ThreadPoolExecutor介绍请往下翻。ThreadPoolExecutor的构造函数如下： 1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) newFixedThreadPool(int nThreads)创建一个可重用的固定线程数的线程池，以共享无界队列方式来运行这些线程。 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; corePoolSize和maximumPoolSize大小一样，使用无界queue的话maximumPoolSize参数是没有意义的。改方法使用的是LinkedBlockingQueue无界队列。keepAliveTime为0. newFixedThreadPool(nThreads, ThreadFactory)使用给定的ThreadFactory创建一个可重用的固定线程数的线程池，以共享无界队列方式运行这些线程。 newSingleThreadExecutor创建一个使用单个线程的线程池，使用无界队列来运行该线程。 newSingleThreadExecutor(ThreadFactory)使用给定的ThreadFactory创建一个单个线程的线程池，使用无界队列来运行该线程。 newCachedThreadPool创建一个可根据需要创建新线程的线程池，以前构造的线程可用时将重用它们。对于执行很多短期异步任务的程序而言，这些线程池通常可提高程序性能。 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; maximumPoolSize为最大，是一个无界线程池。workqueue使用SynchronousQueue，该queue中每个插入操作必须等待另一个线程的对应移除操作。它的主要提供的功能是线程复用，但不能控制线程数量。 newCachedThreadPool(ThreadFactory)使用给定的ThreadFactory创建一个可根据需要创建新线程的线程池，以前构造的线程可用时将重用它们。对于执行很多短期异步任务的程序而言，这些线程池通常可提高程序性能。 newSingleThreadScheduledExecutor创建一个使用单个线程的线程池，该线程池支持定时以及周期性执行任务的功能。 newScheduledThreadPool(corePoolSize)创建一个指定数量的线程的线程池，该线程池支持定时以及周期性执行任务的功能。 AbstractExecutorServiceExecutorService方法的默认实现类。 ScheduledExecutorService一个可定时调度任务的接口。扩展了ExecutorService。支持Future和定期执行任务。 ScheduledThreadPoolExecutorScheduledExecutorService的实现，一个可定时调度任务的线程池。 ThreadPoolExecutor线程池，可以通过调用Executors的静态工厂方法来创建线程池并返回一个ExecutorService对象。 ThreadPoolExecutor是Executors的底层实现，看Executors源码可知，大部分的生成线程池的方法内部都是调用此类的方法。 该类继承了AbstractExecutorService。 构造方法123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;&#x3D; 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue &#x3D;&#x3D; null || threadFactory &#x3D;&#x3D; null || handler &#x3D;&#x3D; null) throw new NullPointerException(); this.corePoolSize &#x3D; corePoolSize; this.maximumPoolSize &#x3D; maximumPoolSize; this.workQueue &#x3D; workQueue; this.keepAliveTime &#x3D; unit.toNanos(keepAliveTime); this.threadFactory &#x3D; threadFactory; this.handler &#x3D; handler;&#125; corePoolSize 池中所保存的核心线程数，包括空闲线程。 maximumPoolSize池中允许创建的最大线程数。当workqueue使用无界队列LinkedBlockingQueue等时，此参数无效。 keepAliveTime当前线程池线程总数大于核心线程数时，终止多余的空闲线程时间。 unitkeepAliveTime参数的时间单位 workQueue工作队列，如果当前线程池达到核心线程数时，且当前所有线程都处于活动状态，则将新加入的任务放到此队列中。仅保持由execute方法提交的Runnable任务。 ArrayBlockingQueue 基于数组结构有界队列，FIFO原则对任务进行排序，队列满了之后的任务，调用拒绝策略。 LinkedBlockingQueue 基于链表结构的无界队列，FIFO原则对任务进行排序。 SynchronousQueue 直接将任务提交给线程而不是将它加入到队列，实际上此队列是空的。每个插入的操作必须等到另一个调用移除的操作；如果新任务来了线程池没有任何可用线程处理的话，则调用拒绝策略。 PriorityBlockingQueue 具有优先级的队列的有界队列，可以自定义优先级；默认是按自然排序。 threadFactory 执行程序创建新线程时使用的工厂。 handler 超出线程范围和队列容量时，执行被阻塞，此时可以选择用此handler进行处理。 Callable，Future与FutureTask在之前创建线程的时候都是继承Thread或者实现Runnable接口，这种方法在任务完成后无法获取执行结果。而在Java5之后有了Runnable和Future，可以在任务执行完之后得到任务执行结果。 CallableCallable能产生结果，Future能拿到结果。Callable和Runnable接口类似，Runnable不会返回结果，也无法抛出返回结果的异常，而Callable可以返回值，这个值可被Future拿到。 Callable一般和ExecutorService一起使用，ExecutorService的submit方法提交的是Runnable或者是Callable类型的Task。 FutureFuture对具体提交的Callable任务执行结果进行取消，查询是否完成，获取结果。可以通过get方法获取执行结果，该方法会阻塞直到任务返回结果。Future接口的具体实现都在FutureTask中。 cancel()方法1boolean cancel(boolean mayInterruptIfRunning); 可以取消任务，成功返回true，失败返回false。 参数mayInterruptIfRunning表示是否取消正在执行但是没有执行完成的任务，true可以取消，false不取消 如果任务已经完成，无论参数是true或false，都返回false 如果任务正在执行，若参数为true，返回true；若参数为false，返回false； 如果任务还未执行，无论参数是true或false，都返回true。 isCancelled()方法表示任务是否被取消成功。 isDone()方法表示任务是否已经完成。 get()方法1V get() throws InterruptedException, ExecutionException; 用来获取执行结果，会一直阻塞等到任务执行完成之后返回。 get(timeout,unit)方法12V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; 用来获取执行结果，指定时间内获取不到结果，返回null FutureTaskFutureTask实现了RunnableFuture接口，RunnableFuture接口继承了Runnable和Future接口。 是Future接口的唯一实现。 FutureTask是为了弥补Thread的不足而设计的，它可以让程序员准确地知道线程什么时候执行完成并获得到线程执行完成后返回的结果（如果有需要） 可用于要异步获取执行结果或取消执行任务的场景。 FutureTask是一种可以取消的异步的计算任务。它的计算是通过Callable实现的，它等价于可以携带结果的Runnable，并且有三个状态：等待、运行和完成。完成包括所有计算以任意的方式结束，包括正常结束、取消和异常。 利用开始和取消计算的方法、查询计算是否完成的方法和获取计算结果的方法，此类提供了对 Future 的基本实现。仅在计算完成时才能获取结果；如果计算尚未完成，则阻塞 get 方法。一旦计算完成，就不能再重新开始或取消计算。 CompletionService我们可以通过线程池的submit方法提交一个Callable任务，利用返回的Future的get方法来获取任务运行的结果，但是这种方法需要自己循环获取task，而且get方法会阻塞。 还可以用CompletionService来实现，CompletionService维护一个保存Future对象的BlockQueue，当Future对象状态是结束的时候，会加入到队列中，可以通过take方法，取出Future对象。 submit()方法，用于提交任务。 take()方法，获取任务结果。获取并移除表示下一个已完成任务的Future，如果任务不存在，则等待。 poll()方法，获取任务结果。获取并移除表示下一个已完成任务的Future，如果不存在，则返回null。 方法的实现都在ExecutorCompletionService中。 ExecutorCompletionServiceExecutorCompletionService是CompletionService的实现类，在submit任务时，会创建一个QueueingFuture，然后将创建的QueueingFuture交给executor去完成任务的执行。 QueueingFuture继承自FutureTask类。 内部维护了一个可阻塞的队列，具体实现使用LinkedBlockingQueue。 提交到ExecutorCompletionService的任务会在内部被包装成QueueingFuture，并由内部的executor来执行这个任务，当任务执行完成后，会被加入到内部的队列里面，外部程序就可以通过take或者poll方法来获取完成的任务了。 实例摘自线程池实例：使用Executors和ThreadPoolExecutor这篇文章，如有需要点击标题查看全文。 首先创建一个实现Runable接口的类： 123456789101112131415161718192021222324252627282930package com.journaldev.threadpool; public class WorkerThread implements Runnable &#123; private String command; public WorkerThread(String s)&#123; this.command&#x3D;s; &#125; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()+&quot; Start. Command &#x3D; &quot;+command); processCommand(); System.out.println(Thread.currentThread().getName()+&quot; End.&quot;); &#125; private void processCommand() &#123; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; @Override public String toString()&#123; return this.command; &#125;&#125; 测试程序： 1234567891011121314151617181920package com.journaldev.threadpool; import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors; public class SimpleThreadPool &#123; public static void main(String[] args) &#123; ExecutorService executor &#x3D; Executors.newFixedThreadPool(5); for (int i &#x3D; 0; i &lt; 10; i++) &#123; Runnable worker &#x3D; new WorkerThread(&quot;&quot; + i); executor.execute(worker); &#125; executor.shutdown(); while (!executor.isTerminated()) &#123; &#125; System.out.println(&quot;Finished all threads&quot;); &#125; &#125; 上面的代码中，创建了一个能包含5个线程的固定大小的线程池，for循环向线程池提交10个任务。首先启动5个线程，其他的任务等待，当其中的任务执行完成，等待的任务会被选中一个执行。 参考http://my.oschina.net/smartsales/blog/529044 http://blog.csdn.net/ns_code/article/details/17465497 http://www.cnblogs.com/MOBIN/p/5436482.html http://www.infoq.com/cn/articles/executor-framework-thread-pool-task-execution-part-01 http://my.oschina.net/pingpangkuangmo/blog/666762 http://blog.csdn.net/gemmem/article/details/8956703 http://uule.iteye.com/blog/1539084 http://brokendreams.iteye.com/blog/2252800]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ConcurrentLinkedQueue简介]]></title>
      <url>%2F2016%2F08%2F05%2FConcurrentLinkedQueue%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[ConcurrentLinkedQueue是一个基于链表的无界线程安全队列，非阻塞实现方式，先进先出，适合高并发的场景。 非阻塞的性能较好，采用CAS，避免加锁的时间，保证数据一致性。 采用“wait-free”算法实现。 （此部分源码看的比较吃力，很多不懂的地方，还有很多不知道的地方，希望不要误导读者，有好的文章之类的，希望能推荐下，谢谢） 定义ConcurrentLinkedQueue继承AbstractQueue，实现 Queue, Serializable接口。内部通过链表实现。 ConcurrentLinkedQueue链表节点Node的数据item是volatile类型的，next节点也是volatile类型的。 默认构造一个空的ConcurrentLinkedQueue，head=tail= new Node(null) 源码分析 jdk1.7.0_71 add(E)方法添加元素到队列尾部，实现是用offer，下面会说offer方法。 123public boolean add(E e) &#123; return offer(e);&#125; offer(E)方法添加元素到队列尾部。 123456789101112131415161718192021222324252627282930313233public boolean offer(E e) &#123; checkNotNull(e); &#x2F;&#x2F;创建新节点 final Node&lt;E&gt; newNode &#x3D; new Node&lt;E&gt;(e); &#x2F;&#x2F;循环开始，tail赋值给t，t赋值给p，此处是死循环，保证该入队操作能够一直重试，直到入队成功 for (Node&lt;E&gt; t &#x3D; tail, p &#x3D; t;;) &#123; &#x2F;&#x2F;p的next赋值给q Node&lt;E&gt; q &#x3D; p.next; &#x2F;&#x2F;如果q是null，说明tail的next是null，tail指向的是队列尾部，所以tail的next应该始终是null，此处表示p是最后一个节点 if (q &#x3D;&#x3D; null) &#123; &#x2F;&#x2F; p是尾节点，则p的next节点是要入队列的节点 &#x2F;&#x2F;cas操作，若失败表示其他线程对尾节点进行了修改，重新循环 &#x2F;&#x2F;将p（p指向tail）的next指向新节点，若成功，进入if语句 if (p.casNext(null, newNode)) &#123; &#x2F;&#x2F;cas操作成功后，判断p是否等于t，p不等于t，设置newNode为新的尾节点,p不等于t表示什么？(此处有不明白，希望高手帮帮忙。) if (p !&#x3D; t) &#x2F;&#x2F; hop two nodes at a time casTail(t, newNode); &#x2F;&#x2F; Failure is OK. return true; &#125; &#x2F;&#x2F; p和q相等（这部分不是太理解，希望高手帮忙下） &#125; else if (p &#x3D;&#x3D; q) &#x2F;&#x2F; We have fallen off list. If tail is unchanged, it &#x2F;&#x2F; will also be off-list, in which case we need to &#x2F;&#x2F; jump to head, from which all live nodes are always &#x2F;&#x2F; reachable. Else the new tail is a better bet. p &#x3D; (t !&#x3D; (t &#x3D; tail)) ? t : head; else &#x2F;&#x2F; Check for tail updates after two hops. p &#x3D; (p !&#x3D; t &amp;&amp; t !&#x3D; (t &#x3D; tail)) ? t : q; &#125;&#125; poll()方法删除并返回头部元素 12345678910111213141516171819202122232425public E poll() &#123; &#x2F;&#x2F;设置循环标记 restartFromHead: for (;;) &#123; for (Node&lt;E&gt; h &#x3D; head, p &#x3D; h, q;;) &#123; E item &#x3D; p.item; &#x2F;&#x2F;表头数据不为null，cas操作设置表头数据为null成功进入if if (item !&#x3D; null &amp;&amp; p.casItem(item, null)) &#123; &#x2F;&#x2F;p不等于h，队列头发生了变化，更新队列头为p，返回原来队列头的item if (p !&#x3D; h) &#x2F;&#x2F; hop two nodes at a time updateHead(h, ((q &#x3D; p.next) !&#x3D; null) ? q : p); return item; &#125; &#x2F;&#x2F;队列头下一个节点为null，更新头尾p返回null else if ((q &#x3D; p.next) &#x3D;&#x3D; null) &#123; updateHead(h, p); return null; &#125; else if (p &#x3D;&#x3D; q) continue restartFromHead; else p &#x3D; q; &#125; &#125;&#125; peek()方法返回队列头部的元素，跟poll方法类似 12345678910111213141516public E peek() &#123; restartFromHead: for (;;) &#123; for (Node&lt;E&gt; h &#x3D; head, p &#x3D; h, q;;) &#123; E item &#x3D; p.item; if (item !&#x3D; null || (q &#x3D; p.next) &#x3D;&#x3D; null) &#123; updateHead(h, p); return item; &#125; else if (p &#x3D;&#x3D; q) continue restartFromHead; else p &#x3D; q; &#125; &#125;&#125; size()方法需要遍历队列，不推荐使用，尽量使用isEmpty() 123456789public int size() &#123; int count &#x3D; 0; for (Node&lt;E&gt; p &#x3D; first(); p !&#x3D; null; p &#x3D; succ(p)) if (p.item !&#x3D; null) &#x2F;&#x2F; Collection.size() spec says to max out if (++count &#x3D;&#x3D; Integer.MAX_VALUE) break; return count;&#125; 参考http://www.infoq.com/cn/articles/ConcurrentLinkedQueue http://www.cnblogs.com/skywang12345/p/3498995.html http://vickyqi.com/2015/10/29/JDK%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E2%80%94%E2%80%94ConcurrentLinkedQueue/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[LinkedBlockingQueue简介]]></title>
      <url>%2F2016%2F08%2F05%2FLinkedBlockingQueue%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[LinkedBlockingQueue是一个单向链表实现的阻塞队列，先进先出的顺序。支持多线程并发操作。 相比于数组实现的ArrayBlockingQueue的有界，LinkedBlockingQueue可认为是无界队列。多用于任务队列。 定义LinkedBlockingQueue继承AbstractQueue，实现了BlockingQueue，Serializable接口。内部使用单向链表存储数据。 默认初始化容量是Integer最大值。 插入和取出使用不同的锁，putLock插入锁，takeLock取出锁，添加和删除数据的时候可以并行。多CPU情况下可以同一时刻既消费又生产。 源码分析 jdk1.7.0_71 put(E)方法向队列尾部添加元素，队列已满的时候，阻塞等待。 1234567891011121314151617181920212223public void put(E e) throws InterruptedException &#123; if (e &#x3D;&#x3D; null) throw new NullPointerException(); int c &#x3D; -1; Node&lt;E&gt; node &#x3D; new Node(e); final ReentrantLock putLock &#x3D; this.putLock; final AtomicInteger count &#x3D; this.count; putLock.lockInterruptibly(); try &#123; while (count.get() &#x3D;&#x3D; capacity) &#123; notFull.await(); &#125; enqueue(node); c &#x3D; count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125; if (c &#x3D;&#x3D; 0) signalNotEmpty();&#125; offer(E)方法向队列尾部添加元素，队列已满的时候，直接返回false。 1234567891011121314151617181920212223public boolean offer(E e) &#123; if (e &#x3D;&#x3D; null) throw new NullPointerException(); final AtomicInteger count &#x3D; this.count; if (count.get() &#x3D;&#x3D; capacity) return false; int c &#x3D; -1; Node&lt;E&gt; node &#x3D; new Node(e); final ReentrantLock putLock &#x3D; this.putLock; putLock.lock(); try &#123; if (count.get() &lt; capacity) &#123; enqueue(node); c &#x3D; count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); &#125; &#125; finally &#123; putLock.unlock(); &#125; if (c &#x3D;&#x3D; 0) signalNotEmpty(); return c &gt;&#x3D; 0;&#125; 不做过多分析，发现下面参考处的文章写得不错，建议看下。 参考http://www.jianshu.com/p/cc2281b1a6bc]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[我的计算机之路]]></title>
      <url>%2F2016%2F07%2F29%2F%E6%88%91%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B9%8B%E8%B7%AF%2F</url>
      <content type="text"><![CDATA[从03年接触第一本计算机相关的书，到第一次接触计算机申请第一个qq，到第一台手机，第一台智能机，在手机上做开发学习，到第二次高考报志愿的毫不犹豫的选择计算机，到现在找工作都感觉困难，到现在的感觉迷茫，有时候很想退回去03年，不去翻看那几本书！ 2003年，3本书和一张光盘家里很穷，我还在上初中。有关这3本书和光盘的来历有点记不清楚了，但是这三本书和光盘的主人我记得，是我一个从小就很崇拜的堂叔的。堂叔长得帅气，很稳重，那时候技校到处都是招计算机，厨师之类的，他去培训了计算机。这书有可能就是他不用了，不知道怎么的就到我手里了。（现在还在馋涎他的7位QQ）。 关于三本书记得都不太清楚了，一本大概是Frontpage2000，一本是网页制作与网站之类的，一本是有关电脑维修之类的，还有一张至今藏在老家快要坍塌的房子里的光盘，内容我到现在都不知道是啥。 就是这三本书，带我走上了‘歧途’。简单的看了一点之后，发现这东西好神奇！然后就在我长大的那间屋子里，我看完了这三本书。从此一发不可收拾，电脑变成了我唯一的梦想，什么社会主义接班人，什么科学家的我都不在乎了。 后来街上有了网吧，但是对于我来说那地方仍然是个只有贵族才能去的地方。终于有一天，我另外一个叔带我去了网吧，第一次摸到了电脑，申请了第一个qq，激动的不行！在那之后，也和同学去了几次网吧，他们都是去玩游戏聊天，但是我却一点兴趣都有，在网上翻看各种电脑计算机网络网站网页等等的一些信息，不知道为什么我要看这些，但是我却一直这样，直到后来上高中也是如此。 第一台手机和编程差不多应该是04年的时候，家里买了第一台手机，摩托罗拉v8088，没几天便玩的烂熟，闭着眼都能直到我操作的是啥。唯一一个功能是我不敢碰的：Internet，很想点，但是又怕收费挨揍。后来又接触到了很多很多的手机三星的抽拉天线的那种老式手机，诺基亚，波导，摩托罗拉等等~直到遇到了三星D908，哇好神奇，可以安装Java软件游戏！还可以刷机！刷机！刷机！扩大运存等等。 从此便进入了一个新天地里，到处找资源破解刷机发布出去等等。随着知道的越来越多，也越来约不满足，饿着肚子攒钱，终于到手一台神器：二手的多普达D9000，这是神器，这是智能机，这是全键盘，这是触屏，这是小型电脑，这是砖头块！运行wm6.0，相当智能。 进入WM时代，也正是他将要没落的时候，也正是那时候让我知道了外面更精彩的世界。用这台手机，我自学了c/pocket c,开始用手机写了程序，知道了python，也了解了诺基亚更多的东西，用各种模拟器体验了Android和IOS系统等等。 当我开始刷了WM6.5的时候，也体验了诺基亚的智能操作系统，那时候便感觉s60和wm即将被Android代替！但是没想到IOS会和Android平分天下。 就这样，我意外的考上了二本，报志愿的时候，其他的专业一眼没看，全部计算机。 2010沈阳化工大学，网络工程大学就正式开始了我的计算机生涯，协会面试，给自己和同学做了很多自我介绍的作品，网页等等，顺利进入各种协会。不就便成了老师手下的得力干将，各种做网站，给学校维护网站，计算机，做项目，去外地做实施。大学生活就这么很快的过去了，我感觉什么都没有做好，什么都还没体验。 2013大三结束来到上海大三结束来到上海！开始了我的Java~好迷茫！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SpringBoot简易教程]]></title>
      <url>%2F2016%2F07%2F08%2FSpringBoot%E7%AE%80%E6%98%93%E6%95%99%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[此为个人学习所用,从pom文件配置,datasource,log配置,到集成druid以及dubbo等都只做了简单的介绍.顺序按照个人习惯,从建立项目,到每项配置挨个进行.SpringBoot零配置,但是此项目还是用到了xml进行配置dubbo等,注解方式暂时没有去做.源码请点此查看 构建工具配置Maven可以使用两种方式:继承starter parent或者使用依赖管理器配置. 继承spring-boot-starter-parent12345&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;&#x2F;artifactId&gt; &lt;version&gt;1.3.6.RELEASE&lt;&#x2F;version&gt; &lt;&#x2F;parent&gt; 接着下面的依赖可以指定导入其他的starter. 使用依赖管理注意加上&lt;scope&gt;import&lt;/scope&gt; 123456789101112&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;!-- Import dependency management from Spring Boot --&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;&#x2F;artifactId&gt; &lt;version&gt;1.3.6.RELEASE&lt;&#x2F;version&gt; &lt;type&gt;pom&lt;&#x2F;type&gt; &lt;scope&gt;import&lt;&#x2F;scope&gt; &lt;&#x2F;dependency&gt; &lt;&#x2F;dependencies&gt; &lt;&#x2F;dependencyManagement&gt; 接着下面的依赖可以指定导入其他的starter. Gradle直接添加各个starter依赖,无需配置parent之类的. 123dependencies &#123; compile(&quot;org.springframework.boot:spring-boot-starter-web:1.3.6.RELEASE&quot;)&#125; spring-boot-starter列表 名称 描述 spring-boot-starter 核心starter,包含自动配置支持,日志和 YAML配置文件的支持 spring-boot-starter-actuator 生产环境,监控和管理应用程序 spring-boot-starter-amqp 通过 spring-rabbit 支持 AMQP spring-boot-starter-aop 包含 spring-aop 和 AspectJ 来支持面向切面编程（AOP） spring-boot-starter-artemis 通过Apache Artemis支持JMS API spring-boot-starter-batch 支持Spring Batch包括HSQLDB spring-boot-starter-cache 支持Spring Cache抽象化 spring-boot-starter-cloud-connectors 对Spring Cloud Connectors的支持，简化在云平台下（例如，Cloud Foundry 和Heroku）服务的连接 spring-boot-starter-data-elasticsearch 对Elasticsearch搜索和分析引擎的支持，包括spring-data-elasticsearch spring-boot-starter-data-gemfire 对GemFire分布式数据存储的支持，包括spring-data-gemfire spring-boot-starter-data-jpa 包含spring-data-jpa,spring-orm和Hibernate来支持JPA spring-boot-starter-data-mongodb 包含spring-data-mongodb来支持MongoDB spring-boot-starter-data-rest 通过spring-data-rest-webmvc支持以REST方式暴露Spring Data仓库 spring-boot-starter-data-solr 包含spring-data-solr支持Apache Solr搜索平台 spring-boot-starter-freemarker 支持使用FreeMarker作为模板引擎 spring-boot-starter-groovy-templates 支持使用groovy作为模板引擎 spring-boot-starter-hateoas 通过spring-hateoas支持基于HATEOAS的RESTful服务 spring-boot-starter-hornetq 通过HornetQ支持JMS API spring-boot-starter-integration 支持通用spring-integration模块 spring-boot-starter-jdbc 支持JDBC spring-boot-starter-jersey 对Jersey RESTful Web服务框架的支持 spring-boot-starter-jta-atomikos 通过Atomikos支持JTA分布式事务 spring-boot-starter-jta-bitronix 通过Bitronix支持JTA分布式事务 spring-boot-starter-mail 对javax.mail的支持 spring-boot-starter-mobile 对spring-mobile的支持 spring-boot-starter-mustache 支持使用Mustache作为模板引擎 spring-boot-starter-redis 包含spring-redis支持REDIS键值数据存储 spring-boot-starter-security 支持spring-security spring-boot-starter-social-facebook 支持spring-social-facebook spring-boot-starter-social-linkedin 支持spring-social-linkedin spring-boot-starter-social-twitter 支持spring-social-twitter spring-boot-starter-test 对常用测试依赖的支持,包括JUnit, Hamcrest和Mockito,还有spring-test模块 spring-boot-starter-thymeleaf 对Thymeleaf模板引擎的支持,包括和Spring的集成 spring-boot-starter-velocity 支持velocity模板引擎 spring-boot-starter-web 对全栈web开发的支持,包括Tomcat和spring-webmvc spring-boot-starter-websocket 支持WebSocket开发支持 spring-boot-starter-ws 支持Spring Web Services 生产准备的starts 名称 描述 spring-boot-starter-actuator 生产环境,监控和管理应用程序 spring-boot-starter-remote-shell 支持远程ssh shell 可替换spring boot中默认的starters 名称 描述 spring-boot-starter-jetty 导入Jetty HTTP引擎,作为Tomcat的替代 spring-boot-starter-log4j 对Log4J日志系统的支持 spring-boot-starter-logging 导入Spring Boot的默认日志系统Logback spring-boot-starter-tomcat 导入Spring Boot的默认HTTP引擎Tomcat spring-boot-starter-undertow 导入Undertow HTTP引擎,作为Tomcat的替代 注意:其他Starters的支持可参考官方文档说明,Starters 日志记录##Logback日志记录两种方式: 在src/main/resources(以Maven项目为例)下面创建logback.xml 12345&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;configuration&gt; &lt;include resource&#x3D;&quot;org&#x2F;springframework&#x2F;boot&#x2F;logging&#x2F;logback&#x2F;base.xml&quot;&#x2F;&gt; &lt;logger name&#x3D;&quot;org.springframework.web&quot; level&#x3D;&quot;DEBUG&quot;&#x2F;&gt;&lt;&#x2F;configuration&gt; 在application.properties或者application.yml中配置 application.properties: 1logging.level.org.springframework.web&#x3D;DEBUG application.yml: 1234spring:logging: level: org.springframework.web: DEBUG ##Logback多环境配置(yml)参考 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253spring: profiles: #可在此处选择环境的配置,dev,prod,test #也可以在启动时添加参数-Dspring.profiles.active&#x3D;dev active: dev---#dev环境spring: profiles: dev# 日志,logback配置logging: #日志文件 file: logs&#x2F;spring-boot-setup.log pattern: #控制台输出格式 console: &quot;%d %-5level %logger : %msg%n&quot; #文件输出格式 file: &quot;%d %-5level [%thread] %logger : %msg%n&quot; #日志级别 level: org.springframework.web: DEBUG---#prod环境spring: profiles: prod# 日志,logback配置logging: #日志文件 file: logs&#x2F;spring-boot-setup.log pattern: #控制台无输出 #文件输出格式 file: &quot;%d %-5level [%thread] %logger : %msg%n&quot; #日志级别 level: org.springframework.web: WARN---#test环境spring: profiles: test# 日志,logback配置logging: #日志文件 file: logs&#x2F;spring-boot-setup.log pattern: #控制台输出格式 console: &quot;%d %-5level %logger : %msg%n&quot; #文件输出格式 file: &quot;%d %-5level [%thread] %logger : %msg%n&quot; #日志级别 level: org.springframework.web: INFO 数据库数据源以mysql为例: 注意:使用数据库需要在pom文件中添加spring-boot-starter-jdbc和mysql-connector-java的依赖 123456#数据源 datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;xxx-test username: root password: 123456 数据库连接池默认Tomcat JDBC连接池Spring Boot默认采用Tomcat JDBC连接池 12345678910datasource: max-idle: 10 max-wait: 10000 min-idle: 5 initial-size: 5 validation-query: SELECT 1 test-on-borrow: false test-while-idle: true time-between-eviction-runs-millis: 18800 jdbc-interceptors: ConnectionState;SlowQueryReport(threshold&#x3D;0) Druid首先添加上druid的依赖: 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;&#x2F;groupId&gt; &lt;artifactId&gt;druid&lt;&#x2F;artifactId&gt; &lt;version&gt;1.0.18&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; 使用其他的连接池,需要配置自己的DataSource bean: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697@Component@ConfigurationProperties(prefix &#x3D; &quot;spring.datasource&quot;)public class DruidConfig &#123; private String url; private String username; private String password; private String driverClassName; private int initialSize; private int maxActive; private int minIdle; private int maxWait; private long timeBetweenEvictionRunsMillis; private long minEvictableIdleTimeMillis; private String validationQuery; private boolean testWhileIdle; private boolean testOnBorrow; private boolean testOnReturn; private boolean poolPreparedStatements; private int maxPoolPreparedStatementPerConnectionSize; private String filters; public DruidConfig() &#123; &#125; public DruidConfig(String url, String username, String password, String driverClassName, int initialSize, int maxActive, int minIdle, int maxWait, long timeBetweenEvictionRunsMillis, long minEvictableIdleTimeMillis, String validationQuery, boolean testWhileIdle, boolean testOnBorrow, boolean testOnReturn, boolean poolPreparedStatements, int maxPoolPreparedStatementPerConnectionSize, String filters) &#123; this.url &#x3D; url; this.username &#x3D; username; this.password &#x3D; password; this.driverClassName &#x3D; driverClassName; this.initialSize &#x3D; initialSize; this.maxActive &#x3D; maxActive; this.minIdle &#x3D; minIdle; this.maxWait &#x3D; maxWait; this.timeBetweenEvictionRunsMillis &#x3D; timeBetweenEvictionRunsMillis; this.minEvictableIdleTimeMillis &#x3D; minEvictableIdleTimeMillis; this.validationQuery &#x3D; validationQuery; this.testWhileIdle &#x3D; testWhileIdle; this.testOnBorrow &#x3D; testOnBorrow; this.testOnReturn &#x3D; testOnReturn; this.poolPreparedStatements &#x3D; poolPreparedStatements; this.maxPoolPreparedStatementPerConnectionSize &#x3D; maxPoolPreparedStatementPerConnectionSize; this.filters &#x3D; filters; &#125; @Bean @Primary public DataSource dataSource() throws Exception&#123; DruidDataSource druidDataSource &#x3D; new DruidDataSource(); druidDataSource.setUrl(this.url); druidDataSource.setUsername(this.username); druidDataSource.setPassword(this.password); druidDataSource.setDriverClassName(this.driverClassName); druidDataSource.setInitialSize(this.initialSize); druidDataSource.setMaxActive(this.maxActive); druidDataSource.setMinIdle(this.minIdle); druidDataSource.setMaxWait(this.maxWait); druidDataSource.setTimeBetweenEvictionRunsMillis(this.timeBetweenEvictionRunsMillis); druidDataSource.setMinEvictableIdleTimeMillis(this.minEvictableIdleTimeMillis); druidDataSource.setValidationQuery(this.validationQuery); druidDataSource.setTestWhileIdle(this.testWhileIdle); druidDataSource.setTestOnBorrow(this.testOnBorrow); druidDataSource.setTestOnReturn(this.testOnReturn); druidDataSource.setPoolPreparedStatements(this.poolPreparedStatements); druidDataSource.setMaxPoolPreparedStatementPerConnectionSize(this.maxPoolPreparedStatementPerConnectionSize); druidDataSource.setFilters(this.filters); try &#123; if(null !&#x3D; druidDataSource) &#123; druidDataSource.setFilters(&quot;wall,stat&quot;); druidDataSource.setUseGlobalDataSourceStat(true); druidDataSource.init(); &#125; &#125; catch (Exception e) &#123; throw new RuntimeException(&quot;load datasource error, dbProperties is :&quot;, e); &#125; return druidDataSource; &#125; ... geter and setter ... 配置druid的数据监控页面路径和拦截路径: 1234567891011121314@Bean public ServletRegistrationBean druidServlet() &#123; return new ServletRegistrationBean(new StatViewServlet(), &quot;&#x2F;druid&#x2F;*&quot;); &#125; @Bean public FilterRegistrationBean filterRegistrationBean() &#123; FilterRegistrationBean filterRegistrationBean &#x3D; new FilterRegistrationBean(); filterRegistrationBean.setFilter(new WebStatFilter()); filterRegistrationBean.addUrlPatterns(&quot;&#x2F;*&quot;); filterRegistrationBean.addInitParameter(&quot;exclusions&quot;, &quot;*.js,*.gif,*.jpg,*.png,*.css,*.ico,&#x2F;druid&#x2F;*&quot;); return filterRegistrationBean; &#125; 然后浏览器访问http://localhost:8080/druid即可看到界面. Mybatis集成添加依赖12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;&#x2F;artifactId&gt; &lt;version&gt;1.1.1&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; 配置application.yml1234#Mybatis配置mybatis: mapperLocations: classpath*:me.cxis.springboot.setup.mapper&#x2F;*.xml typeAliasesPackage: me.cxis.springboot.setup.dto 编写UserMapper接口和UserMapper.xml文件UserMapper接口: 1234@Mapperpublic interface UserMapper &#123; List&lt;User&gt; getUserList();&#125; UserMapper.xml文件: 12345&lt;mapper namespace&#x3D;&quot;me.cxis.springboot.setup.mapper.UserMapper&quot;&gt; &lt;select id&#x3D;&quot;getUserList&quot; resultType&#x3D;&quot;me.cxis.springboot.setup.dto.User&quot;&gt; select * from t_user; &lt;&#x2F;select&gt;&lt;&#x2F;mapper&gt; 事务管理在Application中添加注解@EnableTransactionManagement启用事务管理,在需要开启事务的地方使用注解@Transactional FreeMarker模板引擎添加依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-freemarker&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt; 添加配置在application.yml中添加freemarker配置 123456789#freemarker配置 freemarker: cache: false charset: UTF-8 check-template-location: true content-type: text&#x2F;html expose-request-attributes: true expose-session-attributes: true request-context-attribute: request 创建templates目录src/main/resources 创建目录 templates,接着在此目录下创建模板文件test.ftl 1234567891011121314&lt;!DOCTYPE html&gt;&lt;html lang&#x3D;&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset&#x3D;&quot;UTF-8&quot;&gt; &lt;title&gt;Freemarker&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;&lt;body&gt; Date: $&#123;time?date&#125; &lt;br&gt; Time: $&#123;time?time&#125; &lt;br&gt; Message: $&#123;message&#125;&lt;&#x2F;body&gt;&lt;&#x2F;html&gt; 编写Controller代码: 123456@RequestMapping(value &#x3D; &quot;test&quot;) public String testFreeMarker(ModelMap modelMap)&#123; modelMap.put(&quot;time&quot;,new Date()); modelMap.put(&quot;message&quot;,&quot;测试Freemarker&quot;); return &quot;test&quot;; &#125; 集成dubbo添加依赖分别添加dubbo,zookeeper,zkclient的依赖,同时需要排除依赖中的spring,log4j等 12345678910111213141516171819202122232425262728293031&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;&#x2F;groupId&gt; &lt;artifactId&gt;dubbo&lt;&#x2F;artifactId&gt; &lt;version&gt;2.5.3&lt;&#x2F;version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring&lt;&#x2F;artifactId&gt; &lt;&#x2F;exclusion&gt; &lt;&#x2F;exclusions&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;&#x2F;groupId&gt; &lt;artifactId&gt;zookeeper&lt;&#x2F;artifactId&gt; &lt;version&gt;3.4.6&lt;&#x2F;version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;&#x2F;groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;&#x2F;artifactId&gt; &lt;&#x2F;exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;log4j&lt;&#x2F;groupId&gt; &lt;artifactId&gt;log4j&lt;&#x2F;artifactId&gt; &lt;&#x2F;exclusion&gt; &lt;&#x2F;exclusions&gt; &lt;&#x2F;dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;&#x2F;groupId&gt; &lt;artifactId&gt;zkclient&lt;&#x2F;artifactId&gt; &lt;version&gt;0.1&lt;&#x2F;version&gt; &lt;&#x2F;dependency&gt; 服务提供方添加dubbo.properties文件 12345678910111213dubbo.container&#x3D;log4j,springdubbo.application.name&#x3D;tb-coredubbo.application.owner&#x3D;#dubbo.registry.address&#x3D;multicast:&#x2F;&#x2F;224.5.6.7:1234dubbo.registry.address&#x3D;zookeeper\:&#x2F;&#x2F;127.0.0.1\:2181#dubbo.registry.address&#x3D;redis:&#x2F;&#x2F;127.0.0.1:6379#dubbo.registry.address&#x3D;dubbo:&#x2F;&#x2F;127.0.0.1:9090dubbo.monitor.protocol&#x3D;registrydubbo.protocol.name&#x3D;dubbodubbo.protocol.port&#x3D;20881dubbo.service.loadbalance&#x3D;roundrobindubbo.log4j.file&#x3D;logs&#x2F;SpringBootDubboProvider.logdubbo.log4j.level&#x3D;DEBUG 添加dubbo-provider.xml 1234567891011&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xmlns:dubbo&#x3D;&quot;http:&#x2F;&#x2F;code.alibabatech.com&#x2F;schema&#x2F;dubbo&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans.xsd http:&#x2F;&#x2F;code.alibabatech.com&#x2F;schema&#x2F;dubbo http:&#x2F;&#x2F;code.alibabatech.com&#x2F;schema&#x2F;dubbo&#x2F;dubbo.xsd&quot;&gt; &lt;bean id&#x3D;&quot;userService&quot; class&#x3D;&quot;me.cxis.springboot.setup.service.impl.UserServiceImpl&quot;&gt;&lt;&#x2F;bean&gt; &lt;dubbo:service timeout&#x3D;&quot;3000&quot; retries&#x3D;&quot;0&quot; interface&#x3D;&quot;me.cxis.springboot.setup.service.UserService&quot; ref&#x3D;&quot;userService&quot;&#x2F;&gt;&lt;&#x2F;beans&gt; 在application添加注解,导入dubbo配置文件 123456@ImportResource(&quot;classpath*:dubbo-provider.xml&quot;)public class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class,args); &#125;&#125; 服务消费方添加dubbo.properties文件 12345678910111213dubbo.container&#x3D;log4j,springdubbo.application.name&#x3D;SpringBootDubboConsumerdubbo.application.owner&#x3D;#dubbo.registry.address&#x3D;multicast:&#x2F;&#x2F;224.5.6.7:1234dubbo.registry.address&#x3D;zookeeper\:&#x2F;&#x2F;127.0.0.1\:2181#dubbo.registry.address&#x3D;redis:&#x2F;&#x2F;127.0.0.1:6379#dubbo.registry.address&#x3D;dubbo:&#x2F;&#x2F;127.0.0.1:9090dubbo.monitor.protocol&#x3D;registrydubbo.protocol.name&#x3D;dubbodubbo.protocol.port&#x3D;20884dubbo.service.loadbalance&#x3D;roundrobindubbo.log4j.file&#x3D;logs&#x2F;SpringBootDubboConsumer.logdubbo.log4j.level&#x3D;DEBUG 添加dubbo-consumer.xml 12345678910&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;beans xmlns&#x3D;&quot;http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xmlns:dubbo&#x3D;&quot;http:&#x2F;&#x2F;code.alibabatech.com&#x2F;schema&#x2F;dubbo&quot; xsi:schemaLocation&#x3D;&quot; http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans http:&#x2F;&#x2F;www.springframework.org&#x2F;schema&#x2F;beans&#x2F;spring-beans-3.0.xsd http:&#x2F;&#x2F;code.alibabatech.com&#x2F;schema&#x2F;dubbo http:&#x2F;&#x2F;code.alibabatech.com&#x2F;schema&#x2F;dubbo&#x2F;dubbo.xsd&quot;&gt; &lt;dubbo:reference id&#x3D;&quot;userService&quot; interface&#x3D;&quot;me.cxis.springboot.setup.service.UserService&quot;&#x2F;&gt;&lt;&#x2F;beans&gt; 在application添加注解,导入dubbo配置文件 123456@ImportResource(&quot;classpath*:dubbo-consumer.xml&quot;)public class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class,args); &#125;&#125; 参考http://docs.spring.io/spring-boot/docs/current/reference/htmlsingle https://www.ibm.com/developerworks/cn/java/j-lo-spring-boot/ https://qbgbook.gitbooks.io/spring-boot-reference-guide-zh/content/ https://springframework.guru/using-yaml-in-spring-boot-to-configure-logback/ http://blog.csdn.net/catoop/article/details/50501714 http://my.oschina.net/angerbaby/blog/552936 http://www.voidcn.com/blog/yingxiake/article/p-5930835.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[tomcat与memcached-session-manager共享session测试]]></title>
      <url>%2F2016%2F07%2F01%2Ftomcat-%E4%B8%8Ememcached-session-manager%E5%85%B1%E4%BA%ABsession%E6%B5%8B%E8%AF%95%2F</url>
      <content type="text"><![CDATA[简介看书刚好看到集群session共享,总觉得只看不做,不能确定这到底是怎么运行的.所以就做了这个测试.有关Memcached-Session-Manager,Memcached,以及集群session共享等相关知识,请自行补充.本次就简单记录下测试过程.有关其他的方式以及其他的情况,本文不做说明,有需要的话,会再写其他情况和方式下的文章. 环境说明 本机OSX 10.11,tomca7.0.57,memcached-1.4.24 虚拟机Ubuntu16.04,tomca7.0.57,memcached-1.4.24 使用non-sticky sessions（非粘性session） 序列化:使用默认,java进行序列化，由memcached-session-manager.jar这个jar包来提供方法. 有关粘性和非粘性的区别以及序列化等不做解释. 具体步骤安装jdk,memcached,tomcat不做详细说明 放jar包将如下相关jar包分别放置到两台机器的tomcat $CATALINA_HOME/lib/目录中. memcached-session-manager-${version}.jar memcached-session-manager-tc7-${version}.jar spymemcached-2.11.1.jar 修改tomcat配置文件两台机器分别修改tomcat $CATALINA_HOME/conf/context.xml文件,添加如下代码到Context节点下: 123456&lt;Manager className&#x3D;&quot;de.javakaffee.web.msm.MemcachedBackupSessionManager&quot; memcachedNodes&#x3D;&quot;n1:192.168.110.197:11211,n2:192.168.110.198:11211&quot; sticky&#x3D;&quot;false&quot; sessionBackupAsync&#x3D;&quot;false&quot; requestUriIgnorePattern&#x3D;&quot;.*\.(ico|png|gif|jpg|css|js)$&quot; &#x2F;&gt; 部署Web项目到tomcat新建测试用的web项目,并部署到两台tomcat中.测试代码简单如下: 12345&lt;body&gt; Session ID:&lt;%&#x3D;session.getId()%&gt; &lt;br&gt; IP:&lt;%&#x3D;request.getServerName()%&gt; &lt;br&gt; Port:&lt;%&#x3D;request.getServerPort()%&gt;&lt;&#x2F;body&gt; 启动两台机器的memcached1memcached -m 32 -p 11211 -d 启动两台机器的tomcat查看tomcat信息tail -f catalina.out未报错,看到类似如下信息就启动成功 12345678信息: --------- finished initialization:- sticky: false- operation timeout: 1000- node ids: [n1, n2]- failover node ids: []- storage key prefix: null-------- 访问测试页面分别访问两台机器的测试页面: 同一个浏览器 两个浏览器 结束掉一个机器的memcached进程在访问等等 同一个浏览器不同标签页访问192.168.110.197和192.168.110.198 得到的sessionid都是一样的: 1234567Session ID:39D5E175513B4496C136F5E1554478CD-n1 IP:192.168.110.197 Port:8080Session ID:39D5E175513B4496C136F5E1554478CD-n1 IP:192.168.110.198 Port:8080 关闭ip为197的memcached进程之后,刷新页面: 1234567Session ID:39D5E175513B4496C136F5E1554478CD-n2 IP:192.168.110.197 Port:8080Session ID:39D5E175513B4496C136F5E1554478CD-n2 IP:192.168.110.198 Port:8080 测试成功. 参考https://github.com/magro/memcached-session-manager/wiki/SetupAndConfiguration#introduction http://laoxu.blog.51cto.com/4120547/1566477]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[一次简单的持久带内存溢出java.lang.OutOfMemoryError: PermGen space]]></title>
      <url>%2F2016%2F06%2F28%2F%E4%B8%80%E6%AC%A1%E7%AE%80%E5%8D%95%E7%9A%84%E6%8C%81%E4%B9%85%E4%BB%A3%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BAjava-lang-OutOfMemoryError-PermGen-space%2F</url>
      <content type="text"><![CDATA[简介昨天拿到服务器之后,便部署新开发的项目上去.顺带测试,运行不久,发现程序运行缓慢,随即提示java.lang.OutOfMemoryError: PermGen space.以前没遇到过这种情况,记录下来.服务器上的软件以及设置是一个酱油弄的,没仔细去查看,不知道是不是有问题. 查看tomcat pid1234jps -l 发现两个tomcatjps -v找到我部署程序的那个tomcat pid 32365 查看虚拟机相关信息查看jstat -gc123jstat -gc 32365S0C S1C S0U S1U EC EU OC OU PC PU YGC YGCT FGC FGCT GCT6848.0 6848.0 0.0 0.0 54976.0 742.8 137236.0 75708.3 65536.0 65535.9 115 1.345 688 172.945 174.290 发现PC和PU两个数值相同了,持久代已经使用完. 参数代表含义如下: 123456789101112131415S0C 年轻代中第一个survivor（幸存区）的容量 (字节)S1C 年轻代中第二个survivor（幸存区）的容量 (字节)S0U 年轻代中第一个survivor（幸存区）目前已使用空间 (字节)S1U 年轻代中第二个survivor（幸存区）目前已使用空间 (字节)EC 年轻代中Eden（伊甸园）的容量 (字节)EU 年轻代中Eden（伊甸园）目前已使用空间 (字节)OC Old代的容量 (字节)OU Old代目前已使用空间 (字节)PC Perm(持久代)的容量 (字节)PU Perm(持久代)目前已使用空间 (字节)YGC 从应用程序启动到采样时年轻代中gc次数YGCT 从应用程序启动到采样时年轻代中gc所用时间(s)FGC 从应用程序启动到采样时old代(全gc)gc次数FGCT 从应用程序启动到采样时old代(全gc)gc所用时间(s)GCT 从应用程序启动到采样时gc用的总时间(s) 查看jstat -gcpermcapacity123jstat -gcpermcapacity 32365PGCMN PGCMX PGC PC YGC FGC FGCT GCT12288.0 65536.0 65536.0 65536.0 115 610 153.078 154.423 持久代初始大小(PGCMN)12M,最大(PGCMX)64M,上面一步显示,64M已经用完.可以考虑增加持久代大小64M增大到256M. 参数代表含义如下: 12345678PGCMN perm代中初始化(最小)的大小 (字节)PGCMX perm代的最大容量 (字节)PGC perm代当前新生成的容量 (字节)PC Perm(持久代)的容量 (字节)YGC 从应用程序启动到采样时年轻代中gc次数FGC 从应用程序启动到采样时old代(全gc)gc次数FGCT 从应用程序启动到采样时old代(全gc)gc所用时间(s)GCT 从应用程序启动到采样时gc用的总时间(s) 设置tomcat tomcat bin 目录下找到setenv.sh,没有的话新建一个 添加如下内容到setenv.sh export CATALINA_OPTS=&quot;$CATALINA_OPTS -XX:PermSize=256m -XX:MaxPermSize=256m&quot; 重启tomcat 参考http://stackoverflow.com/questions/19769675/tomcat-7-outofmemoryerror-from-uncaughtexceptionhandler http://tdcq.iteye.com/blog/1990666]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring事务简介]]></title>
      <url>%2F2016%2F06%2F13%2FSpring%E4%BA%8B%E5%8A%A1%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[事务的传播行为Spring事务有7种传播行为: PROPAGATION_REQUIRED 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。 PROPAGATION_SUPPORTS 支持当前事务，如果当前没有事务，就以非事务方式执行。 PROPAGATION_MANDATORY 支持当前事务，如果当前没有事务，就抛出异常。 PROPAGATION_REQUIRES_NEW 新建事务，如果当前存在事务，把当前事务挂起。 PROPAGATION_NOT_SUPPORTED 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER 以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED 如果一个活动的事务存在，则运行在一个嵌套的事务中. 如果没有活动事务, 则按PROPAGATION_REQUIRED 属性执行 事务隔离级别Spring事务有5种隔离级别 ISOLATION_DEFAULT 这是一个PlatfromTransactionManager默认的隔离级别，使用数据库默认的事务隔离级别. ISOLATION_READ_UNCOMMITTED 这是事务最低的隔离级别，允许读取尚未提交的更改。可能导致脏读、幻影读或不可重复读。 ISOLATION_READ_COMMITTED 允许从已经提交的并发事务读取。可防止脏读，但幻影读和不可重复读仍可能会发生。 ISOLATION_REPEATABLE_READ 对相同字段的多次读取的结果是一致的，除非数据被当前事务本身改变。可防止脏读和不可重复读，但幻影读仍可能发生。 ISOLATION_SERIALIZABLE 这是花费最高代价但是最可靠的事务隔离级别。事务被处理为顺序执行。除了防止脏读，不可重复读外，还避免了幻像读。 只读事务超时回滚规则Spring默认情况下会对RunTimeException进行事务回滚。这个异常是unchecked,如果遇到checked意外就不回滚。 改变默认规则： 让checked例外也回滚：在整个方法前加上 @Transactional(rollbackFor=Exception.class) 让unchecked例外不回滚： @Transactional(notRollbackFor=RunTimeException.class) 不需要事务管理的(只查询的)方法：@Transactional(propagation=Propagation.NOT_SUPPORTED) 如果不添加rollbackFor等属性，Spring碰到Unchecked Exceptions都会回滚，不仅是RuntimeException，也包括Error。 注意:如果异常被try｛｝catch｛｝了，事务就不回滚了，如果想让事务回滚必须再往外抛try｛｝catch｛throw Exception｝。 参考http://fhjxp.iteye.com/blog/124978 http://liubingwwww.blog.163.com/blog/static/3048510720091842335402/ http://www.cnblogs.com/zhishan/p/3195219.html http://www.cnblogs.com/0201zcr/p/4678649.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[synchronized和volatile简介]]></title>
      <url>%2F2016%2F06%2F08%2Fsynchronized%E5%92%8Cvolatile%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[简介(转)这个可能是最好的对比volatile和synchronized作用的文章了。 volatile是一个变量修饰符，而synchronized是一个方法或块的修饰符。所以我们使用这两种关键字来指定三种简单的存取变量的方式。 12345678int i1;int geti1() &#123;return i1;&#125;volatile int i2;int geti2() &#123;return i2;&#125;int i3;synchronized int geti3() &#123;return i3;&#125; geti1()在当前线程中立即获取在i1变量中的值。线程可以获得变量的本地拷贝，而所获得的变量的值并不一定与其他线程所获得的值相同。特别是，如果其他的线程修改了i1的值，那么当前线程获得的i1的值可能与修改后的值有所差别。 实际上，Java有一种主内存的机制，使用一个主内存来保存变量当前的正确的值。线程将变量的值拷贝到自己独立的内存中，而这些线程的内存拷贝可能与主内存中的值不同。所以实际当中可能发生这样的情况，在主内存中i1的值为1，线程1和线程2都更改了i1，但是却没把更新的值传回给主内存或其他线程中，那么可能在线程1中i1的值为2，线程2中i1的值却为3。 另一方面，geti2()可以有效的从主内存中获取i2的值。一个volatile类型的变量不允许线程从主内存中将变量的值拷贝到自己的存储空间。因此，一个声明为volatile类型的变量将在所有的线程中同步的获得数据，不论你在任何线程中更改了变量，其他的线程将立即得到同样的结果。由于线程存取或更改自己的数据拷贝有更高的效率，所以volatile类型变量在性能上有所消耗。 那么如果volatile变量已经可以使数据在线程间同步，那么synchronizes用来干什么呢？两者有两方面的不同。首先，synchronized获取和释放由监听器控制的锁，如果两个线程都使用一个监听器(即相同对象锁)，那么监听器可以强制在一个时刻只有一个线程能处理代码块，这是最一般的同步。 另外，synchronized还能使内存同步。在实际当中，synchronized使得所有的线程内存与主内存相同步。所以geti3()的执行过程如下： 线程从监听器获取对象的锁。(这里假设监听器非锁，否则线程只有等到监听器解锁才能获取对象锁) 线程内存更新所有的变量，也就是说他将读取主内存中的变量使自己的变量保证有效。(JVM会使用一个“脏”标志来最优化过程，使得仅仅具有“脏”标志变量被更新。详细的情况查询JAVA规范的17.9) 代码块被执行(在这个例子中，设置返回值为刚刚从主内存重置的i3当前的值。) 任何变量的变更将被写回到主内存中。但是这个例子中geti3()没有什么变化。 线程释放对象的锁给监听器。所以volatile只能在线程内存和主内存之间同步一个变量的值，而synchronized则同步在线程内存和主内存之间的所有变量的值，并且通过锁住和释放监听器来实现。显然，synchronized在性能上将比volatile更加有所消耗。 关于两者的区别 volatile本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取；synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。 volatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别的 volatile仅能实现变量的修改可见性，不能保证原子性；而synchronized则可以保证变量的修改可见性和原子性 volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞。 volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化 参考http://blog.csdn.net/wanghai__/article/details/6260178]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[乐观锁与悲观锁简介]]></title>
      <url>%2F2016%2F06%2F03%2F%E4%B9%90%E8%A7%82%E9%94%81%E4%B8%8E%E6%82%B2%E8%A7%82%E9%94%81%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[悲观锁 在关系数据库管理系统里，悲观并发控制（又名“悲观锁”，Pessimistic Concurrency Control，缩写“PCC”）是一种并发控制的方法。它可以阻止一个事务以影响其他用户的方式来修改数据。如果一个事务执行的操作都某行数据应用了锁，那只有当这个事务把锁释放，其他事务才能够执行与该锁冲突的操作。悲观并发控制主要用于数据争用激烈的环境，以及发生并发冲突时使用锁保护数据的成本要低于回滚事务的成本的环境中。 悲观锁，正如其名，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度(悲观)，因此，在整个数据处理过程中，将数据处于锁定状态。 悲观锁的实现，往往依靠数据库提供的锁机制 （也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）. 悲观锁,假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。悲观锁假定其他用户企图访问或者改变你正在访问、更改的对象的概率是很高的，因此在悲观锁的环境中，在你开始改变此对象之前就将该对象锁住，并且直到你提交了所作的更改之后才释放锁。悲观的缺陷是不论是页锁还是行锁，加锁的时间可能会很长，这样可能会长时间的限制其他用户的访问，也就是说悲观锁的并发访问性不好。 悲观锁应用 需要使用数据库的锁机制 乐观锁 在关系数据库管理系统里，乐观并发控制（又名“乐观锁”，Optimistic Concurrency Control，缩写“OCC”）是一种并发控制的方法。它假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，正在提交的事务会进行回滚。乐观事务控制最早是由孔祥重（H.T.Kung）教授提出。 乐观锁（ Optimistic Locking ） 相对悲观锁而言，乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。 乐观锁,假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。乐观锁不能解决脏读的问题。乐观锁则认为其他用户企图改变你正在更改的对象的概率是很小的，因此乐观锁直到你准备提交所作的更改时才将对象锁住，当你读取以及改变该对象时并不加锁。可见乐观锁加锁的时间要比悲观锁短，乐观锁可以用较大的锁粒度获得较好的并发访问性能。但是如果第二个用户恰好在第一个用户提交更改之前读取了该对象，那么当他完成了自己的更改进行提交时，数据库就会发现该对象已经变化了，这样，第二个用户不得不重新读取该对象并作出更改。这说明在乐观锁环境中，会增加并发用户读取对象的次数。 乐观锁应用 使用版本号 使用时间戳 乐观锁与悲观锁的优点和缺点悲观并发控制实际上是“先取锁再访问”的保守策略，为数据处理的安全提供了保证。但是在效率方面，处理加锁的机制会让数据库产生额外的开销，还有增加产生死锁的机会；另外，在只读型事务处理中由于不会产生冲突，也没必要使用锁，这样做只能增加系统负载；还有会降低了并行性，一个事务如果锁定了某行数据，其他事务就必须等待该事务处理完才可以处理那行数 乐观并发控制相信事务之间的数据竞争(data race)的概率是比较小的，因此尽可能直接做下去，直到提交的时候才去锁定，所以不会产生任何锁和死锁。但如果直接简单这么做，还是有可能会遇到不可预期的结果，例如两个事务都读取了数据库的某一行，经过修改以后写回数据库，这时就遇到了问题。 从数据库厂商的角度看，使用乐观的页锁是比较好的，尤其在影响很多行的批量操作中可以放比较少的锁，从而降低对资源的需求提高数据库的性能。再考虑聚集索引。在数据库中记录是按照聚集索引的物理顺序存放的。如果使用页锁，当两个用户同时访问更改位于同一数据页上的相邻两行时，其中一个用户必须等待另一个用户释放锁，这会明显地降低系统的性能。interbase和大多数关系数据库一样，采用的是乐观锁，而且读锁是共享的，写锁是排他的。可以在一个读锁上再放置读锁，但不能再放置写锁；你不能在写锁上再放置任何锁。锁是目前解决多用户并发访问的有效手段。 在实际生产环境里边,如果并发量不大且不允许脏读，可以使用悲观锁解决并发问题；但如果系统的并发非常大的话,悲观锁定会带来非常大的性能问题,所以我们就要选择乐观锁定的方法. 参考http://www.cnblogs.com/Bob-FD/p/3352216.html http://www.hollischuang.com/archives/934]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CyclicBarrier简介]]></title>
      <url>%2F2016%2F06%2F01%2FCyclicBarrier%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[CyclicBarrier简介 CyclicBarrier和CountDownLatch不同,是当await的数量达到了设定的数量之后,才继续往下执行 CyclicBarrier数的是调用了CyclicBarrier.await()进入等待的线程数,当线程数达到了CyclicBarrier初始时规定的数目时，所有进入等待状态的线程被唤醒并继续。 CyclicBarrier就象它名字的意思一样，可看成是个障碍，所有的线程必须到齐后才能一起通过这个障碍。 CyclicBarrier初始时还可带一个Runnable的参数，此Runnable任务在CyclicBarrier的数目达到后，所有其它线程被唤醒前被执行。 源码分析 jdk1.7.0_71 参考http://xijunhu.iteye.com/blog/713433 http://www.cnblogs.com/techyc/archive/2013/03/13/2957059.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CountDownLatch简介]]></title>
      <url>%2F2016%2F06%2F01%2FCountDownLatch%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[CountDownLatch是并发包中提供的一个可用于控制多个线程同时开始某动作的类，可以看做是一个计数器，计数器操作是院子操作，同时只能有一个线程去操作这个计数器。可以向CountDownLatch对象设置一个初始的数字作为计数值，任何调用这个对象上的await()方法都会阻塞，直到这个计数器的计数值被其他的线程减为0为止。 CountDownLatch的一个非常典型的应用场景是：有一个任务想要往下执行，但必须要等到其他的任务执行完毕后才可以继续往下执行。假如我们这个想要继续往下执行的任务调用一个CountDownLatch对象的await()方法，其他的任务执行完自己的任务后调用同一个CountDownLatch对象上的countDown()方法，这个调用await()方法的任务将一直阻塞等待，直到这个CountDownLatch对象的计数值减到0为止。 源码分析 jdk1.7.0_71 await()countDown()参考http://zapldy.iteye.com/blog/746458 http://www.cnblogs.com/skywang12345/p/3533887.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Semaphore简介]]></title>
      <url>%2F2016%2F06%2F01%2FSemaphore%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[Semaphore简介 Semaphore是并发包中提供的用于控制某资源同时被访问的个数 操作系统的信号量是个很重要的概念，在进程控制方面都有应用。Java 并发库 的Semaphore 可以很轻松完成信号量控制，Semaphore可以控制某个资源可被同时访问的个数，通过 acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。 Semaphore维护了当前访问的个数，提供同步机制，控制同时访问的个数 Semaphore类只是一个资源数量的抽象表示,并不负责管理资源对象本身,可能有多个线程同时获取到资源使用许可,因此需要使用同步机制避免数据竞争. 源码分析 jdk1.7.0_71 Semaphore(int permits)1234&#x2F;&#x2F;指定许可数初始化,非公平模式public Semaphore(int permits) &#123; sync &#x3D; new NonfairSync(permits); &#125; Semaphore(int permits,boolean fair)1234&#x2F;&#x2F;可在初始化时指定第二个参数为true,使用公平模式public Semaphore(int permits, boolean fair) &#123; sync &#x3D; fair ? new FairSync(permits) : new NonfairSync(permits); &#125; acquire() 阻塞,获取许可,可以被中断123public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; acquireUninterruptibly()获取许可,不可中断123public void acquireUninterruptibly() &#123; sync.acquireShared(1); &#125; tryAcquire()非阻塞,获取许可123public boolean tryAcquire() &#123; return sync.nonfairTryAcquireShared(1) &gt;&#x3D; 0; &#125; tryAcquire(long timeout,TimeUnit unit)非阻塞,获取许可1234public boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout)); &#125; release()释放许可123public void release() &#123; sync.releaseShared(1); &#125; 参考http://www.cnblogs.com/whgw/archive/2011/09/29/2195555.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java中的ScheduledThreadPoolExecutor]]></title>
      <url>%2F2016%2F05%2F30%2FJava%E4%B8%AD%E7%9A%84ScheduledThreadPoolExecutor%2F</url>
      <content type="text"><![CDATA[ScheduledThreadPoolExecutor使用和原理学习。 原理ScheduledThreadPoolExecutor提供了延迟和周期执行功能，内部实现相当于使用DelayQueue延时队列、PriorityQueue优先级队列和Delayed三者来配合实现的功能，在使用延时队列实现我们自己的业务功能时，也会使用这三个组件来配合。但是实际上ScheduledThreadPoolExecutor不是直接使用这三个组件来实现，而是在内部实现了几个功能类似的内部类： DelayedWorkQueue，功能相当于DelayQueue，只不过这个内部没有依赖PriorityQueue，而是直接实现了堆排序功能。 ScheduledFutureTask，相当于实现了Delayed接口的业务类，ScheduledFutureTask的父接口的父接口ScheduledFuture继承了Delayed接口，ScheduledFutureTask实现了getDelay和compareTo方法，这两个方法可以参考DelayQueue解析中的使用。 方法 schedule，给定延迟后，执行任务 scheduleAtFixedRate，每个任务都在指定的时间间隔内执行，如果一个任务瞬间执行完，指定的时间间隔还有很多剩余的，下一个任务也不会执行；如果一个任务在指定的时间间隔没有执行完，占用了下个任务的时间，那这个任务执行完后下个任务立马就开始。 scheduleWithFixedDelay，在一次任务结束后，间隔指定的时间，再继续执行下一次任务，不管一次任务执行多长时间，在这次任务结束后都会暂停指定的时间，接下来再执行下面的任务。就是说我不管，我每次任务完成都必须要休息一定时间。 源码123456789101112131415/** * 给定延迟后，执行任务，只会执行一次 */ public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit) &#123; if (command == null || unit == null) throw new NullPointerException(); // 创建执行的Task实例，由于schedule只执行一次，所以实例化ScheduledFutureTask的时候周期数是0 RunnableScheduledFuture&lt;?&gt; t = decorateTask(command, new ScheduledFutureTask&lt;Void&gt;(command, null, triggerTime(delay, unit))); delayedExecute(t); return t; &#125; 1234567891011121314151617181920212223242526/** * 每个任务都在指定的时间间隔内执行，如果一个任务瞬间执行完， * 指定的时间间隔还有很多剩余的，下一个任务也不会执行；如果一 * 个任务在指定的时间间隔没有执行完，占用了下个任务的时间， * 那这个任务执行完后下个任务立马就开始。 */ public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) &#123; if (command == null || unit == null) throw new NullPointerException(); if (period &lt;= 0) throw new IllegalArgumentException(); // 实例化ScheduledFutureTask的时候周期数为指定的周期数 ScheduledFutureTask&lt;Void&gt; sft = new ScheduledFutureTask&lt;Void&gt;(command, null, triggerTime(initialDelay, unit), unit.toNanos(period)); RunnableScheduledFuture&lt;Void&gt; t = decorateTask(command, sft); sft.outerTask = t; // 延迟执行 delayedExecute(t); return t; &#125; 1234567891011121314151617181920212223242526/** * 在一次任务结束后，间隔指定的时间，再继续执行下一次任务， * 不管一次任务执行多长时间，在这次任务结束后都会暂停指定的 * 时间，接下来再执行下面的任务。就是说我不管，我每次任务完成 * 都必须要休息一定时间。 */ public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit) &#123; if (command == null || unit == null) throw new NullPointerException(); if (delay &lt;= 0) throw new IllegalArgumentException(); // 实例化ScheduledFutureTask的时候周期数是指定的延时时长，并且是负数 ScheduledFutureTask&lt;Void&gt; sft = new ScheduledFutureTask&lt;Void&gt;(command, null, triggerTime(initialDelay, unit), unit.toNanos(-delay)); RunnableScheduledFuture&lt;Void&gt; t = decorateTask(command, sft); sft.outerTask = t; // 延迟执行 delayedExecute(t); return t; &#125; ScheduledFutureTask是实现了Delayed接口的类，重写的getDelay和compareTo方法跟我们自己实现业务逻辑一样。 run方法： 123456789101112131415161718public void run() &#123; // 是否是周期任务 boolean periodic = isPeriodic(); // 判断当前线程状态是否能执行任务 if (!canRunInCurrentRunState(periodic)) cancel(false); // 不是周期性任务，直接执行 else if (!periodic) ScheduledFutureTask.super.run(); // 周期性任务，执行任务，设置下次执行时间 else if (ScheduledFutureTask.super.runAndReset()) &#123; // 设置下次执行时间 // scheduleAtFixedRate和scheduleWithFixedDelay的period不同，处理也不一样 setNextRunTime(); // 将下次要执行的任务添加到队列中 reExecutePeriodic(outerTask); &#125; &#125; 1234567891011private void setNextRunTime() &#123; // scheduleAtFixedRate的period是大于0的 // scheduleWithFixedDelay是小于0的 long p = period; //scheduleAtFixedRate，下次时间执行的时间等于上次开始执行时间加上周期时间 if (p &gt; 0) time += p; else // 下次执行时间等于当前时间加上周期时间，也就是要暂停period时间 time = triggerTime(-p); &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ThreadPoolExecutor简介]]></title>
      <url>%2F2016%2F05%2F30%2FThreadPoolExecutor%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[ThreadPoolExecutor简介 并发包中提供的一个线程池服务 线程池的工作过程 线程池刚创建,里面没有线程.任务队列是作为参数传进来的.线程池不会立即执行任务. 调用execute()方法添加一个任务,线程池会做如下判断: 如果正在运行的线程数量小于corePoolSize,马上创建线程运行这个任务 如果正在运行的线程数量大于或等于corePoolSize,这个任务放入队列 如果队列满了,且正在运行的线程数量小于maximumPoolSize,就要创建线程运行这个任务 如果队列满了,而且正在运行的线程数量大于或等于maximumPoolSize,通过 handler所指定的策略来处理此任务 当一个线程完成任务时,会从队列取下一个任务来执行 当一个线程空闲时,超过keepAliveTime,线程池会判断,如果当前运行的线程数大于corePoolSize,这个线程会被停掉. 任务队列选择 ArrayBlockingQueue LinkedBlockingQueue 没有大小限制 handler选择 ThreadPoolExecutor.AbortPolicy() 抛出java.util.concurrent.RejectedExecutionException异常 ThreadPoolExecutor.CallerRunsPolicy() 重试添加当前的任务，他会自动重复调用execute()方法 ThreadPoolExecutor.DiscardOldestPolicy() 抛弃旧的任务 ThreadPoolExecutor.DiscardPolicy() 抛弃当前的任务 源码分析 jdk1.7.0_71 构造123456789public ThreadPoolExecutor(int corePoolSize,&#x2F;&#x2F;线程池维护线程的最少数量int maximumPoolSize,&#x2F;&#x2F;线程池维护线程的最大数量 long keepAliveTime,&#x2F;&#x2F;线程池维护线程所允许的空闲时间TimeUnit unit,&#x2F;&#x2F;线程池维护线程所允许的空闲时间的单位 BlockingQueue&lt;Runnable&gt; workQueue,&#x2F;&#x2F;线程池所使用的缓冲队列ThreadFactory threadFactory,&#x2F;&#x2F;执行程序创建新线程时使用的工厂RejectedExecutionHandler handler&#x2F;&#x2F;线程池对拒绝任务的处理策略 )&#123;&#125; execute(Runnable command) 添加任务到线程池123456public void execute(Runnable command) &#123;&#x2F;&#x2F;command为空抛异常&#x2F;&#x2F;如果正在运行的线程数量小于corePoolSize,会立即addWorker(),创建新线程运行&#x2F;&#x2F;如果正在执行的数量大于等于corePoolSize,将任务放到阻塞队列.如果阻塞队列没有满并且是运行着的,直接放入阻塞队列.放入队列之后还要再做一次检查,如果线程池不在运行状态,把刚才的任务移除,调用reject方法,否则查看worker数量,若为0起一个新的worker去执行任务&#x2F;&#x2F;加入队列失败的话,会addWorker尝试一个新的worker去执行任务,新worker创建失败,调用reject方法&#125; addWorker(Runnable firstTask, boolean core) 详细查看此文章 123firstTask表示需要跑的任务。boolean类型的core参数为true的话表示使用线程池的基本大小为false使用线程池最大大小 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c &#x3D; ctl.get(); int rs &#x3D; runStateOf(c); &#x2F;&#x2F; 线程池当前状态 &#x2F;&#x2F; 这个判断转换成 rs &gt;&#x3D; SHUTDOWN &amp;&amp; (rs !&#x3D; SHUTDOWN || firstTask !&#x3D; null || workQueue.isEmpty)。 &#x2F;&#x2F; 概括为3个条件： &#x2F;&#x2F; 1. 线程池不在RUNNING状态并且状态是STOP、TIDYING或TERMINATED中的任意一种状态 &#x2F;&#x2F; 2. 线程池不在RUNNING状态，线程池接受了新的任务 &#x2F;&#x2F; 3. 线程池不在RUNNING状态，阻塞队列为空。 满足这3个条件中的任意一个的话，拒绝执行任务 if (rs &gt;&#x3D; SHUTDOWN &amp;&amp; ! (rs &#x3D;&#x3D; SHUTDOWN &amp;&amp; firstTask &#x3D;&#x3D; null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc &#x3D; workerCountOf(c); &#x2F;&#x2F; 线程池线程个数 if (wc &gt;&#x3D; CAPACITY || wc &gt;&#x3D; (core ? corePoolSize : maximumPoolSize)) &#x2F;&#x2F; 如果线程池线程数量超过线程池最大容量或者线程数量超过了基本大小(core参数为true，core参数为false的话判断超过最大大小) return false; &#x2F;&#x2F; 超过直接返回false if (compareAndIncrementWorkerCount(c)) &#x2F;&#x2F; 没有超过各种大小的话，cas操作线程池线程数量+1，cas成功的话跳出循环 break retry; c &#x3D; ctl.get(); &#x2F;&#x2F; 重新检查状态 if (runStateOf(c) !&#x3D; rs) &#x2F;&#x2F; 如果状态改变了，重新循环操作 continue retry; &#x2F;&#x2F; else CAS failed due to workerCount change; retry inner loop &#125; &#125; &#x2F;&#x2F; 走到这一步说明cas操作成功了，线程池线程数量+1 boolean workerStarted &#x3D; false; &#x2F;&#x2F; 任务是否成功启动标识 boolean workerAdded &#x3D; false; &#x2F;&#x2F; 任务是否添加成功标识 Worker w &#x3D; null; try &#123; final ReentrantLock mainLock &#x3D; this.mainLock; &#x2F;&#x2F; 得到线程池的可重入锁 w &#x3D; new Worker(firstTask); &#x2F;&#x2F; 基于任务firstTask构造worker final Thread t &#x3D; w.thread; &#x2F;&#x2F; 使用Worker的属性thread，这个thread是使用ThreadFactory构造出来的 if (t !&#x3D; null) &#123; &#x2F;&#x2F; ThreadFactory构造出的Thread有可能是null，做个判断 mainLock.lock(); &#x2F;&#x2F; 锁住，防止并发 try &#123; &#x2F;&#x2F; 在锁住之后再重新检测一下状态 int c &#x3D; ctl.get(); int rs &#x3D; runStateOf(c); if (rs &lt; SHUTDOWN || (rs &#x3D;&#x3D; SHUTDOWN &amp;&amp; firstTask &#x3D;&#x3D; null)) &#123; &#x2F;&#x2F; 如果线程池在RUNNING状态或者线程池在SHUTDOWN状态并且任务是个null if (t.isAlive()) &#x2F;&#x2F; 判断线程是否还活着，也就是说线程已经启动并且还没死掉 throw new IllegalThreadStateException(); &#x2F;&#x2F; 如果存在已经启动并且还没死的线程，抛出异常 workers.add(w); &#x2F;&#x2F; worker添加到线程池的workers属性中，是个HashSet int s &#x3D; workers.size(); &#x2F;&#x2F; 得到目前线程池中的线程个数 if (s &gt; largestPoolSize) &#x2F;&#x2F; 如果线程池中的线程个数超过了线程池中的最大线程数时，更新一下这个最大线程数 largestPoolSize &#x3D; s; workerAdded &#x3D; true; &#x2F;&#x2F; 标识一下任务已经添加成功 &#125; &#125; finally &#123; mainLock.unlock(); &#x2F;&#x2F; 解锁 &#125; if (workerAdded) &#123; &#x2F;&#x2F; 如果任务添加成功，运行任务，改变一下任务成功启动标识 t.start(); &#x2F;&#x2F; 启动线程，这里的t是Worker中的thread属性，所以相当于就是调用了Worker的run方法 workerStarted &#x3D; true; &#125; &#125; &#125; finally &#123; if (! workerStarted) &#x2F;&#x2F; 如果任务启动失败，调用addWorkerFailed方法 addWorkerFailed(w); &#125; return workerStarted;&#125; 参考http://fulong258.blog.163.com/blog/static/17895044201082951820935 http://www.oschina.net/question/12_2656 http://coach.iteye.com/blog/855850 http://fangjian0423.github.io/2016/03/22/java-threadpool-analysis/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[AtomicInteger简介]]></title>
      <url>%2F2016%2F05%2F30%2FAtomicInteger%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[AtomicInteger简介 支持原子操作的Integer类 主要用于在高并发环境下的高效程序处理。使用非阻塞算法来实现并发控制。 源码分析 jdk1.7.0_71 123456&#x2F;&#x2F;在更新操作时提供“比较并替换”的作用private static final Unsafe unsafe &#x3D; Unsafe.getUnsafe();&#x2F;&#x2F;用来记录value本身在内存的偏移地址private static final long valueOffset;&#x2F;&#x2F;用来存储整数的时间变量，这里被声明为volatile，就是为了保证在更新操作时，当前线程可以拿到value最新的值private volatile int value; AtomicInteger(int initialValue) 初始化1public AtomicInteger(int initialValue)&#123;&#125; AtomicInteger()1public AtomicInteger()&#123;&#125; get()获取当前值123public final int get() &#123; return value; &#125; set(int value)设置值123public final void set(int newValue) &#123; value &#x3D; newValue; &#125; lazySet(int newValue)1234567&#x2F;&#x2F;lazySet延时设置变量值，这个等价于set()方法，但是由于字段是&#x2F;&#x2F;volatile类型的，因此次字段的修改会比普通字段（非volatile&#x2F;&#x2F;字段）有稍微的性能延时（尽管可以忽略），所以如果不是&#x2F;&#x2F;想立即读取设置的新值，允许在“后台”修改值，那么此方法就很有用。public final void lazySet(int newValue) &#123; unsafe.putOrderedInt(this, valueOffset, newValue); &#125; getAndSet(int newValue)设定新数据,返回旧数据1public final int getAndSet(int newValue) &#123;&#125; compareAndSet(int expect,int update)比较并设置12345public final boolean compareAndSet(int expect, int update) &#123;&#x2F;&#x2F;使用unsafe的native方法，实现高效的硬件级别CAS&#x2F;&#x2F;native方法return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125; weakCompareAndSet(int expect,int update)比较并设置123public final boolean weakCompareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125; getAndIncrement()以原子方式将当前值加 1，相当于线程安全的i++操作12345678public final int getAndIncrement() &#123; for (;;) &#123; int current &#x3D; get(); int next &#x3D; current + 1; if (compareAndSet(current, next)) return current; &#125; &#125; incrementAndGet( )以原子方式将当前值加 1， 相当于线程安全的++i操作。1public final int incrementAndGet() &#123;&#125; getAndDecrement( )以原子方式将当前值减 1， 相当于线程安全的i–操作。1public final int getAndDecrement() &#123;&#125; decrementAndGet ( )以原子方式将当前值减 1，相当于线程安全的–i操作。1234public final int decrementAndGet() &#123;&#125;&#96;&#96;&#96; ## addAndGet( )： 以原子方式将给定值与当前值相加， 实际上就是等于线程安全的i &#x3D;i+delta操作。 public final int addAndGet(int delta) {} 12## getAndAdd( )：以原子方式将给定值与当前值相加， 相当于线程安全的t&#x3D;i;i+&#x3D;delta;return t;操作 public final int getAndAdd(int delta) {} # 参考 [http://www.itzhai.com/the-introduction-and-use-of-atomicinteger.html#read-more](http://www.itzhai.com/the-introduction-and-use-of-atomicinteger.html#read-more) [http://hittyt.iteye.com/blog/1130990](http://hittyt.iteye.com/blog/1130990) [http://chenzehe.iteye.com/blog/1759884](http://chenzehe.iteye.com/blog/1759884)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java中的DelayQueue延时队列]]></title>
      <url>%2F2016%2F05%2F29%2FJava%E4%B8%AD%E7%9A%84DelayQueue%E5%BB%B6%E6%97%B6%E9%98%9F%E5%88%97%2F</url>
      <content type="text"><![CDATA[DelayQueue使用和原理学习。 简介DelayQueue是一个无界阻塞队列，支持延时获取元素。内部使用PriorityQueue优先级队列来存储元素，存储的元素需要实现Delayed接口。 也就是在往DelayQueue中放元素的时候，该元素必须实现Delayed接口，并且可以指定一个需要延迟的时间，等过了一段时间到了我们指定的延迟时间后，可以获取到该元素，继续针对该元素处理。 示例模拟延迟发送短信功能，发短信的时候可以指定延时多久进行发送。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * 延迟短信 */public class DelayedSms implements Delayed &#123; /** * 短信内容 */ private String sms; /** * 短信创建时间 */ private long createTime; /** * 短信发送时间 */ private long sendTime; /** * 返回剩余的时间 * @param unit * @return */ @Override public long getDelay(TimeUnit unit) &#123; long remaining = unit.convert(sendTime - System.currentTimeMillis(), TimeUnit.MILLISECONDS); System.out.println("剩余时间：" + remaining + "ms"); return remaining; &#125; /** * 延时队列内部比较排序 * @param other * @return */ @Override public int compareTo(Delayed other) &#123; return Long.compare(this.getDelay(TimeUnit.MILLISECONDS), other.getDelay(TimeUnit.MILLISECONDS)); &#125; // ... getter and setter... @Override public String toString() &#123;...&#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142public class SmsSender &#123; private DelayQueue&lt;DelayedSms&gt; queue = new DelayQueue&lt;&gt;(); public SmsSender() &#123; new Thread(new SmsSendTask()).start(); &#125; /** * 发送延时短信 * @param sms 短信内容 * @param createTime 短信创建时间 * @param delay 要延长的时间，毫秒 */ public void sendDelaySms(String sms, long createTime, long delay) &#123; DelayedSms delayedSms = new DelayedSms(); delayedSms.setSms(sms); delayedSms.setCreateTime(createTime); delayedSms.setSendTime(createTime + delay); queue.offer(delayedSms); &#125; private class SmsSendTask implements Runnable &#123; @Override public void run() &#123; while (true) &#123; try &#123; DelayedSms sms = queue.take(); sendSms(sms); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; private void sendSms(DelayedSms sms) &#123; System.out.println("发送短信：" + sms.getSms() + "，createTime：" + new Date(sms.getCreateTime()) + "，sendTime: " + new Date(sms.getSendTime()) + "，发送时间：" + new Date(System.currentTimeMillis())); &#125;&#125; 1234567891011121314151617public class Client &#123; public static void main(String[] args) throws InterruptedException &#123; SmsSender smsSender = new SmsSender(); long createTime = System.currentTimeMillis(); // 延时20s发送 smsSender.sendDelaySms("短信1", createTime, 20 * 1000); // 延时30秒发送 smsSender.sendDelaySms("短信2", createTime, 30 * 1000); // 延时10秒发送 smsSender.sendDelaySms("短信3", createTime, 10 * 1000); &#125;&#125; 解析延时队列重点：阻塞队列、PriorityQueue、Delayed。延时队列是使用优先级队列来实现的一个阻塞队列，队列中存放的是实现接口Delayed的元素，优先队列比较是根据指定的延时时间。 阻塞队列延时队列是阻塞队列，获取元素的时候如果没有元素到期，获取元素的线程会被阻塞。 Delayed延时队列中存放的元素必须实现Delayed接口，该接口定义了一个getDelay方法，是我们必须要实现的方法，该方法用来返回元素到过期时间还剩余多少时间。 Delayed还继承了接口Comparable，compareTo方法也是我们必须要实现的，该方法用来确定元素在PriorityQueue中的顺序。 PriorityQueue延时队列内部使用PriorityQueue实现，PriorityQueue中存放的元素必须实现Delayed接口，根据元素的compareTo方法来确定元素顺序 源码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495public class DelayQueue&lt;E extends Delayed&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt; &#123; /** * 重入锁，保证队列操作的安全 */ private final transient ReentrantLock lock = new ReentrantLock(); /** * 优先级队列，用来存储元素，可以根据我们在compareTo方法中指定的算法来排序我们的元素 */ private final PriorityQueue&lt;E&gt; q = new PriorityQueue&lt;E&gt;(); /** * leader指向第一个从队列获取元素时阻塞等待的线程，用来优化内部阻塞通知， * 减少其他线程不必要的等待时间 * * 采用的是Leader-Follower模式 */ private Thread leader = null; /** * 队列头部有可用新元素或者新线程需要成为新的leader时需要被通知 */ private final Condition available = lock.newCondition(); public boolean offer(E e) &#123; // 添加元素进队列，先加锁 final ReentrantLock lock = this.lock; lock.lock(); try &#123; // 使用优先级队列，添加元素进队列，优先级队列会对元素按照指定规则排序 q.offer(e); // 添加完元素后，获取优先级队列的队头元素 // 如果刚添加的元素在队列头部，说明刚添加的元素就是要到期的元素 if (q.peek() == e) &#123; // leader置为null leader = null; // 唤醒阻塞在等待队列的线程 available.signal(); &#125; return true; &#125; finally &#123; lock.unlock(); &#125; &#125; public E take() throws InterruptedException &#123; // 出队列前先加锁 final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; for (;;) &#123; // 获取队列头的元素 E first = q.peek(); //队列中没有元素， if (first == null) // 当前线程等待 available.await(); else &#123; // 获取到了队列头元素 // 查看下我们定义元素时设置的延时时间规则，看是否到期 long delay = first.getDelay(NANOSECONDS); // 队列头元素已经过期，直接返回队列头元素 if (delay &lt;= 0) return q.poll(); first = null; // don't retain ref while waiting // 走到这里说明队列中有元素，但都还没到过期时间 // 如果leader存在，说明有其他的线程已经调用了take获取 if (leader != null) // 当前线程挂起等待 available.await(); else &#123; // leader为空，将当前线程变成leader Thread thisThread = Thread.currentThread(); leader = thisThread; try &#123; // 上面已经有了剩余的时间，当前线程就可以直接挂起等待这剩余的一段时间 available.awaitNanos(delay); &#125; finally &#123; if (leader == thisThread) leader = null; &#125; &#125; &#125; &#125; &#125; finally &#123; // leader处理完，返回了需要的元素，这里要唤醒其他的follower if (leader == null &amp;&amp; q.peek() != null) available.signal(); lock.unlock(); &#125; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ArrayBlockingQueue简介]]></title>
      <url>%2F2016%2F05%2F29%2FArrayBlockingQueue%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[ArrayBlockingQueue基于数组，先进先出，从尾部插入到队列，从头部开始返回。 线程安全的有序阻塞队列，内部通过“互斥锁”保护竞争资源。 指定时间的阻塞读写 容量可限制 定义ArrayBlockingQueue继承AbstractQueue，实现了BlockingQueue，Serializable接口，内部元素使用Object[]数组保存。初始化时候需要指定容量ArrayBlockingQueue(int capacity)，ArrayBlockingQueue默认会使用非公平锁。 ArrayBlockingQueue只使用一把锁，造成在存取两种操作时会竞争同一把锁，而使得性能相对低下。 add(E)方法和offer(E)调用父类中的add方法，查看源码可知父类中的add方法是调用offer方法实现,所以查看offer方法源码，如下： 1234567891011121314151617181920public boolean offer(E e) &#123; &#x2F;&#x2F;检查元素不为null checkNotNull(e); &#x2F;&#x2F;加锁，独占锁保护竞态资源。 final ReentrantLock lock &#x3D; this.lock; lock.lock(); try &#123; &#x2F;&#x2F;队列已满，返回false if (count &#x3D;&#x3D; items.length) return false; else &#123; &#x2F;&#x2F;插入元素,返回true insert(e); return true; &#125; &#125; finally &#123; &#x2F;&#x2F;释放锁 lock.unlock(); &#125;&#125; insert源码如下： 12345678910private void insert(E x) &#123; &#x2F;&#x2F;将元素添加到队列中 items[putIndex] &#x3D; x; &#x2F;&#x2F;putIndex表示下一个被添加元素的索引，设置下一个被添加元素的索引，若队列满了，就设置下一个被添加元素索引为0 putIndex &#x3D; inc(putIndex); &#x2F;&#x2F;队列的元素数加1 ++count; &#x2F;&#x2F;唤醒notEmpty上的等待线程,也就是取元素的线程。 notEmpty.signal();&#125; take()方法123456789101112131415public E take() throws InterruptedException &#123; &#x2F;&#x2F;获取独占锁，加锁，线程是中断状态的话会抛异常 final ReentrantLock lock &#x3D; this.lock; lock.lockInterruptibly(); try &#123; &#x2F;&#x2F;队列为空，会一直等待 while (count &#x3D;&#x3D; 0) notEmpty.await(); &#x2F;&#x2F;取元素的方法 return extract(); &#125; finally &#123; &#x2F;&#x2F;释放锁 lock.unlock(); &#125;&#125; 12345678910111213private E extract() &#123; final Object[] items &#x3D; this.items; E x &#x3D; this.&lt;E&gt;cast(items[takeIndex]); &#x2F;&#x2F;取完之后，删除元素 items[takeIndex] &#x3D; null; &#x2F;&#x2F;设置下一个被取出的元素索引，若是最后一个元素，下一个被取出的元素索引为0 takeIndex &#x3D; inc(takeIndex); &#x2F;&#x2F;元素数减1 --count; &#x2F;&#x2F;唤醒添加元素的线程 notFull.signal(); return x;&#125; 源码分析 jdk1.7.0_71 1234567891011121314&#x2F;&#x2F;队列元素final Object[] items;&#x2F;&#x2F;下次被take,poll,remove的索引int takeIndex;&#x2F;&#x2F;下次被put,offer,add的索引int putIndex;&#x2F;&#x2F;队列中元素的个数int count;&#x2F;&#x2F;保护所有访问的主锁final ReentrantLock lock;&#x2F;&#x2F;等待take锁,读线程条件private final Condition notEmpty;&#x2F;&#x2F;等待put锁,写线程条件private final Condition notFull; ArrayBlockingQueue(int capacity) 给定容量和默认的访问规则初始化1public ArrayBlockingQueue(int capacity)&#123;&#125; ArrayBlockingQueue(int capacity, boolean fair)知道你跟容量和访问规则123456789&#x2F;&#x2F;fair为true,在插入和删除时,线程的队列访问会阻塞,并且按照先进先出的顺序,false,访问顺序是不确定的public ArrayBlockingQueue(int capacity, boolean fair) &#123; if (capacity &lt;&#x3D; 0) throw new IllegalArgumentException(); this.items &#x3D; new Object[capacity]; lock &#x3D; new ReentrantLock(fair); notEmpty &#x3D; lock.newCondition(); notFull &#x3D; lock.newCondition(); &#125; ArrayBlockingQueue(int capacity, boolean fair,Collection&lt;? extends E&gt; c) 指定容量,访问规则,集合来初始化12public ArrayBlockingQueue(int capacity, boolean fair, Collection&lt;? extends E&gt; c) &#123;&#125; add(E e) 添加元素到队列末尾,成功返回true,队列满了抛异常IllegalStateException123public boolean add(E e) &#123; return super.add(e); &#125; offer(E e)添加元素到队列末尾,成功返回true,队列满了返回false1public boolean offer(E e) &#123;&#125; put(E e) 添加元素到队列末尾,队列满了,等待.1public void put(E e) throws InterruptedException &#123;&#125; offer(E e, long timeout, TimeUnit unit)添加元素到队列末尾,如果队列满了,等待指定的时间1public boolean offer(E e, long timeout, TimeUnit unit)&#123;&#125; poll() 移除队列头1public E poll() &#123;&#125; take() 移除队列头,队列为空的话就等待1public E take() throws InterruptedException &#123;&#125; poll(long timeout, TimeUnit unit)移除队列头,队列为空,等待指定的时间1public E poll(long timeout, TimeUnit unit) throws InterruptedException &#123;&#125; peek()返回队列头,不删除1public E peek() &#123;&#125; size()1public int size()&#123;&#125; remainingCapacity() 返回无阻塞情况下队列能接受容量的大小1public int remainingCapacity() &#123;&#125; remove(Object o)从队列中删除元素1public boolean remove(Object o) &#123;&#125; contains(Object o) 是否包含元素1public boolean contains(Object o) &#123;&#125; toArray()1public Object[] toArray()&#123;&#125; toArray(T[] a)1public &lt;T&gt; T[] toArray(T[] a) &#123;&#125; toString()1public String toString()&#123;&#125; clear()1public void clear()&#123;&#125; drainTo(Collection&lt;? super E&gt; c)移除队列中可用元素,添加到集合中1public int drainTo(Collection&lt;? super E&gt; c) &#123;&#125; drainTo(Collection&lt;? super E&gt; c, int maxElements)移除队列中给定数量的可用元素,添加到集合中1public int drainTo(Collection&lt;? super E&gt; c, int maxElements) &#123;&#125; iterator() 返回一个迭代器123public Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; 参考http://www.jianshu.com/p/9a652250e0d1]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CopyOnWriteArraySet简介]]></title>
      <url>%2F2016%2F05%2F27%2FCopyOnWriteArraySet%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[基于CopyOnWriteArrayList实现，线程安全无需集合。 add调用的是CopyOnWriteArraylist的addIfAbsent方法。 CopyOnWriteArraySet每次add要进行遍历数组,性能略低于CopyOnWriteArrayList。 适用于set大小一般很小，读操作远远多于写操作的场景。 定义CopyOnWriteArraySet集成AbstractSet，实现Serializable接口。是基于CopyOnWriteArrayList实现。 add方法通过CopyOnWriteArrayList的addIfAbsent实现。基本方法都在CopyOnWriteArrayList中说明过，不做过多讲解。 源码分析 jdk1.7.0_71 1&#x2F;&#x2F;基于CopyOnWriteArrayList 参考]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[TreeSet简介]]></title>
      <url>%2F2016%2F05%2F27%2FTreeSet%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[TreeSet简介 TreeSet支持排序 基于TreeMap实现 非线程安全的 不支持get(int)来获取指定位置的元素 源码分析 jdk1.7.0_71 1&#x2F;&#x2F;基于TreeMap 参考]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HashSet简介]]></title>
      <url>%2F2016%2F05%2F27%2FHashSet%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[HashSet简介 HashSet是Set接口的实现,不允许元素重复 元素不重复是基于HashMap实现 非线程安全的 不支持通过get(int)获取指定位置的元素,只能通过Iterator方法来获取 源码分析 jdk1.7.0_71 1&#x2F;&#x2F; 空构造 实际是new 一个HashMap123public HashSet() &#123; map &#x3D; new HashMap&lt;&gt;(); &#125; 参考]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[TreeMap简介]]></title>
      <url>%2F2016%2F05%2F27%2FTreeMap%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[TreeMap是支持排序的map，基于红黑树，无容量限制，TreeMap非线程安全。 TreeMap继承AbstractMap，实现NavigableMap、Cloneable、Serializable三个接口。其中AbstractMap表明TreeMap为一个Map即支持key-value的集合， NavigableMap则意味着它支持一系列的导航方法，具备针对给定搜索目标返回最接近匹配项的导航方法 。 TreeMap put()方法源码分析 jdk1.7.0_71 12345678&#x2F;&#x2F;用于排序的comparatorprivate final Comparator&lt;? super K&gt; comparator;&#x2F;&#x2F;根节点private transient Entry&lt;K,V&gt; root &#x3D; null;&#x2F;&#x2F;TreeMap的元素数量private transient int size &#x3D; 0;&#x2F;&#x2F;结构修改次数private transient int modCount &#x3D; 0; 空构造123public TreeMap() &#123; comparator &#x3D; null; &#125; 使用给定的comparator初始化空的TreeMap123public TreeMap(Comparator&lt;? super K&gt; comparator) &#123; this.comparator &#x3D; comparator; &#125; 使用给定的map初始化TreeMap1234public TreeMap(Map&lt;? extends K, ? extends V&gt; m) &#123; comparator &#x3D; null; putAll(m); &#125; 使用SortedMap初始化1public TreeMap(SortedMap&lt;K, ? extends V&gt; m) &#123;&#125; 参考]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ConcurrentHashMap简介]]></title>
      <url>%2F2016%2F05%2F26%2FConcurrentHashMap%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[ConcurrentHashMap为了高并发而设计，相比于HashTable和HashMap有更多优势。HashTable是同步的，在多线程环境下，能保证程序执行的正确性，每次同步执行的时候都要锁住整个结构。HashMap不是同步的，在单线程情况下效率高。 ConcurrentHashMap锁方式是稍微细粒度的，内部采用分离锁的设计。它默认将Hash表分为16个分段，get，put，remove等常用操作只锁当前需要用到的分段。对于每个Segment，采用final和volatile关键字。 concurrenthashmap采用了二次hash的方式，第一次hash将key映射到对应的segment，而第二次hash则是映射到segment的不同桶中。 原来只能一个线程进入，现在却能同时16个写线程进入，写线程需要锁定，读线程几乎不受限制，并发性是显而易见的。只有size等操作才需要锁定整个表。 定义ConcurrentHashMap继承AbstractMap，实现了ConcurrentMap,Serializable接口。ConcurrentMap继承了Map，添加了一些原子性方法，如putIfAbsent，remove，replace等。 数据结构ConcurrentHashMap是由Segment数组结构，HashEntry数组结构和链表组成。Segment是可重入锁ReentrantLock，扮演锁角色。每个Segment的结构和HashMap类似，数组加链表存储结构。 HashEntry的key，hash采用final，可以避免并发修改问题，HashEntry链的尾部是不能修改的，而next和value采用volatile，可以避免使用同步造成的并发性能灾难。 ConcurrentHashMap为了高并发而设计，相比于HashTable和HashMap有更多优势。HashTable是同步的，在多线程环境下，能保证程序执行的正确性，每次同步执行的时候都要锁住整个结构。HashMap不是同步的，在单线程情况下效率高。 ConcurrentHashMap锁方式是稍微细粒度的，内部采用分离锁的设计。它默认将Hash表分为16个分段，get，put，remove等常用操作只锁当前需要用到的分段。对于每个Segment，采用final和volatile关键字。 concurrenthashmap采用了二次hash的方式，第一次hash将key映射到对应的segment，而第二次hash则是映射到segment的不同桶中。 原来只能一个线程进入，现在却能同时16个写线程进入，写线程需要锁定，读线程几乎不受限制，并发性是显而易见的。只有size等操作才需要锁定整个表。 定义ConcurrentHashMap继承AbstractMap，实现了ConcurrentMap,Serializable接口。ConcurrentMap继承了Map，添加了一些原子性方法，如putIfAbsent，remove，replace等。 数据结构ConcurrentHashMap是由Segment数组结构，HashEntry数组结构和链表组成。Segment是可重入锁ReentrantLock，扮演锁角色。每个Segment的结构和HashMap类似，数组加链表存储结构。 HashEntry的key，hash采用final，可以避免并发修改问题，HashEntry链的尾部是不能修改的，而next和value采用volatile，可以避免使用同步造成的并发性能灾难。 Segment&lt;K,V&gt;Segment是ConcurrentHashMap的内部类，继承ReentrantLock，实现了Serializable接口。操作基本上都在Segment上，Segment中的table是一个HashEntry数组，数据就存放到这个数组中。看到这里对比下HashMap的存储结构，就大概能明白。具体方法在接下来的ConcurrentHashMap的具体方法中讲解。 初始化ConcurrentHashMap初始化是通过initialCapacity，loadFactor，concurrencyLevel等参数来初始化Segment数组，段偏移量segmentShift，段掩码segmentMask和每个segment里的HashEntry数组。 123456789101112131415161718192021222324252627282930313233public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; &#x2F;&#x2F;校验参数 if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;&#x3D; 0) throw new IllegalArgumentException(); &#x2F;&#x2F;并发级别数大于最大Segment数量 if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel &#x3D; MAX_SEGMENTS; &#x2F;&#x2F; Find power-of-two sizes best matching arguments int sshift &#x3D; 0; int ssize &#x3D; 1; while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;&#x3D; 1; &#125; this.segmentShift &#x3D; 32 - sshift; this.segmentMask &#x3D; ssize - 1; if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity &#x3D; MAXIMUM_CAPACITY; int c &#x3D; initialCapacity &#x2F; ssize; if (c * ssize &lt; initialCapacity) ++c; int cap &#x3D; MIN_SEGMENT_TABLE_CAPACITY; while (cap &lt; c) cap &lt;&lt;&#x3D; 1; &#x2F;&#x2F; create segments and segments[0] Segment&lt;K,V&gt; s0 &#x3D; new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V&gt;[])new HashEntry[cap]); Segment&lt;K,V&gt;[] ss &#x3D; (Segment&lt;K,V&gt;[])new Segment[ssize]; UNSAFE.putOrderedObject(ss, SBASE, s0); &#x2F;&#x2F; ordered write of segments[0] this.segments &#x3D; ss;&#125; segments数组的长度ssize通过concurrencyLevel计算得出。为了能通过按位与的哈希算法来定位segments数组的索引，必须保证segments数组的长度是2的N次方（power-of-two size），所以必须计算出一个是大于或等于concurrencyLevel的最小的2的N次方值来作为segments数组的长度。假如concurrencyLevel等于14，15或16，ssize都会等于16，即容器里锁的个数也是16。注意concurrencyLevel的最大大小是65535，意味着segments数组的长度最大为65536，对应的二进制是16位。 初始化segmentShift和segmentMask。 这两个全局变量在定位segment时的哈希算法里需要使用，sshift等于ssize从1向左移位的次数，在默认情况下concurrencyLevel等于16，1需要向左移位移动4次，所以sshift等于4。segmentShift用于定位参与hash运算的位数，segmentShift等于32减sshift，所以等于28，这里之所以用32是因为ConcurrentHashMap里的hash()方法输出的最大数是32位的，后面的测试中我们可以看到这点。segmentMask是哈希运算的掩码，等于ssize减1，即15，掩码的二进制各个位的值都是1。因为ssize的最大长度是65536，所以segmentShift最大值是16，segmentMask最大值是65535，对应的二进制是16位，每个位都是1。 初始化每个Segment。输入参数initialCapacity是ConcurrentHashMap的初始化容量，loadfactor是每个segment的负载因子，在构造方法里需要通过这两个参数来初始化数组中的每个segment。 变量cap就是segment里HashEntry数组的长度，它等于initialCapacity除以ssize的倍数c，如果c大于1，就会取大于等于c的2的N次方值，所以cap不是1，就是2的N次方。segment的容量threshold＝(int)cap*loadFactor，默认情况下initialCapacity等于16，loadfactor等于0.75，通过运算cap等于1，threshold等于零。 put(key,value)方法123456789101112131415public V put(K key, V value) &#123; Segment&lt;K,V&gt; s; if (value &#x3D;&#x3D; null) throw new NullPointerException(); &#x2F;&#x2F;计算key的哈希值 int hash &#x3D; hash(key); &#x2F;&#x2F;定位segment需要用到这个计算的数值 int j &#x3D; (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; if ((s &#x3D; (Segment&lt;K,V&gt;)UNSAFE.getObject &#x2F;&#x2F; nonvolatile; recheck (segments, (j &lt;&lt; SSHIFT) + SBASE)) &#x3D;&#x3D; null) &#x2F;&#x2F; in ensureSegment &#x2F;&#x2F;获取指定segment，若不存在新建一个，并记录在Segment数组中 s &#x3D; ensureSegment(j); &#x2F;&#x2F;put方法，在Segment内部类中实现 return s.put(key, hash, value, false);&#125; Segment内部类中的put方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; &#x2F;&#x2F;tryLock(): 如果锁可用, 则获取锁, 并立即返回true, 否则返回false。 &#x2F;&#x2F;该方法和lock()的区别在于, tryLock()只是&quot;试图&quot;获取锁, 如果锁不可用, 不会导致当前线程被禁用, 当前线程仍然继续往下执行代码。而lock()方法则是一定要获取到锁, 如果锁不可用, 就一直等待, 在未获得锁之前,当前线程并不继续向下执行。 &#x2F;&#x2F;scanAndLockForPut扫描指定key的节点，并获取锁，如果不存在就新建一个HashEntry HashEntry&lt;K,V&gt; node &#x3D; tryLock() ? null : scanAndLockForPut(key, hash, value); V oldValue; try &#123; HashEntry&lt;K,V&gt;[] tab &#x3D; table; int index &#x3D; (tab.length - 1) &amp; hash; HashEntry&lt;K,V&gt; first &#x3D; entryAt(tab, index); for (HashEntry&lt;K,V&gt; e &#x3D; first;;) &#123; if (e !&#x3D; null) &#123; K k; if ((k &#x3D; e.key) &#x3D;&#x3D; key || (e.hash &#x3D;&#x3D; hash &amp;&amp; key.equals(k))) &#123; oldValue &#x3D; e.value; if (!onlyIfAbsent) &#123; e.value &#x3D; value; ++modCount; &#125; break; &#125; e &#x3D; e.next; &#125; else &#123; if (node !&#x3D; null) node.setNext(first); else node &#x3D; new HashEntry&lt;K,V&gt;(hash, key, value, first); int c &#x3D; count + 1; if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); else setEntryAt(tab, index, node); ++modCount; count &#x3D; c; oldValue &#x3D; null; break; &#125; &#125; &#125; finally &#123; unlock(); &#125; return oldValue;&#125; put操作开始，首先定位到Segment，为了线程安全，锁定当前Segment；然后在Segment里进行插入操作，首先判断是否需要扩容，然后在定位添加元素的位置放在HashEntry数组里。 扩容：在插入元素前会先判断Segment里的HashEntry数组是否超过容量（threshold），如果超过阀值，数组进行扩容。值得一提的是，Segment的扩容判断比HashMap更恰当，因为HashMap是在插入元素后判断元素是否已经到达容量的，如果到达了就进行扩容，但是很有可能扩容之后没有新元素插入，这时HashMap就进行了一次无效的扩容。 扩容的时候首先会创建一个两倍于原容量的数组，然后将原数组里的元素进行再hash后插入到新的数组里。为了高效ConcurrentHashMap不会对整个容器进行扩容，而只对某个segment进行扩容。 get(key)方法1234567891011121314151617public V get(Object key) &#123; Segment&lt;K,V&gt; s; &#x2F;&#x2F; manually integrate access methods to reduce overhead HashEntry&lt;K,V&gt;[] tab; int h &#x3D; hash(key); long u &#x3D; (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE; if ((s &#x3D; (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) !&#x3D; null &amp;&amp; (tab &#x3D; s.table) !&#x3D; null) &#123; for (HashEntry&lt;K,V&gt; e &#x3D; (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE); e !&#x3D; null; e &#x3D; e.next) &#123; K k; if ((k &#x3D; e.key) &#x3D;&#x3D; key || (e.hash &#x3D;&#x3D; h &amp;&amp; key.equals(k))) return e.value; &#125; &#125; return null;&#125; size()方法我们要统计整个ConcurrentHashMap里元素的大小，就必须统计所有Segment里元素的大小后求和。Segment里的全局变量count是一个volatile变量，那么在多线程场景下，我们是不是直接把所有Segment的count相加就可以得到整个ConcurrentHashMap大小了呢？不是的，虽然相加时可以获取每个Segment的count的最新值，但是拿到之后可能累加前使用的count发生了变化，那么统计结果就不准了。所以最安全的做法，是在统计size的时候把所有Segment的put，remove和clean方法全部锁住，但是这种做法显然非常低效。 因为在累加count操作过程中，之前累加过的count发生变化的几率非常小，所以ConcurrentHashMap的做法是先尝试2次通过不锁住Segment的方式来统计各个Segment大小，如果统计的过程中，容器的count发生了变化，则再采用加锁的方式来统计所有Segment的大小。 迭代ConcurrentHashMap使用了不同于传统集合的快速失败迭代器的另一种迭代方式，我们称为弱一致迭代器。在这种迭代方式中，当iterator被创建后集合再发生改变就不再是抛出 ConcurrentModificationException，取而代之的是在改变时new新的数据从而不影响原有的数 据，iterator完成后再将头指针替换为新的数据，这样iterator线程可以使用原来老的数据，而写线程也可以并发的完成改变，更重要的，这保证了多个线程并发执行的连续性和扩展性，是性能提升的关键。 源码分析 jdk1.7.0_71 12345678910111213141516171819202122232425262728&#x2F;&#x2F;默认容量static final int DEFAULT_INITIAL_CAPACITY &#x3D; 16;&#x2F;&#x2F;默认负载因子static final float DEFAULT_LOAD_FACTOR &#x3D; 0.75f;&#x2F;&#x2F;并发级别static final int DEFAULT_CONCURRENCY_LEVEL &#x3D; 16;&#x2F;&#x2F;最大容量static final int MAXIMUM_CAPACITY &#x3D; 1 &lt;&lt; 30;&#x2F;&#x2F;每个segment最小容量static final int MIN_SEGMENT_TABLE_CAPACITY &#x3D; 2;&#x2F;&#x2F;最大segment数量static final int MAX_SEGMENTS &#x3D; 1 &lt;&lt; 16;&#x2F;&#x2F;lock之前尝试的次数static final int RETRIES_BEFORE_LOCK &#x3D; 2;&#x2F;&#x2F;计算哈希值时候用到private transient final int hashSeed &#x3D; randomHashSeed(this);&#x2F;&#x2F;segment的掩码值,用于计算key所在segments索引值final int segmentMask;&#x2F;&#x2F;segment的偏移值,用于计算key所在segments索引值final int segmentShift;&#x2F;&#x2F;segment数组,其内部是由HashEntry数组实现,正因为有了多个segment，才提高了并发度final Segment&lt;K,V&gt;[] segments;&#x2F;&#x2F;transient Set&lt;K&gt; keySet;&#x2F;&#x2F;transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;&#x2F;&#x2F;transient Collection&lt;V&gt; values; Holder 静态内部类,存放一些在虚拟机启动后才能初始化的值容量阈值，初始化hashSeed的时候会用到该值1static final int ALTERNATIVE_HASHING; static静态块1获取系统变量jdk.map.althashing.threshold ConcurrentHashMap(int initialCapacity,float loadFactor, int concurrencyLevel) 构造 传入的参数有initialCapacity，loadFactor，concurrencyLevel这三个。 initialCapacity表示新创建的这个ConcurrentHashMap的初始容量，也就是上面的结构图中的Entry数量。默认值为static final int DEFAULT_INITIAL_CAPACITY = 16; loadFactor表示负载因子，就是当ConcurrentHashMap中的元素个数大于loadFactor * 最大容量时就需要rehash，扩容。默认值为static final float DEFAULT_LOAD_FACTOR = 0.75f; concurrencyLevel表示并发级别，这个值用来确定Segment的个数，Segment的个数是大于等于concurrencyLevel的第一个2的n次方的数。比如，如果concurrencyLevel为12，13，14，15，16这些数，则Segment的数目为16(2的4次方)。默认值为static final int DEFAULT_CONCURRENCY_LEVEL = 16;。理想情况下ConcurrentHashMap的真正的并发访问量能够达到concurrencyLevel，因为有concurrencyLevel个Segment，假如有concurrencyLevel个线程需要访问Map，并且需要访问的数据都恰好分别落在不同的Segment中，则这些线程能够无竞争地自由访问（因为他们不需要竞争同一把锁），达到同时访问的效果。这也是为什么这个参数起名为“并发级别”的原因。 初始化的一些动作： 验证参数的合法性，如果不合法，直接抛出异常。 concurrencyLevel也就是Segment的个数不能超过规定的最大Segment的个数，默认值为static final int MAX_SEGMENTS = 1 &lt;&lt; 16;，如果超过这个值，设置为这个值。 然后使用循环找到大于等于concurrencyLevel的第一个2的n次方的数ssize，这个数就是Segment数组的大小，并记录一共向左按位移动的次数sshift，并令segmentShift = 32 - sshift，并且segmentMask的值等于ssize - 1，segmentMask的各个二进制位都为1，目的是之后可以通过key的hash值与这个值做&amp;运算确定Segment的索引。 检查给的容量值是否大于允许的最大容量值，如果大于该值，设置为该值。最大容量值为static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;。 然后计算每个Segment平均应该放置多少个元素，这个值c是向上取整的值。比如初始容量为15，Segment个数为4，则每个Segment平均需要放置4个元素。 最后创建一个Segment实例，将其当做Segment数组的第一个元素。 12345678910111213141516171819202122232425262728if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;&#x3D; 0) throw new IllegalArgumentException(); if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel &#x3D; MAX_SEGMENTS; &#x2F;&#x2F; Find power-of-two sizes best matching arguments int sshift &#x3D; 0; int ssize &#x3D; 1; while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;&#x3D; 1; &#125; this.segmentShift &#x3D; 32 - sshift; this.segmentMask &#x3D; ssize - 1; if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity &#x3D; MAXIMUM_CAPACITY; int c &#x3D; initialCapacity &#x2F; ssize; if (c * ssize &lt; initialCapacity) ++c; int cap &#x3D; MIN_SEGMENT_TABLE_CAPACITY; while (cap &lt; c) cap &lt;&lt;&#x3D; 1; &#x2F;&#x2F; create segments and segments[0] Segment&lt;K,V&gt; s0 &#x3D; new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V&gt;[])new HashEntry[cap]); Segment&lt;K,V&gt;[] ss &#x3D; (Segment&lt;K,V&gt;[])new Segment[ssize]; UNSAFE.putOrderedObject(ss, SBASE, s0); &#x2F;&#x2F; ordered write of segments[0] this.segments &#x3D; ss; ConcurrentHashMap(int initialCapacity, float loadFactor) 指定初始容量和负载因子123public ConcurrentHashMap(int initialCapacity, float loadFactor) &#123; this(initialCapacity, loadFactor, DEFAULT_CONCURRENCY_LEVEL); &#125; ConcurrentHashMap(int initialCapacity) 指定初始容量123public ConcurrentHashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL); &#125; ConcurrentHashMap(int initialCapacity) 空构造123public ConcurrentHashMap() &#123; this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL); &#125; ConcurrentHashMap(Map&lt;? extends K, ? extends V&gt; m) 使用map初始化1public ConcurrentHashMap(Map&lt;? extends K, ? extends V&gt; m) &#123;&#125; isEmpty() 是否为空12&#x2F;&#x2F;为了避免错误统计,会把每个segment的modCount都加起来进行判断public boolean isEmpty() &#123;&#125; size() 返回大小1public int size() &#123;&#125; get(Object key) 根据key获取value1public V get(Object key) &#123;&#125; containsKey(Object key) 是否包含key1public boolean containsKey(Object key) &#123;&#125; containsValue(Object value) 是否包含value12&#x2F;&#x2F;思路和size()相同public boolean containsValue(Object value)&#123;&#125; put(K key, V value)1public V put(K key, V value) &#123;&#125; putIfAbsent(K key, V value) 如果不存在对应的key,就放进去1public V putIfAbsent(K key, V value) &#123;&#125; putAll(Map&lt;? extends K, ? extends V&gt; m) 把指定map放进去1public void putAll(Map&lt;? extends K, ? extends V&gt; m)&#123;&#125; remove(Object key) 删除1public V remove(Object key)&#123;&#125; remove(Object key, Object value)删除1public boolean remove(Object key, Object value)&#123;&#125; replace(K key, V oldValue, V newValue) 替换1public boolean replace(K key, V oldValue, V newValue) &#123;&#125; replace(K key, V value) 替换1public V replace(K key, V value)&#123;&#125; clear() 清空1public void clear()&#123;&#125; Segment&lt;K,V&gt; (–重要–)123456789101112&#x2F;&#x2F;最大的尝试加锁的次数static final int MAX_SCAN_RETRIES &#x3D;Runtime.getRuntime().availableProcessors() &gt; 1 ? 64 : 1;&#x2F;&#x2F;每个segment存放数据的tabletransient volatile HashEntry&lt;K,V&gt;[] table;&#x2F;&#x2F;segment元素的数量transient int count;&#x2F;&#x2F;segment的修改数transient int modCount;&#x2F;&#x2F;扩容的临界值transient int threshold;&#x2F;&#x2F;负载因子final float loadFactor; put(K key, int hash, V value, boolean onlyIfAbsent)12345final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; &#x2F;&#x2F;加锁 &#x2F;&#x2F;修改 &#x2F;&#x2F;解锁&#125; 参考http://my.oschina.net/indestiny/blog/209458 http://qifuguang.me/2015/09/10/[Java%E5%B9%B6%E5%8F%91%E5%8C%85%E5%AD%A6%E4%B9%A0%E5%85%AB]%E6%B7%B1%E5%BA%A6%E5%89%96%E6%9E%90ConcurrentHashMap/ http://www.importnew.com/20952.html http://www.importnew.com/16147.html Segment&lt;K,V&gt;Segment是ConcurrentHashMap的内部类，继承ReentrantLock，实现了Serializable接口。操作基本上都在Segment上，Segment中的table是一个HashEntry数组，数据就存放到这个数组中。看到这里对比下HashMap的存储结构，就大概能明白。具体方法在接下来的ConcurrentHashMap的具体方法中讲解。 初始化ConcurrentHashMap初始化是通过initialCapacity，loadFactor，concurrencyLevel等参数来初始化Segment数组，段偏移量segmentShift，段掩码segmentMask和每个segment里的HashEntry数组。 123456789101112131415161718192021222324252627282930313233public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; &#x2F;&#x2F;校验参数 if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;&#x3D; 0) throw new IllegalArgumentException(); &#x2F;&#x2F;并发级别数大于最大Segment数量 if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel &#x3D; MAX_SEGMENTS; &#x2F;&#x2F; Find power-of-two sizes best matching arguments int sshift &#x3D; 0; int ssize &#x3D; 1; while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;&#x3D; 1; &#125; this.segmentShift &#x3D; 32 - sshift; this.segmentMask &#x3D; ssize - 1; if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity &#x3D; MAXIMUM_CAPACITY; int c &#x3D; initialCapacity &#x2F; ssize; if (c * ssize &lt; initialCapacity) ++c; int cap &#x3D; MIN_SEGMENT_TABLE_CAPACITY; while (cap &lt; c) cap &lt;&lt;&#x3D; 1; &#x2F;&#x2F; create segments and segments[0] Segment&lt;K,V&gt; s0 &#x3D; new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V&gt;[])new HashEntry[cap]); Segment&lt;K,V&gt;[] ss &#x3D; (Segment&lt;K,V&gt;[])new Segment[ssize]; UNSAFE.putOrderedObject(ss, SBASE, s0); &#x2F;&#x2F; ordered write of segments[0] this.segments &#x3D; ss;&#125; segments数组的长度ssize通过concurrencyLevel计算得出。为了能通过按位与的哈希算法来定位segments数组的索引，必须保证segments数组的长度是2的N次方（power-of-two size），所以必须计算出一个是大于或等于concurrencyLevel的最小的2的N次方值来作为segments数组的长度。假如concurrencyLevel等于14，15或16，ssize都会等于16，即容器里锁的个数也是16。注意concurrencyLevel的最大大小是65535，意味着segments数组的长度最大为65536，对应的二进制是16位。 初始化segmentShift和segmentMask。 这两个全局变量在定位segment时的哈希算法里需要使用，sshift等于ssize从1向左移位的次数，在默认情况下concurrencyLevel等于16，1需要向左移位移动4次，所以sshift等于4。segmentShift用于定位参与hash运算的位数，segmentShift等于32减sshift，所以等于28，这里之所以用32是因为ConcurrentHashMap里的hash()方法输出的最大数是32位的，后面的测试中我们可以看到这点。segmentMask是哈希运算的掩码，等于ssize减1，即15，掩码的二进制各个位的值都是1。因为ssize的最大长度是65536，所以segmentShift最大值是16，segmentMask最大值是65535，对应的二进制是16位，每个位都是1。 初始化每个Segment。输入参数initialCapacity是ConcurrentHashMap的初始化容量，loadfactor是每个segment的负载因子，在构造方法里需要通过这两个参数来初始化数组中的每个segment。 变量cap就是segment里HashEntry数组的长度，它等于initialCapacity除以ssize的倍数c，如果c大于1，就会取大于等于c的2的N次方值，所以cap不是1，就是2的N次方。segment的容量threshold＝(int)cap*loadFactor，默认情况下initialCapacity等于16，loadfactor等于0.75，通过运算cap等于1，threshold等于零。 put(key,value)方法123456789101112131415public V put(K key, V value) &#123; Segment&lt;K,V&gt; s; if (value &#x3D;&#x3D; null) throw new NullPointerException(); &#x2F;&#x2F;计算key的哈希值 int hash &#x3D; hash(key); &#x2F;&#x2F;定位segment需要用到这个计算的数值 int j &#x3D; (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; if ((s &#x3D; (Segment&lt;K,V&gt;)UNSAFE.getObject &#x2F;&#x2F; nonvolatile; recheck (segments, (j &lt;&lt; SSHIFT) + SBASE)) &#x3D;&#x3D; null) &#x2F;&#x2F; in ensureSegment &#x2F;&#x2F;获取指定segment，若不存在新建一个，并记录在Segment数组中 s &#x3D; ensureSegment(j); &#x2F;&#x2F;put方法，在Segment内部类中实现 return s.put(key, hash, value, false);&#125; Segment内部类中的put方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; &#x2F;&#x2F;tryLock(): 如果锁可用, 则获取锁, 并立即返回true, 否则返回false。 &#x2F;&#x2F;该方法和lock()的区别在于, tryLock()只是&quot;试图&quot;获取锁, 如果锁不可用, 不会导致当前线程被禁用, 当前线程仍然继续往下执行代码。而lock()方法则是一定要获取到锁, 如果锁不可用, 就一直等待, 在未获得锁之前,当前线程并不继续向下执行。 &#x2F;&#x2F;scanAndLockForPut扫描指定key的节点，并获取锁，如果不存在就新建一个HashEntry HashEntry&lt;K,V&gt; node &#x3D; tryLock() ? null : scanAndLockForPut(key, hash, value); V oldValue; try &#123; HashEntry&lt;K,V&gt;[] tab &#x3D; table; int index &#x3D; (tab.length - 1) &amp; hash; HashEntry&lt;K,V&gt; first &#x3D; entryAt(tab, index); for (HashEntry&lt;K,V&gt; e &#x3D; first;;) &#123; if (e !&#x3D; null) &#123; K k; if ((k &#x3D; e.key) &#x3D;&#x3D; key || (e.hash &#x3D;&#x3D; hash &amp;&amp; key.equals(k))) &#123; oldValue &#x3D; e.value; if (!onlyIfAbsent) &#123; e.value &#x3D; value; ++modCount; &#125; break; &#125; e &#x3D; e.next; &#125; else &#123; if (node !&#x3D; null) node.setNext(first); else node &#x3D; new HashEntry&lt;K,V&gt;(hash, key, value, first); int c &#x3D; count + 1; if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); else setEntryAt(tab, index, node); ++modCount; count &#x3D; c; oldValue &#x3D; null; break; &#125; &#125; &#125; finally &#123; unlock(); &#125; return oldValue;&#125; put操作开始，首先定位到Segment，为了线程安全，锁定当前Segment；然后在Segment里进行插入操作，首先判断是否需要扩容，然后在定位添加元素的位置放在HashEntry数组里。 扩容：在插入元素前会先判断Segment里的HashEntry数组是否超过容量（threshold），如果超过阀值，数组进行扩容。值得一提的是，Segment的扩容判断比HashMap更恰当，因为HashMap是在插入元素后判断元素是否已经到达容量的，如果到达了就进行扩容，但是很有可能扩容之后没有新元素插入，这时HashMap就进行了一次无效的扩容。 扩容的时候首先会创建一个两倍于原容量的数组，然后将原数组里的元素进行再hash后插入到新的数组里。为了高效ConcurrentHashMap不会对整个容器进行扩容，而只对某个segment进行扩容。 get(key)方法1234567891011121314151617public V get(Object key) &#123; Segment&lt;K,V&gt; s; &#x2F;&#x2F; manually integrate access methods to reduce overhead HashEntry&lt;K,V&gt;[] tab; int h &#x3D; hash(key); long u &#x3D; (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE; if ((s &#x3D; (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) !&#x3D; null &amp;&amp; (tab &#x3D; s.table) !&#x3D; null) &#123; for (HashEntry&lt;K,V&gt; e &#x3D; (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE); e !&#x3D; null; e &#x3D; e.next) &#123; K k; if ((k &#x3D; e.key) &#x3D;&#x3D; key || (e.hash &#x3D;&#x3D; h &amp;&amp; key.equals(k))) return e.value; &#125; &#125; return null;&#125; size()方法我们要统计整个ConcurrentHashMap里元素的大小，就必须统计所有Segment里元素的大小后求和。Segment里的全局变量count是一个volatile变量，那么在多线程场景下，我们是不是直接把所有Segment的count相加就可以得到整个ConcurrentHashMap大小了呢？不是的，虽然相加时可以获取每个Segment的count的最新值，但是拿到之后可能累加前使用的count发生了变化，那么统计结果就不准了。所以最安全的做法，是在统计size的时候把所有Segment的put，remove和clean方法全部锁住，但是这种做法显然非常低效。 因为在累加count操作过程中，之前累加过的count发生变化的几率非常小，所以ConcurrentHashMap的做法是先尝试2次通过不锁住Segment的方式来统计各个Segment大小，如果统计的过程中，容器的count发生了变化，则再采用加锁的方式来统计所有Segment的大小。 迭代ConcurrentHashMap使用了不同于传统集合的快速失败迭代器的另一种迭代方式，我们称为弱一致迭代器。在这种迭代方式中，当iterator被创建后集合再发生改变就不再是抛出 ConcurrentModificationException，取而代之的是在改变时new新的数据从而不影响原有的数 据，iterator完成后再将头指针替换为新的数据，这样iterator线程可以使用原来老的数据，而写线程也可以并发的完成改变，更重要的，这保证了多个线程并发执行的连续性和扩展性，是性能提升的关键。 源码分析 jdk1.7.0_71 12345678910111213141516171819202122232425262728&#x2F;&#x2F;默认容量static final int DEFAULT_INITIAL_CAPACITY &#x3D; 16;&#x2F;&#x2F;默认负载因子static final float DEFAULT_LOAD_FACTOR &#x3D; 0.75f;&#x2F;&#x2F;并发级别static final int DEFAULT_CONCURRENCY_LEVEL &#x3D; 16;&#x2F;&#x2F;最大容量static final int MAXIMUM_CAPACITY &#x3D; 1 &lt;&lt; 30;&#x2F;&#x2F;每个segment最小容量static final int MIN_SEGMENT_TABLE_CAPACITY &#x3D; 2;&#x2F;&#x2F;最大segment数量static final int MAX_SEGMENTS &#x3D; 1 &lt;&lt; 16;&#x2F;&#x2F;lock之前尝试的次数static final int RETRIES_BEFORE_LOCK &#x3D; 2;&#x2F;&#x2F;计算哈希值时候用到private transient final int hashSeed &#x3D; randomHashSeed(this);&#x2F;&#x2F;segment的掩码值,用于计算key所在segments索引值final int segmentMask;&#x2F;&#x2F;segment的偏移值,用于计算key所在segments索引值final int segmentShift;&#x2F;&#x2F;segment数组,其内部是由HashEntry数组实现,正因为有了多个segment，才提高了并发度final Segment&lt;K,V&gt;[] segments;&#x2F;&#x2F;transient Set&lt;K&gt; keySet;&#x2F;&#x2F;transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;&#x2F;&#x2F;transient Collection&lt;V&gt; values; Holder 静态内部类,存放一些在虚拟机启动后才能初始化的值容量阈值，初始化hashSeed的时候会用到该值1static final int ALTERNATIVE_HASHING; static静态块1获取系统变量jdk.map.althashing.threshold ConcurrentHashMap(int initialCapacity,float loadFactor, int concurrencyLevel) 构造 传入的参数有initialCapacity，loadFactor，concurrencyLevel这三个。 initialCapacity表示新创建的这个ConcurrentHashMap的初始容量，也就是上面的结构图中的Entry数量。默认值为static final int DEFAULT_INITIAL_CAPACITY = 16; loadFactor表示负载因子，就是当ConcurrentHashMap中的元素个数大于loadFactor * 最大容量时就需要rehash，扩容。默认值为static final float DEFAULT_LOAD_FACTOR = 0.75f; concurrencyLevel表示并发级别，这个值用来确定Segment的个数，Segment的个数是大于等于concurrencyLevel的第一个2的n次方的数。比如，如果concurrencyLevel为12，13，14，15，16这些数，则Segment的数目为16(2的4次方)。默认值为static final int DEFAULT_CONCURRENCY_LEVEL = 16;。理想情况下ConcurrentHashMap的真正的并发访问量能够达到concurrencyLevel，因为有concurrencyLevel个Segment，假如有concurrencyLevel个线程需要访问Map，并且需要访问的数据都恰好分别落在不同的Segment中，则这些线程能够无竞争地自由访问（因为他们不需要竞争同一把锁），达到同时访问的效果。这也是为什么这个参数起名为“并发级别”的原因。 初始化的一些动作： 验证参数的合法性，如果不合法，直接抛出异常。 concurrencyLevel也就是Segment的个数不能超过规定的最大Segment的个数，默认值为static final int MAX_SEGMENTS = 1 &lt;&lt; 16;，如果超过这个值，设置为这个值。 然后使用循环找到大于等于concurrencyLevel的第一个2的n次方的数ssize，这个数就是Segment数组的大小，并记录一共向左按位移动的次数sshift，并令segmentShift = 32 - sshift，并且segmentMask的值等于ssize - 1，segmentMask的各个二进制位都为1，目的是之后可以通过key的hash值与这个值做&amp;运算确定Segment的索引。 检查给的容量值是否大于允许的最大容量值，如果大于该值，设置为该值。最大容量值为static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;。 然后计算每个Segment平均应该放置多少个元素，这个值c是向上取整的值。比如初始容量为15，Segment个数为4，则每个Segment平均需要放置4个元素。 最后创建一个Segment实例，将其当做Segment数组的第一个元素。 12345678910111213141516171819202122232425262728if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;&#x3D; 0) throw new IllegalArgumentException(); if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel &#x3D; MAX_SEGMENTS; &#x2F;&#x2F; Find power-of-two sizes best matching arguments int sshift &#x3D; 0; int ssize &#x3D; 1; while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;&#x3D; 1; &#125; this.segmentShift &#x3D; 32 - sshift; this.segmentMask &#x3D; ssize - 1; if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity &#x3D; MAXIMUM_CAPACITY; int c &#x3D; initialCapacity &#x2F; ssize; if (c * ssize &lt; initialCapacity) ++c; int cap &#x3D; MIN_SEGMENT_TABLE_CAPACITY; while (cap &lt; c) cap &lt;&lt;&#x3D; 1; &#x2F;&#x2F; create segments and segments[0] Segment&lt;K,V&gt; s0 &#x3D; new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V&gt;[])new HashEntry[cap]); Segment&lt;K,V&gt;[] ss &#x3D; (Segment&lt;K,V&gt;[])new Segment[ssize]; UNSAFE.putOrderedObject(ss, SBASE, s0); &#x2F;&#x2F; ordered write of segments[0] this.segments &#x3D; ss; ConcurrentHashMap(int initialCapacity, float loadFactor) 指定初始容量和负载因子123public ConcurrentHashMap(int initialCapacity, float loadFactor) &#123; this(initialCapacity, loadFactor, DEFAULT_CONCURRENCY_LEVEL); &#125; ConcurrentHashMap(int initialCapacity) 指定初始容量123public ConcurrentHashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL); &#125; ConcurrentHashMap(int initialCapacity) 空构造123public ConcurrentHashMap() &#123; this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL); &#125; ConcurrentHashMap(Map&lt;? extends K, ? extends V&gt; m) 使用map初始化1public ConcurrentHashMap(Map&lt;? extends K, ? extends V&gt; m) &#123;&#125; isEmpty() 是否为空12&#x2F;&#x2F;为了避免错误统计,会把每个segment的modCount都加起来进行判断public boolean isEmpty() &#123;&#125; size() 返回大小1public int size() &#123;&#125; get(Object key) 根据key获取value1public V get(Object key) &#123;&#125; containsKey(Object key) 是否包含key1public boolean containsKey(Object key) &#123;&#125; containsValue(Object value) 是否包含value12&#x2F;&#x2F;思路和size()相同public boolean containsValue(Object value)&#123;&#125; put(K key, V value)1public V put(K key, V value) &#123;&#125; putIfAbsent(K key, V value) 如果不存在对应的key,就放进去1public V putIfAbsent(K key, V value) &#123;&#125; putAll(Map&lt;? extends K, ? extends V&gt; m) 把指定map放进去1public void putAll(Map&lt;? extends K, ? extends V&gt; m)&#123;&#125; remove(Object key) 删除1public V remove(Object key)&#123;&#125; remove(Object key, Object value)删除1public boolean remove(Object key, Object value)&#123;&#125; replace(K key, V oldValue, V newValue) 替换1public boolean replace(K key, V oldValue, V newValue) &#123;&#125; replace(K key, V value) 替换1public V replace(K key, V value)&#123;&#125; clear() 清空1public void clear()&#123;&#125; Segment&lt;K,V&gt; (–重要–)123456789101112&#x2F;&#x2F;最大的尝试加锁的次数static final int MAX_SCAN_RETRIES &#x3D;Runtime.getRuntime().availableProcessors() &gt; 1 ? 64 : 1;&#x2F;&#x2F;每个segment存放数据的tabletransient volatile HashEntry&lt;K,V&gt;[] table;&#x2F;&#x2F;segment元素的数量transient int count;&#x2F;&#x2F;segment的修改数transient int modCount;&#x2F;&#x2F;扩容的临界值transient int threshold;&#x2F;&#x2F;负载因子final float loadFactor; put(K key, int hash, V value, boolean onlyIfAbsent)12345final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; &#x2F;&#x2F;加锁 &#x2F;&#x2F;修改 &#x2F;&#x2F;解锁&#125; 参考http://my.oschina.net/indestiny/blog/209458 http://qifuguang.me/2015/09/10/[Java%E5%B9%B6%E5%8F%91%E5%8C%85%E5%AD%A6%E4%B9%A0%E5%85%AB]%E6%B7%B1%E5%BA%A6%E5%89%96%E6%9E%90ConcurrentHashMap/ http://www.importnew.com/20952.html http://www.importnew.com/16147.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HashTable简介]]></title>
      <url>%2F2016%2F05%2F26%2FHashTable%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[HashTable继承Dictionary类，实现Map接口。其中Dictionary类是任何可将键映射到相应值的类（如 Hashtable）的抽象父类。每个键和每个值都是一个对象。在任何一个 Dictionary 对象中，每个键至多与一个值相关联。Map是”key-value键值对”接口。 HashTable与HashMap的区别 HashTable基于Dictionary类，而HashMap是基于AbstractMap。Dictionary是什么？它是任何可将键映射到相应值的类的抽象父类，而AbstractMap是基于Map接口的骨干实现，它以最大限度地减少实现此接口所需的工作。 HashMap可以允许存在一个为null的key和任意个为null的value，但是HashTable中的key和value都不允许为null。当HashMap遇到为null的key时，它会调用putForNullKey方法来进行处理。对于value没有进行任何处理，只要是对象都可以。而当HashTable遇到null时，他会直接抛出NullPointerException异常信息。 Hashtable的方法是同步的，而HashMap的方法不是。所以有人一般都建议如果是涉及到多线程同步时采用HashTable，没有涉及就采用HashMap。 源码分析 jdk1.7.0_71 123456789101112&#x2F;&#x2F;用于存储数据的表private transient Entry&lt;K,V&gt;[] table;&#x2F;&#x2F;表中键值对的数private transient int count;&#x2F;&#x2F;下次扩充的临界值 capacity * loadFactorprivate int threshold;&#x2F;&#x2F;哈希表的负载因子private float loadFactor;&#x2F;&#x2F;在使用迭代器遍历的时候，用来检查列表中的元素是否发生结构性变化（列表元素数量发生改变的一个计数）了，主要在多线程环境下需要使用，防止一个线程正在迭代遍历，另一个线程修改了这个列表的结构。private transient int modCount;&#x2F;&#x2F;容量阈值，默认大小为Integer.MAX_VALUEstatic final int ALTERNATIVE_HASHING_THRESHOLD_DEFAULT &#x3D; Integer.MAX_VALUE; Holder 静态内部类,存放一些在虚拟机启动后才能初始化的值容量阈值，初始化hashSeed的时候会用到该值1static final int ALTERNATIVE_HASHING_THRESHOLD; static静态块12获取系统变量jdk.map.althashing.thresholdjdk.map.althashing.threshold系统变量默认为-1，如果为-1，则将阈值设为Integer.MAX_VALUE Hashtable(int initialCapacity, float loadFactor) 指定容量和负载因子 构造1234public Hashtable(int initialCapacity, float loadFactor) &#123; ... initHashSeedAsNeeded();&#125; Hashtable(int initialCapacity) 指定初始容量的构造,负载因子为0.75f1public Hashtable(int initialCapacity) &#123;&#125; Hashtable() 默认初始容量11和默认负载因子0.75f的构造1public Hashtable()&#123;&#125; Hashtable(Map&lt;? extends K, ? extends V&gt; m) 用map初始化12345public Hashtable(Map&lt;? extends K, ? extends V&gt; m) &#123; this(Math.max(2*t.size(), 11), 0.75f); &#x2F;&#x2F;把元素放入到Hashtable中 putAll(t);&#125; size() key-value映射个数123public synchronized int size() &#123; return size; &#125; isEmpty()是否为空123public synchronized boolean isEmpty() &#123; return size &#x3D;&#x3D; 0; &#125; keys() 返回keys枚举123public synchronized Enumeration&lt;K&gt; keys() &#123; return this.&lt;K&gt;getEnumeration(KEYS); &#125; elements() 返回values枚举123public synchronized elements&lt;V&gt; keys() &#123; return this.&lt;V&gt;getEnumeration(VALUES); &#125; contains(Object value)是否包含指定value1public synchronized boolean contains(Object value) &#123;&#125; containsValue(Object value) 是否包含value1public boolean containsValue(Object value) &#123;&#125; containsKey(Object key) 是否包含key123public boolean containsKey(Object key) &#123; return getEntry(key) !&#x3D; null; &#125; get(Object key) 根据key获取value1234public synchronized V get(Object key) &#123;&#125;&#96;&#96;&#96; ## put(K key, V value) 将指定的key value放入Hashtable中,若已存在key,就替换旧值 public synchronized V put(K key, V value) {} 12## remove(Object key) 根据key删除 public synchronized V remove(Object key) { removeEntryForKey(key);} 12## putAll(Map&lt;? extends K, ? extends V&gt; m) 把指定的元素 全部放入HashMap中,已经存在的key,会把旧value覆盖掉 public synchronized void putAll(Map&lt;? extends K, ? extends V&gt; m) {} 12## clear() 清空 public synchronized void clear(){} 12## clone() 浅拷贝 public Object clone() {} 12## toString() public synchronized String toString() {} ``` 参考]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HashMap简介]]></title>
      <url>%2F2016%2F05%2F25%2FHashMap%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[HashMap基于哈希表的Map接口实现，是以key-value存储形式存在。 系统会根据hash算法来计算key-value的存储位置，可以通过key快速存取value。 HashMap基于hashing原理，我们通过put()和get()方法储存和获取对象。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，然后找到bucket位置来储存值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。 HashMap使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中。 HashMap在每个链表节点中储存键值对对象。 当两个不同的键对象的hashcode相同时会发生什么？ 它们会储存在同一个bucket位置的链表中。键对象的equals()方法用来找到键值对。 定义HashMap实现了Map接口，Map接口定义了键映射到值的规则。HashMap继承了AbstractMap，AbstractMap提供接口的主要实现，以最大限度的减少HashMap实现Map接口所需的工作。 初始容量和负载因子默认初始容量16，默认负载因子0.75。这两个参数是影响HashMap性能的重要参数，其中容量表示哈希表中桶的数量，初始容量是创建哈希表时的容量，负载因子是哈希表在其容量自动增加之前可以达到多满的一种尺度，它衡量的是一个散列表的空间的使用程度，负载因子越大表示散列表的装填程度越高，反之愈小。对于使用链表法的散列表来说，查找一个元素的平均时间是O(1+a)，因此如果负载因子越大，对空间的利用更充分，然而后果是查找效率的降低；如果负载因子太小，那么散列表的数据将过于稀疏，对空间造成严重浪费。系统默认负载因子为0.75，一般情况下我们是无需修改的。 数据结构Java中最常用的两种结构是数组和模拟指针(引用)，几乎所有的数据结构都可以利用这两种来组合实现，HashMap也是如此。实际上HashMap是一个“链表散列”，如下是它数据结构： HashMap基于哈希表的Map接口实现，是以key-value存储形式存在。 系统会根据hash算法来计算key-value的存储位置，可以通过key快速存取value。 HashMap基于hashing原理，我们通过put()和get()方法储存和获取对象。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，然后找到bucket位置来储存值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。 HashMap使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中。 HashMap在每个链表节点中储存键值对对象。 当两个不同的键对象的hashcode相同时会发生什么？ 它们会储存在同一个bucket位置的链表中。键对象的equals()方法用来找到键值对。 定义HashMap实现了Map接口，Map接口定义了键映射到值的规则。HashMap继承了AbstractMap，AbstractMap提供接口的主要实现，以最大限度的减少HashMap实现Map接口所需的工作。 初始容量和负载因子默认初始容量16，默认负载因子0.75。这两个参数是影响HashMap性能的重要参数，其中容量表示哈希表中桶的数量，初始容量是创建哈希表时的容量，负载因子是哈希表在其容量自动增加之前可以达到多满的一种尺度，它衡量的是一个散列表的空间的使用程度，负载因子越大表示散列表的装填程度越高，反之愈小。对于使用链表法的散列表来说，查找一个元素的平均时间是O(1+a)，因此如果负载因子越大，对空间的利用更充分，然而后果是查找效率的降低；如果负载因子太小，那么散列表的数据将过于稀疏，对空间造成严重浪费。系统默认负载因子为0.75，一般情况下我们是无需修改的。 数据结构Java中最常用的两种结构是数组和模拟指针(引用)，几乎所有的数据结构都可以利用这两种来组合实现，HashMap也是如此。实际上HashMap是一个“链表散列”，如下是它数据结构： HashMap底层实现还是数组，只是数组的每一项都是一条链。其中参数initialCapacity就代表了该数组的长度。 1234&#x2F;&#x2F;空表static final Entry&lt;?,?&gt;[] EMPTY_TABLE &#x3D; &#123;&#125;;&#x2F;&#x2F;用于存储的表，长度可以调整，且必须是2的n次幂transient Entry&lt;K,V&gt;[] table &#x3D; (Entry&lt;K,V&gt;[]) EMPTY_TABLE; 每次新建一个HashMap时，都会初始化一个table数组。table数组的元素为Entry节点。 其中Entry为HashMap的内部类，它包含了键key、值value、下一个节点next，以及hash值，这是非常重要的，正是由于Entry才构成了table数组的项为链表。 存储实现：put(key,value)1234567891011121314151617181920212223242526272829public V put(K key, V value) &#123; &#x2F;&#x2F;当表为空表时，扩展表 if (table &#x3D;&#x3D; EMPTY_TABLE) &#123; inflateTable(threshold); &#125; &#x2F;&#x2F;当key为null时，保存null在table第一个位置中 if (key &#x3D;&#x3D; null) return putForNullKey(value); &#x2F;&#x2F;计算key的hash值 int hash &#x3D; hash(key); &#x2F;&#x2F;计算key hash值在table数组中的位置 int i &#x3D; indexFor(hash, table.length); &#x2F;&#x2F;在i处开始迭代e，找到key保存的位置 for (Entry&lt;K,V&gt; e &#x3D; table[i]; e !&#x3D; null; e &#x3D; e.next) &#123; Object k; &#x2F;&#x2F;判断该条链上是否有hash值相同的（key相同），若存在相同的，则直接覆盖value，返回旧value if (e.hash &#x3D;&#x3D; hash &amp;&amp; ((k &#x3D; e.key) &#x3D;&#x3D; key || key.equals(k))) &#123; V oldValue &#x3D; e.value; e.value &#x3D; value; e.recordAccess(this); return oldValue; &#125; &#125; &#x2F;&#x2F;修改次数加1 modCount++; &#x2F;&#x2F;将key，value添加到i位置处 addEntry(hash, key, value, i); return null;&#125; 通过源码我们可以清晰看到HashMap保存数据的过程为：首先判断表是否为空，为空的话，先扩展表；然后判断key是否为null，若为null，则直接调用putForNullKey方法。若不为空则先计算key的hash值，然后根据hash值搜索在table数组中的索引位置，如果table数组在该位置处有元素，则通过比较是否存在相同的key，若存在则覆盖原来key的value，否则将该元素保存在链头（最先保存的元素放在链尾）。若table在该处没有元素，则直接保存。 迭代：此处迭代原因就是为了防止存在相同的key值，若发现两个hash值（key）相同时，HashMap的处理方式是用新value替换旧value，这里并没有处理key，这就解释了HashMap中没有两个相同的key。 int hash = hash(key); hash方法，计算key的hash值，代码如下： 1234567891011121314final int hash(Object k) &#123; int h &#x3D; hashSeed; if (0 !&#x3D; h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^&#x3D; k.hashCode(); &#x2F;&#x2F; This function ensures that hashCodes that differ only by &#x2F;&#x2F; constant multiples at each bit position have a bounded &#x2F;&#x2F; number of collisions (approximately 8 at default load factor). h ^&#x3D; (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; 对于HashMap的table而言，数据分布需要均匀（最好每项都只有一个元素，这样就可以直接找到），不能太紧也不能太松，太紧会导致查询速度慢，太松则浪费空间。计算hash值后，怎么才能保证table元素分布均与呢？我们会想到取模，但是由于取模的消耗较大，HashMap是这样处理的：调用indexFor方法。 1234static int indexFor(int h, int length) &#123; &#x2F;&#x2F; assert Integer.bitCount(length) &#x3D;&#x3D; 1 : &quot;length must be a non-zero power of 2&quot;; return h &amp; (length-1); &#125; HashMap的底层数组长度总是2的n次方，在构造函数中存在：capacity &lt;&lt;= 1;这样做总是能够保证HashMap的底层数组长度为2的n次方。当length为2的n次方时，h&amp;(length - 1)就相当于对length取模，而且速度比直接取模快得多，这是HashMap在速度上的一个优化。 indexFor方法，该方法仅有一条语句：h&amp;(length - 1)，这句话除了上面的取模运算外还有一个非常重要的责任：均匀分布table数据和充分利用空间。 当length = 2^n时，不同的hash值发生碰撞的概率比较小，这样就会使得数据在table数组中分布较均匀，查询速度也较快。 这里我们再来复习put的流程：当我们想往一个HashMap中添加一对key-value时，系统首先会计算key的hash值，然后根据hash值确认在table中存储的位置。若该位置没有元素，则直接插入。否则迭代该处元素链表并依此比较其key的hash值。如果两个hash值相等且key值相等(e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))),则用新的Entry的value覆盖原来节点的value。如果两个hash值相等但key值不等 ，则将该节点插入该链表的链头。具体的实现过程见addEntry方法，如下： 12345678910void addEntry(int hash, K key, V value, int bucketIndex) &#123; &#x2F;&#x2F;HashMap元素超过极限，则扩容为两倍 if ((size &gt;&#x3D; threshold) &amp;&amp; (null !&#x3D; table[bucketIndex])) &#123; resize(2 * table.length); hash &#x3D; (null !&#x3D; key) ? hash(key) : 0; bucketIndex &#x3D; indexFor(hash, table.length); &#125; &#x2F;&#x2F;创建新的Entry createEntry(hash, key, value, bucketIndex);&#125; 1234567void createEntry(int hash, K key, V value, int bucketIndex) &#123; &#x2F;&#x2F;获取bucketIndex处的Entry Entry&lt;K,V&gt; e &#x3D; table[bucketIndex]; &#x2F;&#x2F;将新创建的 Entry 放入 bucketIndex 索引处，并让新的 Entry 指向原来的 Entry table[bucketIndex] &#x3D; new Entry&lt;&gt;(hash, key, value, e); size++;&#125; 链的产生：这是一个非常优雅的设计。系统总是将新的Entry对象添加到bucketIndex处。如果bucketIndex处已经有了对象，那么新添加的Entry对象将指向原有的Entry对象，形成一条Entry链，但是若bucketIndex处没有Entry对象，也就是e==null,那么新添加的Entry对象指向null，也就不会产生Entry链了。 扩容问题：随着HashMap中元素的数量越来越多，发生碰撞的概率就越来越大，所产生的链表长度就会越来越长，这样势必会影响HashMap的速度，为了保证HashMap的效率，系统必须要在某个临界点进行扩容处理。该临界点在当HashMap中元素的数量等于table数组长度*加载因子。但是扩容是一个非常耗时的过程，因为它需要重新计算这些数据在新table数组中的位置并进行复制处理。所以如果我们已经预知HashMap中元素的个数，那么预设元素的个数能够有效的提高HashMap的性能。 读取实现：get(key)通过key的hash值找到在table数组中的索引处的Entry，然后返回该key对应的value即可。 123456789public V get(Object key) &#123; &#x2F;&#x2F;若为null，获取null对应的value if (key &#x3D;&#x3D; null) return getForNullKey(); &#x2F;&#x2F;getEntry(key)为真正获取方法 Entry&lt;K,V&gt; entry &#x3D; getEntry(key); return null &#x3D;&#x3D; entry ? null : entry.getValue();&#125; 123456789101112131415161718final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size &#x3D;&#x3D; 0) &#123; return null; &#125; &#x2F;&#x2F;根据key获取hash值 int hash &#x3D; (key &#x3D;&#x3D; null) ? 0 : hash(key); &#x2F;&#x2F;取出table数组中指定索引处的值 for (Entry&lt;K,V&gt; e &#x3D; table[indexFor(hash, table.length)]; e !&#x3D; null; e &#x3D; e.next) &#123; Object k; &#x2F;&#x2F;key相同，返回对应的value if (e.hash &#x3D;&#x3D; hash &amp;&amp; ((k &#x3D; e.key) &#x3D;&#x3D; key || (key !&#x3D; null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125; 在这里能够根据key快速的取到value除了和HashMap的数据结构密不可分外，还和Entry有莫大的关系，在前面就提到过，HashMap在存储过程中并没有将key，value分开来存储，而是当做一个整体key-value来处理的，这个整体就是Entry对象。同时value也只相当于key的附属而已。在存储的过程中，系统根据key的hashcode来决定Entry在table数组中的存储位置，在取的过程中同样根据key的hashcode取出相对应的Entry对象。 源码分析 jdk1.7.0_71 1234567891011121314151617181920212223&#x2F;&#x2F;默认初始化容量static final int DEFAULT_INITIAL_CAPACITY &#x3D; 1 &lt;&lt; 4;&#x2F;&#x2F;最大容量static final int MAXIMUM_CAPACITY &#x3D; 1 &lt;&lt; 30;&#x2F;&#x2F;系统默认负载因子static final float DEFAULT_LOAD_FACTOR &#x3D; 0.75f;&#x2F;&#x2F;空表static final Entry&lt;?,?&gt;[] EMPTY_TABLE &#x3D; &#123;&#125;;&#x2F;&#x2F;用于存储的表，长度可以调整，且必须是2的n次幂transient Entry&lt;K,V&gt;[] table &#x3D; (Entry&lt;K,V&gt;[]) EMPTY_TABLE;&#x2F;&#x2F;map的sizetransient int size;&#x2F;&#x2F;下次扩充的临界值 capacity * load factorint threshold;&#x2F;&#x2F;哈希表的负载因子final float loadFactor;&#x2F;&#x2F;在使用迭代器遍历的时候，用来检查列表中的元素是否发生结构性变化（列表元素数量发生改变的一个计数）了，主要在多线程环境下需要使用，防止一个线程正在迭代遍历，另一个线程修改了这个列表的结构。transient int modCount;&#x2F;&#x2F;容量阈值，默认大小为Integer.MAX_VALUEstatic final int ALTERNATIVE_HASHING_THRESHOLD_DEFAULT &#x3D; Integer.MAX_VALUE;&#x2F;&#x2F;计算哈希值得时候用transient int hashSeed &#x3D; 0; Holder 静态内部类,存放一些在虚拟机启动后才能初始化的值容量阈值，初始化hashSeed的时候会用到该值1static final int ALTERNATIVE_HASHING_THRESHOLD; static静态块12获取系统变量jdk.map.althashing.thresholdjdk.map.althashing.threshold系统变量默认为-1，如果为-1，则将阈值设为Integer.MAX_VALUE HashMap(int initialCapacity, float loadFactor) 指定容量和负载因子 构造1234public HashMap(int initialCapacity, float loadFactor) &#123; ... init();&#125; HashMap(int initialCapacity) 指定初始容量的构造,负载因子为默认1public HashMap(int initialCapacity) &#123;&#125; HashMap() 默认初始容量和默认负载因子的构造1public HashMap()&#123;&#125; HashMap(Map&lt;? extends K, ? extends V&gt; m) 用map初始化123456789public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; &#x2F;&#x2F;调用构造,初始化空的hashMap this(Math.max((int) (m.size() &#x2F; DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR); &#x2F;&#x2F;扩容 inflateTable(threshold); &#x2F;&#x2F;把元素放入到HashMap中 putAllForCreate(m);&#125; size() key-value映射个数123public int size() &#123; return size; &#125; isEmpty()是否为空123public boolean isEmpty() &#123; return size &#x3D;&#x3D; 0; &#125; get(Object key) 根据key获取value123456public V get(Object key) &#123; &#x2F;&#x2F;获取key为null的 getForNullKey(); &#x2F;&#x2F;获取其他的key,利用hash值查找 getEntry(Object key);&#125; containsKey(Object key) 是否包含key123public boolean containsKey(Object key) &#123; return getEntry(key) !&#x3D; null; &#125; put(K key, V value) 将指定的key value放入HashMap中,若已存在key,就替换旧值1public V put(K key, V value) &#123;&#125; resize(int newCapacity) 重新设置大小1void resize(int newCapacity)&#123;&#125; transfer(Entry[] newTable, boolean rehash)现有的table放入新的table12345void transfer(Entry[] newTable, boolean rehash) &#123;&#125;&#96;&#96;&#96; ## putAll(Map&lt;? extends K, ? extends V&gt; m) 把指定的元素 全部放入HashMap中,已经存在的key,会把旧value覆盖掉 public void putAll(Map&lt;? extends K, ? extends V&gt; m) {} 12## remove(Object key) 根据key删除 public V remove(Object key) { removeEntryForKey(key);} 12## clear() 清空 public void clear(){} 12## containsValue(Object value) 是否包含value public boolean containsValue(Object value) {} 12## clone() 浅拷贝 public Object clone() {} 12345## static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; 内部类## addEntry(int hash, K key, V value, int bucketIndex) 添加一个键值对 void addEntry(int hash, K key, V value, int bucketIndex) {} 12## createEntry(int hash, K key, V value, int bucketIndex) 添加一个键值对 void createEntry(int hash, K key, V value, int bucketIndex) {} # 参考 [http://www.cnblogs.com/chenpi/p/5280304.html](http://www.cnblogs.com/chenpi/p/5280304.html) [http://www.cnblogs.com/justany/archive/2013/02/01/2889335.html](http://www.cnblogs.com/justany/archive/2013/02/01/2889335.html) [http://tangyanbo.iteye.com/blog/1756536](http://tangyanbo.iteye.com/blog/1756536) [http://www.importnew.com/7099.html](http://www.importnew.com/7099.html) [http://www.cnblogs.com/chenssy/p/3521565.html](http://www.cnblogs.com/chenssy/p/3521565.html) HashMap底层实现还是数组，只是数组的每一项都是一条链。其中参数initialCapacity就代表了该数组的长度。 1234&#x2F;&#x2F;空表static final Entry&lt;?,?&gt;[] EMPTY_TABLE &#x3D; &#123;&#125;;&#x2F;&#x2F;用于存储的表，长度可以调整，且必须是2的n次幂transient Entry&lt;K,V&gt;[] table &#x3D; (Entry&lt;K,V&gt;[]) EMPTY_TABLE; 每次新建一个HashMap时，都会初始化一个table数组。table数组的元素为Entry节点。 其中Entry为HashMap的内部类，它包含了键key、值value、下一个节点next，以及hash值，这是非常重要的，正是由于Entry才构成了table数组的项为链表。 # 存储实现：put(key,value) 1234567891011121314151617181920212223242526272829public V put(K key, V value) &#123; &#x2F;&#x2F;当表为空表时，扩展表 if (table &#x3D;&#x3D; EMPTY_TABLE) &#123; inflateTable(threshold); &#125; &#x2F;&#x2F;当key为null时，保存null在table第一个位置中 if (key &#x3D;&#x3D; null) return putForNullKey(value); &#x2F;&#x2F;计算key的hash值 int hash &#x3D; hash(key); &#x2F;&#x2F;计算key hash值在table数组中的位置 int i &#x3D; indexFor(hash, table.length); &#x2F;&#x2F;在i处开始迭代e，找到key保存的位置 for (Entry&lt;K,V&gt; e &#x3D; table[i]; e !&#x3D; null; e &#x3D; e.next) &#123; Object k; &#x2F;&#x2F;判断该条链上是否有hash值相同的（key相同），若存在相同的，则直接覆盖value，返回旧value if (e.hash &#x3D;&#x3D; hash &amp;&amp; ((k &#x3D; e.key) &#x3D;&#x3D; key || key.equals(k))) &#123; V oldValue &#x3D; e.value; e.value &#x3D; value; e.recordAccess(this); return oldValue; &#125; &#125; &#x2F;&#x2F;修改次数加1 modCount++; &#x2F;&#x2F;将key，value添加到i位置处 addEntry(hash, key, value, i); return null;&#125; 通过源码我们可以清晰看到HashMap保存数据的过程为：首先判断表是否为空，为空的话，先扩展表；然后判断key是否为null，若为null，则直接调用putForNullKey方法。若不为空则先计算key的hash值，然后根据hash值搜索在table数组中的索引位置，如果table数组在该位置处有元素，则通过比较是否存在相同的key，若存在则覆盖原来key的value，否则将该元素保存在链头（最先保存的元素放在链尾）。若table在该处没有元素，则直接保存。 1. 迭代：此处迭代原因就是为了防止存在相同的key值，若发现两个hash值（key）相同时，HashMap的处理方式是用新value替换旧value，这里并没有处理key，这就解释了HashMap中没有两个相同的key。 2. `int hash = hash(key);` hash方法，计算key的hash值，代码如下： 1234567891011121314final int hash(Object k) &#123; int h &#x3D; hashSeed; if (0 !&#x3D; h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^&#x3D; k.hashCode(); &#x2F;&#x2F; This function ensures that hashCodes that differ only by &#x2F;&#x2F; constant multiples at each bit position have a bounded &#x2F;&#x2F; number of collisions (approximately 8 at default load factor). h ^&#x3D; (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; 3. 对于HashMap的table而言，数据分布需要均匀（最好每项都只有一个元素，这样就可以直接找到），不能太紧也不能太松，太紧会导致查询速度慢，太松则浪费空间。计算hash值后，怎么才能保证table元素分布均与呢？我们会想到取模，但是由于取模的消耗较大，HashMap是这样处理的：调用indexFor方法。 1234static int indexFor(int h, int length) &#123; &#x2F;&#x2F; assert Integer.bitCount(length) &#x3D;&#x3D; 1 : &quot;length must be a non-zero power of 2&quot;; return h &amp; (length-1); &#125; HashMap的底层数组长度总是2的n次方，在构造函数中存在：capacity &lt;&lt;= 1;这样做总是能够保证HashMap的底层数组长度为2的n次方。当length为2的n次方时，h&amp;(length - 1)就相当于对length取模，而且速度比直接取模快得多，这是HashMap在速度上的一个优化。 indexFor方法，该方法仅有一条语句：h&amp;(length - 1)，这句话除了上面的取模运算外还有一个非常重要的责任：均匀分布table数据和充分利用空间。 当length = 2^n时，不同的hash值发生碰撞的概率比较小，这样就会使得数据在table数组中分布较均匀，查询速度也较快。 这里我们再来复习put的流程：当我们想往一个HashMap中添加一对key-value时，系统首先会计算key的hash值，然后根据hash值确认在table中存储的位置。若该位置没有元素，则直接插入。否则迭代该处元素链表并依此比较其key的hash值。如果两个hash值相等且key值相等(e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))),则用新的Entry的value覆盖原来节点的value。如果两个hash值相等但key值不等 ，则将该节点插入该链表的链头。具体的实现过程见addEntry方法，如下： 12345678910void addEntry(int hash, K key, V value, int bucketIndex) &#123; &#x2F;&#x2F;HashMap元素超过极限，则扩容为两倍 if ((size &gt;&#x3D; threshold) &amp;&amp; (null !&#x3D; table[bucketIndex])) &#123; resize(2 * table.length); hash &#x3D; (null !&#x3D; key) ? hash(key) : 0; bucketIndex &#x3D; indexFor(hash, table.length); &#125; &#x2F;&#x2F;创建新的Entry createEntry(hash, key, value, bucketIndex);&#125; 1234567void createEntry(int hash, K key, V value, int bucketIndex) &#123; &#x2F;&#x2F;获取bucketIndex处的Entry Entry&lt;K,V&gt; e &#x3D; table[bucketIndex]; &#x2F;&#x2F;将新创建的 Entry 放入 bucketIndex 索引处，并让新的 Entry 指向原来的 Entry table[bucketIndex] &#x3D; new Entry&lt;&gt;(hash, key, value, e); size++;&#125; 1. 链的产生：这是一个非常优雅的设计。系统总是将新的Entry对象添加到bucketIndex处。如果bucketIndex处已经有了对象，那么新添加的Entry对象将指向原有的Entry对象，形成一条Entry链，但是若bucketIndex处没有Entry对象，也就是e==null,那么新添加的Entry对象指向null，也就不会产生Entry链了。 2. 扩容问题：随着HashMap中元素的数量越来越多，发生碰撞的概率就越来越大，所产生的链表长度就会越来越长，这样势必会影响HashMap的速度，为了保证HashMap的效率，系统必须要在某个临界点进行扩容处理。该临界点在当HashMap中元素的数量等于table数组长度*加载因子。但是扩容是一个非常耗时的过程，因为它需要重新计算这些数据在新table数组中的位置并进行复制处理。所以如果我们已经预知HashMap中元素的个数，那么预设元素的个数能够有效的提高HashMap的性能。 # 读取实现：get(key) 通过key的hash值找到在table数组中的索引处的Entry，然后返回该key对应的value即可。 123456789public V get(Object key) &#123; &#x2F;&#x2F;若为null，获取null对应的value if (key &#x3D;&#x3D; null) return getForNullKey(); &#x2F;&#x2F;getEntry(key)为真正获取方法 Entry&lt;K,V&gt; entry &#x3D; getEntry(key); return null &#x3D;&#x3D; entry ? null : entry.getValue();&#125; 123456789101112131415161718final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size &#x3D;&#x3D; 0) &#123; return null; &#125; &#x2F;&#x2F;根据key获取hash值 int hash &#x3D; (key &#x3D;&#x3D; null) ? 0 : hash(key); &#x2F;&#x2F;取出table数组中指定索引处的值 for (Entry&lt;K,V&gt; e &#x3D; table[indexFor(hash, table.length)]; e !&#x3D; null; e &#x3D; e.next) &#123; Object k; &#x2F;&#x2F;key相同，返回对应的value if (e.hash &#x3D;&#x3D; hash &amp;&amp; ((k &#x3D; e.key) &#x3D;&#x3D; key || (key !&#x3D; null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125; 在这里能够根据key快速的取到value除了和HashMap的数据结构密不可分外，还和Entry有莫大的关系，在前面就提到过，HashMap在存储过程中并没有将key，value分开来存储，而是当做一个整体key-value来处理的，这个整体就是Entry对象。同时value也只相当于key的附属而已。在存储的过程中，系统根据key的hashcode来决定Entry在table数组中的存储位置，在取的过程中同样根据key的hashcode取出相对应的Entry对象。 # 源码分析 &gt; jdk1.7.0_71 1234567891011121314151617181920212223&#x2F;&#x2F;默认初始化容量static final int DEFAULT_INITIAL_CAPACITY &#x3D; 1 &lt;&lt; 4;&#x2F;&#x2F;最大容量static final int MAXIMUM_CAPACITY &#x3D; 1 &lt;&lt; 30;&#x2F;&#x2F;系统默认负载因子static final float DEFAULT_LOAD_FACTOR &#x3D; 0.75f;&#x2F;&#x2F;空表static final Entry&lt;?,?&gt;[] EMPTY_TABLE &#x3D; &#123;&#125;;&#x2F;&#x2F;用于存储的表，长度可以调整，且必须是2的n次幂transient Entry&lt;K,V&gt;[] table &#x3D; (Entry&lt;K,V&gt;[]) EMPTY_TABLE;&#x2F;&#x2F;map的sizetransient int size;&#x2F;&#x2F;下次扩充的临界值 capacity * load factorint threshold;&#x2F;&#x2F;哈希表的负载因子final float loadFactor;&#x2F;&#x2F;在使用迭代器遍历的时候，用来检查列表中的元素是否发生结构性变化（列表元素数量发生改变的一个计数）了，主要在多线程环境下需要使用，防止一个线程正在迭代遍历，另一个线程修改了这个列表的结构。transient int modCount;&#x2F;&#x2F;容量阈值，默认大小为Integer.MAX_VALUEstatic final int ALTERNATIVE_HASHING_THRESHOLD_DEFAULT &#x3D; Integer.MAX_VALUE;&#x2F;&#x2F;计算哈希值得时候用transient int hashSeed &#x3D; 0; ## Holder 静态内部类,存放一些在虚拟机启动后才能初始化的值 ### 容量阈值，初始化hashSeed的时候会用到该值 1static final int ALTERNATIVE_HASHING_THRESHOLD; ### static静态块 12获取系统变量jdk.map.althashing.thresholdjdk.map.althashing.threshold系统变量默认为-1，如果为-1，则将阈值设为Integer.MAX_VALUE ## HashMap(int initialCapacity, float loadFactor) 指定容量和负载因子 构造 1234public HashMap(int initialCapacity, float loadFactor) &#123; ... init();&#125; ## HashMap(int initialCapacity) 指定初始容量的构造,负载因子为默认 1public HashMap(int initialCapacity) &#123;&#125; ## HashMap() 默认初始容量和默认负载因子的构造 1public HashMap()&#123;&#125; ## HashMap(Map&lt;? extends K, ? extends V&gt; m) 用map初始化 123456789public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; &#x2F;&#x2F;调用构造,初始化空的hashMap this(Math.max((int) (m.size() &#x2F; DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR); &#x2F;&#x2F;扩容 inflateTable(threshold); &#x2F;&#x2F;把元素放入到HashMap中 putAllForCreate(m);&#125; ## size() key-value映射个数 123public int size() &#123; return size; &#125; ## isEmpty()是否为空 123public boolean isEmpty() &#123; return size &#x3D;&#x3D; 0; &#125; ## get(Object key) 根据key获取value 123456public V get(Object key) &#123; &#x2F;&#x2F;获取key为null的 getForNullKey(); &#x2F;&#x2F;获取其他的key,利用hash值查找 getEntry(Object key);&#125; ## containsKey(Object key) 是否包含key 123public boolean containsKey(Object key) &#123; return getEntry(key) !&#x3D; null; &#125; ## put(K key, V value) 将指定的key value放入HashMap中,若已存在key,就替换旧值 1public V put(K key, V value) &#123;&#125; ## resize(int newCapacity) 重新设置大小 1void resize(int newCapacity)&#123;&#125; ## transfer(Entry[] newTable, boolean rehash)现有的table放入新的table 12345void transfer(Entry[] newTable, boolean rehash) &#123;&#125;&#96;&#96;&#96; ## putAll(Map&lt;? extends K, ? extends V&gt; m) 把指定的元素 全部放入HashMap中,已经存在的key,会把旧value覆盖掉 public void putAll(Map&lt;? extends K, ? extends V&gt; m) {} 12## remove(Object key) 根据key删除 public V remove(Object key) { removeEntryForKey(key); } 12## clear() 清空 public void clear(){} 12## containsValue(Object value) 是否包含value public boolean containsValue(Object value) {} 12## clone() 浅拷贝 public Object clone() {} 12345## static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; 内部类## addEntry(int hash, K key, V value, int bucketIndex) 添加一个键值对 void addEntry(int hash, K key, V value, int bucketIndex) {} 12## createEntry(int hash, K key, V value, int bucketIndex) 添加一个键值对 void createEntry(int hash, K key, V value, int bucketIndex) {}参考http://www.cnblogs.com/chenpi/p/5280304.html http://www.cnblogs.com/justany/archive/2013/02/01/2889335.html http://tangyanbo.iteye.com/blog/1756536 http://www.importnew.com/7099.html http://www.cnblogs.com/chenssy/p/3521565.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CopyOnWriteArrayList简介]]></title>
      <url>%2F2016%2F05%2F25%2FCopyOnWriteArrayList%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[CopyOnWriteArrayList，写数组的拷贝，支持高效率并发且是线程安全的,读操作无锁的ArrayList。所有可变操作都是通过对底层数组进行一次新的复制来实现。 CopyOnWriteArrayList适合使用在读操作远远大于写操作的场景里，比如缓存。它不存在扩容的概念，每次写操作都要复制一个副本，在副本的基础上修改后改变Array引用。CopyOnWriteArrayList中写操作需要大面积复制数组，所以性能肯定很差 在迭代器上进行的元素更改操作（remove、set和add）不受支持。这些方法将抛出UnsupportedOperationException。 定义CopyOnWriteArrayList跟ArrayList一样实现了List, RandomAccess, Cloneable, Serializable接口，但是没有继承AbstractList。 初始化时候新建一个容量为0的数组。 add(E e)方法123456789101112131415161718192021public boolean add(E e) &#123; &#x2F;&#x2F;获得锁，添加的时候首先进行锁定 final ReentrantLock lock &#x3D; this.lock; lock.lock(); try &#123; &#x2F;&#x2F;获取当前数组 Object[] elements &#x3D; getArray(); &#x2F;&#x2F;获取当前数组的长度 int len &#x3D; elements.length; &#x2F;&#x2F;这个是重点，创建新数组，容量为旧数组长度加1，将旧数组拷贝到新数组中 Object[] newElements &#x3D; Arrays.copyOf(elements, len + 1); &#x2F;&#x2F;要添加的数据添加到新数组的末尾 newElements[len] &#x3D; e; &#x2F;&#x2F;将数组引用指向新数组，完成了添加元素操作 setArray(newElements); return true; &#125; finally &#123; &#x2F;&#x2F;解锁 lock.unlock(); &#125;&#125; 从上面来说，每次添加一个新元素都会长度加1，然后复制整个旧数组，由此可见对于写多的操作，效率肯定不会很好。所以CopyOnWriteArrayList适合读多写少的场景。 add(int index, E element)方法12345678910111213141516171819202122232425262728293031323334public void add(int index, E element) &#123; &#x2F;&#x2F;同样也是先加锁 final ReentrantLock lock &#x3D; this.lock; lock.lock(); try &#123; &#x2F;&#x2F;获取旧数组 Object[] elements &#x3D; getArray(); &#x2F;&#x2F;获取旧数组长度 int len &#x3D; elements.length; &#x2F;&#x2F;校验指定的index if (index &gt; len || index &lt; 0) throw new IndexOutOfBoundsException(&quot;Index: &quot;+index+ &quot;, Size: &quot;+len); Object[] newElements; int numMoved &#x3D; len - index; if (numMoved &#x3D;&#x3D; 0)&#x2F;&#x2F;需要插入的位置正好等于数组长度，数组长度加1，旧数据拷贝到新数组 newElements &#x3D; Arrays.copyOf(elements, len + 1); else &#123; &#x2F;&#x2F;新数组长度增加1 newElements &#x3D; new Object[len + 1]; &#x2F;&#x2F;分两次拷贝，第一次拷贝旧数组0到index处的到新数组0到index，第二次拷贝旧数组index到最后的数组到新数组index+1到最后 System.arraycopy(elements, 0, newElements, 0, index); System.arraycopy(elements, index, newElements, index + 1, numMoved); &#125; &#x2F;&#x2F;index初插入数据 newElements[index] &#x3D; element; &#x2F;&#x2F;新数组指向全局数组 setArray(newElements); &#125; finally &#123; &#x2F;&#x2F;解锁 lock.unlock(); &#125;&#125; set(int index, E element)方法1234567891011121314151617181920212223242526272829public E set(int index, E element) &#123; &#x2F;&#x2F;修改元素之前首先加锁 final ReentrantLock lock &#x3D; this.lock; lock.lock(); try &#123; &#x2F;&#x2F;获取原来的数组 Object[] elements &#x3D; getArray(); &#x2F;&#x2F;index位置的元素 E oldValue &#x3D; get(elements, index); &#x2F;&#x2F;新旧值不相等才进行替换 if (oldValue !&#x3D; element) &#123; &#x2F;&#x2F;原来的长度 int len &#x3D; elements.length; &#x2F;&#x2F;拷贝一份到新数组 Object[] newElements &#x3D; Arrays.copyOf(elements, len); &#x2F;&#x2F;替换元素 newElements[index] &#x3D; element; &#x2F;&#x2F;新数组指向全局数组 setArray(newElements); &#125; else &#123; &#x2F;&#x2F; Not quite a no-op; ensures volatile write semantics setArray(elements); &#125; return oldValue; &#125; finally &#123; &#x2F;&#x2F;解锁 lock.unlock(); &#125;&#125; get(int index)方法读的时候不加锁，代码如下： 123public E get(int index) &#123; return get(getArray(), index);&#125; 123private E get(Object[] a, int index) &#123; return (E) a[index];&#125; remove（）remove方法不再过多介绍，看完add和set方法应该就能理解。 迭代内部类COWIterator 实现了ListIterator接口。迭代的时候不能进行remove，add，set等方法，会抛异常。 迭代速度快，迭代时是迭代的数组快照。 12&#x2F;** Snapshot of the array *&#x2F;private final Object[] snapshot; 源码分析 jdk1.7.0_71 123456&#x2F;&#x2F;锁,保护所有存取器transient final ReentrantLock lock &#x3D; new ReentrantLock();&#x2F;&#x2F;保存数据的数组private volatile transient Object[] array;final Object[] getArray() &#123;return array;&#125;final void setArray(Object[] a) &#123;array &#x3D; a;&#125; 空构造,初始化一个长度为0的数组123public CopyOnWriteArrayList() &#123; setArray(new Object[0]); &#125; 利用集合初始化一个CopyOnWriteArrayList1public CopyOnWriteArrayList(Collection&lt;? extends E&gt; c) &#123;&#125; 利用数组初始化一个CopyOnWriteArrayList1public CopyOnWriteArrayList(E[] toCopyIn) &#123;&#125; size() 大小1public int size() &#123;&#125; isEmpty()是否为空1public boolean isEmpty()&#123;&#125; indexOf(Object o, Object[] elements,int index, int fence) 元素索引1private static int indexOf(Object o, Object[] elements,int index, int fence) &#123;&#125; indexOf() 元素索引1public int indexOf(Object o)&#123;&#125; indexOf(E e, int index) 元素索引1public int indexOf(E e, int index) &#123;&#125; lastIndexOf(Object o, Object[] elements, int index) 元素索引,最后一个1private static int lastIndexOf(Object o, Object[] elements, int index) &#123;&#125; lastIndexOf(Object o) 元素索引,最后一个1public int indexOf(E e, int index) &#123;&#125; lastIndexOf(E e, int index) 元素索引,最后一个1public int lastIndexOf(E e, int index) &#123;&#125; contains(Object o) 是否包含元素1public boolean contains(Object o)&#123;&#125; clone() 浅拷贝1public Object clone() &#123;&#125; toArray() 转换成数组1public Object[] toArray()&#123;&#125; toArray(T a[]) 转换成指定类型的数组1public &lt;T&gt; T[] toArray(T a[]) &#123;&#125; E get(int index)获取指定位置的元素1public E get(int index)&#123;&#125; set(int index, E element) 指定位置设置元素 写元素的时候,先获得锁,finall块中释放锁 123456789101112131415161718192021public E set(int index, E element) &#123; final ReentrantLock lock &#x3D; this.lock; lock.lock(); try &#123; Object[] elements &#x3D; getArray(); E oldValue &#x3D; get(elements, index); if (oldValue !&#x3D; element) &#123; int len &#x3D; elements.length; Object[] newElements &#x3D; Arrays.copyOf(elements, len); newElements[index] &#x3D; element; setArray(newElements); &#125; else &#123; &#x2F;&#x2F; Not quite a no-op; ensures volatile write semantics setArray(elements); &#125; return oldValue; &#125; finally &#123; lock.unlock(); &#125; &#125; add(E e) 元素添加到末尾1public boolean add(E e) &#123;&#125; add(int index, E element) 指定位置之后插入元素1public void add(int index, E element)&#123;&#125; remove(int index)删除指定位置的元素1public E remove(int index) &#123;&#125; remove(Object o) 删除第一个匹配的元素1public boolean remove(Object o) &#123;&#125; removeRange(int fromIndex, int toIndex) 删除指定区间的元素1private void removeRange(int fromIndex, int toIndex) &#123;&#125; addIfAbsent(E e) 如果元素不存在就添加进list中1public boolean addIfAbsent(E e)&#123;&#125; containsAll(Collection&lt;?&gt; c)是否包含全部1public boolean containsAll(Collection&lt;?&gt; c)&#123;&#125; removeAll(Collection&lt;?&gt; c) 移除全部包含在集合中的元素1public boolean removeAll(Collection&lt;?&gt; c)&#123;&#125; retainAll(Collection&lt;?&gt; c) 保留指定集合的元素,其他的删除1public boolean retainAll(Collection&lt;?&gt; c)&#123;&#125; addAllAbsent(Collection&lt;? extends E&gt; c) 如果不存在就添加进去1public int addAllAbsent(Collection&lt;? extends E&gt; c) &#123;&#125; clear() 清空list1public void clear()&#123;&#125; addAll(Collection&lt;? extends E&gt; c)添加集合中的元素到尾部1public void addAll(Collection&lt;? extends E&gt; c)&#123;&#125; addAll(int index, Collection&lt;? extends E&gt; c) 添加集合中元素到指定位置之后1public boolean addAll(int index, Collection&lt;? extends E&gt; c)&#123;&#125; toString()1public String toString()&#123;&#125; equals(Object o)1234567891011121314151617public boolean equals(Object o) &#123; if (o &#x3D;&#x3D; this) return true; if (!(o instanceof List)) return false; List&lt;?&gt; list &#x3D; (List&lt;?&gt;)(o); Iterator&lt;?&gt; it &#x3D; list.iterator(); Object[] elements &#x3D; getArray(); int len &#x3D; elements.length; for (int i &#x3D; 0; i &lt; len; ++i) if (!it.hasNext() || !eq(elements[i], it.next())) return false; if (it.hasNext()) return false; return true; &#125; hashCode()1public int hashCode&#123;&#125; listIterator(final int index)和 listIterator() 返回一个迭代器,支持向前和向后遍历123public ListIterator&lt;E&gt; listIterator(final int index) &#123;&#125;public ListIterator&lt;E&gt; listIterator() &#123;&#125; iterator() 只能向后遍历1public Iterator&lt;E&gt; iterator() &#123;&#125; subList() 返回部分list12345public List&lt;E&gt; subList(int fromIndex, int toIndex) &#123; ... return new COWSubList&lt;E&gt;(this, fromIndex, toIndex); ...&#125; 参考http://www.cnblogs.com/sunwei2012/archive/2010/10/08/1845656.html http://my.oschina.net/jielucky/blog/167198]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Stack简介]]></title>
      <url>%2F2016%2F05%2F25%2FStack%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[Stack简介 Stack基于Vector实现,支持LIFO 后进先出 源码分析 jdk1.7.0_71 默认构造12public Stack() &#123; &#125; push(E item)将元素压入顶端12345public E push(E item) &#123; addElement(item); return item; &#125; pop() 删除顶部的元素,同步方法123456789public synchronized E pop() &#123; E obj; int len &#x3D; size(); obj &#x3D; peek(); removeElementAt(len - 1); return obj; &#125; peek() 获取顶端元素1234567public synchronized E peek() &#123; int len &#x3D; size(); if (len &#x3D;&#x3D; 0) throw new EmptyStackException(); return elementAt(len - 1); &#125; empty() 是否为空1public boolean empty()&#123;&#125; search(Object o) 查询当前o距离栈底的距离12345678public synchronized int search(Object o) &#123; int i &#x3D; lastIndexOf(o); if (i &gt;&#x3D; 0) &#123; return size() - i; &#125; return -1; &#125; 参考]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Vector简介]]></title>
      <url>%2F2016%2F05%2F24%2FVector%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[Vector简介 Vector和ArrayList类似,基于Object数组方式实现 Vector是同步访问的,操作是线程安全的 源码分析 jdk1.7.0_71 123456&#x2F;&#x2F;保存Vector中的元素protected Object[] elementData;&#x2F;&#x2F;Vector中存储的元素个数protected int elementCount;&#x2F;&#x2F;Vector容量自动增长的大小,此数值小于等于0,容量增长为2倍protected int capacityIncrement; Vector(int initialCapacity, int capacityIncrement) 初始容量和初始自动增长 构造1public Vector(int initialCapacity, int capacityIncrement)&#123;&#125; Vector(int initialCapacity) 初始容量 ,自动增长2倍 构造1public Vector(int initialCapacity)&#123;&#125; Vector() 初始容量10,自动增长2倍 构造1public Vector()&#123;&#125; Vector(Collection&lt;? extends E&gt; c) 使用集合初始化1public Vector(Collection&lt;? extends E&gt; c)&#123;&#125; copyInto(Object[] anArray) 将Vector中的元素拷到Object数组中1public synchronized void copyInto(Object[] anArray) &#123;&#125; trimToSize()1public synchronized void trimToSize() &#123;&#125; ensureCapacity(int minCapacity) 增加容量1public synchronized void ensureCapacity(int minCapacity) &#123;&#125; grow(int minCapacity) 真正增长容量的方法1private void grow(int minCapacity) &#123;&#125; setSize(int newSize) 设置大小1public synchronized void setSize(int newSize) &#123;&#125; capacity() Vector的容量1public synchronized int capacity() &#123;&#125; size() Vector包含元素的数量1public synchronized int size() &#123;&#125; isEmpty()是否为空1public synchronized boolean isEmpty() &#123;&#125; elements()返回一个枚举123456789101112131415161718public Enumeration&lt;E&gt; elements() &#123; return new Enumeration&lt;E&gt;() &#123; int count &#x3D; 0; public boolean hasMoreElements() &#123; return count &lt; elementCount; &#125; public E nextElement() &#123; synchronized (Vector.this) &#123; if (count &lt; elementCount) &#123; return elementData(count++); &#125; &#125; throw new NoSuchElementException(&quot;Vector Enumeration&quot;); &#125; &#125;;&#125; contains(Object o) 是否包含指定元素1public boolean contains(Object o) &#123;&#125; indexOf(Object o) 返回第一个匹配的索引1public int indexOf(Object o) &#123;&#125; indexOf(Object o, int index) 返回第一个从index开始的匹配的Object1public synchronized int indexOf(Object o, int index)&#123;&#125; lastIndexOf(Object o) 返回最后一个匹配的索引1public synchronized int lastIndexOf(Object o) &#123;&#125; lastIndexOf(Object o, int index)返回最后一个从index开始的匹配的Object1public synchronized int lastIndexOf(Object o, int index) &#123;&#125; elementAt(int index) 返回指定位置的元素1public synchronized E elementAt(int index) &#123;&#125; firstElement() 第一个元素1public synchronized E firstElement()&#123;&#125; lastElement() 最后一个元素1public synchronized E lastElement() &#123;&#125; setElementAt(E obj, int index) 设置指定位置的元素1public synchronized void setElementAt(E obj, int index) &#123;&#125; removeElementAt(int index) 移除指定位置的元素1public synchronized void removeElementAt(int index) &#123;&#125; insertElementAt(E obj,int index)指定位置之后插入元素1public synchronized void insertElementAt(E obj, int index) &#123;&#125; addElement(E obj) 添加元素到最后1public synchronized void addElement(E obj) &#123;&#125; removeElement(Object obj) 删除第一个匹配的元素1public synchronized boolean removeElement(Object obj) &#123;&#125; removeAllElements() 删除所有元素1public synchronized void removeAllElements() &#123;&#125; clone() 深拷贝1public synchronized Object clone() &#123;&#125; toArray() 返回Object数组1public synchronized Object[] toArray() &#123;&#125; toArray(T[] a) 返回指定类型的数组1public synchronized &lt;T&gt; T[] toArray(T[] a) &#123;&#125; elementData(int index) 返回指定位置的元素1E elementData(int index) &#123;&#125; get(int index) 获取指定位置的元素1public synchronized E get(int index) &#123;&#125; set(int index, E element) 替换指定位置的元素1public synchronized E set(int index, E element) &#123;&#125; add(E e) 添加元素到末尾1public synchronized boolean add(E e) &#123;&#125; remove(Object o) 删除第一个匹配的元素1public boolean remove(Object o) &#123;&#125; add(int index, E element) 指定位置后面插入元素1public void add(int index, E element)&#123;&#125; remove(int index) 删除指定位置的元素1public synchronized E remove(int index) &#123;&#125; clear() 清空vector1public void clear() &#123;&#125; containsAll(Collection&lt;?&gt; c) 是否包含指定的集合1public synchronized boolean containsAll(Collection&lt;?&gt; c) &#123;&#125; addAll(Collection&lt;? extends E&gt; c) 把集合添加到vector的末尾1public synchronized boolean addAll(Collection&lt;? extends E&gt; c) &#123;&#125; removeAll(Collection&lt;?&gt; c) 删除vector中所有的指定集合中的元素1public synchronized boolean removeAll(Collection&lt;?&gt; c) &#123;&#125; retainAll(Collection&lt;?&gt; c)保留指定的集合元素,其他的删除1public synchronized boolean retainAll(Collection&lt;?&gt; c) &#123;&#125; addAll(int index, Collection&lt;? extends E&gt; c) 添加指定的集合元素到指定的位置之后1public synchronized boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123;&#125; equals(Object o)1public synchronized boolean equals(Object o) &#123;&#125; hashCode()1public synchronized int hashCode() &#123;&#125; toString()1public synchronized String toString() &#123;&#125; subList(int fromIndex, int toIndex)返回一个子list1public synchronized List&lt;E&gt; subList(int fromIndex, int toIndex) &#123;&#125; removeRange(int fromIndex, int toIndex) 删除指定区间的元素1protected synchronized void removeRange(int fromIndex, int toIndex) &#123;&#125; listIterator(int index)/listIterator() 返回一个ListIterator12345public synchronized ListIterator&lt;E&gt; listIterator(int index) &#123;&#125;public synchronized ListIterator&lt;E&gt; listIterator() &#123; return new ListItr(0); &#125; iterator() 返回一个Iterator123public synchronized Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; 参考http://www.cnblogs.com/skywang12345/p/3308833.html http://www.runoob.com/java/java-vector-class.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[LinkedList简介]]></title>
      <url>%2F2016%2F05%2F23%2FLinkedList%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[LinkedList简介 LinkedList基于双向链表实现 LinkedList相对于Arraylist来说,get和set等随机访问会比较慢,LinkedList需要移动指针；add和remove会比较快。 LinkedList类还为在列表开头和结尾的get，remove，insert元素提供统一的命名方法，这些操作允许将链表用做堆栈、队列或者双端队列。此类实现 Deque 接口，为 add、poll 提供先进先出队列操作，以及其他堆栈和双端队列操作。 非线程安全，不同步。 定义LinkedList集成AbstractSequentialList，实现了List，Deque，Cloneable，Serializable接口。AbstractSequentialList提供了骨干实现。Deque一个线性 collection，支持在两端插入和移除元素，定义了双端队列的操作。 源码分析 jdk1.7.0_71 123456&#x2F;&#x2F;节点个数transient int size &#x3D; 0;&#x2F;&#x2F;前驱节点transient Node&lt;E&gt; first;&#x2F;&#x2F;后继节点transient Node&lt;E&gt; last; 无参构造1public LinkedList() &#123;&#125; 根据其他容器进行构造1public LinkedList(Collection&lt;? extends E&gt; c) &#123;&#125; getFirst()/getLast() 获取第一个/获取最后一个12public E getFirst() &#123;&#125;public E getLast() &#123;&#125; removeFirst()/removeLast() 删除第一个/删除最后一个12public E removeFirst() &#123;&#125;public E removeLast() &#123;&#125; addFirst(E e)/addLast(E e) 添加到头/尾12public void addFirst(E e) &#123;&#125;public void addLast(E e) &#123;&#125; 是否包含指定的元素123public boolean contains(Object o) &#123; return indexOf(o) !&#x3D; -1;&#125; 指定元素的位置索引1public int indexOf(Object o) &#123;&#125; 指定元素的最后的位置索引1public int lastIndexOf(Object o) &#123;&#125; list的大小123public int size() &#123; return size;&#125; add() 添加到末尾1public boolean add(E e) &#123;&#125; remove(Object o)/removeFirstOccurrence(Object o) 移除第一个o123public boolean remove(Object o) &#123;&#125;public boolean removeFirstOccurrence(Object o)&#123;&#125; addAll(Collection&lt;? extends E&gt; c) 添加到list结尾1public boolean addAll(Collection&lt;? extends E&gt; c) &#123;&#125; addAll(int index, Collection&lt;? extends E&gt; c) 指定的位置以后添加全部1public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123;&#125; clear() 清空1public void clear() &#123;&#125; get(int index) 获取指定位置的元素1public E get(int index) &#123;&#125; 指定位置替换成新元素,返回旧元素1public E set(int index, E element) &#123;&#125; add(int index, E element)指定位置插入指定元素1public void add(int index, E element) &#123;&#125; remove(int index) 移除指定位置的元素1public E remove(int index) &#123;&#125; peek()/peekFirst() 获取list头123public E peek() &#123;&#125;public E peekFirst() &#123;&#125; element() 获取list头1public E element() &#123;&#125; poll()/pollFirst() 获取list头,并删除123public E poll() &#123;&#125;public E pollFirst() &#123;&#125; remove() 删除第一个1public E remove() &#123;&#125; offer(E e)/offerLast(E e) 添加e到尾部123public boolean offer(E e) &#123;&#125;public boolean offerLast(E e) &#123;&#125; offerFirst(E e)/push(E e) 添加e到头部123public boolean offerFirst(E e) &#123;&#125;public void push(E e)&#123;&#125; peekLast() 获取list尾1public E peekLast() &#123;&#125; pollLast() 获取list尾,并删除1public E pollLast pop() 删除头1public E pop()&#123;&#125; removeLastOccurrence(Object o)从后面开始删除第一个匹配的元素1public boolean removeLastOccurrence(Object o) &#123;&#125; listIterator(int index)从指定的位置开始返回一个listIterator1public ListIterator&lt;E&gt; listIterator(int index) &#123;&#125; descendingIterator() 逆序迭代器1234public Iterator&lt;E&gt; descendingIterator() &#123; &#x2F;&#x2F;内部类 return new DescendingIterator(); &#125; clone() 浅拷贝1public Object clone() &#123;&#125; toArray() 转换成Object数组1public Object[] toArray() &#123;&#125; toArray(T[] a) 转换成指定类型的数组1234567891011121314public &lt;T&gt; T[] toArray(T[] a) &#123; if (a.length &lt; size) a &#x3D; (T[])java.lang.reflect.Array.newInstance( a.getClass().getComponentType(), size); int i &#x3D; 0; Object[] result &#x3D; a; for (Node&lt;E&gt; x &#x3D; first; x !&#x3D; null; x &#x3D; x.next) result[i++] &#x3D; x.item; if (a.length &gt; size) a[size] &#x3D; null; return a; &#125; 参考https://www.zybuluo.com/pastqing/note/208830 http://blog.csdn.net/u013256816/article/details/50916689]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ArrayList简介]]></title>
      <url>%2F2016%2F05%2F20%2FArrayList%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[ArrayList简介ArrayList实现了List接口，内部以数组存储数据，允许重复的值。由于内部是数组实现，所以ArrayList具有数组所有的特性，通过索引支持随机访问，查询速度快，但是插入和删除的效率比较低。 ArrayList默认初始容量为10，每次添加新元素时都会检查是否需要扩容操作。扩容操作需要重新拷贝数组，比较耗时，所以如果预先能知道数组的大小，在初始化时候可以指定一个初始容量。 ArrayList不是线程安全的，使用时应注意。 源码分析 jdk1.7.0_71 12345678&#x2F;&#x2F;默认容量private static final int DEFAULT_CAPACITY &#x3D; 10;&#x2F;&#x2F;默认空的数组,定义空的ArrayListprivate static final Object[] EMPTY_ELEMENTDATA &#x3D; &#123;&#125;;&#x2F;&#x2F;保存ArrayList中元素的数组，以下基本操作都是基于该数组private transient Object[] elementData;&#x2F;&#x2F;ArrayList中元素数组的容量private int size; 无参构造函数12&#x2F;&#x2F;构造一个空的Object数组，初始容量为10 public ArrayList() &#123;&#125; 指定容量大小的构造函数12&#x2F;&#x2F;指定初始容量public ArrayList(int initialCapacity) &#123;&#125; 指定初始值为继承Collection接口的集合的构造函数1public ArrayList(Collection&lt;? extends E&gt; c) &#123;&#125; trimToSize1234567&#x2F;&#x2F;ArrayList每次增长会预申请1.5倍+1的空间,&#x2F;&#x2F;举个例子就是当size() &#x3D; 1000的时候，ArrayList已经申请了1200空间&#x2F;&#x2F;trimToSize 的作用是删除多余的200public void trimToSize() &#123; modCount++; ... &#125; 关于modCount modCount定义在抽象类AbstratList中， 源码的注释基本说明了它的用处:在使用迭代器遍历的时候，用来检查列表中的元素是否发生结构性变化（列表元素数量发生改变的一个计数）了，主要在多线程环境下需要使用，防止一个线程正在迭代遍历，另一个线程修改了这个列表的结构。 ensureCapacity12&#x2F;&#x2F;增加此ArrayList实例的容量，如果需要，以确保其能容纳至少由最小容量参数指定的元素数public void ensureCapacity(int minCapacity) &#123;&#125; grow()方法,实际的扩容方法,扩充为原来的1.5倍1234567891011121314&#x2F;&#x2F;数组最大值private static final int MAX_ARRAY_SIZE &#x3D; Integer.MAX_VALUE - 8;private void grow(int minCapacity) &#123; &#x2F;&#x2F; overflow-conscious code int oldCapacity &#x3D; elementData.length; int newCapacity &#x3D; oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity &#x3D; minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity &#x3D; hugeCapacity(minCapacity); &#x2F;&#x2F; minCapacity is usually close to size, so this is a win: elementData &#x3D; Arrays.copyOf(elementData, newCapacity);&#125; size() ArrayList的大小1public int size() &#123;&#125; isEmpty() 不包含元素,返回true1public boolean isEmpty() &#123;&#125; contains()包含指定的元素,返回true1public boolean contains(Object o) &#123;&#125; indexOf()1public int indexOf(Object o) &#123;&#125; lastIndexOf()1public int lastIndexOf(Object o) &#123;&#125; clone() 浅拷贝1public Object clone() &#123;&#125; toArray() 返回Object数组1public Object[] toArray() &#123;&#125; toArray(T[] a)123456&#x2F;&#x2F;返回数组的运行时类型是指定数组的。如果列表中指定的数组能容纳，则在其中返回。&#x2F;&#x2F;否则，一个新的数组分配具有指定数组的运行时类型和此列表的大小。&#x2F;&#x2F;如果列表中指定的数组能容纳更加节省空间(即数组的元素比列表元素多)，&#x2F;&#x2F;那么会将紧挨着collection尾部的元素设置为null。public &lt;T&gt; T[] toArray(T[] a) &#123;&#125; elementData() 根据索引返回数据1E elementData(int index) &#123;&#125; get(int index) 根据索引获取1234public E get(int index) &#123; rangeCheck(index);&#x2F;&#x2F;范围检查,看是否给定的index是否超出数组大小 ... &#125; set(int index, E element) 根据索引替换1234public E set(int index, E element) &#123; rangeCheck(index); ... &#125; add(E e) 添加元素到元素末尾1234public boolean add(E e) &#123; ensureCapacityInternal(size + 1); &#x2F;&#x2F; Increments modCount!! ... &#125; add(int index,E element) 添加元素到指定位置1234public void add(int index, E element) &#123; rangeCheckForAdd(index); ... &#125; remove(int index)删除指定位置的元素12345public E remove(int index) &#123; ... elementData[--size] &#x3D; null; &#x2F;&#x2F; clear to let GC do its work ...&#125; remove(Object o) 删除指定元素12345public boolean remove(Object o) &#123; ... fastRemove(index); ... &#125; fastRemove(int index)快速删除,不检查边界,无返回值1private void fastRemove(int index) &#123;&#125; clear() 清空123456789public void clear() &#123; modCount++; &#x2F;&#x2F; clear to let GC do its work for (int i &#x3D; 0; i &lt; size; i++) elementData[i] &#x3D; null; size &#x3D; 0; &#125; addAll(Collection&lt;? extends E&gt; c) 添加指定的集合到末尾1public boolean addAll(Collection&lt;? extends E&gt; c) &#123;&#125; addAll(int index, Collection&lt;? extends E&gt; c) 添加指定元素到指定的位置1public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123;&#125; removeRange(int fromIndex, int toIndex) 删除指定区间的元素1protected void removeRange(int fromIndex, int toIndex) &#123;&#125; removeAll(Collection&lt;?&gt; c) 删除指定的集合元素123public boolean removeAll(Collection&lt;?&gt; c) &#123; return batchRemove(c, false); &#125; retainAll(Collection&lt;?&gt; c) 保留指定集合元素123public boolean retainAll(Collection&lt;?&gt; c) &#123; return batchRemove(c, true); &#125; listIterator(int index)和 listIterator() 返回一个迭代器,支持向前和向后遍历123public ListIterator&lt;E&gt; listIterator(int index) &#123;&#125;public ListIterator&lt;E&gt; listIterator() &#123;&#125; iterator() 只能向后遍历1public Iterator&lt;E&gt; iterator() &#123;&#125; subList() 返回部分list1public List&lt;E&gt; subList(int fromIndex, int toIndex) &#123;&#125; http://blog.csdn.net/crave_shy/article/details/17436773 http://www.importnew.com/19233.html https://www.zybuluo.com/pastqing/note/200073 http://www.cnblogs.com/sipher/articles/2429812.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用Hexo在GitHub上搭建个人博客]]></title>
      <url>%2F2016%2F05%2F03%2Fuse-hexo-build-personal-blog-on-github%2F</url>
      <content type="text"><![CDATA[本机环境 系统：Ubuntu 16.04 LTS Hexo:3.2.0 NodeJS:v5.11.0 Git:2.7.4 重要环境 安装nodejs 安装git 注册github 使用github搭建个人博客，详细参考：GitHub pages 安装Hexo1. mkdir hexo #新建hexo目录 2. cd hexo #进入hexo目录 3. npm install -g hexo #如果不成功使用npm install -g hexo --registry=https://registry.npm.taobao.org 4. hexo init #如果还是卡，不成功，请使用npm config set registry &quot;https://registry.npm.taobao.org&quot;（详细请搜索npm代理之类的文章，国内npm被墙，所以很慢，可使用阿里的npm镜像） 5. hexo g #或者hexo generate 6. hexo s #或者hexo server 7. 使用http://localhost:4000查看是否启动成功安装hexo主题此处使用hexo-theme-next主题，详情：hexo-theme-next，如有需要可选择其他的主题。 1. hexo clean 2. git clone https://github.com/iissnan/hexo-theme-next themes/next 启用主题修改hexo目录下的站点配置文件_config.yml，将theme: landscape修改为theme: next 查看主题1.hexo g 2.hexo s #启动服务，输入http://127.0.0.1:4000查看 3.启动成功之后，关于主题配置请查看：[主题配置](http://theme-next.iissnan.com/getting-started.html)生成静态文件hexo generate发布到github 修改站点配置文件_config.yml,找到下面内容：123456789# Deployment## Docs: https:&#x2F;&#x2F;hexo.io&#x2F;docs&#x2F;deployment.htmldeploy:type:修改为：deploy:type: gitrepository: https:&#x2F;&#x2F;github.com&#x2F;你的用户名&#x2F;你的用户名.github.com.git # 这是你自己的仓库地址，注意换成自己的用户名branch: master 执行hexo deploy 查看http://dachengxi.github.com 写博客或添加页面123451. hexo new &quot;postName&quot; #新建文章2. hexo new page &quot;pageName&quot; #新建页面3. hexo generate #生成静态页面至public目录4. hexo server #开启预览访问端口（默认端口4000，&#39;ctrl + c&#39;关闭server）5. hexo deploy #将.deploy目录部署到GitHub 错误解决参考 http://codepub.cn/2015/04/06/Github-Pages-personal-blog-from-Octopress-to-Hexo/ http://www.cnblogs.com/zhcncn/p/4097881.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[数据库索引简介]]></title>
      <url>%2F2015%2F06%2F07%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[数据库索引的定义数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。提高数据库表数据访问速度的数据库对象. 索引简介索引可以避免全表扫描，多数查询可以仅扫描少量索引页及数据页,而不是遍历所有数据页，可以大大加快数据的检索速度，这也是创建索引的最主要的原因。索引还可以用于避免排序操作。通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。 索引分类 聚集索引 非聚集索引 聚集索引 索引键值的逻辑顺序与索引所服务的表中相应行的物理顺序相同。 一个表只能包含一个聚集索引。 聚集索引对经常要搜索范围值的列特别有效。 聚集索引表记录的排列顺序与索引的排列顺序一样，查询速度快，但是对表进行修改速度较慢。 聚集索引 非聚集索引 该索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同。 一个表中可以存在多个非聚集索引。 非聚集索引的顺序和表中记录的顺序不一致。 参考https://zh.wikipedia.org/wiki/数据库索引 http://blog.csdn.net/kennyrose/article/details/7532032 http://www.cnblogs.com/aspnethot/articles/1504082.html http://www.cnblogs.com/morvenhuang/archive/2009/03/30/1425534.html http://blog.csdn.net/pang040328/article/details/4164874 http://www.ituring.com.cn/article/986]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[分库分表简介]]></title>
      <url>%2F2015%2F06%2F03%2F%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[分库分表简介 此部分简介都是参考别人已经有的文章,目前还没在实际中使用分库分表,对此部分知识的理解还不够透彻.以后会添加自己的经验. 基于业务垂直划分 基于数据水平拆分 两者结合 参考http://leibinhui.iteye.com/blog/1949056 http://www.voidcn.com/blog/stubborn_cow/article/p-5046773.html http://my.oschina.net/cmcm/blog/175104 http://www.infoq.com/cn/articles/yupoo-partition-database]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>%2F2014%2F05%2F02%2Fhello-world%2F</url>
      <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[LogCollector中JMX的应用]]></title>
      <url>%2F2010%2F05%2F24%2FLogCollector%E4%B8%ADJMX%E7%9A%84%E5%BA%94%E7%94%A8%2F</url>
      <content type="text"><![CDATA[LogCollector中JMX的使用学习。 // TODO]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[LogCollector中ScheduledExecutorService的应用]]></title>
      <url>%2F2010%2F05%2F21%2FLogCollector%E4%B8%ADScheduledExecutorService%E7%9A%84%E5%BA%94%E7%94%A8%2F</url>
      <content type="text"><![CDATA[LogCollector中ScheduledExecutorService的使用学习。 在定时发送心跳包的场景下可以使用，比如scheduleWithFixedDelay，每隔一定时间就发送一次心跳。 使用方法示例： 1234567891011public class ScheduleWithFixedDelayExample &#123; private static ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool( 1, new NoneDaemonThreadFactory("testFixedDelay") ); public static void main(String[] args) &#123; scheduledExecutorService.scheduleWithFixedDelay(new TestTask1(), 0L, 3, TimeUnit.SECONDS); &#125;&#125; 12345678910111213141516public class TestTask1 implements Runnable &#123; @Override public void run() &#123; System.out.println("任务开始执行时间：" + new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(new Date())); long start = System.currentTimeMillis(); int random = new Random().nextInt(10); try &#123; Thread.sleep(random * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("任务执行花费时间：" + (System.currentTimeMillis() - start)); System.out.println("任务结束执行时间：" + new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(new Date())); &#125;&#125; 123456789101112131415161718192021222324252627282930313233public class NoneDaemonThreadFactory implements ThreadFactory &#123; private final static AtomicInteger poolNumber = new AtomicInteger(1); private final AtomicInteger threadNumber = new AtomicInteger(1); private final ThreadGroup group; private final String threadNamePrefix; public NoneDaemonThreadFactory(String prefix) &#123; SecurityManager securityManager = System.getSecurityManager(); group = securityManager == null ? Thread.currentThread().getThreadGroup() : securityManager.getThreadGroup(); threadNamePrefix = String.format("%s-%d-", prefix, poolNumber.getAndIncrement()); &#125; @Override public Thread newThread(Runnable r) &#123; Thread thread = new Thread( group, r, threadNamePrefix + threadNumber.getAndIncrement(), 0 ); if (thread.getPriority() != Thread.NORM_PRIORITY) &#123; thread.setPriority(Thread.NORM_PRIORITY); &#125; return thread; &#125;&#125; scheduleWithFixedDelay，在一次任务结束后，间隔指定的时间，再继续执行下一次任务，不管一次任务执行多长时间，在这次任务结束后都会暂停指定的时间，接下来再执行下面的任务。就是说我不管，我每次任务完成都必须要休息一定时间。 scheduleAtFixedRate，每个任务都在指定的时间间隔内执行，如果一个任务瞬间执行完，指定的时间间隔还有很多剩余的，下一个任务也不会执行；如果一个任务在指定的时间间隔没有执行完，占用了下个任务的时间，那这个任务执行完后下个任务立马就开始。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[LogCollector设计文档]]></title>
      <url>%2F2010%2F05%2F20%2FLogCollector%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3%2F</url>
      <content type="text"><![CDATA[LogCollector的模块和整体架构。 LogCollector-client，需要应用依赖此库，用来收集JVM等日志信息转发到localAgent上 LogCollector-localAgent，作为Kafka的消息发送端，将接收到的日志发送到server上、监听日志文件收集日志文件发送到Kafka LogCollector-server，处理收到的消息，可进行业务处理和分析，存储到Elasticsearch中 整体架构使用drawio画图，这是源文件：LogCollector整体架构 参考 https://www.jianshu.com/p/8b45af25cbe9 https://www.jianshu.com/p/63d7d4d0e598 https://www.cnblogs.com/wzj4858/p/8252730.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[LogCollector的设计思路]]></title>
      <url>%2F2010%2F05%2F20%2FLogCollector%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%2F</url>
      <content type="text"><![CDATA[大概列一下日志收集系统需要实现的功能。 日志收集方案有很多种解决方案，日志收集工具也比较多，比如Logstash、Filebeat、Flume、Scribe等等。具体的可查看参考文档和网上一系列的文章。 要自己实现一套日志收集的系统，现有的工具可以作为参考，根据实际情况进行开发，下面大概列一下日志收集系统实现需要的东西，做一个简单的日志收集系统。 系统日志收集，应用心跳收集、可实现为一个库，应用程序需要依赖此库 日志收集的代理，需要部署在和应用相同的服务器上，应用日志收集、接收和转发应用发来的心跳和日志 依赖Kafka，日志收集代理会把消息发送到Kafka上 日志收集服务器，作为Kafka的消费者，消费日志消息，并可进行加工处理、转发消息 依赖Elasticsearch，日志收集服务器可将日志存储到Elasticsearch 参考 https://www.jianshu.com/p/8b45af25cbe9 https://www.jianshu.com/p/63d7d4d0e598 https://www.cnblogs.com/wzj4858/p/8252730.html]]></content>
    </entry>

    
  
  
</search>
